{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Grid_SearchCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7mJMiThKvtT"
      },
      "source": [
        "# <font color=\"purple\"><b>Grid Search CV Algorithm for Fully Connected Networks</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUrakNvqKvtU"
      },
      "source": [
        "Using the grid search CV algorithm, the hyperparameters of this model is sought.\n",
        "<li><b> Learning Rate:</b> 0.1, 0.01</li>\n",
        "<li><b> Regularization Penalty:</b>0.01, 0.001, 0.0001</li>\n",
        "<li><b> Batch Size:</b> 64, 128</li>\n",
        "<li><b> Epochs:</b> 50, 100, 150</li>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rFQbEcDKvtV"
      },
      "source": [
        "## <font color=\"blue\">Import Libraries</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nhsKKJZ02AK"
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from itertools import product\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow\n",
        "import json\n",
        "import cv2\n",
        "import io\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "try:\n",
        "    to_unicode = unicode\n",
        "except NameError:\n",
        "    to_unicode = str\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdoFKvR-m04D"
      },
      "source": [
        "!pip install hickle\n",
        "import hickle as hkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqmnAXulmtWm"
      },
      "source": [
        "data = hkl.load(\"data.hkl\")\n",
        "X_train, X_test, Y_train, y_test = data['xtrain'], data['xtest'], data['ytrain'], data['ytest']\n",
        "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4zwcqNAnEoE"
      },
      "source": [
        "from tensorflow.data import Dataset\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D,Input,MaxPooling2D, Dense, Dropout, MaxPool1D, Flatten, AveragePooling1D, BatchNormalization\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW_D-_Dqm5mg"
      },
      "source": [
        "def model_1(weight_decay):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=(32, 32, 1), kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4, activation='softmax', kernel_regularizer=l2(weight_decay)))\n",
        "  return model\n",
        "\n",
        "\n",
        "def model_2(weight_decay):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=(32, 32, 1), kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4, activation='softmax', kernel_regularizer=l2(weight_decay)))\n",
        "  return model\n",
        "\n",
        "\n",
        "def model_3(weight_decay):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=(32, 32, 1),kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(256, kernel_size=(3, 3), activation='relu',kernel_regularizer=l2(weight_decay)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4, activation='softmax',kernel_regularizer=l2(weight_decay)))\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9X1E2wybnZj"
      },
      "source": [
        "<font color=\"blue\"> The algorithm below is that ... </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8U0Vk9t0l3V"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def encoded_label(y_predict):\n",
        "  y_list = [] \n",
        "  for y_hat in y_predict:\n",
        "    y_hat = np.argmax(y_hat)\n",
        "    y_list.append(to_categorical(y_hat))\n",
        "  return y_list\n",
        "\n",
        "\n",
        "def KFold_GridSearchCV(input_dim, X, Y, X_test, y_test, combinations, filename=\"log.csv\", acc_loss_json=\"hist.json\"):\n",
        "    \"\"\"Summary: Grid Search CV for 3 Folds Cross Validation\n",
        "    \"\"\"\n",
        "    res_df = pd.DataFrame(columns=['momentum','learning rate','batch size',\n",
        "                                      'loss1', 'acc1','loss2', 'acc2','loss3', 'acc3', 'widing factor',\n",
        "                                      'prec1', 'prec2', 'prec3', 'recall1', 'recall2', 'recall3'])\n",
        "    generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)\n",
        "    hist_dict_global = {}\n",
        "\n",
        "    for i, combination in enumerate(combinations):\n",
        "        kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
        "        metrics_dict = {}\n",
        "  \n",
        "        for j, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "            X_train, X_val = X[train_index], X[test_index]\n",
        "            y_train, y_val = Y[train_index], Y[test_index]\n",
        "            model = model_1(combination[2])\n",
        "            opt = tensorflow.keras.optimizers.SGD(learning_rate=combination[0])\n",
        "            model.compile(loss='categorical_crossentropy', optimizer=opt, metrics= ['accuracy'])\n",
        "            hist = model.fit(generator.flow(X_train, y_train, batch_size=combination[1]), steps_per_epoch=len(X_train) // combination[1], epochs=combination[3],\n",
        "                                      validation_data=(X_val, y_val),\n",
        "                                      validation_steps=len(X_val) // combination[1],)\n",
        "            loss, acc = model.evaluate(X_test, y_test)\n",
        "            #yhat_classes = encoded_label( model.predict(X_test))\n",
        "            predict =  model.predict(X_test)\n",
        "            yhat_classes = np.argmax(predict, axis=1)\n",
        "            print(yhat_classes)\n",
        "            print(y_test)\n",
        "            cm = confusion_matrix(np.argmax(y_test, axis=1), yhat_classes)\n",
        "            recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "            precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "\n",
        "            recall_avg = np.mean(recall)\n",
        "            precision_avg = np.mean(precision)\n",
        "            metrics_dict[j+1] = {\"loss\": loss, \"acc\": acc, \"epoch_stopped\": combination[3], \"precision_avg\":precision_avg,\n",
        "                                 \"avg_recall\":recall_avg}\n",
        "            graph_loss_acc = {\"id\": i, \"com\":j+1, \"val_acc\":hist.history[\"val_accuracy\"], \"train_acc\":hist.history[\"accuracy\"],\n",
        "                                    \"val_loss\":hist.history[\"val_loss\"], \"train_loss\":hist.history[\"loss\"], \"epoch_stopped\": combination[3], 'learning rate': combination[0],\n",
        "                                    'batch size': combination[1], 'reg_penalty': combination[2]}\n",
        "\n",
        "              # Write JSON file\n",
        "            with io.open(acc_loss_json, 'a+', encoding='utf8') as outfile:\n",
        "                str_ = json.dumps(graph_loss_acc)\n",
        "                outfile.write(to_unicode(str_))\n",
        "        row = {'momentum': combination[4],'learning rate': combination[0],\n",
        "               'batch size': combination[1],\n",
        "               'reg_penalty': combination[2],\n",
        "               'epoch_stopped': metrics_dict[1][\"epoch_stopped\"],\n",
        "               'widing factor' : 1,\n",
        "               'loss1': metrics_dict[1][\"loss\"],\n",
        "               'acc1': metrics_dict[1][\"acc\"],\n",
        "               'loss2': metrics_dict[2][\"loss\"],\n",
        "               'acc2': metrics_dict[2][\"acc\"],\n",
        "               'loss3': metrics_dict[3][\"loss\"],\n",
        "               'acc3': metrics_dict[3][\"acc\"],\n",
        "               'prec1':metrics_dict[1][\"precision_avg\"],\n",
        "               'prec2':metrics_dict[2][\"precision_avg\"],\n",
        "               'prec3':metrics_dict[3][\"precision_avg\"],\n",
        "               'recall1':metrics_dict[1][\"avg_recall\"],\n",
        "               'recall2':metrics_dict[2][\"avg_recall\"],\n",
        "               'recall3':metrics_dict[3][\"avg_recall\"]}\n",
        "        res_df = res_df.append(row , ignore_index=True)\n",
        "        res_df.to_csv(filename, sep=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgO8xJ0Fe93I"
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    learning_rate = [0.1,0.01]\n",
        "    batch_size = [64,128]\n",
        "    reg_penalty = [0,0.01, 0.001, 0.0001]\n",
        "    epochs = [50,100,150]\n",
        "    momentum = [0.9]\n",
        "    in_dim = (32,32,1)\n",
        "    grid_result = \"grid_model_1.csv\"\n",
        "    acc_loss_json = \"history.json\"\n",
        "    # create list of all different parameter combinations\n",
        "    param_grid = dict(learning_rate = learning_rate, batch_size = batch_size, \n",
        "                      reg_penalty = reg_penalty, epochs = epochs, momentum=momentum)\n",
        "    combinations = list(product(*param_grid.values()))\n",
        "    KFold_GridSearchCV(in_dim,X_train,Y_train,X_test, y_test, combinations, grid_result, acc_loss_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVp5lMuhpAMW"
      },
      "source": [
        "data  = pd.read_csv(\"grid_model_1.csv\", sep=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "rru6HHyrsgbl",
        "outputId": "01496643-5865-41a6-85c2-f69242b5912b"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>momentum</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>batch size</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>widing factor</th>\n",
              "      <th>prec1</th>\n",
              "      <th>prec2</th>\n",
              "      <th>prec3</th>\n",
              "      <th>recall1</th>\n",
              "      <th>recall2</th>\n",
              "      <th>recall3</th>\n",
              "      <th>epoch_stopped</th>\n",
              "      <th>reg_penalty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.078664</td>\n",
              "      <td>0.541012</td>\n",
              "      <td>1.087765</td>\n",
              "      <td>0.560209</td>\n",
              "      <td>1.140540</td>\n",
              "      <td>0.495637</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.545625</td>\n",
              "      <td>0.570303</td>\n",
              "      <td>0.540447</td>\n",
              "      <td>0.549296</td>\n",
              "      <td>0.561227</td>\n",
              "      <td>0.506039</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.090459</td>\n",
              "      <td>0.544503</td>\n",
              "      <td>1.052103</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>0.991915</td>\n",
              "      <td>0.586387</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.567745</td>\n",
              "      <td>0.581882</td>\n",
              "      <td>0.587054</td>\n",
              "      <td>0.549632</td>\n",
              "      <td>0.571559</td>\n",
              "      <td>0.584749</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.203270</td>\n",
              "      <td>0.549738</td>\n",
              "      <td>1.024475</td>\n",
              "      <td>0.607330</td>\n",
              "      <td>1.099551</td>\n",
              "      <td>0.542757</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.597314</td>\n",
              "      <td>0.629707</td>\n",
              "      <td>0.583353</td>\n",
              "      <td>0.558664</td>\n",
              "      <td>0.612029</td>\n",
              "      <td>0.532126</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.331875</td>\n",
              "      <td>0.450262</td>\n",
              "      <td>1.357389</td>\n",
              "      <td>0.425829</td>\n",
              "      <td>1.136434</td>\n",
              "      <td>0.542757</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.520104</td>\n",
              "      <td>0.556441</td>\n",
              "      <td>0.541896</td>\n",
              "      <td>0.467984</td>\n",
              "      <td>0.441258</td>\n",
              "      <td>0.549730</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.286225</td>\n",
              "      <td>0.490401</td>\n",
              "      <td>1.218342</td>\n",
              "      <td>0.539267</td>\n",
              "      <td>1.207052</td>\n",
              "      <td>0.537522</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.552838</td>\n",
              "      <td>0.569478</td>\n",
              "      <td>0.586226</td>\n",
              "      <td>0.494587</td>\n",
              "      <td>0.541650</td>\n",
              "      <td>0.547532</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   momentum  learning rate  batch size  ...   recall3  epoch_stopped  reg_penalty\n",
              "0       0.9            0.1        64.0  ...  0.506039           50.0         0.00\n",
              "1       0.9            0.1        64.0  ...  0.584749          100.0         0.00\n",
              "2       0.9            0.1        64.0  ...  0.532126          150.0         0.00\n",
              "3       0.9            0.1        64.0  ...  0.549730           50.0         0.01\n",
              "4       0.9            0.1        64.0  ...  0.547532          100.0         0.01\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeVPJJQQt36n"
      },
      "source": [
        "data[\"loss_mean\"] = (data[\"loss1\"]+data[\"loss2\"]+data[\"loss3\"])/3\n",
        "data[\"acc_mean\"] = (data[\"acc1\"]+data[\"acc2\"]+data[\"acc3\"])/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPIKRbPMuUOr"
      },
      "source": [
        "data['epoch'] = data['epoch_stopped']\n",
        "data['weight_decay'] = data['reg_penalty']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_2tMeO6x9Uq"
      },
      "source": [
        "data['recall_mean'] = (data['recall1']+data['recall2']+data['recall3'])/3\n",
        "data['prec_mean'] = (data['prec1']+data['prec2']+data['prec3'])/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA0eRctYuWl-"
      },
      "source": [
        "column_list = [\"momentum\", \"learning rate\", \"epoch\",\"batch size\",\"weight_decay\",\"loss_mean\", \"acc_mean\",\"recall_mean\", \"prec_mean\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "McsMaiLZuZaa",
        "outputId": "d04090a8-b295-45ad-d64f-e5965741cd80"
      },
      "source": [
        "data.sort_values(axis=0, by=\"loss_mean\", ascending=True)[column_list].head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>momentum</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>epoch</th>\n",
              "      <th>batch size</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>loss_mean</th>\n",
              "      <th>acc_mean</th>\n",
              "      <th>recall_mean</th>\n",
              "      <th>prec_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.01</td>\n",
              "      <td>50.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.012071</td>\n",
              "      <td>0.612565</td>\n",
              "      <td>0.614360</td>\n",
              "      <td>0.615845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.026681</td>\n",
              "      <td>0.614311</td>\n",
              "      <td>0.612435</td>\n",
              "      <td>0.619908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.10</td>\n",
              "      <td>150.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1.027309</td>\n",
              "      <td>0.603258</td>\n",
              "      <td>0.601262</td>\n",
              "      <td>0.606730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    momentum  learning rate  epoch  ...  acc_mean  recall_mean  prec_mean\n",
              "24       0.9           0.01   50.0  ...  0.612565     0.614360   0.615845\n",
              "34       0.9           0.01  100.0  ...  0.614311     0.612435   0.619908\n",
              "8        0.9           0.10  150.0  ...  0.603258     0.601262   0.606730\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCgRAh43udBu"
      },
      "source": [
        "data[\"loss_na\"] = data.loc[:,[\"loss1\",\"loss2\", \"loss3\"]].isnull().sum(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "-ptzEmSHudkM",
        "outputId": "72a8ca57-603a-451f-8702-962b4be4f91a"
      },
      "source": [
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>momentum</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>batch size</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>widing factor</th>\n",
              "      <th>prec1</th>\n",
              "      <th>prec2</th>\n",
              "      <th>prec3</th>\n",
              "      <th>recall1</th>\n",
              "      <th>recall2</th>\n",
              "      <th>recall3</th>\n",
              "      <th>epoch_stopped</th>\n",
              "      <th>reg_penalty</th>\n",
              "      <th>loss_mean</th>\n",
              "      <th>acc_mean</th>\n",
              "      <th>epoch</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>loss_na</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.078664</td>\n",
              "      <td>0.541012</td>\n",
              "      <td>1.087765</td>\n",
              "      <td>0.560209</td>\n",
              "      <td>1.140540</td>\n",
              "      <td>0.495637</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.545625</td>\n",
              "      <td>0.570303</td>\n",
              "      <td>0.540447</td>\n",
              "      <td>0.549296</td>\n",
              "      <td>0.561227</td>\n",
              "      <td>0.506039</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.102323</td>\n",
              "      <td>0.532286</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.090459</td>\n",
              "      <td>0.544503</td>\n",
              "      <td>1.052103</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>0.991915</td>\n",
              "      <td>0.586387</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.567745</td>\n",
              "      <td>0.581882</td>\n",
              "      <td>0.587054</td>\n",
              "      <td>0.549632</td>\n",
              "      <td>0.571559</td>\n",
              "      <td>0.584749</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.044826</td>\n",
              "      <td>0.566609</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.203270</td>\n",
              "      <td>0.549738</td>\n",
              "      <td>1.024475</td>\n",
              "      <td>0.607330</td>\n",
              "      <td>1.099551</td>\n",
              "      <td>0.542757</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.597314</td>\n",
              "      <td>0.629707</td>\n",
              "      <td>0.583353</td>\n",
              "      <td>0.558664</td>\n",
              "      <td>0.612029</td>\n",
              "      <td>0.532126</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.109098</td>\n",
              "      <td>0.566608</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   momentum  learning rate  batch size  ...  epoch  weight_decay  loss_na\n",
              "0       0.9            0.1        64.0  ...   50.0           0.0        0\n",
              "1       0.9            0.1        64.0  ...  100.0           0.0        0\n",
              "2       0.9            0.1        64.0  ...  150.0           0.0        0\n",
              "\n",
              "[3 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBBXsz_rzQl-"
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShIJn_53mawD"
      },
      "source": [
        "kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
        "result = []\n",
        "for j, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
        "  x_train, x_val = X_train[train_index], X_train[test_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[test_index]\n",
        "  model = model_2(0)\n",
        "  opt = tensorflow.keras.optimizers.SGD(learning_rate=0.01)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics= ['accuracy'])\n",
        "  hist = model.fit(generator.flow(x_train, y_train, batch_size=64), steps_per_epoch=len(x_train) //64 , epochs=50,\n",
        "                   validation_data=(x_val, y_val),\n",
        "                  validation_steps=len(x_val) //64 ,)\n",
        "\n",
        "  test = model.evaluate(X_test, y_test)\n",
        "  result.append(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj6hnUVRzjX-",
        "outputId": "41b04e1e-d756-437a-afff-ca9f3fcff46c"
      },
      "source": [
        "mean_acc = (result[0][1]+result[1][1]+result[2][1])/3;mean_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6305991808573405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_AccCit1De3",
        "outputId": "a6299f58-4389-4f39-f318-e2371e94f4e5"
      },
      "source": [
        "mean_loss = (result[0][0]+result[1][0]+result[2][0])/3;mean_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9891296029090881"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gdDigrPzYM5"
      },
      "source": [
        "kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
        "result_2 = []\n",
        "for j, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
        "  x_train, x_val = X_train[train_index], X_train[test_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[test_index]\n",
        "  model = model_3(0.0001)\n",
        "  opt = tensorflow.keras.optimizers.SGD(learning_rate=0.01)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics= ['accuracy'])\n",
        "  hist = model.fit(generator.flow(x_train, y_train, batch_size=64), steps_per_epoch=len(x_train) //64 , epochs=100,\n",
        "                   validation_data=(x_val, y_val),\n",
        "                  validation_steps=len(x_val) //64 ,)\n",
        "\n",
        "  test = model.evaluate(X_test, y_test)\n",
        "  result_2.append(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYVQINoA2F4l",
        "outputId": "ac29f686-9b48-4193-bf01-4a17ab589d91"
      },
      "source": [
        "mean_acc = (result_2[0][1]+result_2[1][1]+result_2[2][1])/3;mean_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7108784119288126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guueg5Wo2IE8",
        "outputId": "986e139c-1224-43a7-b8fc-59d57e72d3a8"
      },
      "source": [
        "mean_loss = (result_2[0][0]+result_2[1][0]+result_2[2][0])/3;mean_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9208946625391642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luS42Hil0H5R",
        "outputId": "91c28154-8014-42a9-fbf2-8935cb4c521a"
      },
      "source": [
        "mean_acc = (result_2[0][1]+result_2[1][1]+result_2[2][1])/3;mean_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6783013343811035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Zg3pI61W_J",
        "outputId": "fe5f7861-58e9-47f6-8134-8872e494e268"
      },
      "source": [
        "mean_loss = (result_2[0][0]+result_2[1][0]+result_2[2][0])/3;mean_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8747362097104391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWx9Jej11f_V",
        "outputId": "a5b72e6c-de64-4bee-da66-d48a5e6e1870"
      },
      "source": [
        "model = model_1(0)\n",
        "opt = tensorflow.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics= ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_162\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_342 (Conv2D)          (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_343 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_183 (MaxPoolin (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_183 (Bat (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "flatten_162 (Flatten)        (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 4)                 50180     \n",
            "=================================================================\n",
            "Total params: 69,252\n",
            "Trainable params: 69,124\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8mg2Bup1lPJ",
        "outputId": "6a2348f9-f6d8-47d3-a5d7-9169d3906d76"
      },
      "source": [
        "model = model_2(0)\n",
        "opt = tensorflow.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics= ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_154\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_320 (Conv2D)          (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_321 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_166 (MaxPoolin (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_166 (Bat (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_322 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_167 (MaxPoolin (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_167 (Bat (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten_154 (Flatten)        (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 4)                 18436     \n",
            "=================================================================\n",
            "Total params: 111,876\n",
            "Trainable params: 111,492\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZImk4zB1mxk",
        "outputId": "805f844e-1312-423a-b309-35944f11a210"
      },
      "source": [
        "model = model_3(0)\n",
        "opt = tensorflow.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics= ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_155\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_323 (Conv2D)          (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_324 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_168 (MaxPoolin (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_168 (Bat (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_325 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_169 (MaxPoolin (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_169 (Bat (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_326 (Conv2D)          (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_170 (MaxPoolin (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_170 (Bat (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_155 (Flatten)        (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 393,732\n",
            "Trainable params: 392,836\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}