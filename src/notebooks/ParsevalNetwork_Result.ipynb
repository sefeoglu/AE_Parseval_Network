{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ParsevalNetwork_Result.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgKND0sckj9i"
      },
      "source": [
        "# <font color=\"purple\">Adversarial Training of Residual Network</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPX5KF4nkj9k"
      },
      "source": [
        "Definition of WideResNet and Architecture:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W07XrKzjkj9l"
      },
      "source": [
        "##  <center>The Result of Residual Network </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6LWZY55kj9m"
      },
      "source": [
        "***Road Map***\n",
        "* Data Preprocessing\n",
        "* Model Cross Validation Results\n",
        "* Evaluate the GridSearchCV Results\n",
        "* Model Training and Learning Curves\n",
        "* Model Adversarial Training Approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkb49Wg6kj9n"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3etlaVjipGZ"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1,'/home/sefika/AE_Parseval_Network/src/cleverhans/future/tf2/attacks')\n",
        "import cleverhans\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlx9oRcwjDbJ"
      },
      "source": [
        "!pip install -qq -e git+http://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "import sys\n",
        "sys.path.append('/content/src/cleverhans')\n",
        "import cleverhans"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIEl6l0kkj9o",
        "outputId": "3ab24e3c-f43c-49f8-d5c9-d57d0cdf0cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import  KFold\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "from parsevalnet import ParsevalNetwork\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "# utility functions\n",
        "from preprocessing import preprocessing_data\n",
        "# Define configuration parameters\n",
        "from _utility import lrate\n",
        "from training import train\n",
        "from adversarial_training import  AdversarialTraining"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tensorflow Version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhvWP7D-kj9v"
      },
      "source": [
        "## <font color=\"green\"> Data Preprocessing </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Tkt8tPkj9w"
      },
      "source": [
        "* Read Data from File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbL58svXkj9x"
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS5UxTh4kj91"
      },
      "source": [
        "* Call data preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lggXy4Xckj96"
      },
      "source": [
        "X, y = preprocessing_data(data)\n",
        "X_train, X_test, Y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "x_train, X_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMx1UO52ozNP"
      },
      "source": [
        "## <font color=\"green\"> Utilize Functions </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN9n1xLKpNAk"
      },
      "source": [
        "* Flipping the image using data augmentation technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MywglnvLo3b-"
      },
      "source": [
        "generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evs0Sbh8i-pZ"
      },
      "source": [
        "### <font color = \"green\">Some Parameters Regarding Adversarial Examples</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIgl4BDQjPFL"
      },
      "source": [
        "# predefined epsilon values\n",
        "epsilon_list = [0.003,0.005,0.01,0.02]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzFqxjQOkj9-"
      },
      "source": [
        "## <font color=\"purple\"> 1.) Baseline of the Model</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKaBoHadkj-M"
      },
      "source": [
        "EPOCHS = 50\n",
        "BS = 64\n",
        "init = (32, 32,1)\n",
        "sgd = SGD(lr=0.1, momentum=0.9)\n",
        "parameter = {'epochs': EPOCHS, 'batch_size': BS, 'optimizer': sgd}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l_vYwIqtwdf"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "callbacks_list = [lrate, es]\n",
        "parseval = ParsevalNetwork(init,0.0001, 0.9, nb_classes=4, N=2, k=1, dropout=0.0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE0ESEsu0kyV"
      },
      "source": [
        "result_df = train(parseval, X_train, Y_train, X_test, y_test, EPOCHS, BS, sgd, generator, callbacks_list, epsilon_list, model_name=\"Parseval\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwWhlkgG1PA8"
      },
      "source": [
        "result_df[\"clean_mean\"] = np.sum(result_df['acc_clean'])/10.0\n",
        "result_df[\"0.003_mean\"] = np.sum(result_df['0.003_acc'])/10.0\n",
        "result_df[\"0.005_mean\"] = np.sum(result_df['0.005_acc'])/10.0\n",
        "result_df[\"0.02_mean\"] = np.sum(result_df['0.02_acc'])/10.0\n",
        "result_df[\"0.01_mean\"] = np.sum(result_df['0.01_acc'])/10.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mR0LQQp0ZAu",
        "outputId": "e529df4b-4a96-4492-9948-3d90e47eb70c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "result_df.head(1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>0.003_loss</th>\n",
              "      <th>0.003_acc</th>\n",
              "      <th>0.005_loss</th>\n",
              "      <th>0.005_acc</th>\n",
              "      <th>0.02_acc</th>\n",
              "      <th>0.02_loss</th>\n",
              "      <th>0.01_acc</th>\n",
              "      <th>0.01_clean</th>\n",
              "      <th>0.01_loss</th>\n",
              "      <th>clean_mean</th>\n",
              "      <th>0.003_mean</th>\n",
              "      <th>0.005_mean</th>\n",
              "      <th>0.02_mean</th>\n",
              "      <th>0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.849743</td>\n",
              "      <td>0.684119</td>\n",
              "      <td>0.966569</td>\n",
              "      <td>0.647469</td>\n",
              "      <td>1.049518</td>\n",
              "      <td>0.609075</td>\n",
              "      <td>0.525305</td>\n",
              "      <td>1.269353</td>\n",
              "      <td>0.406632</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.406632</td>\n",
              "      <td>0.703141</td>\n",
              "      <td>0.657941</td>\n",
              "      <td>0.626003</td>\n",
              "      <td>0.555323</td>\n",
              "      <td>0.424607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  0.003_loss  ...  0.005_mean  0.02_mean  0.01_mean\n",
              "0    0.849743   0.684119    0.966569  ...    0.626003   0.555323   0.424607\n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3mH9_WMkj-a"
      },
      "source": [
        "## <font color=\"purple\">2.) Adversarial Training on Baseline Model</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAoBGHiWTnc9",
        "outputId": "9a14babf-4d18-473f-cd24-5d32b2a9fea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "adversarial_training =  AdversarialTraining(parameter)\n",
        "result_adv_df = adversarial_training.train(parseval, X_train, Y_train, X_test, y_test, epsilon_list, callbacks_list,model_name=\"parseval\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6590 - acc: 0.7665 - val_loss: 0.7585 - val_acc: 0.7184\n",
            "Epoch 48/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6597 - acc: 0.7674 - val_loss: 0.7659 - val_acc: 0.7223\n",
            "Epoch 49/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6706 - acc: 0.7624 - val_loss: 0.7801 - val_acc: 0.7204\n",
            "Epoch 50/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6671 - acc: 0.7613 - val_loss: 0.7734 - val_acc: 0.7126\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8118 - acc: 0.7173\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9315 - acc: 0.6876\n",
            "epsilon: 0.003 and test evaluation : 0.931526243686676, 0.687609076499939\n",
            "SNR: 50.23597717285156\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0167 - acc: 0.6597\n",
            "epsilon: 0.005 and test evaluation : 1.0167371034622192, 0.6596858501434326\n",
            "SNR: 45.798683166503906\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.2370 - acc: 0.5759\n",
            "epsilon: 0.01 and test evaluation : 1.2369736433029175, 0.5759162306785583\n",
            "SNR: 39.77808713912964\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6689 - acc: 0.4328\n",
            "epsilon: 0.02 and test evaluation : 1.6688659191131592, 0.4328097701072693\n",
            "SNR: 33.75748634338379\n",
            "Parseval  Network-16-1 created.\n",
            "Finished compiling\n",
            "[0.003, 0.005, 0.01, 0.02]\n",
            "Epoch 1/50\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 1.3686 - acc: 0.3462 - val_loss: 1.2783 - val_acc: 0.3961\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.3117 - acc: 0.3772 - val_loss: 1.2726 - val_acc: 0.3903\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.3081 - acc: 0.3655 - val_loss: 1.2499 - val_acc: 0.4039\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 1.2739 - acc: 0.4247 - val_loss: 1.2870 - val_acc: 0.4272\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.2120 - acc: 0.4842 - val_loss: 1.0974 - val_acc: 0.5515\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1690 - acc: 0.5133 - val_loss: 1.0818 - val_acc: 0.5709\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1309 - acc: 0.5433 - val_loss: 1.0670 - val_acc: 0.5728\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.0927 - acc: 0.5543 - val_loss: 1.0284 - val_acc: 0.5767\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0702 - acc: 0.5716 - val_loss: 1.0153 - val_acc: 0.5825\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0684 - acc: 0.5615 - val_loss: 1.0609 - val_acc: 0.5515\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.9956 - acc: 0.6068 - val_loss: 0.9718 - val_acc: 0.6058\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.9329 - acc: 0.6363 - val_loss: 0.9306 - val_acc: 0.6194\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.9088 - acc: 0.6479 - val_loss: 0.9088 - val_acc: 0.6660\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8830 - acc: 0.6525 - val_loss: 0.8789 - val_acc: 0.6621\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8618 - acc: 0.6689 - val_loss: 0.8619 - val_acc: 0.6641\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8457 - acc: 0.6768 - val_loss: 0.8617 - val_acc: 0.6796\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8364 - acc: 0.6836 - val_loss: 0.8675 - val_acc: 0.6699\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8173 - acc: 0.6930 - val_loss: 0.8809 - val_acc: 0.6660\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8049 - acc: 0.6950 - val_loss: 0.8392 - val_acc: 0.6835\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7952 - acc: 0.7037 - val_loss: 0.8577 - val_acc: 0.6699\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7986 - acc: 0.6945 - val_loss: 0.8391 - val_acc: 0.6874\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7385 - acc: 0.7254 - val_loss: 0.8165 - val_acc: 0.7010\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7411 - acc: 0.7313 - val_loss: 0.8642 - val_acc: 0.6835\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7264 - acc: 0.7324 - val_loss: 0.8301 - val_acc: 0.6816\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7231 - acc: 0.7372 - val_loss: 0.8072 - val_acc: 0.7049\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7246 - acc: 0.7361 - val_loss: 0.8233 - val_acc: 0.7010\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7213 - acc: 0.7370 - val_loss: 0.8061 - val_acc: 0.7068\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7092 - acc: 0.7435 - val_loss: 0.8068 - val_acc: 0.6951\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7157 - acc: 0.7414 - val_loss: 0.8026 - val_acc: 0.7029\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7077 - acc: 0.7392 - val_loss: 0.8046 - val_acc: 0.7146\n",
            "Epoch 31/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6903 - acc: 0.7497 - val_loss: 0.8182 - val_acc: 0.7029\n",
            "Epoch 32/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7002 - acc: 0.7444 - val_loss: 0.7929 - val_acc: 0.6971\n",
            "Epoch 33/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6994 - acc: 0.7387 - val_loss: 0.8132 - val_acc: 0.7068\n",
            "Epoch 34/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7075 - acc: 0.7420 - val_loss: 0.8014 - val_acc: 0.7029\n",
            "Epoch 35/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7032 - acc: 0.7414 - val_loss: 0.7966 - val_acc: 0.7029\n",
            "Epoch 36/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7137 - acc: 0.7407 - val_loss: 0.8073 - val_acc: 0.7068\n",
            "Epoch 37/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7055 - acc: 0.7453 - val_loss: 0.7992 - val_acc: 0.7029\n",
            "Epoch 38/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7055 - acc: 0.7376 - val_loss: 0.8065 - val_acc: 0.6971\n",
            "Epoch 39/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7081 - acc: 0.7365 - val_loss: 0.7985 - val_acc: 0.7010\n",
            "Epoch 40/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7008 - acc: 0.7466 - val_loss: 0.8082 - val_acc: 0.7087\n",
            "Epoch 41/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7057 - acc: 0.7403 - val_loss: 0.7880 - val_acc: 0.7126\n",
            "Epoch 42/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7039 - acc: 0.7433 - val_loss: 0.8071 - val_acc: 0.6913\n",
            "Epoch 43/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6981 - acc: 0.7501 - val_loss: 0.7889 - val_acc: 0.7223\n",
            "Epoch 44/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7074 - acc: 0.7435 - val_loss: 0.7994 - val_acc: 0.6932\n",
            "Epoch 45/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7054 - acc: 0.7462 - val_loss: 0.7961 - val_acc: 0.7049\n",
            "Epoch 46/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7030 - acc: 0.7455 - val_loss: 0.8336 - val_acc: 0.7049\n",
            "Epoch 47/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7010 - acc: 0.7512 - val_loss: 0.8338 - val_acc: 0.6913\n",
            "Epoch 48/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7020 - acc: 0.7490 - val_loss: 0.8060 - val_acc: 0.7029\n",
            "Epoch 49/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7065 - acc: 0.7464 - val_loss: 0.7939 - val_acc: 0.7010\n",
            "Epoch 50/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7054 - acc: 0.7497 - val_loss: 0.8025 - val_acc: 0.6932\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8057 - acc: 0.7033\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9161 - acc: 0.6562\n",
            "epsilon: 0.003 and test evaluation : 0.9160985946655273, 0.6561954617500305\n",
            "SNR: 50.23597717285156\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9921 - acc: 0.6265\n",
            "epsilon: 0.005 and test evaluation : 0.9921091794967651, 0.6265270709991455\n",
            "SNR: 45.798683166503906\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1878 - acc: 0.5445\n",
            "epsilon: 0.01 and test evaluation : 1.1878167390823364, 0.5445026159286499\n",
            "SNR: 39.77808713912964\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5839 - acc: 0.4346\n",
            "epsilon: 0.02 and test evaluation : 1.5839078426361084, 0.43455496430397034\n",
            "SNR: 33.75748634338379\n",
            "Parseval  Network-16-1 created.\n",
            "Finished compiling\n",
            "[0.003, 0.005, 0.01, 0.02]\n",
            "Epoch 1/50\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 1.3696 - acc: 0.3435 - val_loss: 1.3089 - val_acc: 0.3709\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.3098 - acc: 0.3761 - val_loss: 1.3818 - val_acc: 0.3204\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.2899 - acc: 0.3895 - val_loss: 1.2972 - val_acc: 0.3883\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.2823 - acc: 0.3980 - val_loss: 1.4221 - val_acc: 0.3883\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.2370 - acc: 0.4628 - val_loss: 1.1941 - val_acc: 0.5204\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1901 - acc: 0.4980 - val_loss: 1.1909 - val_acc: 0.4990\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1453 - acc: 0.5258 - val_loss: 1.1299 - val_acc: 0.5456\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1163 - acc: 0.5374 - val_loss: 1.1070 - val_acc: 0.5670\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0559 - acc: 0.5733 - val_loss: 1.0281 - val_acc: 0.5922\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0059 - acc: 0.6059 - val_loss: 1.0306 - val_acc: 0.6000\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.9633 - acc: 0.6166 - val_loss: 0.9289 - val_acc: 0.6369\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.8771 - acc: 0.6617 - val_loss: 0.8775 - val_acc: 0.6738\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8469 - acc: 0.6768 - val_loss: 0.8611 - val_acc: 0.6660\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8286 - acc: 0.6882 - val_loss: 0.8178 - val_acc: 0.6913\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7964 - acc: 0.7013 - val_loss: 0.8486 - val_acc: 0.6874\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8052 - acc: 0.6963 - val_loss: 0.8379 - val_acc: 0.6835\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7946 - acc: 0.6989 - val_loss: 0.8106 - val_acc: 0.6816\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7768 - acc: 0.7173 - val_loss: 0.8002 - val_acc: 0.7146\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7733 - acc: 0.7098 - val_loss: 0.7957 - val_acc: 0.7165\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7680 - acc: 0.7147 - val_loss: 0.7935 - val_acc: 0.7243\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7649 - acc: 0.7225 - val_loss: 0.7761 - val_acc: 0.7301\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7272 - acc: 0.7291 - val_loss: 0.7582 - val_acc: 0.7379\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7120 - acc: 0.7405 - val_loss: 0.7466 - val_acc: 0.7379\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7027 - acc: 0.7372 - val_loss: 0.7372 - val_acc: 0.7340\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7003 - acc: 0.7492 - val_loss: 0.7629 - val_acc: 0.7204\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7036 - acc: 0.7420 - val_loss: 0.7329 - val_acc: 0.7379\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7018 - acc: 0.7460 - val_loss: 0.7201 - val_acc: 0.7476\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6879 - acc: 0.7586 - val_loss: 0.7214 - val_acc: 0.7553\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6964 - acc: 0.7457 - val_loss: 0.7299 - val_acc: 0.7437\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6892 - acc: 0.7451 - val_loss: 0.7241 - val_acc: 0.7340\n",
            "Epoch 31/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6792 - acc: 0.7554 - val_loss: 0.7170 - val_acc: 0.7301\n",
            "Epoch 32/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6827 - acc: 0.7501 - val_loss: 0.7159 - val_acc: 0.7437\n",
            "Epoch 33/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6757 - acc: 0.7540 - val_loss: 0.7373 - val_acc: 0.7437\n",
            "Epoch 34/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6807 - acc: 0.7508 - val_loss: 0.7231 - val_acc: 0.7495\n",
            "Epoch 35/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6764 - acc: 0.7551 - val_loss: 0.7246 - val_acc: 0.7456\n",
            "Epoch 36/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6779 - acc: 0.7543 - val_loss: 0.7162 - val_acc: 0.7553\n",
            "Epoch 37/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6788 - acc: 0.7532 - val_loss: 0.7088 - val_acc: 0.7689\n",
            "Epoch 38/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6878 - acc: 0.7490 - val_loss: 0.7261 - val_acc: 0.7398\n",
            "Epoch 39/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6788 - acc: 0.7565 - val_loss: 0.7126 - val_acc: 0.7476\n",
            "Epoch 40/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6812 - acc: 0.7578 - val_loss: 0.7114 - val_acc: 0.7573\n",
            "Epoch 41/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6701 - acc: 0.7582 - val_loss: 0.7116 - val_acc: 0.7456\n",
            "Epoch 42/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6876 - acc: 0.7512 - val_loss: 0.7115 - val_acc: 0.7515\n",
            "Epoch 43/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6840 - acc: 0.7527 - val_loss: 0.7144 - val_acc: 0.7379\n",
            "Epoch 44/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6863 - acc: 0.7536 - val_loss: 0.7167 - val_acc: 0.7476\n",
            "Epoch 45/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6839 - acc: 0.7554 - val_loss: 0.7317 - val_acc: 0.7437\n",
            "Epoch 46/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6810 - acc: 0.7540 - val_loss: 0.7256 - val_acc: 0.7534\n",
            "Epoch 47/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6768 - acc: 0.7540 - val_loss: 0.7219 - val_acc: 0.7495\n",
            "Epoch 48/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6840 - acc: 0.7501 - val_loss: 0.7154 - val_acc: 0.7476\n",
            "Epoch 49/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6815 - acc: 0.7600 - val_loss: 0.7351 - val_acc: 0.7456\n",
            "Epoch 50/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6752 - acc: 0.7600 - val_loss: 0.7199 - val_acc: 0.7476\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8592 - acc: 0.6824\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9723 - acc: 0.6492\n",
            "epsilon: 0.003 and test evaluation : 0.9722734093666077, 0.6492146849632263\n",
            "SNR: 50.23597717285156\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0525 - acc: 0.6195\n",
            "epsilon: 0.005 and test evaluation : 1.0525110960006714, 0.6195462346076965\n",
            "SNR: 45.798683166503906\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2626 - acc: 0.5462\n",
            "epsilon: 0.01 and test evaluation : 1.262573003768921, 0.5462478399276733\n",
            "SNR: 39.77808713912964\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6840 - acc: 0.4223\n",
            "epsilon: 0.02 and test evaluation : 1.6839520931243896, 0.4223385751247406\n",
            "SNR: 33.75748634338379\n",
            "Parseval  Network-16-1 created.\n",
            "Finished compiling\n",
            "[0.003, 0.005, 0.01, 0.02]\n",
            "Epoch 1/50\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 1.3435 - acc: 0.3571 - val_loss: 1.3072 - val_acc: 0.3922\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.2990 - acc: 0.3821 - val_loss: 1.3029 - val_acc: 0.3864\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.2843 - acc: 0.4142 - val_loss: 1.2589 - val_acc: 0.4078\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.2443 - acc: 0.4418 - val_loss: 1.2400 - val_acc: 0.5029\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.1884 - acc: 0.5044 - val_loss: 1.2329 - val_acc: 0.4544\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1567 - acc: 0.5116 - val_loss: 1.0917 - val_acc: 0.5709\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1461 - acc: 0.5212 - val_loss: 1.1071 - val_acc: 0.5340\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0967 - acc: 0.5508 - val_loss: 1.1130 - val_acc: 0.5612\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0651 - acc: 0.5626 - val_loss: 1.0168 - val_acc: 0.6117\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0053 - acc: 0.5976 - val_loss: 0.9993 - val_acc: 0.6194\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.9959 - acc: 0.5963 - val_loss: 0.8979 - val_acc: 0.6660\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8882 - acc: 0.6575 - val_loss: 0.8306 - val_acc: 0.7010\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8479 - acc: 0.6807 - val_loss: 0.8119 - val_acc: 0.6893\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8119 - acc: 0.6908 - val_loss: 0.7893 - val_acc: 0.7049\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7999 - acc: 0.7031 - val_loss: 0.7798 - val_acc: 0.6990\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7815 - acc: 0.7131 - val_loss: 0.7545 - val_acc: 0.7320\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7669 - acc: 0.7171 - val_loss: 0.7394 - val_acc: 0.7262\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7591 - acc: 0.7153 - val_loss: 0.7488 - val_acc: 0.7282\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7404 - acc: 0.7252 - val_loss: 0.7711 - val_acc: 0.7262\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7388 - acc: 0.7256 - val_loss: 0.7489 - val_acc: 0.7223\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7405 - acc: 0.7223 - val_loss: 0.7326 - val_acc: 0.7223\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6863 - acc: 0.7508 - val_loss: 0.7024 - val_acc: 0.7437\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6740 - acc: 0.7600 - val_loss: 0.7141 - val_acc: 0.7340\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6663 - acc: 0.7613 - val_loss: 0.7032 - val_acc: 0.7476\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6730 - acc: 0.7637 - val_loss: 0.7018 - val_acc: 0.7262\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6529 - acc: 0.7637 - val_loss: 0.7110 - val_acc: 0.7320\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6658 - acc: 0.7600 - val_loss: 0.7019 - val_acc: 0.7340\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6645 - acc: 0.7602 - val_loss: 0.7131 - val_acc: 0.7320\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6703 - acc: 0.7556 - val_loss: 0.7097 - val_acc: 0.7379\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6569 - acc: 0.7648 - val_loss: 0.7063 - val_acc: 0.7495\n",
            "Epoch 31/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6514 - acc: 0.7650 - val_loss: 0.7151 - val_acc: 0.7398\n",
            "Epoch 32/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6443 - acc: 0.7683 - val_loss: 0.7081 - val_acc: 0.7495\n",
            "Epoch 33/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6508 - acc: 0.7685 - val_loss: 0.6996 - val_acc: 0.7476\n",
            "Epoch 34/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6441 - acc: 0.7694 - val_loss: 0.7519 - val_acc: 0.7204\n",
            "Epoch 35/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6451 - acc: 0.7742 - val_loss: 0.7042 - val_acc: 0.7476\n",
            "Epoch 36/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6480 - acc: 0.7696 - val_loss: 0.6942 - val_acc: 0.7573\n",
            "Epoch 37/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6540 - acc: 0.7641 - val_loss: 0.6924 - val_acc: 0.7456\n",
            "Epoch 38/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6504 - acc: 0.7724 - val_loss: 0.6977 - val_acc: 0.7456\n",
            "Epoch 39/50\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.6508 - acc: 0.7626 - val_loss: 0.6944 - val_acc: 0.7456\n",
            "Epoch 40/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6519 - acc: 0.7722 - val_loss: 0.7250 - val_acc: 0.7340\n",
            "Epoch 41/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6419 - acc: 0.7702 - val_loss: 0.7006 - val_acc: 0.7573\n",
            "Epoch 42/50\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.6529 - acc: 0.7670 - val_loss: 0.6926 - val_acc: 0.7515\n",
            "Epoch 43/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6510 - acc: 0.7652 - val_loss: 0.7136 - val_acc: 0.7437\n",
            "Epoch 44/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6489 - acc: 0.7720 - val_loss: 0.7294 - val_acc: 0.7340\n",
            "Epoch 45/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6434 - acc: 0.7683 - val_loss: 0.7046 - val_acc: 0.7553\n",
            "Epoch 46/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6482 - acc: 0.7709 - val_loss: 0.7304 - val_acc: 0.7359\n",
            "Epoch 47/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6529 - acc: 0.7628 - val_loss: 0.6981 - val_acc: 0.7437\n",
            "Epoch 48/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6578 - acc: 0.7646 - val_loss: 0.6970 - val_acc: 0.7592\n",
            "Epoch 49/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6439 - acc: 0.7621 - val_loss: 0.7100 - val_acc: 0.7456\n",
            "Epoch 50/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6513 - acc: 0.7737 - val_loss: 0.7309 - val_acc: 0.7223\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8379 - acc: 0.7120\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9631 - acc: 0.6667\n",
            "epsilon: 0.003 and test evaluation : 0.9631458520889282, 0.6666666865348816\n",
            "SNR: 50.23597717285156\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0513 - acc: 0.6335\n",
            "epsilon: 0.005 and test evaluation : 1.0512899160385132, 0.6335078477859497\n",
            "SNR: 45.798683166503906\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.2791 - acc: 0.5620\n",
            "epsilon: 0.01 and test evaluation : 1.2790873050689697, 0.5619546175003052\n",
            "SNR: 39.77808713912964\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7418 - acc: 0.4311\n",
            "epsilon: 0.02 and test evaluation : 1.7417984008789062, 0.43106457591056824\n",
            "SNR: 33.75748634338379\n",
            "Parseval  Network-16-1 created.\n",
            "Finished compiling\n",
            "[0.003, 0.005, 0.01, 0.02]\n",
            "Epoch 1/50\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 1.3504 - acc: 0.3373 - val_loss: 1.3903 - val_acc: 0.3463\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.3105 - acc: 0.3745 - val_loss: 1.2957 - val_acc: 0.3852\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.2761 - acc: 0.4014 - val_loss: 1.2653 - val_acc: 0.4202\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.2437 - acc: 0.4500 - val_loss: 1.3076 - val_acc: 0.4397\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.2240 - acc: 0.4776 - val_loss: 1.2173 - val_acc: 0.4669\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1535 - acc: 0.5198 - val_loss: 1.1388 - val_acc: 0.5253\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.1145 - acc: 0.5434 - val_loss: 1.0945 - val_acc: 0.5350\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 1.0872 - acc: 0.5583 - val_loss: 1.0546 - val_acc: 0.5817\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.0658 - acc: 0.5771 - val_loss: 1.1304 - val_acc: 0.5156\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 1.0401 - acc: 0.5839 - val_loss: 1.0829 - val_acc: 0.5817\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.9820 - acc: 0.6217 - val_loss: 0.9227 - val_acc: 0.6362\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.9136 - acc: 0.6515 - val_loss: 0.8875 - val_acc: 0.6654\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8949 - acc: 0.6557 - val_loss: 0.8962 - val_acc: 0.6556\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.8720 - acc: 0.6699 - val_loss: 0.9040 - val_acc: 0.6537\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.8691 - acc: 0.6686 - val_loss: 0.8430 - val_acc: 0.7023\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.8357 - acc: 0.6915 - val_loss: 0.8311 - val_acc: 0.6868\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.8354 - acc: 0.6872 - val_loss: 0.8298 - val_acc: 0.6984\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8144 - acc: 0.6933 - val_loss: 0.8003 - val_acc: 0.7004\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7975 - acc: 0.7049 - val_loss: 0.8453 - val_acc: 0.6732\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.8006 - acc: 0.7075 - val_loss: 0.7954 - val_acc: 0.6907\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7749 - acc: 0.7066 - val_loss: 0.8097 - val_acc: 0.6907\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7501 - acc: 0.7235 - val_loss: 0.8146 - val_acc: 0.6693\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7373 - acc: 0.7303 - val_loss: 0.7923 - val_acc: 0.7023\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7218 - acc: 0.7346 - val_loss: 0.7709 - val_acc: 0.7023\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7316 - acc: 0.7329 - val_loss: 0.7629 - val_acc: 0.7101\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7342 - acc: 0.7359 - val_loss: 0.7595 - val_acc: 0.7043\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7195 - acc: 0.7394 - val_loss: 0.7813 - val_acc: 0.6887\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7248 - acc: 0.7377 - val_loss: 0.7725 - val_acc: 0.7179\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7075 - acc: 0.7394 - val_loss: 0.7928 - val_acc: 0.6848\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7142 - acc: 0.7399 - val_loss: 0.7842 - val_acc: 0.6984\n",
            "Epoch 31/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7081 - acc: 0.7454 - val_loss: 0.7785 - val_acc: 0.7043\n",
            "Epoch 32/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7192 - acc: 0.7403 - val_loss: 0.8202 - val_acc: 0.7004\n",
            "Epoch 33/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7102 - acc: 0.7416 - val_loss: 0.7712 - val_acc: 0.6946\n",
            "Epoch 34/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6984 - acc: 0.7504 - val_loss: 0.7916 - val_acc: 0.6946\n",
            "Epoch 35/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7186 - acc: 0.7353 - val_loss: 0.8017 - val_acc: 0.6965\n",
            "Epoch 36/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7012 - acc: 0.7403 - val_loss: 0.7916 - val_acc: 0.7023\n",
            "Epoch 37/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7082 - acc: 0.7447 - val_loss: 0.7618 - val_acc: 0.7043\n",
            "Epoch 38/50\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.7108 - acc: 0.7436 - val_loss: 0.7698 - val_acc: 0.7140\n",
            "Epoch 39/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7133 - acc: 0.7484 - val_loss: 0.7827 - val_acc: 0.6887\n",
            "Epoch 40/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7104 - acc: 0.7460 - val_loss: 0.7690 - val_acc: 0.7004\n",
            "Epoch 41/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7089 - acc: 0.7386 - val_loss: 0.7689 - val_acc: 0.7062\n",
            "Epoch 42/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7002 - acc: 0.7491 - val_loss: 0.7681 - val_acc: 0.7043\n",
            "Epoch 43/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7069 - acc: 0.7456 - val_loss: 0.7703 - val_acc: 0.6965\n",
            "Epoch 44/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7051 - acc: 0.7502 - val_loss: 0.7931 - val_acc: 0.7023\n",
            "Epoch 45/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7175 - acc: 0.7423 - val_loss: 0.7984 - val_acc: 0.7004\n",
            "Epoch 46/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7110 - acc: 0.7460 - val_loss: 0.7681 - val_acc: 0.7023\n",
            "Epoch 47/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7094 - acc: 0.7559 - val_loss: 0.8086 - val_acc: 0.6926\n",
            "Epoch 48/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7103 - acc: 0.7434 - val_loss: 0.7883 - val_acc: 0.7043\n",
            "Epoch 49/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6961 - acc: 0.7502 - val_loss: 0.7738 - val_acc: 0.6984\n",
            "Epoch 50/50\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.7026 - acc: 0.7460 - val_loss: 0.8243 - val_acc: 0.6926\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8193 - acc: 0.6946\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9340 - acc: 0.6597\n",
            "epsilon: 0.003 and test evaluation : 0.9340381622314453, 0.6596858501434326\n",
            "SNR: 50.23597717285156\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.0130 - acc: 0.6422\n",
            "epsilon: 0.005 and test evaluation : 1.0130324363708496, 0.6422338485717773\n",
            "SNR: 45.798683166503906\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.2163 - acc: 0.5846\n",
            "epsilon: 0.01 and test evaluation : 1.2162507772445679, 0.584642231464386\n",
            "SNR: 39.77808713912964\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6220 - acc: 0.4695\n",
            "epsilon: 0.02 and test evaluation : 1.6220377683639526, 0.46945899724960327\n",
            "SNR: 33.75748634338379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YzBB_U6A07l",
        "outputId": "e51ea58c-68ca-41af-ba47-286a646feae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "result_adv_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>0.003_loss</th>\n",
              "      <th>0.003_acc</th>\n",
              "      <th>0.005_loss</th>\n",
              "      <th>0.005_acc</th>\n",
              "      <th>0.02_acc</th>\n",
              "      <th>0.02_loss</th>\n",
              "      <th>0.01_acc</th>\n",
              "      <th>0.01_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.882291</td>\n",
              "      <td>0.698080</td>\n",
              "      <td>1.029637</td>\n",
              "      <td>0.638743</td>\n",
              "      <td>1.136114</td>\n",
              "      <td>0.616056</td>\n",
              "      <td>0.521815</td>\n",
              "      <td>1.423629</td>\n",
              "      <td>0.387435</td>\n",
              "      <td>2.016575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.813650</td>\n",
              "      <td>0.706806</td>\n",
              "      <td>0.928804</td>\n",
              "      <td>0.654450</td>\n",
              "      <td>1.008725</td>\n",
              "      <td>0.626527</td>\n",
              "      <td>0.546248</td>\n",
              "      <td>1.213325</td>\n",
              "      <td>0.427574</td>\n",
              "      <td>1.621001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.814444</td>\n",
              "      <td>0.720768</td>\n",
              "      <td>0.930393</td>\n",
              "      <td>0.685864</td>\n",
              "      <td>1.011546</td>\n",
              "      <td>0.645724</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>1.222115</td>\n",
              "      <td>0.448517</td>\n",
              "      <td>1.648703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.828098</td>\n",
              "      <td>0.703316</td>\n",
              "      <td>0.958277</td>\n",
              "      <td>0.659686</td>\n",
              "      <td>1.049816</td>\n",
              "      <td>0.636998</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>1.288000</td>\n",
              "      <td>0.422339</td>\n",
              "      <td>1.771215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.788306</td>\n",
              "      <td>0.724258</td>\n",
              "      <td>0.920664</td>\n",
              "      <td>0.673647</td>\n",
              "      <td>1.014427</td>\n",
              "      <td>0.643979</td>\n",
              "      <td>0.588133</td>\n",
              "      <td>1.259215</td>\n",
              "      <td>0.432810</td>\n",
              "      <td>1.747693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.811801</td>\n",
              "      <td>0.717277</td>\n",
              "      <td>0.931526</td>\n",
              "      <td>0.687609</td>\n",
              "      <td>1.016737</td>\n",
              "      <td>0.659686</td>\n",
              "      <td>0.575916</td>\n",
              "      <td>1.236974</td>\n",
              "      <td>0.432810</td>\n",
              "      <td>1.668866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.805691</td>\n",
              "      <td>0.703316</td>\n",
              "      <td>0.916099</td>\n",
              "      <td>0.656195</td>\n",
              "      <td>0.992109</td>\n",
              "      <td>0.626527</td>\n",
              "      <td>0.544503</td>\n",
              "      <td>1.187817</td>\n",
              "      <td>0.434555</td>\n",
              "      <td>1.583908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.859200</td>\n",
              "      <td>0.682373</td>\n",
              "      <td>0.972273</td>\n",
              "      <td>0.649215</td>\n",
              "      <td>1.052511</td>\n",
              "      <td>0.619546</td>\n",
              "      <td>0.546248</td>\n",
              "      <td>1.262573</td>\n",
              "      <td>0.422339</td>\n",
              "      <td>1.683952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.837950</td>\n",
              "      <td>0.712042</td>\n",
              "      <td>0.963146</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.051290</td>\n",
              "      <td>0.633508</td>\n",
              "      <td>0.561955</td>\n",
              "      <td>1.279087</td>\n",
              "      <td>0.431065</td>\n",
              "      <td>1.741798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.819253</td>\n",
              "      <td>0.694590</td>\n",
              "      <td>0.934038</td>\n",
              "      <td>0.659686</td>\n",
              "      <td>1.013032</td>\n",
              "      <td>0.642234</td>\n",
              "      <td>0.584642</td>\n",
              "      <td>1.216251</td>\n",
              "      <td>0.469459</td>\n",
              "      <td>1.622038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  0.003_loss  ...  0.02_loss  0.01_acc  0.01_loss\n",
              "0    0.882291   0.698080    1.029637  ...   1.423629  0.387435   2.016575\n",
              "1    0.813650   0.706806    0.928804  ...   1.213325  0.427574   1.621001\n",
              "2    0.814444   0.720768    0.930393  ...   1.222115  0.448517   1.648703\n",
              "3    0.828098   0.703316    0.958277  ...   1.288000  0.422339   1.771215\n",
              "4    0.788306   0.724258    0.920664  ...   1.259215  0.432810   1.747693\n",
              "5    0.811801   0.717277    0.931526  ...   1.236974  0.432810   1.668866\n",
              "6    0.805691   0.703316    0.916099  ...   1.187817  0.434555   1.583908\n",
              "7    0.859200   0.682373    0.972273  ...   1.262573  0.422339   1.683952\n",
              "8    0.837950   0.712042    0.963146  ...   1.279087  0.431065   1.741798\n",
              "9    0.819253   0.694590    0.934038  ...   1.216251  0.469459   1.622038\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LT0T19skj-h"
      },
      "source": [
        "### <font color=\"purple\"> Results of Adversarial Training</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSr1gpfzkj-i"
      },
      "source": [
        "result_adv_df[\"clean_mean\"] = np.sum(result_adv_df['acc_clean'])/10.0\n",
        "result_adv_df[\"0.003_mean\"] = np.sum(result_adv_df['0.003_acc'])/10.0\n",
        "result_adv_df[\"0.005_mean\"] = np.sum(result_adv_df['0.005_acc'])/10.0\n",
        "result_adv_df[\"0.02_mean\"] = np.sum(result_adv_df['0.02_acc'])/10.0\n",
        "result_adv_df[\"0.01_mean\"] = np.sum(result_adv_df['0.01_acc'])/10.0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbtKmK02vW3N",
        "outputId": "5a04909c-4471-4888-ab17-553b7a67c269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "column = [\"clean_mean\",\"0.003_mean\",\"0.005_mean\",\"0.02_mean\",\"0.01_mean\"]\n",
        "result_adv_df[column].head(1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_mean</th>\n",
              "      <th>0.003_mean</th>\n",
              "      <th>0.005_mean</th>\n",
              "      <th>0.02_mean</th>\n",
              "      <th>0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.706283</td>\n",
              "      <td>0.663176</td>\n",
              "      <td>0.635079</td>\n",
              "      <td>0.560733</td>\n",
              "      <td>0.43089</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clean_mean  0.003_mean  0.005_mean  0.02_mean  0.01_mean\n",
              "0    0.706283    0.663176    0.635079   0.560733    0.43089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk6SrKnTB_xI"
      },
      "source": [
        "# <font color=\"blue\">Compare Non-Adversarial Training with Adversarial Training</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9cyaTQ_CJj3",
        "outputId": "4156f390-d63c-4f68-81ca-03791124bf47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "result_adv_df[column].head(1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_mean</th>\n",
              "      <th>0.003_mean</th>\n",
              "      <th>0.005_mean</th>\n",
              "      <th>0.02_mean</th>\n",
              "      <th>0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.706283</td>\n",
              "      <td>0.663176</td>\n",
              "      <td>0.635079</td>\n",
              "      <td>0.560733</td>\n",
              "      <td>0.43089</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clean_mean  0.003_mean  0.005_mean  0.02_mean  0.01_mean\n",
              "0    0.706283    0.663176    0.635079   0.560733    0.43089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAvyuKGlCJ2D",
        "outputId": "692e6d7a-c113-4f41-e8d4-22b9148869b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "result_df[column].head(1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_mean</th>\n",
              "      <th>0.003_mean</th>\n",
              "      <th>0.005_mean</th>\n",
              "      <th>0.02_mean</th>\n",
              "      <th>0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.703141</td>\n",
              "      <td>0.657941</td>\n",
              "      <td>0.626003</td>\n",
              "      <td>0.555323</td>\n",
              "      <td>0.424607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clean_mean  0.003_mean  0.005_mean  0.02_mean  0.01_mean\n",
              "0    0.703141    0.657941    0.626003   0.555323   0.424607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziuulXV-B3SN"
      },
      "source": [
        "# <font color=\"blue\">Conclusion</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6wMdcJ37yA9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLwwAqvXsTeo"
      },
      "source": [
        ""
      ]
    }
  ]
}