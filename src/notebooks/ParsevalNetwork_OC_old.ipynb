{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ParsevalNetwork.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_idgCcuZdv0S",
        "colab_type": "text"
      },
      "source": [
        "# **Parseval Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO1kBOuDd2_r",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXS1STy_O_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nX1rD7_O_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eac2e0a9-fceb-465d-930a-304e3677d2be"
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n",
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuUWZk7KeFck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f53224f-9435-47a9-f2d8-e266d45672ef"
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T0HkiPfeH1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crqYw_LJeJif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuCH_ylOeLLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "5cfe02f8-617d-464b-f321-84b8bef1c4c7"
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "closed           1500\n",
              "open             1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJGV2GZWeN-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0d19ebfd-45e2-4989-a548-0b48b47164d8"
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBVaEoQBeP7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Q7NqR4eYQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "x_train, X_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTmOEDcMtSQp",
        "colab_type": "text"
      },
      "source": [
        "# Othogonal Constraint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S2jnj2otWlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.constraints import Constraint\n",
        "from tensorflow.python.ops import math_ops, array_ops\n",
        "\n",
        "class TightFrame(Constraint):\n",
        "\n",
        "\n",
        "    def __init__(self, scale, num_passes=1):\n",
        "        self.scale = scale\n",
        "\n",
        "        if num_passes < 1:\n",
        "            raise ValueError(\"Number of passes cannot be non-positive! (got {})\".format(num_passes))\n",
        "        self.num_passes = num_passes\n",
        "\n",
        "\n",
        "    def __call__(self, w):\n",
        "        transpose_channels = (len(w.shape) == 4)\n",
        "\n",
        "        # Move channels_num to the front in order to make the dimensions correct for matmul\n",
        "        if transpose_channels:\n",
        "            w_reordered = array_ops.reshape(w, (-1, w.shape[0]))\n",
        "\n",
        "        else:\n",
        "            w_reordered = w\n",
        "\n",
        "        last = w_reordered\n",
        "        for i in range(self.num_passes):\n",
        "            temp1 = math_ops.matmul(last, last, transpose_a=True)\n",
        "            temp2 = (1 + self.scale) * w_reordered - self.scale * math_ops.matmul(w_reordered, temp1)\n",
        "\n",
        "            last = temp2\n",
        "\n",
        "        # Move channels_num to the back again\n",
        "        if transpose_channels:\n",
        "            return array_ops.reshape(last, w.shape)\n",
        "        else:\n",
        "            return last\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'scale': self.scale, 'num_passes': self.num_passes}\n",
        "\n",
        "\n",
        "# Alias\n",
        "tight_frame = TightFrame"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4VciYzctsSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0001\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3g_vzsy_ndF",
        "colab_type": "text"
      },
      "source": [
        "**Parseval Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN76FYUZ_3YA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "74ab0a37-5439-4b8c-bca2-4cafd25350cd"
      },
      "source": [
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='Orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_parseval_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, activation='softmax' )(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    parseval_16_2 = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxyMKoeaBqPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.callbacks as callbacks\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiFrat1Bv1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200\n",
        "BS = 128\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygMFWH8Bzfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUvPL0dB48O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd22d9ec-1e0d-430d-e8a9-3aea70ef80ee"
      },
      "source": [
        "parseval_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrJ7xy1Q5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4EpGTMG9jeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 30:\n",
        "        return 0.1\n",
        "    elif epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch < 60:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0CbPY_24ns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57665e0a-41c2-4fdc-e1ee-4862db7cbcaf"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "hist = parseval_16_2.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=EPOCHS,\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 1.4580 - acc: 0.3138 - val_loss: 1.4158 - val_acc: 0.3883 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3531 - acc: 0.3877 - val_loss: 1.3031 - val_acc: 0.4117 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3048 - acc: 0.4104 - val_loss: 1.2649 - val_acc: 0.4175 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2547 - acc: 0.4554 - val_loss: 1.3541 - val_acc: 0.3573 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2192 - acc: 0.4931 - val_loss: 1.1984 - val_acc: 0.4738 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1647 - acc: 0.5133 - val_loss: 1.8081 - val_acc: 0.3437 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1438 - acc: 0.5249 - val_loss: 1.5084 - val_acc: 0.4136 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0993 - acc: 0.5473 - val_loss: 1.1177 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.0660 - acc: 0.5675 - val_loss: 1.2631 - val_acc: 0.5126 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0082 - acc: 0.5952 - val_loss: 0.9855 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9741 - acc: 0.6119 - val_loss: 3.5027 - val_acc: 0.3689 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9502 - acc: 0.6218 - val_loss: 1.2067 - val_acc: 0.5476 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9040 - acc: 0.6505 - val_loss: 0.8853 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8831 - acc: 0.6558 - val_loss: 0.9141 - val_acc: 0.6155 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8381 - acc: 0.6760 - val_loss: 1.0254 - val_acc: 0.6311 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8330 - acc: 0.6778 - val_loss: 1.2513 - val_acc: 0.5806 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8274 - acc: 0.6795 - val_loss: 0.8473 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7881 - acc: 0.7008 - val_loss: 0.8257 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7677 - acc: 0.7097 - val_loss: 0.7891 - val_acc: 0.6835 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7630 - acc: 0.7126 - val_loss: 1.0044 - val_acc: 0.6408 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7542 - acc: 0.7157 - val_loss: 0.9184 - val_acc: 0.6699 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7369 - acc: 0.7217 - val_loss: 0.9205 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7298 - acc: 0.7213 - val_loss: 0.9133 - val_acc: 0.6699 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6922 - acc: 0.7412 - val_loss: 0.8045 - val_acc: 0.7010 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7059 - acc: 0.7348 - val_loss: 0.8673 - val_acc: 0.6951 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6802 - acc: 0.7423 - val_loss: 1.0216 - val_acc: 0.6621 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6749 - acc: 0.7448 - val_loss: 0.8936 - val_acc: 0.7068 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6565 - acc: 0.7532 - val_loss: 0.8169 - val_acc: 0.7029 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6702 - acc: 0.7490 - val_loss: 0.7758 - val_acc: 0.7146 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6572 - acc: 0.7517 - val_loss: 0.7506 - val_acc: 0.7165 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6633 - acc: 0.7466 - val_loss: 0.7521 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6019 - acc: 0.7783 - val_loss: 0.7800 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5873 - acc: 0.7865 - val_loss: 0.7548 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5673 - acc: 0.7923 - val_loss: 0.7642 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5501 - acc: 0.8023 - val_loss: 0.7142 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5441 - acc: 0.8034 - val_loss: 0.7331 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5377 - acc: 0.8063 - val_loss: 0.7065 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5367 - acc: 0.8003 - val_loss: 0.7206 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5253 - acc: 0.8094 - val_loss: 0.7646 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5247 - acc: 0.8078 - val_loss: 0.7296 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5149 - acc: 0.8176 - val_loss: 0.7213 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5165 - acc: 0.8167 - val_loss: 0.7050 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5097 - acc: 0.8151 - val_loss: 0.7395 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5122 - acc: 0.8167 - val_loss: 0.7137 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5044 - acc: 0.8165 - val_loss: 0.7187 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4956 - acc: 0.8236 - val_loss: 0.7383 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5020 - acc: 0.8167 - val_loss: 0.7622 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4945 - acc: 0.8238 - val_loss: 0.7396 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5048 - acc: 0.8160 - val_loss: 0.7391 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5005 - acc: 0.8162 - val_loss: 0.7109 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4960 - acc: 0.8187 - val_loss: 0.7312 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4895 - acc: 0.8253 - val_loss: 0.7481 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4802 - acc: 0.8278 - val_loss: 0.7466 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4827 - acc: 0.8298 - val_loss: 0.7389 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4792 - acc: 0.8276 - val_loss: 0.7568 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4866 - acc: 0.8291 - val_loss: 0.7424 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4901 - acc: 0.8187 - val_loss: 0.7624 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4782 - acc: 0.8244 - val_loss: 0.7635 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4784 - acc: 0.8276 - val_loss: 0.7228 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4768 - acc: 0.8280 - val_loss: 0.7401 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4727 - acc: 0.8287 - val_loss: 0.7418 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4694 - acc: 0.8322 - val_loss: 0.8098 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4649 - acc: 0.8289 - val_loss: 0.7484 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4759 - acc: 0.8271 - val_loss: 0.7830 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4783 - acc: 0.8287 - val_loss: 0.8428 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4613 - acc: 0.8349 - val_loss: 0.7594 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4820 - acc: 0.8289 - val_loss: 0.7189 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4757 - acc: 0.8289 - val_loss: 0.8274 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4643 - acc: 0.8340 - val_loss: 0.7617 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4693 - acc: 0.8289 - val_loss: 0.7948 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4731 - acc: 0.8298 - val_loss: 0.7676 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4647 - acc: 0.8418 - val_loss: 0.7444 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4708 - acc: 0.8307 - val_loss: 0.7507 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4764 - acc: 0.8269 - val_loss: 0.7190 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4778 - acc: 0.8282 - val_loss: 0.7502 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4626 - acc: 0.8344 - val_loss: 0.7310 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4652 - acc: 0.8342 - val_loss: 0.7225 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4645 - acc: 0.8293 - val_loss: 0.7729 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4697 - acc: 0.8307 - val_loss: 0.7511 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4798 - acc: 0.8236 - val_loss: 0.7683 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4656 - acc: 0.8347 - val_loss: 0.7596 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4666 - acc: 0.8298 - val_loss: 0.7752 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4660 - acc: 0.8307 - val_loss: 0.7567 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4669 - acc: 0.8333 - val_loss: 0.7595 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4633 - acc: 0.8369 - val_loss: 0.7693 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4666 - acc: 0.8304 - val_loss: 0.7719 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4641 - acc: 0.8329 - val_loss: 0.7346 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4668 - acc: 0.8322 - val_loss: 0.7654 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4689 - acc: 0.8320 - val_loss: 0.7943 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4699 - acc: 0.8318 - val_loss: 0.7809 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4657 - acc: 0.8324 - val_loss: 0.7268 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4682 - acc: 0.8296 - val_loss: 0.7802 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4668 - acc: 0.8329 - val_loss: 0.7281 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4718 - acc: 0.8265 - val_loss: 0.8360 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4648 - acc: 0.8316 - val_loss: 0.7184 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4740 - acc: 0.8231 - val_loss: 0.7507 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4626 - acc: 0.8304 - val_loss: 0.7624 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4685 - acc: 0.8291 - val_loss: 0.7535 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4646 - acc: 0.8333 - val_loss: 0.7373 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4681 - acc: 0.8307 - val_loss: 0.7867 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4755 - acc: 0.8280 - val_loss: 0.7486 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4672 - acc: 0.8276 - val_loss: 0.7317 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4675 - acc: 0.8302 - val_loss: 0.7310 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4689 - acc: 0.8302 - val_loss: 0.7594 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4748 - acc: 0.8271 - val_loss: 0.7617 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4680 - acc: 0.8300 - val_loss: 0.7587 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4715 - acc: 0.8304 - val_loss: 0.7452 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4676 - acc: 0.8304 - val_loss: 0.7581 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4675 - acc: 0.8271 - val_loss: 0.7570 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4558 - acc: 0.8391 - val_loss: 0.7659 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4710 - acc: 0.8282 - val_loss: 0.7638 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4699 - acc: 0.8286 - val_loss: 0.7602 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4663 - acc: 0.8342 - val_loss: 0.7512 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4596 - acc: 0.8344 - val_loss: 0.7317 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4640 - acc: 0.8304 - val_loss: 0.7179 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4729 - acc: 0.8265 - val_loss: 0.7411 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4615 - acc: 0.8342 - val_loss: 0.7431 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4677 - acc: 0.8318 - val_loss: 0.8205 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4643 - acc: 0.8285 - val_loss: 0.7709 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4712 - acc: 0.8342 - val_loss: 0.7329 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4593 - acc: 0.8342 - val_loss: 0.7393 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4697 - acc: 0.8362 - val_loss: 0.7631 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4633 - acc: 0.8313 - val_loss: 0.8114 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4646 - acc: 0.8309 - val_loss: 0.7532 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4659 - acc: 0.8375 - val_loss: 0.7585 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4697 - acc: 0.8293 - val_loss: 0.7799 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4658 - acc: 0.8311 - val_loss: 0.7293 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4690 - acc: 0.8271 - val_loss: 0.7411 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4715 - acc: 0.8320 - val_loss: 0.7412 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4630 - acc: 0.8267 - val_loss: 0.7334 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4656 - acc: 0.8287 - val_loss: 0.7955 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4635 - acc: 0.8369 - val_loss: 0.7365 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4642 - acc: 0.8316 - val_loss: 0.7459 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4654 - acc: 0.8324 - val_loss: 0.7514 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4668 - acc: 0.8333 - val_loss: 0.7771 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4623 - acc: 0.8313 - val_loss: 0.7711 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4470 - acc: 0.8466 - val_loss: 0.7304 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4601 - acc: 0.8300 - val_loss: 0.7152 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4552 - acc: 0.8380 - val_loss: 0.7560 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4639 - acc: 0.8302 - val_loss: 0.7575 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4598 - acc: 0.8296 - val_loss: 0.7561 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4777 - acc: 0.8247 - val_loss: 0.7517 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4752 - acc: 0.8236 - val_loss: 0.7144 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4688 - acc: 0.8324 - val_loss: 0.7641 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4556 - acc: 0.8338 - val_loss: 0.7311 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4696 - acc: 0.8300 - val_loss: 0.7280 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4719 - acc: 0.8318 - val_loss: 0.7468 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4612 - acc: 0.8403 - val_loss: 0.7137 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4667 - acc: 0.8309 - val_loss: 0.8255 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4664 - acc: 0.8240 - val_loss: 0.7340 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4638 - acc: 0.8260 - val_loss: 0.7456 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4677 - acc: 0.8302 - val_loss: 0.7935 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4641 - acc: 0.8347 - val_loss: 0.7550 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4615 - acc: 0.8336 - val_loss: 0.8031 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4586 - acc: 0.8351 - val_loss: 0.7763 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4668 - acc: 0.8307 - val_loss: 0.7799 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4520 - acc: 0.8344 - val_loss: 0.7382 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4579 - acc: 0.8256 - val_loss: 0.7291 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4571 - acc: 0.8318 - val_loss: 0.7399 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4616 - acc: 0.8362 - val_loss: 0.7125 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4681 - acc: 0.8256 - val_loss: 0.9293 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4632 - acc: 0.8287 - val_loss: 0.7424 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4645 - acc: 0.8311 - val_loss: 0.7403 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4546 - acc: 0.8356 - val_loss: 0.7411 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4641 - acc: 0.8302 - val_loss: 0.7975 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4556 - acc: 0.8427 - val_loss: 0.7391 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4661 - acc: 0.8269 - val_loss: 0.7901 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4653 - acc: 0.8320 - val_loss: 0.7604 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4692 - acc: 0.8213 - val_loss: 0.7373 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4607 - acc: 0.8347 - val_loss: 0.8036 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4591 - acc: 0.8342 - val_loss: 0.7882 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4597 - acc: 0.8356 - val_loss: 0.7684 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4598 - acc: 0.8364 - val_loss: 0.7249 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4578 - acc: 0.8302 - val_loss: 0.7293 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4679 - acc: 0.8276 - val_loss: 0.7706 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4582 - acc: 0.8316 - val_loss: 0.7335 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4609 - acc: 0.8311 - val_loss: 0.7392 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4616 - acc: 0.8316 - val_loss: 0.7354 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4601 - acc: 0.8320 - val_loss: 0.7649 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4471 - acc: 0.8395 - val_loss: 0.7591 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4712 - acc: 0.8249 - val_loss: 0.7578 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4590 - acc: 0.8269 - val_loss: 0.7359 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4547 - acc: 0.8342 - val_loss: 0.7234 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4633 - acc: 0.8287 - val_loss: 0.8082 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4654 - acc: 0.8289 - val_loss: 0.7290 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4633 - acc: 0.8331 - val_loss: 0.7557 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4588 - acc: 0.8362 - val_loss: 0.7627 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4626 - acc: 0.8300 - val_loss: 0.7965 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4526 - acc: 0.8347 - val_loss: 0.7569 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4645 - acc: 0.8353 - val_loss: 0.7207 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4701 - acc: 0.8256 - val_loss: 0.7378 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4576 - acc: 0.8351 - val_loss: 0.7399 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4570 - acc: 0.8324 - val_loss: 0.7753 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4567 - acc: 0.8398 - val_loss: 0.7860 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4614 - acc: 0.8307 - val_loss: 0.7716 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4712 - acc: 0.8253 - val_loss: 0.7683 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4597 - acc: 0.8313 - val_loss: 0.7393 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4711 - acc: 0.8296 - val_loss: 0.7258 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4665 - acc: 0.8289 - val_loss: 0.7375 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4664 - acc: 0.8318 - val_loss: 0.7694 - val_acc: 0.7534 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNGXxJTQq-UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAVQ_YwYpeMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f3cc950f-cf45-4974-f2f4-64420d102171"
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n",
        "pyplot.title('model accuracy')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'val'], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-QerZ4RN91R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bc7412ef-33d9-4f81-f8dc-99c93987601d"
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n",
        "pyplot.title('model accuracy')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'val'], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeg6MBf-GSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_err = [1.0-x for x in hist.history['val_acc']]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC6DagsghRg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "50c70b11-8c64-473c-c019-09cba09d943a"
      },
      "source": [
        "# summarize history for loss\n",
        "pyplot.plot(hist.history['loss'])\n",
        "pyplot.plot(hist.history['val_loss'])\n",
        "pyplot.title('model loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'test'], loc='upper left')\n",
        "pyplot.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgiKT6i5GiJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f2252167-0e72-4378-eaf8-95ec3d29b4f9"
      },
      "source": [
        "pyplot.plot(test_err, label='test')\n",
        "pyplot.savefig(\"deneme_err.png\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IJ9Z-dQKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "parseval_16_2.save(\"parseval_OC.h5\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqddlwbmEV9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = parseval_16_2.predict(X_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ysop6NFDbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ee8bbebf-e8b4-4211-a8de-26a8896308ac"
      },
      "source": [
        "parseval_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6846 - acc: 0.7696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6846140623092651, 0.7696335315704346]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUCxeuFMmMw7",
        "colab_type": "text"
      },
      "source": [
        "# **Adversarial Examples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knp-F1cdmQgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import  KFold\n",
        "\n",
        "class Non_adversarial(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train_iterate(self, X_train, Y_train, X_test, y_test, epochs, BS,sgd, epsilon_list):\n",
        "          init = (32, 32,1)\n",
        "          res_df = pd.DataFrame(columns=['loss_clean','acc_clean',\n",
        "                                  'loss1', 'acc1','loss2', 'acc2','loss3',\n",
        "                                    'acc3','loss4', 'acc4'])\n",
        "          kf = KFold(n_splits=10, random_state=42, shuffle=False)\n",
        "          \n",
        "          for j, (train, val) in enumerate(kf.split(X_train)):\n",
        "            x_train, y_train,  x_val, y_val = X_train[train], Y_train[train], X_train[val], Y_train[val]\n",
        "            model = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "            model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "            hist = model.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=epochs,\n",
        "                            callbacks = [lr_scheduler],\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            validation_steps=x_val.shape[0] // BS,)\n",
        "            loss, acc = model.evaluate(X_test, y_test)\n",
        "            loss1, acc1 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[0]),X_test, y_test, epsilon_list[0])\n",
        "            loss2, acc2 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[1]),X_test, y_test, epsilon_list[1])\n",
        "            loss3, acc3 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[2]),X_test, y_test, epsilon_list[2])\n",
        "            loss4, acc4 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[3]),X_test, y_test, epsilon_list[3])\n",
        "            row = {'loss_clean':loss,'acc_clean':acc, 'loss1':loss1, 'acc1':acc1, 'loss2':loss2,\n",
        "                    'acc2':acc2, 'loss3':loss3, 'acc3':acc3, 'loss4':loss4, 'acc4':acc4}\n",
        "            res_df = res_df.append(row , ignore_index=True)\n",
        "            \n",
        "          return res_df"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVhO4DCbmWAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "50d3792b-8b89-4f35-834f-7157f49c4b88"
      },
      "source": [
        "\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-jv0cr27b/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-jv0cr27b/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 5.8MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.2)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=256b9882da5a61640511f88b9146efad076a833c34f11a6e7f2ee58bcf1d2011\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ikb11eyr/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-29-21b906498791>:8: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv0ZE8pumboZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "def get_adversarial_examples(pretrained_model, X_true, y_true, epsilon):\n",
        "  #The attack requires the model to ouput the logits\n",
        "   \n",
        "  logits_model = tf.keras.Model(pretrained_model.input,pretrained_model.layers[-1].output)\n",
        "  X_adv = []\n",
        "  for i in range(len(X_true)):\n",
        "    random_index = i\n",
        "    original_image = X_true[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_true[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "  X_adv = np.array(X_adv)\n",
        "  return X_adv\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxeGP9HYmd7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_graph(hist):\n",
        "  history = hist\n",
        "  print(history.history.keys())\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  plt.savefig(\"wrn_tensor.png\")\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Wgf8sOmgMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_test(model,X_adv, X_test, y_test, epsilon):\n",
        "  loss, acc = model.evaluate(X_adv,y_test)\n",
        "  print(\"epsilon: {} and test evaluation : {}, {}\".format(epsilon,loss, acc))\n",
        "  SNR = 20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))\n",
        "  print(\"SNR: {}\".format(SNR))\n",
        "  return loss, acc"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKoVsxZDOxyL",
        "colab_type": "text"
      },
      "source": [
        "**Non-Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DWYnAsDsRJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d78MYsOGOw-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1516ce76-ff21-42ca-a3bc-70453bc41503"
      },
      "source": [
        "epsilon_list = [0.003,0.005,0.01,0.02]\n",
        "train_object = Non_adversarial()\n",
        "result_df = train_object.train_iterate(X_train, Y_train, X_test, y_test, EPOCHS, BS,sgd, epsilon_list)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 1.4408 - acc: 0.3276 - val_loss: 1.4334 - val_acc: 0.3049 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 1.3451 - acc: 0.3764 - val_loss: 1.3603 - val_acc: 0.3359 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3041 - acc: 0.3906 - val_loss: 1.5369 - val_acc: 0.2350 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.3210 - acc: 0.3802 - val_loss: 1.3262 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2885 - acc: 0.4083 - val_loss: 1.3183 - val_acc: 0.3592 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2531 - acc: 0.4221 - val_loss: 1.3163 - val_acc: 0.3650 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2411 - acc: 0.4363 - val_loss: 1.3742 - val_acc: 0.3573 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2336 - acc: 0.4589 - val_loss: 1.3494 - val_acc: 0.4214 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1672 - acc: 0.5113 - val_loss: 1.9060 - val_acc: 0.3243 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1359 - acc: 0.5297 - val_loss: 1.6534 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0893 - acc: 0.5504 - val_loss: 1.2395 - val_acc: 0.4388 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0559 - acc: 0.5808 - val_loss: 1.2566 - val_acc: 0.5029 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0367 - acc: 0.5781 - val_loss: 1.1796 - val_acc: 0.5767 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9711 - acc: 0.6130 - val_loss: 1.1546 - val_acc: 0.5456 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9543 - acc: 0.6229 - val_loss: 0.9844 - val_acc: 0.5883 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8850 - acc: 0.6498 - val_loss: 1.4730 - val_acc: 0.5165 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8659 - acc: 0.6585 - val_loss: 0.8304 - val_acc: 0.7068 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8477 - acc: 0.6653 - val_loss: 0.9289 - val_acc: 0.6408 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7987 - acc: 0.6906 - val_loss: 0.9733 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8010 - acc: 0.6911 - val_loss: 0.9153 - val_acc: 0.6738 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7924 - acc: 0.6922 - val_loss: 0.8238 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7616 - acc: 0.7099 - val_loss: 0.8167 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7710 - acc: 0.7133 - val_loss: 0.8170 - val_acc: 0.6835 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7321 - acc: 0.7244 - val_loss: 0.9464 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7266 - acc: 0.7264 - val_loss: 0.8645 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6882 - acc: 0.7410 - val_loss: 0.8614 - val_acc: 0.6738 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6908 - acc: 0.7301 - val_loss: 0.7541 - val_acc: 0.7184 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6940 - acc: 0.7341 - val_loss: 0.8059 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6494 - acc: 0.7539 - val_loss: 0.9793 - val_acc: 0.6583 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6453 - acc: 0.7619 - val_loss: 0.8303 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6357 - acc: 0.7621 - val_loss: 0.7292 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6028 - acc: 0.7732 - val_loss: 0.6979 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5748 - acc: 0.7881 - val_loss: 0.7027 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5679 - acc: 0.7923 - val_loss: 0.6987 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5582 - acc: 0.7996 - val_loss: 0.6907 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5449 - acc: 0.8009 - val_loss: 0.6870 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5363 - acc: 0.8069 - val_loss: 0.6876 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5407 - acc: 0.8051 - val_loss: 0.6814 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5358 - acc: 0.8020 - val_loss: 0.7110 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5330 - acc: 0.8045 - val_loss: 0.6808 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5261 - acc: 0.8080 - val_loss: 0.6758 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5217 - acc: 0.8045 - val_loss: 0.6807 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5198 - acc: 0.8078 - val_loss: 0.6946 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5111 - acc: 0.8107 - val_loss: 0.7070 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5109 - acc: 0.8096 - val_loss: 0.6741 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5079 - acc: 0.8165 - val_loss: 0.6680 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5001 - acc: 0.8142 - val_loss: 0.7003 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5064 - acc: 0.8185 - val_loss: 0.6787 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4971 - acc: 0.8187 - val_loss: 0.7066 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4853 - acc: 0.8234 - val_loss: 0.6763 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4902 - acc: 0.8245 - val_loss: 0.6945 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4929 - acc: 0.8200 - val_loss: 0.6722 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4869 - acc: 0.8253 - val_loss: 0.6712 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4973 - acc: 0.8149 - val_loss: 0.6724 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4851 - acc: 0.8196 - val_loss: 0.6778 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4936 - acc: 0.8187 - val_loss: 0.6902 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4793 - acc: 0.8307 - val_loss: 0.6907 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4800 - acc: 0.8225 - val_loss: 0.6613 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4819 - acc: 0.8269 - val_loss: 0.6696 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4747 - acc: 0.8285 - val_loss: 0.6777 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4682 - acc: 0.8311 - val_loss: 0.6799 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4816 - acc: 0.8207 - val_loss: 0.7632 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4685 - acc: 0.8296 - val_loss: 0.6815 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4760 - acc: 0.8296 - val_loss: 0.6658 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4685 - acc: 0.8225 - val_loss: 0.6752 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4780 - acc: 0.8238 - val_loss: 0.6808 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4753 - acc: 0.8265 - val_loss: 0.6774 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4659 - acc: 0.8289 - val_loss: 0.6811 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4627 - acc: 0.8371 - val_loss: 0.6767 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4728 - acc: 0.8256 - val_loss: 0.6694 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4656 - acc: 0.8309 - val_loss: 0.6854 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4620 - acc: 0.8307 - val_loss: 0.6830 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4706 - acc: 0.8313 - val_loss: 0.6777 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4725 - acc: 0.8236 - val_loss: 0.6735 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4675 - acc: 0.8293 - val_loss: 0.6746 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4821 - acc: 0.8196 - val_loss: 0.6706 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4767 - acc: 0.8229 - val_loss: 0.6718 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4678 - acc: 0.8298 - val_loss: 0.6692 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4764 - acc: 0.8238 - val_loss: 0.7936 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4747 - acc: 0.8282 - val_loss: 0.6801 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4635 - acc: 0.8346 - val_loss: 0.6710 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4693 - acc: 0.8260 - val_loss: 0.6824 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4705 - acc: 0.8304 - val_loss: 0.6890 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4611 - acc: 0.8331 - val_loss: 0.6757 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4739 - acc: 0.8269 - val_loss: 0.6992 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4627 - acc: 0.8362 - val_loss: 0.6799 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4630 - acc: 0.8322 - val_loss: 0.6997 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4704 - acc: 0.8287 - val_loss: 0.6732 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4665 - acc: 0.8285 - val_loss: 0.6735 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4692 - acc: 0.8222 - val_loss: 0.6639 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4696 - acc: 0.8333 - val_loss: 0.6896 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4740 - acc: 0.8262 - val_loss: 0.6691 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4754 - acc: 0.8273 - val_loss: 0.6705 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4660 - acc: 0.8251 - val_loss: 0.6758 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4664 - acc: 0.8269 - val_loss: 0.6671 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4690 - acc: 0.8293 - val_loss: 0.6700 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4755 - acc: 0.8278 - val_loss: 0.6801 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4693 - acc: 0.8296 - val_loss: 0.6712 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4634 - acc: 0.8256 - val_loss: 0.6810 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4727 - acc: 0.8262 - val_loss: 0.6759 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4778 - acc: 0.8273 - val_loss: 0.6622 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4686 - acc: 0.8302 - val_loss: 0.6821 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4649 - acc: 0.8320 - val_loss: 0.6986 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4620 - acc: 0.8353 - val_loss: 0.6753 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4720 - acc: 0.8236 - val_loss: 0.6771 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4670 - acc: 0.8258 - val_loss: 0.6842 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4688 - acc: 0.8302 - val_loss: 0.6717 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4698 - acc: 0.8233 - val_loss: 0.6862 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4745 - acc: 0.8307 - val_loss: 0.6719 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4632 - acc: 0.8282 - val_loss: 0.6696 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4665 - acc: 0.8277 - val_loss: 0.7070 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4615 - acc: 0.8309 - val_loss: 0.6839 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4648 - acc: 0.8318 - val_loss: 0.6795 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4730 - acc: 0.8245 - val_loss: 0.6695 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4731 - acc: 0.8256 - val_loss: 0.6711 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4575 - acc: 0.8322 - val_loss: 0.6640 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4732 - acc: 0.8285 - val_loss: 0.6993 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4625 - acc: 0.8311 - val_loss: 0.6724 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4679 - acc: 0.8231 - val_loss: 0.6674 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4655 - acc: 0.8320 - val_loss: 0.6765 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4601 - acc: 0.8340 - val_loss: 0.6793 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4657 - acc: 0.8304 - val_loss: 0.6712 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4615 - acc: 0.8260 - val_loss: 0.6792 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4656 - acc: 0.8298 - val_loss: 0.6744 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4655 - acc: 0.8309 - val_loss: 0.6886 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4636 - acc: 0.8329 - val_loss: 0.6927 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4702 - acc: 0.8227 - val_loss: 0.6776 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4665 - acc: 0.8245 - val_loss: 0.6740 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4730 - acc: 0.8227 - val_loss: 0.6861 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4741 - acc: 0.8240 - val_loss: 0.6673 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4671 - acc: 0.8278 - val_loss: 0.6809 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4610 - acc: 0.8280 - val_loss: 0.6609 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4715 - acc: 0.8249 - val_loss: 0.6744 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4553 - acc: 0.8402 - val_loss: 0.7719 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4782 - acc: 0.8176 - val_loss: 0.6679 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4771 - acc: 0.8218 - val_loss: 0.6673 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4650 - acc: 0.8302 - val_loss: 0.6631 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4699 - acc: 0.8304 - val_loss: 0.6669 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4677 - acc: 0.8275 - val_loss: 0.6877 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4703 - acc: 0.8227 - val_loss: 0.6745 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4632 - acc: 0.8269 - val_loss: 0.6753 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4600 - acc: 0.8347 - val_loss: 0.6565 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4587 - acc: 0.8278 - val_loss: 0.6689 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4626 - acc: 0.8296 - val_loss: 0.6616 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4749 - acc: 0.8240 - val_loss: 0.6860 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4658 - acc: 0.8298 - val_loss: 0.6611 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4699 - acc: 0.8267 - val_loss: 0.6822 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4635 - acc: 0.8282 - val_loss: 0.6919 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4693 - acc: 0.8266 - val_loss: 0.6739 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4662 - acc: 0.8251 - val_loss: 0.6883 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4630 - acc: 0.8287 - val_loss: 0.6818 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4642 - acc: 0.8273 - val_loss: 0.6748 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4675 - acc: 0.8285 - val_loss: 0.6727 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4631 - acc: 0.8287 - val_loss: 0.6836 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4633 - acc: 0.8260 - val_loss: 0.6650 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4657 - acc: 0.8271 - val_loss: 0.6585 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4655 - acc: 0.8280 - val_loss: 0.6692 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4668 - acc: 0.8262 - val_loss: 0.6600 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4688 - acc: 0.8276 - val_loss: 0.6575 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4570 - acc: 0.8311 - val_loss: 0.6669 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4695 - acc: 0.8249 - val_loss: 0.6737 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4599 - acc: 0.8287 - val_loss: 0.6813 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4689 - acc: 0.8318 - val_loss: 0.7002 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4622 - acc: 0.8307 - val_loss: 0.6626 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4650 - acc: 0.8311 - val_loss: 0.6749 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4665 - acc: 0.8247 - val_loss: 0.6692 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4621 - acc: 0.8338 - val_loss: 0.6900 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4640 - acc: 0.8225 - val_loss: 0.6762 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4599 - acc: 0.8307 - val_loss: 0.6730 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4669 - acc: 0.8267 - val_loss: 0.6675 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4639 - acc: 0.8273 - val_loss: 0.6597 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4618 - acc: 0.8280 - val_loss: 0.7572 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4677 - acc: 0.8318 - val_loss: 0.6771 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4606 - acc: 0.8324 - val_loss: 0.6779 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4615 - acc: 0.8298 - val_loss: 0.6976 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4603 - acc: 0.8336 - val_loss: 0.6734 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4568 - acc: 0.8373 - val_loss: 0.6637 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4598 - acc: 0.8351 - val_loss: 0.6673 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4688 - acc: 0.8307 - val_loss: 0.6917 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4627 - acc: 0.8300 - val_loss: 0.6644 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4631 - acc: 0.8313 - val_loss: 0.6813 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4667 - acc: 0.8253 - val_loss: 0.6718 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4715 - acc: 0.8280 - val_loss: 0.6668 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4664 - acc: 0.8302 - val_loss: 0.6941 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4639 - acc: 0.8329 - val_loss: 0.6740 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4653 - acc: 0.8296 - val_loss: 0.6681 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4711 - acc: 0.8225 - val_loss: 0.7226 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4641 - acc: 0.8351 - val_loss: 0.6663 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4653 - acc: 0.8373 - val_loss: 0.6647 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4583 - acc: 0.8313 - val_loss: 0.6798 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4627 - acc: 0.8268 - val_loss: 0.6756 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4671 - acc: 0.8260 - val_loss: 0.6617 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4641 - acc: 0.8256 - val_loss: 0.6849 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4781 - acc: 0.8247 - val_loss: 0.6700 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4666 - acc: 0.8265 - val_loss: 0.6929 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4643 - acc: 0.8269 - val_loss: 0.6663 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4648 - acc: 0.8342 - val_loss: 0.6776 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4646 - acc: 0.8287 - val_loss: 0.6850 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4657 - acc: 0.8267 - val_loss: 0.6794 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4657 - acc: 0.8265 - val_loss: 0.6722 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5744 - acc: 0.7941\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6958 - acc: 0.7400\n",
            "epsilon: 0.003 and test evaluation : 0.695797860622406, 0.7399650812149048\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7869 - acc: 0.7103\n",
            "epsilon: 0.005 and test evaluation : 0.7869159579277039, 0.7102966904640198\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.0425 - acc: 0.6126\n",
            "epsilon: 0.01 and test evaluation : 1.0425009727478027, 0.6125654578208923\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.6115 - acc: 0.4607\n",
            "epsilon: 0.02 and test evaluation : 1.611462950706482, 0.46073299646377563\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 1.4384 - acc: 0.3279 - val_loss: 1.3950 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3463 - acc: 0.3620 - val_loss: 1.3521 - val_acc: 0.3689 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3157 - acc: 0.3755 - val_loss: 1.3243 - val_acc: 0.4078 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3040 - acc: 0.3813 - val_loss: 1.3197 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2860 - acc: 0.3879 - val_loss: 1.3290 - val_acc: 0.3631 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2741 - acc: 0.4012 - val_loss: 1.2887 - val_acc: 0.3903 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2440 - acc: 0.4352 - val_loss: 1.3503 - val_acc: 0.3612 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2290 - acc: 0.4549 - val_loss: 1.3420 - val_acc: 0.3845 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2098 - acc: 0.4820 - val_loss: 1.1688 - val_acc: 0.5126 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1256 - acc: 0.5355 - val_loss: 1.2073 - val_acc: 0.4971 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1106 - acc: 0.5388 - val_loss: 1.0740 - val_acc: 0.5495 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0768 - acc: 0.5579 - val_loss: 1.0618 - val_acc: 0.5592 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0420 - acc: 0.5701 - val_loss: 1.7202 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9965 - acc: 0.6079 - val_loss: 1.0315 - val_acc: 0.5903 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9521 - acc: 0.6154 - val_loss: 1.0303 - val_acc: 0.5767 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.9131 - acc: 0.6314 - val_loss: 0.9634 - val_acc: 0.6019 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9215 - acc: 0.6261 - val_loss: 0.8799 - val_acc: 0.6291 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8656 - acc: 0.6642 - val_loss: 0.9001 - val_acc: 0.6350 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8371 - acc: 0.6698 - val_loss: 1.0059 - val_acc: 0.6019 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8324 - acc: 0.6869 - val_loss: 0.8769 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8017 - acc: 0.6871 - val_loss: 0.8395 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7900 - acc: 0.6922 - val_loss: 0.7939 - val_acc: 0.6854 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7638 - acc: 0.7071 - val_loss: 0.8768 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7455 - acc: 0.7233 - val_loss: 1.0093 - val_acc: 0.6369 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7575 - acc: 0.7079 - val_loss: 0.8399 - val_acc: 0.6951 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7221 - acc: 0.7275 - val_loss: 0.7867 - val_acc: 0.7087 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7074 - acc: 0.7270 - val_loss: 1.2165 - val_acc: 0.6019 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7163 - acc: 0.7253 - val_loss: 0.7636 - val_acc: 0.7126 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6730 - acc: 0.7486 - val_loss: 0.8492 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6780 - acc: 0.7481 - val_loss: 0.9905 - val_acc: 0.6233 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6806 - acc: 0.7428 - val_loss: 0.7259 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6155 - acc: 0.7790 - val_loss: 0.7250 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6004 - acc: 0.7801 - val_loss: 0.6907 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6002 - acc: 0.7801 - val_loss: 0.6987 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5893 - acc: 0.7894 - val_loss: 0.6879 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5854 - acc: 0.7889 - val_loss: 0.6808 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5789 - acc: 0.7887 - val_loss: 0.6707 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5683 - acc: 0.7958 - val_loss: 0.6765 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5648 - acc: 0.7898 - val_loss: 0.6639 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5610 - acc: 0.7972 - val_loss: 0.6840 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5615 - acc: 0.7992 - val_loss: 0.6845 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5567 - acc: 0.7998 - val_loss: 0.6762 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5487 - acc: 0.8060 - val_loss: 0.6747 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5499 - acc: 0.8020 - val_loss: 0.6744 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5565 - acc: 0.7925 - val_loss: 0.6820 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5522 - acc: 0.7972 - val_loss: 0.6654 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5411 - acc: 0.8032 - val_loss: 0.6530 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5399 - acc: 0.8018 - val_loss: 0.6879 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5336 - acc: 0.8060 - val_loss: 0.6547 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5283 - acc: 0.8076 - val_loss: 0.6690 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5340 - acc: 0.8071 - val_loss: 0.6532 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5234 - acc: 0.8045 - val_loss: 0.6537 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5301 - acc: 0.8091 - val_loss: 0.6829 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5191 - acc: 0.8058 - val_loss: 0.6529 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5280 - acc: 0.8049 - val_loss: 0.6647 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5214 - acc: 0.8084 - val_loss: 0.6714 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5245 - acc: 0.8096 - val_loss: 0.6678 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5259 - acc: 0.8083 - val_loss: 0.6651 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5181 - acc: 0.8111 - val_loss: 0.6434 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5172 - acc: 0.8107 - val_loss: 0.6774 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5062 - acc: 0.8111 - val_loss: 0.6458 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5098 - acc: 0.8136 - val_loss: 0.6469 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5074 - acc: 0.8078 - val_loss: 0.6475 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5113 - acc: 0.8118 - val_loss: 0.6512 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5076 - acc: 0.8074 - val_loss: 0.6509 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5061 - acc: 0.8114 - val_loss: 0.6481 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5138 - acc: 0.8147 - val_loss: 0.7435 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5075 - acc: 0.8149 - val_loss: 0.6443 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5099 - acc: 0.8109 - val_loss: 0.6620 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5126 - acc: 0.8076 - val_loss: 0.6502 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5195 - acc: 0.8065 - val_loss: 0.6415 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5064 - acc: 0.8158 - val_loss: 0.6493 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5129 - acc: 0.8087 - val_loss: 0.6733 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5087 - acc: 0.8191 - val_loss: 0.6818 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5044 - acc: 0.8145 - val_loss: 0.6849 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5183 - acc: 0.8111 - val_loss: 0.6534 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5036 - acc: 0.8127 - val_loss: 0.6439 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5110 - acc: 0.8134 - val_loss: 0.6378 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5166 - acc: 0.8118 - val_loss: 0.6495 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5076 - acc: 0.8120 - val_loss: 0.6519 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5015 - acc: 0.8129 - val_loss: 0.6451 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5039 - acc: 0.8114 - val_loss: 0.6421 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5049 - acc: 0.8198 - val_loss: 0.6692 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5118 - acc: 0.8129 - val_loss: 0.6515 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5073 - acc: 0.8160 - val_loss: 0.6592 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5121 - acc: 0.8109 - val_loss: 0.6510 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5113 - acc: 0.8138 - val_loss: 0.6358 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5067 - acc: 0.8154 - val_loss: 0.6379 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5115 - acc: 0.8165 - val_loss: 0.6454 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5079 - acc: 0.8134 - val_loss: 0.6747 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5101 - acc: 0.8127 - val_loss: 0.6542 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5061 - acc: 0.8105 - val_loss: 0.6643 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5094 - acc: 0.8114 - val_loss: 0.6540 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5019 - acc: 0.8171 - val_loss: 0.6443 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5094 - acc: 0.8178 - val_loss: 0.6554 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5000 - acc: 0.8180 - val_loss: 0.6404 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5057 - acc: 0.8109 - val_loss: 0.6496 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5088 - acc: 0.8138 - val_loss: 0.6479 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5081 - acc: 0.8185 - val_loss: 0.6358 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5066 - acc: 0.8136 - val_loss: 0.6382 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5020 - acc: 0.8185 - val_loss: 0.6468 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5098 - acc: 0.8100 - val_loss: 0.6492 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5073 - acc: 0.8096 - val_loss: 0.6451 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5123 - acc: 0.8136 - val_loss: 0.6430 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5013 - acc: 0.8167 - val_loss: 0.6496 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5068 - acc: 0.8096 - val_loss: 0.6623 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5070 - acc: 0.8147 - val_loss: 0.6497 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5035 - acc: 0.8089 - val_loss: 0.6469 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5089 - acc: 0.8151 - val_loss: 0.6432 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5072 - acc: 0.8147 - val_loss: 0.6603 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5142 - acc: 0.8123 - val_loss: 0.6580 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5127 - acc: 0.8069 - val_loss: 0.6591 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5077 - acc: 0.8167 - val_loss: 0.6471 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5089 - acc: 0.8096 - val_loss: 0.6452 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5074 - acc: 0.8140 - val_loss: 0.6536 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5118 - acc: 0.8105 - val_loss: 0.6500 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5142 - acc: 0.8134 - val_loss: 0.6364 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5070 - acc: 0.8127 - val_loss: 0.6592 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5016 - acc: 0.8196 - val_loss: 0.6532 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5100 - acc: 0.8114 - val_loss: 0.6603 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5115 - acc: 0.8089 - val_loss: 0.6541 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5006 - acc: 0.8169 - val_loss: 0.6698 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5072 - acc: 0.8107 - val_loss: 0.6726 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5037 - acc: 0.8116 - val_loss: 0.6504 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5095 - acc: 0.8074 - val_loss: 0.6524 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5075 - acc: 0.8131 - val_loss: 0.6421 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4959 - acc: 0.8140 - val_loss: 0.6341 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4974 - acc: 0.8158 - val_loss: 0.6539 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4997 - acc: 0.8175 - val_loss: 0.6714 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5010 - acc: 0.8171 - val_loss: 0.6602 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5129 - acc: 0.8127 - val_loss: 0.6594 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5148 - acc: 0.8065 - val_loss: 0.6547 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5098 - acc: 0.8136 - val_loss: 0.6483 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4977 - acc: 0.8165 - val_loss: 0.6504 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5054 - acc: 0.8142 - val_loss: 0.6393 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5099 - acc: 0.8089 - val_loss: 0.6404 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4971 - acc: 0.8174 - val_loss: 0.6870 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4985 - acc: 0.8154 - val_loss: 0.6700 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5019 - acc: 0.8127 - val_loss: 0.6554 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4985 - acc: 0.8168 - val_loss: 0.6484 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5050 - acc: 0.8111 - val_loss: 0.6339 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4986 - acc: 0.8169 - val_loss: 0.6451 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4979 - acc: 0.8160 - val_loss: 0.6553 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5009 - acc: 0.8149 - val_loss: 0.6447 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4948 - acc: 0.8178 - val_loss: 0.6369 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5047 - acc: 0.8220 - val_loss: 0.6390 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5093 - acc: 0.8098 - val_loss: 0.6388 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5059 - acc: 0.8167 - val_loss: 0.6647 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5086 - acc: 0.8129 - val_loss: 0.6762 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5080 - acc: 0.8165 - val_loss: 0.6455 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5055 - acc: 0.8134 - val_loss: 0.6375 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5101 - acc: 0.8145 - val_loss: 0.6428 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5118 - acc: 0.8047 - val_loss: 0.6348 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5156 - acc: 0.8091 - val_loss: 0.6599 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5047 - acc: 0.8118 - val_loss: 0.6866 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4922 - acc: 0.8191 - val_loss: 0.6396 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5123 - acc: 0.8091 - val_loss: 0.6495 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5019 - acc: 0.8158 - val_loss: 0.6392 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5067 - acc: 0.8127 - val_loss: 0.6359 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5015 - acc: 0.8174 - val_loss: 0.6882 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5069 - acc: 0.8123 - val_loss: 0.6429 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4975 - acc: 0.8165 - val_loss: 0.6537 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5138 - acc: 0.8032 - val_loss: 0.6539 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5061 - acc: 0.8131 - val_loss: 0.6462 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5032 - acc: 0.8149 - val_loss: 0.6478 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5010 - acc: 0.8194 - val_loss: 0.6406 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5035 - acc: 0.8125 - val_loss: 0.6646 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5032 - acc: 0.8167 - val_loss: 0.6488 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5050 - acc: 0.8149 - val_loss: 0.6623 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5044 - acc: 0.8142 - val_loss: 0.6552 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5034 - acc: 0.8149 - val_loss: 0.6640 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5049 - acc: 0.8091 - val_loss: 0.6573 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5040 - acc: 0.8156 - val_loss: 0.6491 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5001 - acc: 0.8118 - val_loss: 0.6780 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5064 - acc: 0.8174 - val_loss: 0.6361 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4930 - acc: 0.8151 - val_loss: 0.6502 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4964 - acc: 0.8111 - val_loss: 0.6654 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5062 - acc: 0.8096 - val_loss: 0.6744 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5076 - acc: 0.8127 - val_loss: 0.6451 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4985 - acc: 0.8176 - val_loss: 0.6353 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5050 - acc: 0.8156 - val_loss: 0.6557 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5041 - acc: 0.8116 - val_loss: 0.6525 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4958 - acc: 0.8198 - val_loss: 0.6712 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5108 - acc: 0.8109 - val_loss: 0.6319 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4936 - acc: 0.8182 - val_loss: 0.6483 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4929 - acc: 0.8213 - val_loss: 0.6611 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5074 - acc: 0.8169 - val_loss: 0.7419 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4964 - acc: 0.8140 - val_loss: 0.6502 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5167 - acc: 0.8107 - val_loss: 0.6402 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5058 - acc: 0.8091 - val_loss: 0.6723 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5022 - acc: 0.8178 - val_loss: 0.6358 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5050 - acc: 0.8114 - val_loss: 0.6769 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4937 - acc: 0.8182 - val_loss: 0.6473 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5018 - acc: 0.8125 - val_loss: 0.6392 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5116 - acc: 0.8107 - val_loss: 0.6427 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4971 - acc: 0.8111 - val_loss: 0.6724 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5010 - acc: 0.8096 - val_loss: 0.6369 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5068 - acc: 0.8140 - val_loss: 0.6749 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5010 - acc: 0.8165 - val_loss: 0.6383 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5091 - acc: 0.8162 - val_loss: 0.6445 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5650 - acc: 0.7923\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6773 - acc: 0.7435\n",
            "epsilon: 0.003 and test evaluation : 0.6773117184638977, 0.7434554696083069\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7614 - acc: 0.7086\n",
            "epsilon: 0.005 and test evaluation : 0.7613782286643982, 0.7085514664649963\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.9961 - acc: 0.6370\n",
            "epsilon: 0.01 and test evaluation : 0.9960619211196899, 0.6369982361793518\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.5059 - acc: 0.4852\n",
            "epsilon: 0.02 and test evaluation : 1.5058622360229492, 0.4851658046245575\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 1.4520 - acc: 0.3236 - val_loss: 1.4636 - val_acc: 0.2544 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.3531 - acc: 0.3640 - val_loss: 1.3667 - val_acc: 0.3437 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3187 - acc: 0.3810 - val_loss: 1.3185 - val_acc: 0.3437 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3018 - acc: 0.3817 - val_loss: 1.3284 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2838 - acc: 0.3966 - val_loss: 1.3303 - val_acc: 0.3573 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2678 - acc: 0.4197 - val_loss: 1.2347 - val_acc: 0.4447 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2419 - acc: 0.4403 - val_loss: 1.3809 - val_acc: 0.3476 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2170 - acc: 0.4776 - val_loss: 1.3430 - val_acc: 0.4447 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1646 - acc: 0.5064 - val_loss: 1.1778 - val_acc: 0.5029 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1186 - acc: 0.5366 - val_loss: 1.0744 - val_acc: 0.5515 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0614 - acc: 0.5664 - val_loss: 1.1308 - val_acc: 0.5107 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0351 - acc: 0.5850 - val_loss: 1.0047 - val_acc: 0.5825 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9730 - acc: 0.6158 - val_loss: 1.0132 - val_acc: 0.5301 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.9792 - acc: 0.6003 - val_loss: 0.9901 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.9377 - acc: 0.6229 - val_loss: 0.8279 - val_acc: 0.6369 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8777 - acc: 0.6580 - val_loss: 0.7796 - val_acc: 0.6660 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8736 - acc: 0.6527 - val_loss: 0.8219 - val_acc: 0.6583 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8355 - acc: 0.6691 - val_loss: 0.9852 - val_acc: 0.5845 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8450 - acc: 0.6767 - val_loss: 0.7352 - val_acc: 0.7126 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8005 - acc: 0.6973 - val_loss: 1.3455 - val_acc: 0.5320 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7974 - acc: 0.6944 - val_loss: 0.7001 - val_acc: 0.7359 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7695 - acc: 0.7006 - val_loss: 0.7117 - val_acc: 0.7184 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7550 - acc: 0.7024 - val_loss: 0.7760 - val_acc: 0.6777 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7681 - acc: 0.7057 - val_loss: 0.7126 - val_acc: 0.7379 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7358 - acc: 0.7199 - val_loss: 0.8764 - val_acc: 0.6777 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7390 - acc: 0.7173 - val_loss: 0.9295 - val_acc: 0.6524 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7672 - acc: 0.7026 - val_loss: 0.6508 - val_acc: 0.7650 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7104 - acc: 0.7304 - val_loss: 0.8053 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7057 - acc: 0.7310 - val_loss: 0.7080 - val_acc: 0.7534 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6941 - acc: 0.7383 - val_loss: 0.7216 - val_acc: 0.7282 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7304 - acc: 0.7157 - val_loss: 0.6724 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6604 - acc: 0.7489 - val_loss: 0.6152 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6292 - acc: 0.7641 - val_loss: 0.5850 - val_acc: 0.7903 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6104 - acc: 0.7665 - val_loss: 0.5932 - val_acc: 0.7864 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5921 - acc: 0.7818 - val_loss: 0.5941 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5966 - acc: 0.7794 - val_loss: 0.5796 - val_acc: 0.7903 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5792 - acc: 0.7876 - val_loss: 0.5989 - val_acc: 0.7845 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5812 - acc: 0.7858 - val_loss: 0.5813 - val_acc: 0.7981 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5770 - acc: 0.7914 - val_loss: 0.5676 - val_acc: 0.8019 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5685 - acc: 0.7912 - val_loss: 0.6419 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5662 - acc: 0.7949 - val_loss: 0.5628 - val_acc: 0.8155 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5602 - acc: 0.7956 - val_loss: 0.5857 - val_acc: 0.8000 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5581 - acc: 0.7901 - val_loss: 0.5726 - val_acc: 0.8136 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5557 - acc: 0.7932 - val_loss: 0.5665 - val_acc: 0.8155 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5517 - acc: 0.8023 - val_loss: 0.5599 - val_acc: 0.8039 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5437 - acc: 0.8016 - val_loss: 0.5680 - val_acc: 0.8117 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5510 - acc: 0.7952 - val_loss: 0.5774 - val_acc: 0.8039 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.5494 - acc: 0.8005 - val_loss: 0.5539 - val_acc: 0.8136 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5441 - acc: 0.8009 - val_loss: 0.5638 - val_acc: 0.8078 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5433 - acc: 0.8005 - val_loss: 0.5780 - val_acc: 0.7942 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5425 - acc: 0.8063 - val_loss: 0.6089 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5358 - acc: 0.7980 - val_loss: 0.5740 - val_acc: 0.8058 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5375 - acc: 0.8045 - val_loss: 0.5561 - val_acc: 0.8155 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5318 - acc: 0.8084 - val_loss: 0.5748 - val_acc: 0.8058 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5361 - acc: 0.7983 - val_loss: 0.5986 - val_acc: 0.7961 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5264 - acc: 0.8069 - val_loss: 0.6263 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5226 - acc: 0.8107 - val_loss: 0.5480 - val_acc: 0.8136 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5217 - acc: 0.8060 - val_loss: 0.5772 - val_acc: 0.8058 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5227 - acc: 0.8074 - val_loss: 0.5964 - val_acc: 0.7903 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5209 - acc: 0.8040 - val_loss: 0.5797 - val_acc: 0.7942 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5163 - acc: 0.8094 - val_loss: 0.5858 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5083 - acc: 0.8138 - val_loss: 0.5665 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5180 - acc: 0.8096 - val_loss: 0.5591 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5150 - acc: 0.8131 - val_loss: 0.5745 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5190 - acc: 0.8049 - val_loss: 0.5931 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5200 - acc: 0.8076 - val_loss: 0.5645 - val_acc: 0.8097 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5112 - acc: 0.8078 - val_loss: 0.5510 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5138 - acc: 0.8131 - val_loss: 0.5625 - val_acc: 0.8078 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5213 - acc: 0.8089 - val_loss: 0.5864 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5155 - acc: 0.8111 - val_loss: 0.5503 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5121 - acc: 0.8125 - val_loss: 0.5868 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5173 - acc: 0.8085 - val_loss: 0.5906 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5186 - acc: 0.8120 - val_loss: 0.5723 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5167 - acc: 0.8094 - val_loss: 0.5479 - val_acc: 0.8078 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5092 - acc: 0.8138 - val_loss: 0.5621 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5106 - acc: 0.8105 - val_loss: 0.5610 - val_acc: 0.8097 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5196 - acc: 0.8045 - val_loss: 0.6218 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5099 - acc: 0.8162 - val_loss: 0.5736 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5134 - acc: 0.8091 - val_loss: 0.5845 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5097 - acc: 0.8100 - val_loss: 0.6051 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5065 - acc: 0.8091 - val_loss: 0.5975 - val_acc: 0.8097 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5124 - acc: 0.8160 - val_loss: 0.5582 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5112 - acc: 0.8105 - val_loss: 0.5578 - val_acc: 0.8214 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5188 - acc: 0.8051 - val_loss: 0.5533 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5154 - acc: 0.8051 - val_loss: 0.5639 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5123 - acc: 0.8162 - val_loss: 0.5719 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5203 - acc: 0.8060 - val_loss: 0.5559 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5118 - acc: 0.8111 - val_loss: 0.5779 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5243 - acc: 0.8016 - val_loss: 0.5891 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5250 - acc: 0.8043 - val_loss: 0.5401 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5152 - acc: 0.8083 - val_loss: 0.5675 - val_acc: 0.8214 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5173 - acc: 0.8089 - val_loss: 0.5711 - val_acc: 0.8078 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5097 - acc: 0.8078 - val_loss: 0.5506 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5178 - acc: 0.8049 - val_loss: 0.5460 - val_acc: 0.8233 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5108 - acc: 0.8134 - val_loss: 0.5490 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5180 - acc: 0.8047 - val_loss: 0.5413 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5145 - acc: 0.8098 - val_loss: 0.5503 - val_acc: 0.8078 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5122 - acc: 0.8089 - val_loss: 0.5968 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5118 - acc: 0.8149 - val_loss: 0.5772 - val_acc: 0.8136 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5143 - acc: 0.8111 - val_loss: 0.5626 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5096 - acc: 0.8107 - val_loss: 0.5799 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5109 - acc: 0.8158 - val_loss: 0.5519 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5114 - acc: 0.8156 - val_loss: 0.5664 - val_acc: 0.8233 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5097 - acc: 0.8123 - val_loss: 0.5547 - val_acc: 0.8078 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5122 - acc: 0.8085 - val_loss: 0.5691 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5091 - acc: 0.8123 - val_loss: 0.5804 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5160 - acc: 0.8074 - val_loss: 0.5898 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5129 - acc: 0.8087 - val_loss: 0.5597 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5080 - acc: 0.8078 - val_loss: 0.5987 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5113 - acc: 0.8125 - val_loss: 0.5838 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5170 - acc: 0.8005 - val_loss: 0.5903 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5120 - acc: 0.8067 - val_loss: 0.5613 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5179 - acc: 0.8069 - val_loss: 0.5524 - val_acc: 0.8252 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5204 - acc: 0.8058 - val_loss: 0.5696 - val_acc: 0.8136 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5070 - acc: 0.8138 - val_loss: 0.5949 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5125 - acc: 0.8120 - val_loss: 0.5700 - val_acc: 0.8136 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5126 - acc: 0.8069 - val_loss: 0.5527 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5127 - acc: 0.8100 - val_loss: 0.5832 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5149 - acc: 0.8103 - val_loss: 0.6155 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5094 - acc: 0.8129 - val_loss: 0.5613 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5153 - acc: 0.8071 - val_loss: 0.5706 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5102 - acc: 0.8107 - val_loss: 0.5389 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5176 - acc: 0.8138 - val_loss: 0.5801 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5060 - acc: 0.8132 - val_loss: 0.5482 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5161 - acc: 0.8096 - val_loss: 0.5728 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5110 - acc: 0.8162 - val_loss: 0.5536 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5109 - acc: 0.8120 - val_loss: 0.5601 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5140 - acc: 0.8127 - val_loss: 0.5431 - val_acc: 0.8097 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5194 - acc: 0.8074 - val_loss: 0.5743 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5186 - acc: 0.8036 - val_loss: 0.5550 - val_acc: 0.8233 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5077 - acc: 0.8145 - val_loss: 0.6297 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5136 - acc: 0.8127 - val_loss: 0.6037 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5122 - acc: 0.8056 - val_loss: 0.5711 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5155 - acc: 0.8109 - val_loss: 0.5470 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5069 - acc: 0.8105 - val_loss: 0.5408 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5081 - acc: 0.8114 - val_loss: 0.5759 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5151 - acc: 0.8091 - val_loss: 0.5618 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5098 - acc: 0.8071 - val_loss: 0.5896 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5142 - acc: 0.8051 - val_loss: 0.5755 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5221 - acc: 0.7978 - val_loss: 0.5660 - val_acc: 0.8136 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5158 - acc: 0.8089 - val_loss: 0.6082 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5043 - acc: 0.8105 - val_loss: 0.5718 - val_acc: 0.8136 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5082 - acc: 0.8174 - val_loss: 0.5675 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5120 - acc: 0.8083 - val_loss: 0.5787 - val_acc: 0.8097 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5024 - acc: 0.8158 - val_loss: 0.5643 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5109 - acc: 0.8071 - val_loss: 0.5759 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5124 - acc: 0.8140 - val_loss: 0.5550 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5053 - acc: 0.8125 - val_loss: 0.6064 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5095 - acc: 0.8096 - val_loss: 0.5419 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5089 - acc: 0.8087 - val_loss: 0.5566 - val_acc: 0.8272 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5091 - acc: 0.8165 - val_loss: 0.5758 - val_acc: 0.8097 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5102 - acc: 0.8078 - val_loss: 0.6139 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5047 - acc: 0.8134 - val_loss: 0.5559 - val_acc: 0.8233 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5123 - acc: 0.8080 - val_loss: 0.5565 - val_acc: 0.8233 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5127 - acc: 0.8103 - val_loss: 0.5473 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5119 - acc: 0.8116 - val_loss: 0.5332 - val_acc: 0.8136 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5096 - acc: 0.8154 - val_loss: 0.5609 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5110 - acc: 0.8109 - val_loss: 0.5433 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5092 - acc: 0.8103 - val_loss: 0.6068 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5160 - acc: 0.8076 - val_loss: 0.5971 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5123 - acc: 0.8098 - val_loss: 0.5514 - val_acc: 0.8214 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5069 - acc: 0.8140 - val_loss: 0.5482 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4984 - acc: 0.8100 - val_loss: 0.5554 - val_acc: 0.8214 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5167 - acc: 0.8049 - val_loss: 0.6048 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5044 - acc: 0.8149 - val_loss: 0.5664 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5083 - acc: 0.8125 - val_loss: 0.6088 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5066 - acc: 0.8098 - val_loss: 0.5553 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5037 - acc: 0.8136 - val_loss: 0.6085 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5106 - acc: 0.8125 - val_loss: 0.5929 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5142 - acc: 0.8105 - val_loss: 0.5573 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5112 - acc: 0.8142 - val_loss: 0.5676 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5129 - acc: 0.8045 - val_loss: 0.5856 - val_acc: 0.8136 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5041 - acc: 0.8136 - val_loss: 0.5833 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5080 - acc: 0.8096 - val_loss: 0.6169 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5115 - acc: 0.8100 - val_loss: 0.5584 - val_acc: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4972 - acc: 0.8136 - val_loss: 0.5539 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5103 - acc: 0.8131 - val_loss: 0.5522 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5117 - acc: 0.8160 - val_loss: 0.5335 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5122 - acc: 0.8065 - val_loss: 0.5973 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5136 - acc: 0.8076 - val_loss: 0.5621 - val_acc: 0.8214 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5181 - acc: 0.8045 - val_loss: 0.5579 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5075 - acc: 0.8083 - val_loss: 0.5801 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5103 - acc: 0.8107 - val_loss: 0.5690 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5060 - acc: 0.8145 - val_loss: 0.5676 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5117 - acc: 0.8040 - val_loss: 0.5857 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5076 - acc: 0.8100 - val_loss: 0.5563 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5065 - acc: 0.8154 - val_loss: 0.5549 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5043 - acc: 0.8182 - val_loss: 0.5461 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5090 - acc: 0.8136 - val_loss: 0.5545 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5094 - acc: 0.8109 - val_loss: 0.5783 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5114 - acc: 0.8089 - val_loss: 0.5688 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5015 - acc: 0.8145 - val_loss: 0.5751 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5012 - acc: 0.8140 - val_loss: 0.5507 - val_acc: 0.8155 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5050 - acc: 0.8065 - val_loss: 0.5658 - val_acc: 0.8078 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5173 - acc: 0.8027 - val_loss: 0.5885 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5083 - acc: 0.8129 - val_loss: 0.5709 - val_acc: 0.8117 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5075 - acc: 0.8176 - val_loss: 0.5653 - val_acc: 0.8194 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5027 - acc: 0.8176 - val_loss: 0.6175 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5053 - acc: 0.8134 - val_loss: 0.5952 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5049 - acc: 0.8160 - val_loss: 0.5789 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6583 - acc: 0.7504\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7857 - acc: 0.7120\n",
            "epsilon: 0.003 and test evaluation : 0.7857383489608765, 0.7120419144630432\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8785 - acc: 0.6824\n",
            "epsilon: 0.005 and test evaluation : 0.8784926533699036, 0.6823734641075134\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.1319 - acc: 0.6073\n",
            "epsilon: 0.01 and test evaluation : 1.1319059133529663, 0.6073298454284668\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.6889 - acc: 0.4590\n",
            "epsilon: 0.02 and test evaluation : 1.6889249086380005, 0.4589877724647522\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 1.4440 - acc: 0.3298 - val_loss: 1.3705 - val_acc: 0.3437 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.3521 - acc: 0.3684 - val_loss: 1.4212 - val_acc: 0.2544 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3218 - acc: 0.3761 - val_loss: 1.4051 - val_acc: 0.3379 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.3036 - acc: 0.3810 - val_loss: 1.2589 - val_acc: 0.3942 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2778 - acc: 0.4041 - val_loss: 1.2551 - val_acc: 0.4524 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2708 - acc: 0.4192 - val_loss: 1.3230 - val_acc: 0.4718 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2215 - acc: 0.4663 - val_loss: 1.2541 - val_acc: 0.4524 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1851 - acc: 0.4953 - val_loss: 1.4961 - val_acc: 0.3495 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1458 - acc: 0.5166 - val_loss: 1.1696 - val_acc: 0.4777 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0889 - acc: 0.5568 - val_loss: 1.0956 - val_acc: 0.5728 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0666 - acc: 0.5719 - val_loss: 1.0781 - val_acc: 0.5573 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0202 - acc: 0.5910 - val_loss: 1.0852 - val_acc: 0.5631 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9760 - acc: 0.6028 - val_loss: 0.9994 - val_acc: 0.5942 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9681 - acc: 0.6158 - val_loss: 0.9206 - val_acc: 0.6272 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8929 - acc: 0.6482 - val_loss: 1.0481 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8838 - acc: 0.6531 - val_loss: 0.9467 - val_acc: 0.6291 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8437 - acc: 0.6684 - val_loss: 0.8144 - val_acc: 0.6621 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8124 - acc: 0.6858 - val_loss: 0.8769 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8035 - acc: 0.6873 - val_loss: 0.8289 - val_acc: 0.6971 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7842 - acc: 0.6971 - val_loss: 0.9103 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7837 - acc: 0.6962 - val_loss: 0.7780 - val_acc: 0.7301 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7478 - acc: 0.7079 - val_loss: 0.8615 - val_acc: 0.6777 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7527 - acc: 0.7130 - val_loss: 1.0271 - val_acc: 0.6136 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7267 - acc: 0.7268 - val_loss: 0.8227 - val_acc: 0.7107 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.7118 - acc: 0.7210 - val_loss: 0.7425 - val_acc: 0.7379 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7067 - acc: 0.7355 - val_loss: 0.7430 - val_acc: 0.7340 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6916 - acc: 0.7310 - val_loss: 0.7722 - val_acc: 0.7126 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6854 - acc: 0.7370 - val_loss: 0.7778 - val_acc: 0.7107 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6635 - acc: 0.7554 - val_loss: 0.7312 - val_acc: 0.7262 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6566 - acc: 0.7577 - val_loss: 0.7686 - val_acc: 0.7068 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7633 - acc: 0.7013 - val_loss: 0.9210 - val_acc: 0.6738 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6802 - acc: 0.7457 - val_loss: 0.7151 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6366 - acc: 0.7623 - val_loss: 0.7131 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6123 - acc: 0.7743 - val_loss: 0.6733 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6007 - acc: 0.7723 - val_loss: 0.6484 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5887 - acc: 0.7845 - val_loss: 0.6610 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5707 - acc: 0.7901 - val_loss: 0.6639 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5749 - acc: 0.7830 - val_loss: 0.7077 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5664 - acc: 0.7921 - val_loss: 0.6477 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5615 - acc: 0.7927 - val_loss: 0.6420 - val_acc: 0.7748 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5508 - acc: 0.7994 - val_loss: 0.6375 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5524 - acc: 0.7929 - val_loss: 0.6499 - val_acc: 0.7786 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5469 - acc: 0.8003 - val_loss: 0.6436 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5475 - acc: 0.7978 - val_loss: 0.6612 - val_acc: 0.7786 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5278 - acc: 0.8069 - val_loss: 0.6265 - val_acc: 0.7806 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5325 - acc: 0.8019 - val_loss: 0.6390 - val_acc: 0.7806 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5307 - acc: 0.8091 - val_loss: 0.6749 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5325 - acc: 0.8116 - val_loss: 0.6571 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5220 - acc: 0.8049 - val_loss: 0.6167 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5206 - acc: 0.8083 - val_loss: 0.6341 - val_acc: 0.7767 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5150 - acc: 0.8154 - val_loss: 0.6152 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5188 - acc: 0.8151 - val_loss: 0.6354 - val_acc: 0.7806 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5101 - acc: 0.8147 - val_loss: 0.6152 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5106 - acc: 0.8180 - val_loss: 0.6063 - val_acc: 0.7806 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5122 - acc: 0.8114 - val_loss: 0.6131 - val_acc: 0.7883 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5016 - acc: 0.8162 - val_loss: 0.6165 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5050 - acc: 0.8174 - val_loss: 0.6262 - val_acc: 0.7883 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4972 - acc: 0.8251 - val_loss: 0.6401 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4916 - acc: 0.8196 - val_loss: 0.5982 - val_acc: 0.7845 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4945 - acc: 0.8156 - val_loss: 0.6003 - val_acc: 0.7845 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4898 - acc: 0.8260 - val_loss: 0.6045 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4949 - acc: 0.8196 - val_loss: 0.6216 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4935 - acc: 0.8233 - val_loss: 0.6111 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4938 - acc: 0.8231 - val_loss: 0.6229 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4959 - acc: 0.8162 - val_loss: 0.6008 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4987 - acc: 0.8216 - val_loss: 0.6051 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4930 - acc: 0.8182 - val_loss: 0.6203 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4842 - acc: 0.8236 - val_loss: 0.6246 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4854 - acc: 0.8216 - val_loss: 0.6297 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4947 - acc: 0.8218 - val_loss: 0.6645 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4997 - acc: 0.8171 - val_loss: 0.6143 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4921 - acc: 0.8185 - val_loss: 0.6274 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4903 - acc: 0.8249 - val_loss: 0.6130 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4853 - acc: 0.8233 - val_loss: 0.6514 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4928 - acc: 0.8267 - val_loss: 0.6023 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4927 - acc: 0.8236 - val_loss: 0.6161 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4941 - acc: 0.8222 - val_loss: 0.6065 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4933 - acc: 0.8245 - val_loss: 0.6095 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4918 - acc: 0.8194 - val_loss: 0.6046 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4943 - acc: 0.8162 - val_loss: 0.6223 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4829 - acc: 0.8218 - val_loss: 0.5955 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4920 - acc: 0.8182 - val_loss: 0.6389 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4870 - acc: 0.8251 - val_loss: 0.6526 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4907 - acc: 0.8207 - val_loss: 0.6148 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4913 - acc: 0.8220 - val_loss: 0.6217 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4844 - acc: 0.8220 - val_loss: 0.6076 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4746 - acc: 0.8258 - val_loss: 0.6142 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4882 - acc: 0.8194 - val_loss: 0.6579 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4871 - acc: 0.8187 - val_loss: 0.6120 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4960 - acc: 0.8218 - val_loss: 0.6794 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4842 - acc: 0.8213 - val_loss: 0.6363 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4905 - acc: 0.8176 - val_loss: 0.5986 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4823 - acc: 0.8225 - val_loss: 0.6000 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4848 - acc: 0.8253 - val_loss: 0.6199 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4858 - acc: 0.8216 - val_loss: 0.6144 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4896 - acc: 0.8216 - val_loss: 0.6022 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4859 - acc: 0.8210 - val_loss: 0.6101 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4940 - acc: 0.8256 - val_loss: 0.6332 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4895 - acc: 0.8225 - val_loss: 0.6559 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4845 - acc: 0.8182 - val_loss: 0.6080 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4901 - acc: 0.8192 - val_loss: 0.6208 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4863 - acc: 0.8196 - val_loss: 0.6299 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4926 - acc: 0.8200 - val_loss: 0.6228 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4786 - acc: 0.8265 - val_loss: 0.6701 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4839 - acc: 0.8233 - val_loss: 0.6039 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4874 - acc: 0.8187 - val_loss: 0.6009 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4875 - acc: 0.8213 - val_loss: 0.6103 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4849 - acc: 0.8211 - val_loss: 0.6163 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4954 - acc: 0.8180 - val_loss: 0.6292 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4908 - acc: 0.8258 - val_loss: 0.5995 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4864 - acc: 0.8207 - val_loss: 0.5970 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4895 - acc: 0.8200 - val_loss: 0.6073 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4831 - acc: 0.8233 - val_loss: 0.6378 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4896 - acc: 0.8222 - val_loss: 0.5934 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4948 - acc: 0.8182 - val_loss: 0.6135 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4901 - acc: 0.8194 - val_loss: 0.6075 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4870 - acc: 0.8176 - val_loss: 0.6002 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4912 - acc: 0.8198 - val_loss: 0.6090 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4923 - acc: 0.8218 - val_loss: 0.6128 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4834 - acc: 0.8242 - val_loss: 0.6144 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4742 - acc: 0.8267 - val_loss: 0.5980 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4832 - acc: 0.8222 - val_loss: 0.5942 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4795 - acc: 0.8282 - val_loss: 0.6388 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4869 - acc: 0.8191 - val_loss: 0.6962 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4848 - acc: 0.8185 - val_loss: 0.6216 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4895 - acc: 0.8160 - val_loss: 0.6102 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4890 - acc: 0.8233 - val_loss: 0.6259 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4830 - acc: 0.8225 - val_loss: 0.6079 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4831 - acc: 0.8213 - val_loss: 0.6062 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4880 - acc: 0.8194 - val_loss: 0.6047 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4859 - acc: 0.8196 - val_loss: 0.6025 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4862 - acc: 0.8213 - val_loss: 0.6114 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4830 - acc: 0.8236 - val_loss: 0.5946 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4815 - acc: 0.8236 - val_loss: 0.5957 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4923 - acc: 0.8233 - val_loss: 0.6354 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4833 - acc: 0.8251 - val_loss: 0.6024 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4902 - acc: 0.8154 - val_loss: 0.6183 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4850 - acc: 0.8265 - val_loss: 0.6054 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4921 - acc: 0.8207 - val_loss: 0.6012 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4844 - acc: 0.8233 - val_loss: 0.6307 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4848 - acc: 0.8269 - val_loss: 0.6140 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4868 - acc: 0.8182 - val_loss: 0.6183 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4826 - acc: 0.8227 - val_loss: 0.6004 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4881 - acc: 0.8236 - val_loss: 0.6091 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4866 - acc: 0.8211 - val_loss: 0.6201 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4885 - acc: 0.8145 - val_loss: 0.6279 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4876 - acc: 0.8207 - val_loss: 0.6587 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4886 - acc: 0.8220 - val_loss: 0.6569 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4813 - acc: 0.8211 - val_loss: 0.6163 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4915 - acc: 0.8151 - val_loss: 0.5999 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4856 - acc: 0.8196 - val_loss: 0.6589 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4884 - acc: 0.8225 - val_loss: 0.6267 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4807 - acc: 0.8227 - val_loss: 0.5945 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4922 - acc: 0.8154 - val_loss: 0.5962 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4842 - acc: 0.8198 - val_loss: 0.6044 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4839 - acc: 0.8227 - val_loss: 0.6130 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4765 - acc: 0.8260 - val_loss: 0.6006 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4823 - acc: 0.8267 - val_loss: 0.6054 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4927 - acc: 0.8185 - val_loss: 0.6015 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4904 - acc: 0.8216 - val_loss: 0.6162 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4832 - acc: 0.8225 - val_loss: 0.6180 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4789 - acc: 0.8238 - val_loss: 0.6317 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4862 - acc: 0.8182 - val_loss: 0.6103 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4862 - acc: 0.8198 - val_loss: 0.6311 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4820 - acc: 0.8251 - val_loss: 0.6012 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4845 - acc: 0.8220 - val_loss: 0.6016 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4820 - acc: 0.8227 - val_loss: 0.6080 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4801 - acc: 0.8222 - val_loss: 0.6113 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4820 - acc: 0.8291 - val_loss: 0.6723 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4692 - acc: 0.8293 - val_loss: 0.6129 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4809 - acc: 0.8222 - val_loss: 0.6586 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4762 - acc: 0.8202 - val_loss: 0.6093 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4889 - acc: 0.8236 - val_loss: 0.6259 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4819 - acc: 0.8229 - val_loss: 0.6457 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4865 - acc: 0.8171 - val_loss: 0.6581 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4831 - acc: 0.8238 - val_loss: 0.6330 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4829 - acc: 0.8262 - val_loss: 0.6074 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4810 - acc: 0.8267 - val_loss: 0.5935 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4807 - acc: 0.8242 - val_loss: 0.6071 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4825 - acc: 0.8209 - val_loss: 0.5996 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4772 - acc: 0.8207 - val_loss: 0.6016 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4795 - acc: 0.8293 - val_loss: 0.6154 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4826 - acc: 0.8213 - val_loss: 0.6551 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4834 - acc: 0.8225 - val_loss: 0.6233 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4822 - acc: 0.8233 - val_loss: 0.6186 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4862 - acc: 0.8187 - val_loss: 0.6077 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4775 - acc: 0.8276 - val_loss: 0.6068 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4842 - acc: 0.8247 - val_loss: 0.6011 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4848 - acc: 0.8213 - val_loss: 0.5920 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4806 - acc: 0.8242 - val_loss: 0.6503 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4749 - acc: 0.8222 - val_loss: 0.6112 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4841 - acc: 0.8238 - val_loss: 0.6317 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4764 - acc: 0.8271 - val_loss: 1.0062 - val_acc: 0.6835 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4767 - acc: 0.8311 - val_loss: 0.6564 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4756 - acc: 0.8220 - val_loss: 0.6641 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4827 - acc: 0.8213 - val_loss: 0.6132 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4877 - acc: 0.8207 - val_loss: 0.6162 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4777 - acc: 0.8218 - val_loss: 0.6290 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4791 - acc: 0.8249 - val_loss: 0.6148 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4840 - acc: 0.8258 - val_loss: 0.6112 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5888 - acc: 0.7853\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7180 - acc: 0.7365\n",
            "epsilon: 0.003 and test evaluation : 0.7180300354957581, 0.7364746928215027\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8155 - acc: 0.6928\n",
            "epsilon: 0.005 and test evaluation : 0.8155299425125122, 0.6928446888923645\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.0838 - acc: 0.6195\n",
            "epsilon: 0.01 and test evaluation : 1.083767056465149, 0.6195462346076965\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.6558 - acc: 0.4764\n",
            "epsilon: 0.02 and test evaluation : 1.6558116674423218, 0.47643980383872986\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 1.4336 - acc: 0.3453 - val_loss: 1.4241 - val_acc: 0.3029 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3469 - acc: 0.3697 - val_loss: 1.3095 - val_acc: 0.3359 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3195 - acc: 0.3886 - val_loss: 1.3711 - val_acc: 0.3748 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3087 - acc: 0.3817 - val_loss: 1.2733 - val_acc: 0.3748 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.2896 - acc: 0.3948 - val_loss: 1.2788 - val_acc: 0.3903 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2930 - acc: 0.3979 - val_loss: 1.2645 - val_acc: 0.3631 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2795 - acc: 0.3885 - val_loss: 1.2514 - val_acc: 0.3922 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2607 - acc: 0.4152 - val_loss: 1.2717 - val_acc: 0.4058 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2482 - acc: 0.4203 - val_loss: 1.2562 - val_acc: 0.4019 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2346 - acc: 0.4312 - val_loss: 1.2838 - val_acc: 0.4000 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2055 - acc: 0.4638 - val_loss: 1.2188 - val_acc: 0.4019 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1739 - acc: 0.5029 - val_loss: 1.2436 - val_acc: 0.4252 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1106 - acc: 0.5362 - val_loss: 1.0545 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0604 - acc: 0.5646 - val_loss: 1.3798 - val_acc: 0.4505 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.0060 - acc: 0.5930 - val_loss: 1.2752 - val_acc: 0.5359 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9680 - acc: 0.6063 - val_loss: 1.2711 - val_acc: 0.5476 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9427 - acc: 0.6143 - val_loss: 1.2353 - val_acc: 0.5398 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8709 - acc: 0.6669 - val_loss: 1.2566 - val_acc: 0.5398 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8610 - acc: 0.6605 - val_loss: 0.9556 - val_acc: 0.6233 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8392 - acc: 0.6831 - val_loss: 0.8118 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8107 - acc: 0.6904 - val_loss: 0.9077 - val_acc: 0.6408 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7994 - acc: 0.6858 - val_loss: 1.3394 - val_acc: 0.5184 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7972 - acc: 0.6937 - val_loss: 0.8500 - val_acc: 0.6583 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7784 - acc: 0.6933 - val_loss: 0.7857 - val_acc: 0.7223 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7540 - acc: 0.7053 - val_loss: 0.7509 - val_acc: 0.7184 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7387 - acc: 0.7164 - val_loss: 0.7459 - val_acc: 0.7049 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7230 - acc: 0.7199 - val_loss: 1.1137 - val_acc: 0.6233 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7348 - acc: 0.7157 - val_loss: 0.8601 - val_acc: 0.6641 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7175 - acc: 0.7193 - val_loss: 0.7392 - val_acc: 0.7301 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6860 - acc: 0.7361 - val_loss: 0.9173 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8219 - acc: 0.6804 - val_loss: 0.7810 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6355 - acc: 0.7601 - val_loss: 0.6915 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6153 - acc: 0.7676 - val_loss: 0.6917 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6099 - acc: 0.7732 - val_loss: 0.6972 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6055 - acc: 0.7679 - val_loss: 0.6810 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5888 - acc: 0.7736 - val_loss: 0.6893 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5893 - acc: 0.7781 - val_loss: 0.6821 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5787 - acc: 0.7825 - val_loss: 0.6659 - val_acc: 0.7748 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5741 - acc: 0.7905 - val_loss: 0.7012 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5740 - acc: 0.7836 - val_loss: 0.6730 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5695 - acc: 0.7830 - val_loss: 0.6708 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5710 - acc: 0.7905 - val_loss: 0.6804 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5719 - acc: 0.7858 - val_loss: 0.6555 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5729 - acc: 0.7892 - val_loss: 0.6637 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5601 - acc: 0.7947 - val_loss: 0.6916 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5526 - acc: 0.7980 - val_loss: 0.6647 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5625 - acc: 0.7909 - val_loss: 0.6645 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5473 - acc: 0.7956 - val_loss: 0.6563 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5615 - acc: 0.7954 - val_loss: 0.6663 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5471 - acc: 0.7936 - val_loss: 0.6575 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5521 - acc: 0.7960 - val_loss: 0.6655 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5421 - acc: 0.7960 - val_loss: 0.6458 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5373 - acc: 0.8003 - val_loss: 0.6539 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5385 - acc: 0.7972 - val_loss: 0.6510 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5345 - acc: 0.8040 - val_loss: 0.6872 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5368 - acc: 0.7969 - val_loss: 0.6551 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5360 - acc: 0.8018 - val_loss: 0.6576 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5305 - acc: 0.8047 - val_loss: 0.6526 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5348 - acc: 0.7956 - val_loss: 0.6422 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5255 - acc: 0.8014 - val_loss: 0.6653 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5160 - acc: 0.8096 - val_loss: 0.6518 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5171 - acc: 0.8080 - val_loss: 0.6730 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5257 - acc: 0.8076 - val_loss: 0.6463 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5269 - acc: 0.7998 - val_loss: 0.6643 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5349 - acc: 0.7985 - val_loss: 0.6420 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5272 - acc: 0.8023 - val_loss: 0.6672 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5320 - acc: 0.8038 - val_loss: 0.6479 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5306 - acc: 0.8007 - val_loss: 0.6451 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5213 - acc: 0.8016 - val_loss: 0.6694 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5268 - acc: 0.8045 - val_loss: 0.6691 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5270 - acc: 0.8036 - val_loss: 0.6748 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5266 - acc: 0.8036 - val_loss: 0.6368 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5183 - acc: 0.7989 - val_loss: 0.6537 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5269 - acc: 0.8025 - val_loss: 0.6705 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5254 - acc: 0.8018 - val_loss: 0.6780 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5228 - acc: 0.8036 - val_loss: 0.6597 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5266 - acc: 0.8045 - val_loss: 0.6540 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5153 - acc: 0.8098 - val_loss: 0.6651 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5146 - acc: 0.8071 - val_loss: 0.6450 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5295 - acc: 0.7972 - val_loss: 0.6812 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5267 - acc: 0.8054 - val_loss: 0.6513 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5192 - acc: 0.8036 - val_loss: 0.6972 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5252 - acc: 0.8023 - val_loss: 0.6663 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5302 - acc: 0.8012 - val_loss: 0.6531 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5238 - acc: 0.8007 - val_loss: 0.6743 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5225 - acc: 0.8058 - val_loss: 0.6759 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5223 - acc: 0.8056 - val_loss: 0.6411 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5184 - acc: 0.8040 - val_loss: 0.6462 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5258 - acc: 0.8018 - val_loss: 0.6534 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5284 - acc: 0.8005 - val_loss: 0.6438 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5220 - acc: 0.8032 - val_loss: 0.6526 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5236 - acc: 0.8005 - val_loss: 0.6486 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5247 - acc: 0.7983 - val_loss: 0.6650 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5259 - acc: 0.7974 - val_loss: 0.6644 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5269 - acc: 0.8045 - val_loss: 0.6772 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5235 - acc: 0.8036 - val_loss: 0.6800 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5211 - acc: 0.8045 - val_loss: 0.6713 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5262 - acc: 0.8000 - val_loss: 0.6940 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5306 - acc: 0.7994 - val_loss: 0.6499 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5272 - acc: 0.8034 - val_loss: 0.6716 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5226 - acc: 0.8074 - val_loss: 0.6422 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5211 - acc: 0.8065 - val_loss: 0.6696 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5242 - acc: 0.7998 - val_loss: 0.6700 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5201 - acc: 0.8051 - val_loss: 0.6566 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5148 - acc: 0.8120 - val_loss: 0.6378 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5284 - acc: 0.8009 - val_loss: 0.6417 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5202 - acc: 0.8032 - val_loss: 0.6398 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5279 - acc: 0.8014 - val_loss: 0.6592 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5171 - acc: 0.8036 - val_loss: 0.6665 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5215 - acc: 0.7976 - val_loss: 0.6545 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5176 - acc: 0.8056 - val_loss: 0.6441 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5264 - acc: 0.7989 - val_loss: 0.6529 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5188 - acc: 0.8060 - val_loss: 0.6360 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5182 - acc: 0.8038 - val_loss: 0.6388 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5160 - acc: 0.8062 - val_loss: 0.6912 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5220 - acc: 0.8071 - val_loss: 0.6822 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5089 - acc: 0.8091 - val_loss: 0.6444 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5228 - acc: 0.8014 - val_loss: 0.6503 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5250 - acc: 0.8045 - val_loss: 0.6533 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5311 - acc: 0.7980 - val_loss: 0.6523 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5213 - acc: 0.8029 - val_loss: 0.6718 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5174 - acc: 0.8138 - val_loss: 0.6527 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5201 - acc: 0.8058 - val_loss: 0.6418 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5295 - acc: 0.7987 - val_loss: 0.6493 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5205 - acc: 0.8047 - val_loss: 0.6487 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5190 - acc: 0.8049 - val_loss: 0.6785 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5179 - acc: 0.8049 - val_loss: 0.6520 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5198 - acc: 0.8036 - val_loss: 0.6555 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5255 - acc: 0.8045 - val_loss: 0.6501 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5148 - acc: 0.8016 - val_loss: 0.6506 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5265 - acc: 0.8007 - val_loss: 0.6414 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5189 - acc: 0.8003 - val_loss: 0.6351 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5183 - acc: 0.8012 - val_loss: 0.6606 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5257 - acc: 0.8009 - val_loss: 0.6406 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5170 - acc: 0.8032 - val_loss: 0.6614 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5032 - acc: 0.8160 - val_loss: 0.6450 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5214 - acc: 0.7978 - val_loss: 0.6395 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5225 - acc: 0.7980 - val_loss: 0.6460 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5173 - acc: 0.8069 - val_loss: 0.6547 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5240 - acc: 0.7998 - val_loss: 0.6469 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5195 - acc: 0.8036 - val_loss: 0.6484 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5229 - acc: 0.7978 - val_loss: 0.6977 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5179 - acc: 0.8018 - val_loss: 0.6369 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5224 - acc: 0.8063 - val_loss: 0.6387 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5218 - acc: 0.8027 - val_loss: 0.6366 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5165 - acc: 0.8047 - val_loss: 0.6938 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5088 - acc: 0.8076 - val_loss: 0.6587 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5256 - acc: 0.8045 - val_loss: 0.6572 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5211 - acc: 0.8029 - val_loss: 0.6449 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5156 - acc: 0.8080 - val_loss: 0.6512 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5306 - acc: 0.8005 - val_loss: 0.6407 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5198 - acc: 0.8058 - val_loss: 0.6369 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5181 - acc: 0.8069 - val_loss: 0.6421 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5180 - acc: 0.8063 - val_loss: 0.6597 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5164 - acc: 0.8080 - val_loss: 0.6374 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5196 - acc: 0.8056 - val_loss: 0.6481 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5258 - acc: 0.7994 - val_loss: 0.6404 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5200 - acc: 0.8032 - val_loss: 0.6650 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5212 - acc: 0.8040 - val_loss: 0.6806 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5287 - acc: 0.8027 - val_loss: 0.7306 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5193 - acc: 0.8076 - val_loss: 0.6745 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5173 - acc: 0.8071 - val_loss: 0.6449 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5086 - acc: 0.8162 - val_loss: 0.6494 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5236 - acc: 0.8007 - val_loss: 0.6414 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5204 - acc: 0.8023 - val_loss: 0.6390 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5250 - acc: 0.8029 - val_loss: 0.6373 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5204 - acc: 0.8020 - val_loss: 0.6423 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5186 - acc: 0.8020 - val_loss: 0.6386 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5150 - acc: 0.8060 - val_loss: 0.6572 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5131 - acc: 0.8063 - val_loss: 0.6358 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5209 - acc: 0.8016 - val_loss: 0.6393 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5210 - acc: 0.7954 - val_loss: 0.6366 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5256 - acc: 0.8038 - val_loss: 0.6413 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5185 - acc: 0.8014 - val_loss: 0.6511 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5135 - acc: 0.8051 - val_loss: 0.6567 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5185 - acc: 0.8045 - val_loss: 0.6487 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5174 - acc: 0.8000 - val_loss: 0.6418 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5241 - acc: 0.8014 - val_loss: 0.6629 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5192 - acc: 0.8065 - val_loss: 0.6641 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5200 - acc: 0.8054 - val_loss: 0.6708 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5185 - acc: 0.8034 - val_loss: 0.6470 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5148 - acc: 0.8098 - val_loss: 0.6582 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5199 - acc: 0.7965 - val_loss: 0.6640 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5137 - acc: 0.8098 - val_loss: 0.6545 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5109 - acc: 0.8080 - val_loss: 0.6563 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5161 - acc: 0.8078 - val_loss: 0.6649 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5127 - acc: 0.8067 - val_loss: 0.6554 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5208 - acc: 0.8058 - val_loss: 0.6640 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5215 - acc: 0.8018 - val_loss: 0.6738 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5198 - acc: 0.8016 - val_loss: 0.6474 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5199 - acc: 0.8018 - val_loss: 0.6500 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5148 - acc: 0.8103 - val_loss: 0.6361 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5066 - acc: 0.8089 - val_loss: 0.6518 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5154 - acc: 0.8058 - val_loss: 0.6425 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5096 - acc: 0.8069 - val_loss: 0.6456 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5131 - acc: 0.8034 - val_loss: 0.6388 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5225 - acc: 0.8025 - val_loss: 0.6568 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5098 - acc: 0.8049 - val_loss: 0.6381 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5154 - acc: 0.8074 - val_loss: 0.6439 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5171 - acc: 0.8023 - val_loss: 0.6481 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6016 - acc: 0.7853\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7038 - acc: 0.7330\n",
            "epsilon: 0.003 and test evaluation : 0.7037742137908936, 0.7329843044281006\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7790 - acc: 0.7103\n",
            "epsilon: 0.005 and test evaluation : 0.7789760231971741, 0.7102966904640198\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.9890 - acc: 0.5934\n",
            "epsilon: 0.01 and test evaluation : 0.9890322089195251, 0.5933682322502136\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.4575 - acc: 0.4538\n",
            "epsilon: 0.02 and test evaluation : 1.4575262069702148, 0.45375218987464905\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 1.4492 - acc: 0.3233 - val_loss: 1.4467 - val_acc: 0.3320 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3540 - acc: 0.3739 - val_loss: 1.2939 - val_acc: 0.4019 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3194 - acc: 0.3731 - val_loss: 1.3292 - val_acc: 0.3767 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2962 - acc: 0.3977 - val_loss: 1.5579 - val_acc: 0.3340 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2888 - acc: 0.4021 - val_loss: 1.3329 - val_acc: 0.3262 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2520 - acc: 0.4350 - val_loss: 1.2596 - val_acc: 0.4272 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2207 - acc: 0.4674 - val_loss: 1.2811 - val_acc: 0.4369 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1669 - acc: 0.5140 - val_loss: 1.2153 - val_acc: 0.4718 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1214 - acc: 0.5431 - val_loss: 1.1625 - val_acc: 0.4990 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0972 - acc: 0.5408 - val_loss: 1.0920 - val_acc: 0.5223 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0624 - acc: 0.5621 - val_loss: 1.2370 - val_acc: 0.4874 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0521 - acc: 0.5588 - val_loss: 0.9569 - val_acc: 0.5922 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9803 - acc: 0.5965 - val_loss: 0.9849 - val_acc: 0.6058 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9500 - acc: 0.6154 - val_loss: 1.3679 - val_acc: 0.4854 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8898 - acc: 0.6480 - val_loss: 0.8977 - val_acc: 0.6466 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8844 - acc: 0.6567 - val_loss: 0.8999 - val_acc: 0.6466 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8425 - acc: 0.6667 - val_loss: 0.8640 - val_acc: 0.6583 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8282 - acc: 0.6798 - val_loss: 0.8526 - val_acc: 0.6738 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8117 - acc: 0.6882 - val_loss: 0.9773 - val_acc: 0.6466 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7783 - acc: 0.6995 - val_loss: 0.8610 - val_acc: 0.6641 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7787 - acc: 0.6971 - val_loss: 0.8041 - val_acc: 0.6757 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7624 - acc: 0.6997 - val_loss: 0.7859 - val_acc: 0.6854 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7242 - acc: 0.7210 - val_loss: 0.7813 - val_acc: 0.7010 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7176 - acc: 0.7221 - val_loss: 0.9951 - val_acc: 0.6311 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7186 - acc: 0.7286 - val_loss: 0.8356 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6976 - acc: 0.7390 - val_loss: 0.7603 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6869 - acc: 0.7386 - val_loss: 0.7538 - val_acc: 0.7146 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6722 - acc: 0.7477 - val_loss: 0.7561 - val_acc: 0.7340 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6660 - acc: 0.7459 - val_loss: 0.6983 - val_acc: 0.7398 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6679 - acc: 0.7541 - val_loss: 0.7297 - val_acc: 0.7301 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6098 - acc: 0.7752 - val_loss: 0.7231 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5852 - acc: 0.7834 - val_loss: 0.7096 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5761 - acc: 0.7872 - val_loss: 0.6938 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5610 - acc: 0.7965 - val_loss: 0.6906 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5496 - acc: 0.7994 - val_loss: 0.7050 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5484 - acc: 0.7992 - val_loss: 0.6900 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5424 - acc: 0.7987 - val_loss: 0.6872 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5474 - acc: 0.8023 - val_loss: 0.6872 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5345 - acc: 0.8025 - val_loss: 0.7068 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5303 - acc: 0.8138 - val_loss: 0.6744 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5316 - acc: 0.8080 - val_loss: 0.6702 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5343 - acc: 0.8003 - val_loss: 0.6846 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5227 - acc: 0.8083 - val_loss: 0.6686 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5176 - acc: 0.8060 - val_loss: 0.6829 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5160 - acc: 0.8149 - val_loss: 0.6838 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5161 - acc: 0.8096 - val_loss: 0.6763 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5183 - acc: 0.8103 - val_loss: 0.6879 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5192 - acc: 0.8127 - val_loss: 0.6675 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5135 - acc: 0.8127 - val_loss: 0.6828 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5166 - acc: 0.8098 - val_loss: 0.6758 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5082 - acc: 0.8191 - val_loss: 0.6822 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.5049 - acc: 0.8118 - val_loss: 0.6686 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5076 - acc: 0.8138 - val_loss: 0.6693 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5100 - acc: 0.8094 - val_loss: 0.6670 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5005 - acc: 0.8134 - val_loss: 0.6635 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4956 - acc: 0.8194 - val_loss: 0.6740 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5061 - acc: 0.8127 - val_loss: 0.6772 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5047 - acc: 0.8114 - val_loss: 0.6780 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4881 - acc: 0.8162 - val_loss: 0.6674 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4961 - acc: 0.8178 - val_loss: 0.6813 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4913 - acc: 0.8245 - val_loss: 0.6650 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4875 - acc: 0.8227 - val_loss: 0.6723 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4865 - acc: 0.8178 - val_loss: 0.6632 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4750 - acc: 0.8276 - val_loss: 0.6691 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4850 - acc: 0.8240 - val_loss: 0.6659 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4905 - acc: 0.8187 - val_loss: 0.6704 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4958 - acc: 0.8180 - val_loss: 0.6633 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4908 - acc: 0.8174 - val_loss: 0.6666 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4834 - acc: 0.8189 - val_loss: 0.6662 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4899 - acc: 0.8196 - val_loss: 0.6733 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4864 - acc: 0.8211 - val_loss: 0.6699 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4816 - acc: 0.8229 - val_loss: 0.6704 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4942 - acc: 0.8205 - val_loss: 0.6721 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4897 - acc: 0.8198 - val_loss: 0.6727 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4841 - acc: 0.8196 - val_loss: 0.6746 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4855 - acc: 0.8196 - val_loss: 0.6752 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4863 - acc: 0.8202 - val_loss: 0.6685 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4807 - acc: 0.8198 - val_loss: 0.6586 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4804 - acc: 0.8262 - val_loss: 0.6752 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4895 - acc: 0.8174 - val_loss: 0.6591 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4847 - acc: 0.8189 - val_loss: 0.6635 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4865 - acc: 0.8218 - val_loss: 0.6685 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4818 - acc: 0.8202 - val_loss: 0.6671 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4836 - acc: 0.8196 - val_loss: 0.6608 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4808 - acc: 0.8249 - val_loss: 0.6591 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4842 - acc: 0.8236 - val_loss: 0.6741 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4789 - acc: 0.8240 - val_loss: 0.6727 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4830 - acc: 0.8202 - val_loss: 0.6682 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4851 - acc: 0.8191 - val_loss: 0.6812 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4895 - acc: 0.8198 - val_loss: 0.6710 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4819 - acc: 0.8253 - val_loss: 0.6563 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4760 - acc: 0.8309 - val_loss: 0.6705 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4768 - acc: 0.8291 - val_loss: 0.6647 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4921 - acc: 0.8171 - val_loss: 0.6607 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4864 - acc: 0.8171 - val_loss: 0.6646 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4871 - acc: 0.8233 - val_loss: 0.6582 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4674 - acc: 0.8222 - val_loss: 0.6570 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4871 - acc: 0.8194 - val_loss: 0.6695 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4818 - acc: 0.8196 - val_loss: 0.6972 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4743 - acc: 0.8262 - val_loss: 0.6638 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4887 - acc: 0.8189 - val_loss: 0.7113 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4782 - acc: 0.8249 - val_loss: 0.6689 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4820 - acc: 0.8236 - val_loss: 0.6669 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4828 - acc: 0.8260 - val_loss: 0.6590 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4806 - acc: 0.8287 - val_loss: 0.6652 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4827 - acc: 0.8273 - val_loss: 0.6610 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4946 - acc: 0.8218 - val_loss: 0.6465 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.4857 - acc: 0.8203 - val_loss: 0.6922 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4839 - acc: 0.8225 - val_loss: 0.6579 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4855 - acc: 0.8185 - val_loss: 0.6654 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4815 - acc: 0.8220 - val_loss: 0.6667 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4784 - acc: 0.8200 - val_loss: 0.6648 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4740 - acc: 0.8287 - val_loss: 0.6594 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4814 - acc: 0.8229 - val_loss: 0.6786 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4795 - acc: 0.8267 - val_loss: 0.6717 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4813 - acc: 0.8233 - val_loss: 0.6624 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4829 - acc: 0.8249 - val_loss: 0.6806 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4777 - acc: 0.8269 - val_loss: 0.6603 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4816 - acc: 0.8187 - val_loss: 0.6569 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4773 - acc: 0.8225 - val_loss: 0.6649 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4847 - acc: 0.8211 - val_loss: 0.6623 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4798 - acc: 0.8242 - val_loss: 0.6704 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4810 - acc: 0.8251 - val_loss: 0.6558 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4822 - acc: 0.8202 - val_loss: 0.6551 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4894 - acc: 0.8158 - val_loss: 0.6734 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4870 - acc: 0.8202 - val_loss: 0.6625 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4772 - acc: 0.8209 - val_loss: 0.6709 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4764 - acc: 0.8222 - val_loss: 0.6533 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4778 - acc: 0.8247 - val_loss: 0.6629 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.4833 - acc: 0.8225 - val_loss: 0.6557 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4805 - acc: 0.8218 - val_loss: 0.6713 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4809 - acc: 0.8216 - val_loss: 0.6573 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4809 - acc: 0.8222 - val_loss: 0.6589 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4776 - acc: 0.8249 - val_loss: 0.6628 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4769 - acc: 0.8269 - val_loss: 0.6920 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4785 - acc: 0.8220 - val_loss: 0.6614 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4843 - acc: 0.8218 - val_loss: 0.6645 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4817 - acc: 0.8247 - val_loss: 0.6578 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4880 - acc: 0.8200 - val_loss: 0.6445 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4734 - acc: 0.8231 - val_loss: 0.6656 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4807 - acc: 0.8211 - val_loss: 0.7379 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4825 - acc: 0.8256 - val_loss: 0.6655 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4839 - acc: 0.8207 - val_loss: 0.6578 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4814 - acc: 0.8213 - val_loss: 0.6621 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4757 - acc: 0.8231 - val_loss: 0.6612 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4766 - acc: 0.8249 - val_loss: 0.6782 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4838 - acc: 0.8191 - val_loss: 0.6625 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4793 - acc: 0.8287 - val_loss: 0.6761 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4823 - acc: 0.8236 - val_loss: 0.6530 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4790 - acc: 0.8240 - val_loss: 0.6661 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4762 - acc: 0.8271 - val_loss: 0.6682 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4817 - acc: 0.8209 - val_loss: 0.6761 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4824 - acc: 0.8209 - val_loss: 0.6655 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4718 - acc: 0.8242 - val_loss: 0.6559 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4774 - acc: 0.8245 - val_loss: 0.6499 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4928 - acc: 0.8169 - val_loss: 0.6790 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4840 - acc: 0.8245 - val_loss: 0.6641 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4744 - acc: 0.8191 - val_loss: 0.6808 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4824 - acc: 0.8258 - val_loss: 0.6630 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4808 - acc: 0.8209 - val_loss: 0.6641 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4832 - acc: 0.8260 - val_loss: 0.6645 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4821 - acc: 0.8233 - val_loss: 0.6765 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4840 - acc: 0.8174 - val_loss: 0.6574 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4735 - acc: 0.8271 - val_loss: 0.6624 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4878 - acc: 0.8158 - val_loss: 0.6699 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4764 - acc: 0.8269 - val_loss: 0.6607 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4790 - acc: 0.8176 - val_loss: 0.6543 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4775 - acc: 0.8209 - val_loss: 0.6684 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4855 - acc: 0.8198 - val_loss: 0.6774 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4764 - acc: 0.8267 - val_loss: 0.6689 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4783 - acc: 0.8220 - val_loss: 0.6644 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4804 - acc: 0.8233 - val_loss: 0.6635 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4735 - acc: 0.8273 - val_loss: 0.6778 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4861 - acc: 0.8167 - val_loss: 0.6628 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4778 - acc: 0.8216 - val_loss: 0.6795 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4753 - acc: 0.8244 - val_loss: 0.6659 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4752 - acc: 0.8236 - val_loss: 0.6707 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4872 - acc: 0.8211 - val_loss: 0.6609 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4886 - acc: 0.8136 - val_loss: 0.6643 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4763 - acc: 0.8207 - val_loss: 0.6619 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4719 - acc: 0.8260 - val_loss: 0.6637 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4791 - acc: 0.8191 - val_loss: 0.6793 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4812 - acc: 0.8229 - val_loss: 0.6620 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4745 - acc: 0.8240 - val_loss: 0.6629 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4735 - acc: 0.8278 - val_loss: 0.6627 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4753 - acc: 0.8213 - val_loss: 0.6639 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4811 - acc: 0.8222 - val_loss: 0.6725 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4782 - acc: 0.8211 - val_loss: 0.6570 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4806 - acc: 0.8238 - val_loss: 0.6563 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4708 - acc: 0.8220 - val_loss: 0.6937 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4804 - acc: 0.8234 - val_loss: 0.6542 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4742 - acc: 0.8240 - val_loss: 0.6583 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4791 - acc: 0.8189 - val_loss: 0.6670 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4792 - acc: 0.8236 - val_loss: 0.6646 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4833 - acc: 0.8153 - val_loss: 0.6610 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4835 - acc: 0.8178 - val_loss: 0.6698 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4816 - acc: 0.8229 - val_loss: 0.6670 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4737 - acc: 0.8233 - val_loss: 0.6616 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4802 - acc: 0.8198 - val_loss: 0.6703 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4819 - acc: 0.8220 - val_loss: 0.6595 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5976 - acc: 0.7836\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7174 - acc: 0.7452\n",
            "epsilon: 0.003 and test evaluation : 0.7174163460731506, 0.7452006936073303\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8055 - acc: 0.7138\n",
            "epsilon: 0.005 and test evaluation : 0.8054972887039185, 0.7137870788574219\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.0459 - acc: 0.6405\n",
            "epsilon: 0.01 and test evaluation : 1.0459365844726562, 0.6404886841773987\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.5576 - acc: 0.4782\n",
            "epsilon: 0.02 and test evaluation : 1.5576368570327759, 0.4781849980354309\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 1.4532 - acc: 0.3025 - val_loss: 1.3724 - val_acc: 0.3961 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3553 - acc: 0.3589 - val_loss: 1.3569 - val_acc: 0.3476 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3075 - acc: 0.3859 - val_loss: 1.2857 - val_acc: 0.4097 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2846 - acc: 0.4092 - val_loss: 1.3281 - val_acc: 0.3340 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2565 - acc: 0.4383 - val_loss: 1.3227 - val_acc: 0.3825 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2703 - acc: 0.4330 - val_loss: 1.2271 - val_acc: 0.4602 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2171 - acc: 0.4776 - val_loss: 1.1270 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.1526 - acc: 0.5235 - val_loss: 1.1447 - val_acc: 0.5340 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1103 - acc: 0.5455 - val_loss: 1.0237 - val_acc: 0.5883 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0770 - acc: 0.5559 - val_loss: 1.4104 - val_acc: 0.4097 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0405 - acc: 0.5768 - val_loss: 1.6925 - val_acc: 0.4155 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0254 - acc: 0.5841 - val_loss: 1.0139 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9849 - acc: 0.5994 - val_loss: 1.0138 - val_acc: 0.5534 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9381 - acc: 0.6323 - val_loss: 0.9356 - val_acc: 0.6194 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8884 - acc: 0.6549 - val_loss: 1.3148 - val_acc: 0.4874 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9003 - acc: 0.6467 - val_loss: 0.8350 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8573 - acc: 0.6664 - val_loss: 0.8089 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8196 - acc: 0.6851 - val_loss: 1.4892 - val_acc: 0.4971 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8361 - acc: 0.6751 - val_loss: 0.8266 - val_acc: 0.6854 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7924 - acc: 0.6990 - val_loss: 0.7398 - val_acc: 0.7146 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7663 - acc: 0.7064 - val_loss: 0.8730 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7641 - acc: 0.7124 - val_loss: 0.8539 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7450 - acc: 0.7188 - val_loss: 0.9324 - val_acc: 0.6466 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7392 - acc: 0.7213 - val_loss: 0.8027 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7268 - acc: 0.7233 - val_loss: 0.8557 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7217 - acc: 0.7228 - val_loss: 0.8283 - val_acc: 0.6951 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7088 - acc: 0.7292 - val_loss: 0.9629 - val_acc: 0.6408 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6992 - acc: 0.7372 - val_loss: 0.8328 - val_acc: 0.6699 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.6784 - acc: 0.7410 - val_loss: 0.6834 - val_acc: 0.7379 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6854 - acc: 0.7410 - val_loss: 0.7480 - val_acc: 0.7126 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7602 - acc: 0.7064 - val_loss: 0.7515 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7026 - acc: 0.7350 - val_loss: 0.7259 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6575 - acc: 0.7572 - val_loss: 0.6925 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6459 - acc: 0.7523 - val_loss: 0.6719 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6167 - acc: 0.7719 - val_loss: 0.6696 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6088 - acc: 0.7736 - val_loss: 0.6704 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5962 - acc: 0.7858 - val_loss: 0.6573 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5776 - acc: 0.7825 - val_loss: 0.6503 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5763 - acc: 0.7881 - val_loss: 0.6648 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5809 - acc: 0.7850 - val_loss: 0.6524 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5658 - acc: 0.7945 - val_loss: 0.6829 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5592 - acc: 0.7938 - val_loss: 0.6406 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5527 - acc: 0.7983 - val_loss: 0.6412 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5479 - acc: 0.7949 - val_loss: 0.6430 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5399 - acc: 0.8034 - val_loss: 0.6533 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5410 - acc: 0.8038 - val_loss: 0.6314 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5361 - acc: 0.8034 - val_loss: 0.6432 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5320 - acc: 0.8016 - val_loss: 0.6539 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5369 - acc: 0.8000 - val_loss: 0.6477 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5334 - acc: 0.8054 - val_loss: 0.6284 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5304 - acc: 0.8012 - val_loss: 0.6346 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5224 - acc: 0.8000 - val_loss: 0.6132 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5237 - acc: 0.8049 - val_loss: 0.6158 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5160 - acc: 0.8111 - val_loss: 0.6182 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5267 - acc: 0.8040 - val_loss: 0.6151 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5163 - acc: 0.8089 - val_loss: 0.6189 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5166 - acc: 0.8107 - val_loss: 0.6262 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5126 - acc: 0.8160 - val_loss: 0.6167 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5062 - acc: 0.8151 - val_loss: 0.6225 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5083 - acc: 0.8114 - val_loss: 0.6215 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5042 - acc: 0.8145 - val_loss: 0.6302 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5009 - acc: 0.8213 - val_loss: 0.6316 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4964 - acc: 0.8160 - val_loss: 0.6294 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4928 - acc: 0.8171 - val_loss: 0.6268 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5003 - acc: 0.8165 - val_loss: 0.6149 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5053 - acc: 0.8098 - val_loss: 0.6294 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5038 - acc: 0.8182 - val_loss: 0.6173 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5084 - acc: 0.8127 - val_loss: 0.6050 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5047 - acc: 0.8127 - val_loss: 0.6318 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5061 - acc: 0.8129 - val_loss: 0.6194 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5092 - acc: 0.8080 - val_loss: 0.6287 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5015 - acc: 0.8123 - val_loss: 0.6295 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5046 - acc: 0.8109 - val_loss: 0.6253 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5053 - acc: 0.8116 - val_loss: 0.6079 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4977 - acc: 0.8180 - val_loss: 0.6075 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5057 - acc: 0.8098 - val_loss: 0.6284 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5010 - acc: 0.8134 - val_loss: 0.6187 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5125 - acc: 0.8136 - val_loss: 0.6308 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4976 - acc: 0.8174 - val_loss: 0.6558 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5108 - acc: 0.8127 - val_loss: 0.6182 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5030 - acc: 0.8182 - val_loss: 0.6170 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5033 - acc: 0.8129 - val_loss: 0.6136 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4975 - acc: 0.8167 - val_loss: 0.6162 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5056 - acc: 0.8142 - val_loss: 0.6218 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4993 - acc: 0.8131 - val_loss: 0.6314 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4998 - acc: 0.8120 - val_loss: 0.6311 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4936 - acc: 0.8220 - val_loss: 0.6033 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4962 - acc: 0.8162 - val_loss: 0.6746 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5073 - acc: 0.8109 - val_loss: 0.6089 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5038 - acc: 0.8120 - val_loss: 0.6162 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4936 - acc: 0.8198 - val_loss: 0.6213 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5033 - acc: 0.8109 - val_loss: 0.6120 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4974 - acc: 0.8185 - val_loss: 0.6363 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4985 - acc: 0.8105 - val_loss: 0.6349 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4974 - acc: 0.8156 - val_loss: 0.6190 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4944 - acc: 0.8151 - val_loss: 0.6310 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4935 - acc: 0.8154 - val_loss: 0.6366 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5052 - acc: 0.8078 - val_loss: 0.6097 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4977 - acc: 0.8138 - val_loss: 0.6236 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5075 - acc: 0.8063 - val_loss: 0.6246 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5062 - acc: 0.8105 - val_loss: 0.6191 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4945 - acc: 0.8233 - val_loss: 0.6207 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5035 - acc: 0.8158 - val_loss: 0.6308 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5022 - acc: 0.8160 - val_loss: 0.6164 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5068 - acc: 0.8127 - val_loss: 0.6266 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5015 - acc: 0.8111 - val_loss: 0.6168 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5018 - acc: 0.8083 - val_loss: 0.6101 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4978 - acc: 0.8127 - val_loss: 0.6248 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4933 - acc: 0.8131 - val_loss: 0.6469 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5070 - acc: 0.8116 - val_loss: 0.6179 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4977 - acc: 0.8118 - val_loss: 0.6491 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5067 - acc: 0.8098 - val_loss: 0.6135 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5044 - acc: 0.8136 - val_loss: 0.6236 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4949 - acc: 0.8140 - val_loss: 0.6064 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5013 - acc: 0.8109 - val_loss: 0.6234 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5035 - acc: 0.8118 - val_loss: 0.6134 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5047 - acc: 0.8167 - val_loss: 0.6221 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4945 - acc: 0.8182 - val_loss: 0.6243 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5015 - acc: 0.8100 - val_loss: 0.6160 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4947 - acc: 0.8216 - val_loss: 0.6103 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4924 - acc: 0.8198 - val_loss: 0.6100 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5056 - acc: 0.8142 - val_loss: 0.6149 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5038 - acc: 0.8067 - val_loss: 0.6326 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4879 - acc: 0.8242 - val_loss: 0.6292 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4997 - acc: 0.8162 - val_loss: 0.6491 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5021 - acc: 0.8138 - val_loss: 0.6207 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4855 - acc: 0.8207 - val_loss: 0.6373 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5050 - acc: 0.8069 - val_loss: 0.6115 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4983 - acc: 0.8169 - val_loss: 0.6253 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5010 - acc: 0.8185 - val_loss: 0.6094 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4955 - acc: 0.8147 - val_loss: 0.6367 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4979 - acc: 0.8174 - val_loss: 0.6145 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4939 - acc: 0.8182 - val_loss: 0.6151 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5069 - acc: 0.8114 - val_loss: 0.6217 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4963 - acc: 0.8118 - val_loss: 0.6254 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4985 - acc: 0.8127 - val_loss: 0.6295 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4986 - acc: 0.8142 - val_loss: 0.6117 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.4920 - acc: 0.8134 - val_loss: 0.6215 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4972 - acc: 0.8180 - val_loss: 0.6295 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4872 - acc: 0.8191 - val_loss: 0.6222 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5032 - acc: 0.8125 - val_loss: 0.6473 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4976 - acc: 0.8171 - val_loss: 0.6017 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4964 - acc: 0.8136 - val_loss: 0.6214 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5062 - acc: 0.8089 - val_loss: 0.6202 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5064 - acc: 0.8116 - val_loss: 0.6224 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4976 - acc: 0.8171 - val_loss: 0.6158 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4943 - acc: 0.8145 - val_loss: 0.6388 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4961 - acc: 0.8140 - val_loss: 0.6045 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4963 - acc: 0.8120 - val_loss: 0.6223 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4939 - acc: 0.8179 - val_loss: 0.6094 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4902 - acc: 0.8218 - val_loss: 0.6211 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4949 - acc: 0.8158 - val_loss: 0.6324 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4999 - acc: 0.8167 - val_loss: 0.6403 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4879 - acc: 0.8211 - val_loss: 0.6152 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4988 - acc: 0.8160 - val_loss: 0.6395 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4911 - acc: 0.8180 - val_loss: 0.6174 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5064 - acc: 0.8063 - val_loss: 0.6153 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5009 - acc: 0.8105 - val_loss: 0.6132 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4974 - acc: 0.8123 - val_loss: 0.6154 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4973 - acc: 0.8187 - val_loss: 0.6069 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5012 - acc: 0.8138 - val_loss: 0.6232 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5000 - acc: 0.8158 - val_loss: 0.6003 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4982 - acc: 0.8140 - val_loss: 0.6162 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4903 - acc: 0.8129 - val_loss: 0.6136 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4944 - acc: 0.8134 - val_loss: 0.6317 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4934 - acc: 0.8180 - val_loss: 0.6014 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5028 - acc: 0.8154 - val_loss: 0.6137 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4948 - acc: 0.8162 - val_loss: 0.6179 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5006 - acc: 0.8145 - val_loss: 0.6063 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4946 - acc: 0.8178 - val_loss: 0.6262 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4888 - acc: 0.8154 - val_loss: 0.6624 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4950 - acc: 0.8218 - val_loss: 0.6128 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5005 - acc: 0.8151 - val_loss: 0.6044 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4974 - acc: 0.8120 - val_loss: 0.6320 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4911 - acc: 0.8200 - val_loss: 0.6224 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5048 - acc: 0.8120 - val_loss: 0.6305 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4950 - acc: 0.8198 - val_loss: 0.6293 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4885 - acc: 0.8174 - val_loss: 0.6332 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5017 - acc: 0.8178 - val_loss: 0.6142 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4988 - acc: 0.8136 - val_loss: 0.6031 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5019 - acc: 0.8123 - val_loss: 0.6216 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4949 - acc: 0.8145 - val_loss: 0.6154 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4950 - acc: 0.8131 - val_loss: 0.6148 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5008 - acc: 0.8076 - val_loss: 0.6197 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4835 - acc: 0.8233 - val_loss: 0.6113 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4893 - acc: 0.8191 - val_loss: 0.6063 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4990 - acc: 0.8123 - val_loss: 0.6241 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4893 - acc: 0.8202 - val_loss: 0.6278 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4990 - acc: 0.8178 - val_loss: 0.6082 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4943 - acc: 0.8160 - val_loss: 0.6344 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4938 - acc: 0.8120 - val_loss: 0.6032 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4973 - acc: 0.8120 - val_loss: 0.6429 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5033 - acc: 0.8129 - val_loss: 0.6139 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4916 - acc: 0.8151 - val_loss: 0.6131 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4927 - acc: 0.8123 - val_loss: 0.6112 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5021 - acc: 0.8091 - val_loss: 0.6279 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4885 - acc: 0.8151 - val_loss: 0.6130 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4883 - acc: 0.8225 - val_loss: 0.6145 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4873 - acc: 0.8191 - val_loss: 0.6186 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4978 - acc: 0.8123 - val_loss: 0.6121 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6645 - acc: 0.7522\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7863 - acc: 0.7120\n",
            "epsilon: 0.003 and test evaluation : 0.7863439917564392, 0.7120419144630432\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8752 - acc: 0.6894\n",
            "epsilon: 0.005 and test evaluation : 0.875208854675293, 0.6893543004989624\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.1138 - acc: 0.6370\n",
            "epsilon: 0.01 and test evaluation : 1.1138347387313843, 0.6369982361793518\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.6186 - acc: 0.4834\n",
            "epsilon: 0.02 and test evaluation : 1.6185506582260132, 0.48342058062553406\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 1.4362 - acc: 0.3358 - val_loss: 1.3721 - val_acc: 0.3631 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3504 - acc: 0.3673 - val_loss: 1.3575 - val_acc: 0.3495 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3236 - acc: 0.3771 - val_loss: 1.2706 - val_acc: 0.3883 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2954 - acc: 0.3875 - val_loss: 1.2560 - val_acc: 0.4485 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2815 - acc: 0.3992 - val_loss: 1.2372 - val_acc: 0.4388 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2581 - acc: 0.4174 - val_loss: 1.2296 - val_acc: 0.4447 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2625 - acc: 0.4237 - val_loss: 1.2368 - val_acc: 0.4447 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2180 - acc: 0.4791 - val_loss: 1.2092 - val_acc: 0.4563 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1661 - acc: 0.5095 - val_loss: 1.3452 - val_acc: 0.3825 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1353 - acc: 0.5260 - val_loss: 1.0866 - val_acc: 0.5476 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1335 - acc: 0.5293 - val_loss: 1.4326 - val_acc: 0.4311 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0830 - acc: 0.5635 - val_loss: 1.1161 - val_acc: 0.5476 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0468 - acc: 0.5677 - val_loss: 1.1369 - val_acc: 0.5689 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0312 - acc: 0.5877 - val_loss: 1.0512 - val_acc: 0.5786 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9876 - acc: 0.6005 - val_loss: 1.1361 - val_acc: 0.5359 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9818 - acc: 0.6030 - val_loss: 1.0960 - val_acc: 0.5379 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9245 - acc: 0.6252 - val_loss: 1.1375 - val_acc: 0.5981 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.8975 - acc: 0.6458 - val_loss: 0.8836 - val_acc: 0.6505 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.8482 - acc: 0.6664 - val_loss: 0.7725 - val_acc: 0.7087 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8465 - acc: 0.6711 - val_loss: 0.8733 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8433 - acc: 0.6605 - val_loss: 0.9692 - val_acc: 0.6524 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8039 - acc: 0.6849 - val_loss: 0.6920 - val_acc: 0.7592 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7761 - acc: 0.7017 - val_loss: 0.9214 - val_acc: 0.6505 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7718 - acc: 0.7091 - val_loss: 0.7157 - val_acc: 0.7223 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7327 - acc: 0.7166 - val_loss: 0.7806 - val_acc: 0.7301 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7695 - acc: 0.6991 - val_loss: 0.8701 - val_acc: 0.6621 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7038 - acc: 0.7359 - val_loss: 0.7291 - val_acc: 0.7282 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7123 - acc: 0.7239 - val_loss: 0.6974 - val_acc: 0.7379 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7054 - acc: 0.7344 - val_loss: 0.9699 - val_acc: 0.6544 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7056 - acc: 0.7312 - val_loss: 0.6970 - val_acc: 0.7476 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7436 - acc: 0.7102 - val_loss: 0.7049 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6839 - acc: 0.7417 - val_loss: 0.6663 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6471 - acc: 0.7617 - val_loss: 0.6264 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6265 - acc: 0.7708 - val_loss: 0.6182 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.6122 - acc: 0.7767 - val_loss: 0.5960 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5896 - acc: 0.7810 - val_loss: 0.5813 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5975 - acc: 0.7765 - val_loss: 0.5823 - val_acc: 0.7767 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5789 - acc: 0.7843 - val_loss: 0.5915 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5761 - acc: 0.7863 - val_loss: 0.5811 - val_acc: 0.7806 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5642 - acc: 0.7980 - val_loss: 0.5669 - val_acc: 0.7748 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5673 - acc: 0.7936 - val_loss: 0.5701 - val_acc: 0.7786 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5541 - acc: 0.8016 - val_loss: 0.5665 - val_acc: 0.7864 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5637 - acc: 0.7918 - val_loss: 0.5804 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5524 - acc: 0.7974 - val_loss: 0.5620 - val_acc: 0.7981 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5577 - acc: 0.7949 - val_loss: 0.5621 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5524 - acc: 0.7987 - val_loss: 0.6164 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5563 - acc: 0.7980 - val_loss: 0.5620 - val_acc: 0.7922 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5472 - acc: 0.7972 - val_loss: 0.5594 - val_acc: 0.7961 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5457 - acc: 0.7983 - val_loss: 0.5642 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5438 - acc: 0.8005 - val_loss: 0.5591 - val_acc: 0.7942 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5412 - acc: 0.8027 - val_loss: 0.5520 - val_acc: 0.7942 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5354 - acc: 0.8012 - val_loss: 0.5693 - val_acc: 0.7864 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5306 - acc: 0.8038 - val_loss: 0.5592 - val_acc: 0.7942 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5285 - acc: 0.8111 - val_loss: 0.5570 - val_acc: 0.7806 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5333 - acc: 0.8027 - val_loss: 0.5631 - val_acc: 0.7864 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5182 - acc: 0.8029 - val_loss: 0.5690 - val_acc: 0.7767 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5188 - acc: 0.8049 - val_loss: 0.5581 - val_acc: 0.7864 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5165 - acc: 0.8138 - val_loss: 0.5572 - val_acc: 0.7942 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5172 - acc: 0.8154 - val_loss: 0.5525 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5190 - acc: 0.8131 - val_loss: 0.5606 - val_acc: 0.8000 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5099 - acc: 0.8134 - val_loss: 0.5609 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5159 - acc: 0.8071 - val_loss: 0.5603 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5167 - acc: 0.8120 - val_loss: 0.5648 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5139 - acc: 0.8100 - val_loss: 0.5508 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5178 - acc: 0.8043 - val_loss: 0.5654 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5157 - acc: 0.8082 - val_loss: 0.5557 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5006 - acc: 0.8145 - val_loss: 0.5554 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5141 - acc: 0.8105 - val_loss: 0.5506 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5165 - acc: 0.8074 - val_loss: 0.5548 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5092 - acc: 0.8131 - val_loss: 0.5613 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5107 - acc: 0.8111 - val_loss: 0.5508 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5000 - acc: 0.8242 - val_loss: 0.5586 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5166 - acc: 0.8049 - val_loss: 0.5481 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5144 - acc: 0.8127 - val_loss: 0.5456 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5125 - acc: 0.8098 - val_loss: 0.5782 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5195 - acc: 0.8176 - val_loss: 0.5642 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5189 - acc: 0.8096 - val_loss: 0.5492 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5139 - acc: 0.8067 - val_loss: 0.5542 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5142 - acc: 0.8140 - val_loss: 0.5714 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5107 - acc: 0.8123 - val_loss: 0.5553 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5072 - acc: 0.8120 - val_loss: 0.5579 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5156 - acc: 0.8076 - val_loss: 0.5673 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5091 - acc: 0.8145 - val_loss: 0.5615 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5034 - acc: 0.8140 - val_loss: 0.5590 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5033 - acc: 0.8229 - val_loss: 0.5509 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5126 - acc: 0.8129 - val_loss: 0.5503 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5120 - acc: 0.8167 - val_loss: 0.5516 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5055 - acc: 0.8167 - val_loss: 0.5492 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5158 - acc: 0.8138 - val_loss: 0.5475 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5110 - acc: 0.8151 - val_loss: 0.5459 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5063 - acc: 0.8156 - val_loss: 0.5518 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5079 - acc: 0.8118 - val_loss: 0.5500 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5079 - acc: 0.8138 - val_loss: 0.5928 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5188 - acc: 0.8080 - val_loss: 0.5517 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5124 - acc: 0.8091 - val_loss: 0.5550 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5081 - acc: 0.8111 - val_loss: 0.5474 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5142 - acc: 0.8103 - val_loss: 0.5423 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5043 - acc: 0.8165 - val_loss: 0.5580 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5124 - acc: 0.8129 - val_loss: 0.5504 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5129 - acc: 0.8089 - val_loss: 0.5458 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5055 - acc: 0.8134 - val_loss: 0.5714 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5212 - acc: 0.8089 - val_loss: 0.5500 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5084 - acc: 0.8069 - val_loss: 0.5486 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5039 - acc: 0.8171 - val_loss: 0.5490 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5166 - acc: 0.8098 - val_loss: 0.5474 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5074 - acc: 0.8123 - val_loss: 0.5494 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5186 - acc: 0.8069 - val_loss: 0.5544 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5121 - acc: 0.8098 - val_loss: 0.5565 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5090 - acc: 0.8167 - val_loss: 0.5475 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5086 - acc: 0.8138 - val_loss: 0.5542 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5046 - acc: 0.8136 - val_loss: 0.5569 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5130 - acc: 0.8107 - val_loss: 0.5442 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5093 - acc: 0.8091 - val_loss: 0.5473 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5124 - acc: 0.8085 - val_loss: 0.5425 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5092 - acc: 0.8096 - val_loss: 0.5514 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5186 - acc: 0.8071 - val_loss: 0.5444 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5148 - acc: 0.8076 - val_loss: 0.5483 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5111 - acc: 0.8151 - val_loss: 0.5474 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5063 - acc: 0.8151 - val_loss: 0.5509 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5056 - acc: 0.8154 - val_loss: 0.5482 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5093 - acc: 0.8120 - val_loss: 0.5490 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5074 - acc: 0.8136 - val_loss: 0.5488 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5107 - acc: 0.8100 - val_loss: 0.5512 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5043 - acc: 0.8123 - val_loss: 0.5692 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5107 - acc: 0.8154 - val_loss: 0.5402 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5139 - acc: 0.8118 - val_loss: 0.5496 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5165 - acc: 0.8047 - val_loss: 0.5736 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5087 - acc: 0.8191 - val_loss: 0.5543 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5147 - acc: 0.8118 - val_loss: 0.5438 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5070 - acc: 0.8147 - val_loss: 0.5562 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5077 - acc: 0.8134 - val_loss: 0.5438 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5058 - acc: 0.8178 - val_loss: 0.5582 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5049 - acc: 0.8074 - val_loss: 0.5454 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5097 - acc: 0.8114 - val_loss: 0.5530 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5107 - acc: 0.8105 - val_loss: 0.5463 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5088 - acc: 0.8118 - val_loss: 0.5518 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5098 - acc: 0.8142 - val_loss: 0.5413 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5083 - acc: 0.8129 - val_loss: 0.5505 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5067 - acc: 0.8171 - val_loss: 0.5617 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5130 - acc: 0.8105 - val_loss: 0.5416 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5060 - acc: 0.8154 - val_loss: 0.5444 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4958 - acc: 0.8198 - val_loss: 0.5713 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5123 - acc: 0.8127 - val_loss: 0.5514 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5127 - acc: 0.8114 - val_loss: 0.5486 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5096 - acc: 0.8109 - val_loss: 0.5484 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5068 - acc: 0.8074 - val_loss: 0.5476 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5046 - acc: 0.8191 - val_loss: 0.5424 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5054 - acc: 0.8089 - val_loss: 0.5478 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5134 - acc: 0.8063 - val_loss: 0.5612 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5223 - acc: 0.8107 - val_loss: 0.5668 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5066 - acc: 0.8142 - val_loss: 0.5473 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5147 - acc: 0.8065 - val_loss: 0.5451 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5067 - acc: 0.8111 - val_loss: 0.5415 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5043 - acc: 0.8169 - val_loss: 0.5564 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5102 - acc: 0.8087 - val_loss: 0.5421 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5037 - acc: 0.8134 - val_loss: 0.5572 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5147 - acc: 0.8078 - val_loss: 0.5519 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4992 - acc: 0.8196 - val_loss: 0.5483 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5015 - acc: 0.8198 - val_loss: 0.5478 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5135 - acc: 0.8100 - val_loss: 0.5488 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5168 - acc: 0.8071 - val_loss: 0.5468 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5115 - acc: 0.8158 - val_loss: 0.5483 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5101 - acc: 0.8107 - val_loss: 0.5485 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5018 - acc: 0.8111 - val_loss: 0.5501 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5060 - acc: 0.8129 - val_loss: 0.5419 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5036 - acc: 0.8109 - val_loss: 0.5606 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5106 - acc: 0.8087 - val_loss: 0.5468 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5033 - acc: 0.8127 - val_loss: 0.5528 - val_acc: 0.8019 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5020 - acc: 0.8169 - val_loss: 0.5437 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5052 - acc: 0.8127 - val_loss: 0.5432 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5089 - acc: 0.8094 - val_loss: 0.5369 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5075 - acc: 0.8120 - val_loss: 0.5473 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5078 - acc: 0.8151 - val_loss: 0.5588 - val_acc: 0.8039 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5195 - acc: 0.8060 - val_loss: 0.5481 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5146 - acc: 0.8049 - val_loss: 0.5569 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4942 - acc: 0.8189 - val_loss: 0.5461 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5012 - acc: 0.8134 - val_loss: 0.5464 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5146 - acc: 0.8107 - val_loss: 0.5508 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5034 - acc: 0.8098 - val_loss: 0.5682 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5118 - acc: 0.8105 - val_loss: 0.5562 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4984 - acc: 0.8162 - val_loss: 0.5447 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5126 - acc: 0.8125 - val_loss: 0.5500 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5089 - acc: 0.8116 - val_loss: 0.5586 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5044 - acc: 0.8158 - val_loss: 0.5652 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5013 - acc: 0.8182 - val_loss: 0.5495 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4994 - acc: 0.8185 - val_loss: 0.5465 - val_acc: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5014 - acc: 0.8187 - val_loss: 0.5508 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5023 - acc: 0.8131 - val_loss: 0.5460 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5038 - acc: 0.8147 - val_loss: 0.5727 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5027 - acc: 0.8140 - val_loss: 0.5459 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5068 - acc: 0.8136 - val_loss: 0.5478 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5001 - acc: 0.8140 - val_loss: 0.5512 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5033 - acc: 0.8123 - val_loss: 0.5455 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5084 - acc: 0.8120 - val_loss: 0.5431 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4967 - acc: 0.8154 - val_loss: 0.5550 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5081 - acc: 0.8167 - val_loss: 0.5477 - val_acc: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4941 - acc: 0.8158 - val_loss: 0.5510 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4986 - acc: 0.8151 - val_loss: 0.5475 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5062 - acc: 0.8118 - val_loss: 0.5466 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5022 - acc: 0.8145 - val_loss: 0.5528 - val_acc: 0.7981 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5929 - acc: 0.7661\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7118 - acc: 0.7330\n",
            "epsilon: 0.003 and test evaluation : 0.7117999792098999, 0.7329843044281006\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.8008 - acc: 0.6981\n",
            "epsilon: 0.005 and test evaluation : 0.8007927536964417, 0.69808030128479\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.0445 - acc: 0.6195\n",
            "epsilon: 0.01 and test evaluation : 1.0444830656051636, 0.6195462346076965\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.5624 - acc: 0.4887\n",
            "epsilon: 0.02 and test evaluation : 1.5623533725738525, 0.4886561930179596\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 1.4601 - acc: 0.2943 - val_loss: 1.4157 - val_acc: 0.3146 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.3587 - acc: 0.3737 - val_loss: 2.3795 - val_acc: 0.2738 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3087 - acc: 0.3868 - val_loss: 1.3410 - val_acc: 0.3476 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2892 - acc: 0.3984 - val_loss: 1.2940 - val_acc: 0.4117 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2680 - acc: 0.4152 - val_loss: 1.8937 - val_acc: 0.3243 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2471 - acc: 0.4541 - val_loss: 1.3330 - val_acc: 0.4136 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1921 - acc: 0.4998 - val_loss: 1.3802 - val_acc: 0.3825 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1468 - acc: 0.5271 - val_loss: 1.3372 - val_acc: 0.4272 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1182 - acc: 0.5402 - val_loss: 1.2946 - val_acc: 0.4194 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0602 - acc: 0.5699 - val_loss: 1.1465 - val_acc: 0.5301 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0149 - acc: 0.5879 - val_loss: 1.0107 - val_acc: 0.5728 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9514 - acc: 0.6232 - val_loss: 0.9090 - val_acc: 0.6350 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9307 - acc: 0.6405 - val_loss: 1.0164 - val_acc: 0.5903 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8897 - acc: 0.6507 - val_loss: 2.4122 - val_acc: 0.3359 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8914 - acc: 0.6518 - val_loss: 0.8700 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8450 - acc: 0.6669 - val_loss: 0.8266 - val_acc: 0.6641 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8206 - acc: 0.6806 - val_loss: 1.2353 - val_acc: 0.5126 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8019 - acc: 0.6924 - val_loss: 0.8566 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7975 - acc: 0.6944 - val_loss: 0.9294 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7787 - acc: 0.7031 - val_loss: 0.8384 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7459 - acc: 0.7184 - val_loss: 1.0727 - val_acc: 0.5806 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7432 - acc: 0.7142 - val_loss: 0.7942 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7366 - acc: 0.7148 - val_loss: 0.8569 - val_acc: 0.6524 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7072 - acc: 0.7317 - val_loss: 1.3080 - val_acc: 0.5340 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7094 - acc: 0.7350 - val_loss: 0.9007 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6910 - acc: 0.7410 - val_loss: 0.8283 - val_acc: 0.7049 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6846 - acc: 0.7339 - val_loss: 0.8814 - val_acc: 0.6777 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6620 - acc: 0.7568 - val_loss: 0.7848 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6754 - acc: 0.7461 - val_loss: 0.9209 - val_acc: 0.6330 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6594 - acc: 0.7539 - val_loss: 0.9168 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7371 - acc: 0.7150 - val_loss: 0.8365 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6390 - acc: 0.7585 - val_loss: 0.7374 - val_acc: 0.7282 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5858 - acc: 0.7843 - val_loss: 0.7061 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5632 - acc: 0.7907 - val_loss: 0.6679 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5470 - acc: 0.8020 - val_loss: 0.7029 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5329 - acc: 0.8054 - val_loss: 0.6809 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5309 - acc: 0.8045 - val_loss: 0.6454 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5300 - acc: 0.8069 - val_loss: 0.7004 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5190 - acc: 0.8103 - val_loss: 0.6284 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5141 - acc: 0.8178 - val_loss: 0.6710 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5153 - acc: 0.8136 - val_loss: 0.6630 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4978 - acc: 0.8180 - val_loss: 0.7086 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4980 - acc: 0.8178 - val_loss: 0.6286 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5002 - acc: 0.8171 - val_loss: 0.6753 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4933 - acc: 0.8182 - val_loss: 0.6648 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4962 - acc: 0.8185 - val_loss: 0.6469 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4993 - acc: 0.8136 - val_loss: 0.6544 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4950 - acc: 0.8142 - val_loss: 0.6668 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4875 - acc: 0.8225 - val_loss: 0.9477 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4837 - acc: 0.8240 - val_loss: 0.6645 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4853 - acc: 0.8256 - val_loss: 0.6409 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4724 - acc: 0.8289 - val_loss: 0.6338 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4752 - acc: 0.8289 - val_loss: 0.6588 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4768 - acc: 0.8262 - val_loss: 0.6440 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4732 - acc: 0.8258 - val_loss: 0.6540 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4792 - acc: 0.8238 - val_loss: 0.6776 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4683 - acc: 0.8300 - val_loss: 0.6392 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4615 - acc: 0.8280 - val_loss: 0.6709 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4581 - acc: 0.8338 - val_loss: 0.6719 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4604 - acc: 0.8340 - val_loss: 0.6266 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4558 - acc: 0.8360 - val_loss: 0.6521 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4604 - acc: 0.8322 - val_loss: 0.6419 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4546 - acc: 0.8364 - val_loss: 0.6435 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4599 - acc: 0.8344 - val_loss: 0.6402 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4519 - acc: 0.8400 - val_loss: 0.6782 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4552 - acc: 0.8320 - val_loss: 0.6214 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4573 - acc: 0.8298 - val_loss: 0.6494 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4555 - acc: 0.8358 - val_loss: 0.6302 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4674 - acc: 0.8249 - val_loss: 0.6602 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4572 - acc: 0.8300 - val_loss: 0.6523 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4504 - acc: 0.8367 - val_loss: 0.6687 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4625 - acc: 0.8336 - val_loss: 0.6237 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4474 - acc: 0.8395 - val_loss: 0.6876 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4428 - acc: 0.8333 - val_loss: 0.6749 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4572 - acc: 0.8351 - val_loss: 0.6974 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4475 - acc: 0.8360 - val_loss: 0.6521 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4486 - acc: 0.8369 - val_loss: 0.6651 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4556 - acc: 0.8311 - val_loss: 0.6528 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4649 - acc: 0.8316 - val_loss: 0.6257 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4546 - acc: 0.8347 - val_loss: 0.6414 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4526 - acc: 0.8316 - val_loss: 0.6676 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4623 - acc: 0.8278 - val_loss: 0.6677 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4612 - acc: 0.8304 - val_loss: 0.6730 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4535 - acc: 0.8378 - val_loss: 0.7022 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4496 - acc: 0.8302 - val_loss: 0.6688 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4544 - acc: 0.8320 - val_loss: 0.6729 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4510 - acc: 0.8331 - val_loss: 0.6617 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4565 - acc: 0.8302 - val_loss: 0.6286 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4525 - acc: 0.8324 - val_loss: 0.6961 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4598 - acc: 0.8349 - val_loss: 0.6703 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4538 - acc: 0.8320 - val_loss: 0.6491 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4599 - acc: 0.8304 - val_loss: 0.7062 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4565 - acc: 0.8329 - val_loss: 0.7223 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4608 - acc: 0.8256 - val_loss: 0.6976 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4613 - acc: 0.8327 - val_loss: 0.6892 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4617 - acc: 0.8309 - val_loss: 0.6906 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4448 - acc: 0.8400 - val_loss: 0.6560 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4528 - acc: 0.8375 - val_loss: 0.6146 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4578 - acc: 0.8280 - val_loss: 0.7359 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4570 - acc: 0.8329 - val_loss: 0.6314 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4483 - acc: 0.8318 - val_loss: 0.7136 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4616 - acc: 0.8293 - val_loss: 0.6624 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4550 - acc: 0.8269 - val_loss: 0.6584 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4690 - acc: 0.8253 - val_loss: 0.6852 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4602 - acc: 0.8316 - val_loss: 0.6435 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4509 - acc: 0.8344 - val_loss: 0.6573 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4469 - acc: 0.8329 - val_loss: 0.6455 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4609 - acc: 0.8309 - val_loss: 0.6543 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4523 - acc: 0.8367 - val_loss: 0.6347 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4579 - acc: 0.8282 - val_loss: 0.6503 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4593 - acc: 0.8313 - val_loss: 0.6945 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4512 - acc: 0.8320 - val_loss: 0.6624 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4620 - acc: 0.8251 - val_loss: 0.6554 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4694 - acc: 0.8271 - val_loss: 0.6504 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4663 - acc: 0.8247 - val_loss: 0.7320 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4523 - acc: 0.8336 - val_loss: 0.6657 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4579 - acc: 0.8340 - val_loss: 0.6490 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4609 - acc: 0.8249 - val_loss: 0.6631 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4441 - acc: 0.8347 - val_loss: 0.6131 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4533 - acc: 0.8353 - val_loss: 0.6259 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4525 - acc: 0.8298 - val_loss: 0.6950 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4581 - acc: 0.8311 - val_loss: 0.6228 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4484 - acc: 0.8340 - val_loss: 0.6467 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4511 - acc: 0.8307 - val_loss: 0.6498 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4614 - acc: 0.8253 - val_loss: 0.6437 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4638 - acc: 0.8262 - val_loss: 0.6317 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4534 - acc: 0.8362 - val_loss: 0.6450 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4544 - acc: 0.8309 - val_loss: 0.6376 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4583 - acc: 0.8279 - val_loss: 0.6315 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4630 - acc: 0.8289 - val_loss: 0.6749 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4565 - acc: 0.8269 - val_loss: 0.6603 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4584 - acc: 0.8329 - val_loss: 0.6544 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4544 - acc: 0.8289 - val_loss: 0.6818 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4609 - acc: 0.8269 - val_loss: 0.6385 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4605 - acc: 0.8260 - val_loss: 0.6565 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4644 - acc: 0.8298 - val_loss: 0.6348 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4528 - acc: 0.8262 - val_loss: 0.6712 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4612 - acc: 0.8296 - val_loss: 0.6346 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4574 - acc: 0.8318 - val_loss: 0.6455 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4512 - acc: 0.8373 - val_loss: 0.6966 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4625 - acc: 0.8338 - val_loss: 0.6350 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4509 - acc: 0.8331 - val_loss: 0.6704 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4429 - acc: 0.8356 - val_loss: 0.6758 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4595 - acc: 0.8296 - val_loss: 0.7371 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4525 - acc: 0.8304 - val_loss: 0.6432 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4545 - acc: 0.8320 - val_loss: 0.6636 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4479 - acc: 0.8338 - val_loss: 0.6462 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4554 - acc: 0.8276 - val_loss: 0.6409 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4578 - acc: 0.8318 - val_loss: 0.6712 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4522 - acc: 0.8309 - val_loss: 0.7139 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4500 - acc: 0.8338 - val_loss: 0.6604 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4570 - acc: 0.8280 - val_loss: 0.6714 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4439 - acc: 0.8347 - val_loss: 0.6638 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4515 - acc: 0.8258 - val_loss: 0.6862 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4555 - acc: 0.8300 - val_loss: 0.6925 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4611 - acc: 0.8271 - val_loss: 0.6680 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4542 - acc: 0.8287 - val_loss: 0.6730 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4514 - acc: 0.8380 - val_loss: 0.7109 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4463 - acc: 0.8413 - val_loss: 0.6361 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4642 - acc: 0.8218 - val_loss: 0.6133 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4544 - acc: 0.8256 - val_loss: 0.6193 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4515 - acc: 0.8329 - val_loss: 0.6271 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4488 - acc: 0.8282 - val_loss: 0.6773 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4448 - acc: 0.8358 - val_loss: 0.6275 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4584 - acc: 0.8327 - val_loss: 0.6982 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4539 - acc: 0.8322 - val_loss: 0.6604 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4472 - acc: 0.8351 - val_loss: 0.6431 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4577 - acc: 0.8260 - val_loss: 0.6375 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4483 - acc: 0.8356 - val_loss: 0.6143 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4522 - acc: 0.8302 - val_loss: 0.6151 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4429 - acc: 0.8333 - val_loss: 0.6799 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4418 - acc: 0.8384 - val_loss: 0.6286 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4503 - acc: 0.8329 - val_loss: 0.6430 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4522 - acc: 0.8304 - val_loss: 0.6630 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4529 - acc: 0.8322 - val_loss: 0.6429 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4510 - acc: 0.8336 - val_loss: 0.6572 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4507 - acc: 0.8322 - val_loss: 0.6594 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4448 - acc: 0.8358 - val_loss: 0.6155 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4459 - acc: 0.8358 - val_loss: 0.6521 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4495 - acc: 0.8360 - val_loss: 0.6411 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4563 - acc: 0.8311 - val_loss: 0.6134 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4549 - acc: 0.8316 - val_loss: 0.7341 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4462 - acc: 0.8320 - val_loss: 0.6426 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4572 - acc: 0.8256 - val_loss: 0.6866 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4475 - acc: 0.8353 - val_loss: 0.6796 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4398 - acc: 0.8336 - val_loss: 0.6602 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4493 - acc: 0.8298 - val_loss: 0.6684 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4483 - acc: 0.8338 - val_loss: 0.6625 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4461 - acc: 0.8322 - val_loss: 0.6800 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4508 - acc: 0.8338 - val_loss: 0.6929 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4452 - acc: 0.8322 - val_loss: 0.6407 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4483 - acc: 0.8311 - val_loss: 0.6614 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4481 - acc: 0.8336 - val_loss: 0.6484 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4479 - acc: 0.8347 - val_loss: 0.6776 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4502 - acc: 0.8349 - val_loss: 0.6732 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4518 - acc: 0.8340 - val_loss: 0.6698 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4510 - acc: 0.8336 - val_loss: 0.6880 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4537 - acc: 0.8291 - val_loss: 0.6671 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4441 - acc: 0.8324 - val_loss: 0.6642 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4530 - acc: 0.8304 - val_loss: 0.6257 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6076 - acc: 0.7818\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7368 - acc: 0.7452\n",
            "epsilon: 0.003 and test evaluation : 0.7367936372756958, 0.7452006936073303\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8319 - acc: 0.7068\n",
            "epsilon: 0.005 and test evaluation : 0.8319212198257446, 0.7068063020706177\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.0924 - acc: 0.6335\n",
            "epsilon: 0.01 and test evaluation : 1.092397689819336, 0.6335078477859497\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.6641 - acc: 0.4625\n",
            "epsilon: 0.02 and test evaluation : 1.664070963859558, 0.4624781906604767\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 1.4409 - acc: 0.3282 - val_loss: 1.4121 - val_acc: 0.3249 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3551 - acc: 0.3539 - val_loss: 1.3775 - val_acc: 0.3385 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3182 - acc: 0.3690 - val_loss: 1.9067 - val_acc: 0.2802 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2997 - acc: 0.3803 - val_loss: 1.2851 - val_acc: 0.4066 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2693 - acc: 0.4058 - val_loss: 1.2698 - val_acc: 0.4202 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2499 - acc: 0.4284 - val_loss: 1.3296 - val_acc: 0.3677 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2141 - acc: 0.4664 - val_loss: 1.3954 - val_acc: 0.4202 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1844 - acc: 0.4895 - val_loss: 1.5583 - val_acc: 0.4222 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1257 - acc: 0.5447 - val_loss: 1.1460 - val_acc: 0.5409 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0955 - acc: 0.5445 - val_loss: 1.1844 - val_acc: 0.4981 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0709 - acc: 0.5514 - val_loss: 1.2274 - val_acc: 0.4805 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0145 - acc: 0.5873 - val_loss: 1.2242 - val_acc: 0.5039 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9917 - acc: 0.6068 - val_loss: 0.9704 - val_acc: 0.6518 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9304 - acc: 0.6272 - val_loss: 0.9101 - val_acc: 0.6459 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9286 - acc: 0.6355 - val_loss: 1.0043 - val_acc: 0.5914 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8784 - acc: 0.6525 - val_loss: 0.8989 - val_acc: 0.6576 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8564 - acc: 0.6656 - val_loss: 0.9616 - val_acc: 0.6284 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8264 - acc: 0.6787 - val_loss: 1.0137 - val_acc: 0.6245 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8187 - acc: 0.6829 - val_loss: 0.8241 - val_acc: 0.6946 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7872 - acc: 0.6989 - val_loss: 0.7990 - val_acc: 0.7082 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7643 - acc: 0.7111 - val_loss: 0.8129 - val_acc: 0.7179 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7712 - acc: 0.7014 - val_loss: 0.7838 - val_acc: 0.6946 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7505 - acc: 0.7191 - val_loss: 0.9055 - val_acc: 0.6615 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7322 - acc: 0.7218 - val_loss: 0.7941 - val_acc: 0.6946 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7180 - acc: 0.7315 - val_loss: 0.7453 - val_acc: 0.7451 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7103 - acc: 0.7298 - val_loss: 0.7507 - val_acc: 0.7237 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6786 - acc: 0.7493 - val_loss: 0.8906 - val_acc: 0.6809 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6977 - acc: 0.7402 - val_loss: 0.7768 - val_acc: 0.7101 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6864 - acc: 0.7366 - val_loss: 0.8584 - val_acc: 0.6946 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6702 - acc: 0.7453 - val_loss: 0.8765 - val_acc: 0.6848 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6509 - acc: 0.7573 - val_loss: 0.7746 - val_acc: 0.7043 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6273 - acc: 0.7626 - val_loss: 0.7480 - val_acc: 0.7296 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6026 - acc: 0.7781 - val_loss: 0.7441 - val_acc: 0.7315 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5828 - acc: 0.7866 - val_loss: 0.7148 - val_acc: 0.7315 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5796 - acc: 0.7795 - val_loss: 0.7247 - val_acc: 0.7198 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5655 - acc: 0.7917 - val_loss: 0.6938 - val_acc: 0.7393 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5496 - acc: 0.7959 - val_loss: 0.7027 - val_acc: 0.7451 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5480 - acc: 0.8005 - val_loss: 0.7330 - val_acc: 0.7276 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5529 - acc: 0.7994 - val_loss: 0.6870 - val_acc: 0.7471 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5448 - acc: 0.7996 - val_loss: 0.7066 - val_acc: 0.7315 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5397 - acc: 0.8041 - val_loss: 0.6854 - val_acc: 0.7490 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5309 - acc: 0.8076 - val_loss: 0.6854 - val_acc: 0.7412 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5417 - acc: 0.7999 - val_loss: 0.6890 - val_acc: 0.7471 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5355 - acc: 0.8034 - val_loss: 0.6781 - val_acc: 0.7471 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5241 - acc: 0.8096 - val_loss: 0.6885 - val_acc: 0.7374 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5293 - acc: 0.8085 - val_loss: 0.6907 - val_acc: 0.7374 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5253 - acc: 0.8047 - val_loss: 0.6785 - val_acc: 0.7510 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5144 - acc: 0.8125 - val_loss: 0.6832 - val_acc: 0.7490 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5141 - acc: 0.8090 - val_loss: 0.6793 - val_acc: 0.7490 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5091 - acc: 0.8158 - val_loss: 0.6719 - val_acc: 0.7568 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5074 - acc: 0.8125 - val_loss: 0.6915 - val_acc: 0.7335 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5137 - acc: 0.8045 - val_loss: 0.6741 - val_acc: 0.7393 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5035 - acc: 0.8143 - val_loss: 0.6895 - val_acc: 0.7412 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5107 - acc: 0.8138 - val_loss: 0.7260 - val_acc: 0.7043 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5023 - acc: 0.8198 - val_loss: 0.6762 - val_acc: 0.7451 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5057 - acc: 0.8150 - val_loss: 0.6861 - val_acc: 0.7218 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4965 - acc: 0.8176 - val_loss: 0.6675 - val_acc: 0.7451 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5049 - acc: 0.8161 - val_loss: 0.6980 - val_acc: 0.7296 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4992 - acc: 0.8125 - val_loss: 0.6642 - val_acc: 0.7510 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4973 - acc: 0.8229 - val_loss: 0.6976 - val_acc: 0.7354 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4909 - acc: 0.8181 - val_loss: 0.6730 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4874 - acc: 0.8212 - val_loss: 0.6805 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4950 - acc: 0.8123 - val_loss: 0.7349 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4885 - acc: 0.8194 - val_loss: 0.6630 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4920 - acc: 0.8185 - val_loss: 0.6694 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4850 - acc: 0.8203 - val_loss: 0.6728 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4895 - acc: 0.8203 - val_loss: 0.6870 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4891 - acc: 0.8183 - val_loss: 0.6772 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4907 - acc: 0.8198 - val_loss: 0.7070 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4852 - acc: 0.8245 - val_loss: 0.6963 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4814 - acc: 0.8234 - val_loss: 0.6723 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4902 - acc: 0.8221 - val_loss: 0.6800 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4902 - acc: 0.8218 - val_loss: 0.6710 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4944 - acc: 0.8165 - val_loss: 0.6727 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4921 - acc: 0.8207 - val_loss: 0.6705 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4944 - acc: 0.8136 - val_loss: 0.6929 - val_acc: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4852 - acc: 0.8178 - val_loss: 0.7343 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4865 - acc: 0.8223 - val_loss: 0.6598 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4839 - acc: 0.8232 - val_loss: 0.6855 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4937 - acc: 0.8132 - val_loss: 0.6590 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4881 - acc: 0.8238 - val_loss: 0.6765 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4865 - acc: 0.8218 - val_loss: 0.6764 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4948 - acc: 0.8125 - val_loss: 0.6792 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4827 - acc: 0.8267 - val_loss: 0.6786 - val_acc: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4885 - acc: 0.8221 - val_loss: 0.6973 - val_acc: 0.7218 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4938 - acc: 0.8123 - val_loss: 0.6599 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4921 - acc: 0.8232 - val_loss: 0.6898 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4821 - acc: 0.8185 - val_loss: 0.6803 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4982 - acc: 0.8130 - val_loss: 0.6780 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4859 - acc: 0.8245 - val_loss: 0.7018 - val_acc: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4942 - acc: 0.8138 - val_loss: 0.6935 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4788 - acc: 0.8247 - val_loss: 0.6890 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.4897 - acc: 0.8181 - val_loss: 0.6685 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4853 - acc: 0.8223 - val_loss: 0.6888 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4959 - acc: 0.8170 - val_loss: 0.6698 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4876 - acc: 0.8194 - val_loss: 0.6672 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4910 - acc: 0.8165 - val_loss: 0.6815 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4900 - acc: 0.8205 - val_loss: 0.6907 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4913 - acc: 0.8141 - val_loss: 0.6723 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4890 - acc: 0.8161 - val_loss: 0.6833 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4838 - acc: 0.8227 - val_loss: 0.6762 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4952 - acc: 0.8105 - val_loss: 0.6717 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4907 - acc: 0.8172 - val_loss: 0.6656 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4809 - acc: 0.8327 - val_loss: 0.6681 - val_acc: 0.7549 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4858 - acc: 0.8167 - val_loss: 0.7018 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4887 - acc: 0.8209 - val_loss: 0.6823 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4819 - acc: 0.8223 - val_loss: 0.6833 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4838 - acc: 0.8218 - val_loss: 0.6844 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4800 - acc: 0.8221 - val_loss: 0.6622 - val_acc: 0.7549 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4812 - acc: 0.8212 - val_loss: 0.6672 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4874 - acc: 0.8205 - val_loss: 0.6773 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.4834 - acc: 0.8218 - val_loss: 0.6678 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4926 - acc: 0.8192 - val_loss: 0.6749 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4894 - acc: 0.8192 - val_loss: 0.6652 - val_acc: 0.7607 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4910 - acc: 0.8205 - val_loss: 0.6680 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4867 - acc: 0.8229 - val_loss: 0.6716 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4898 - acc: 0.8107 - val_loss: 0.6691 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4808 - acc: 0.8192 - val_loss: 0.6844 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4917 - acc: 0.8176 - val_loss: 0.6687 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4853 - acc: 0.8216 - val_loss: 0.6727 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4884 - acc: 0.8154 - val_loss: 0.7195 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4823 - acc: 0.8258 - val_loss: 0.6670 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4861 - acc: 0.8130 - val_loss: 0.6607 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4798 - acc: 0.8258 - val_loss: 0.6788 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4855 - acc: 0.8203 - val_loss: 0.6839 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4890 - acc: 0.8227 - val_loss: 0.6785 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4905 - acc: 0.8161 - val_loss: 0.6887 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4898 - acc: 0.8154 - val_loss: 0.6781 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4828 - acc: 0.8223 - val_loss: 0.6774 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4877 - acc: 0.8167 - val_loss: 0.6758 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4819 - acc: 0.8225 - val_loss: 0.6933 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4848 - acc: 0.8245 - val_loss: 0.6628 - val_acc: 0.7568 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4834 - acc: 0.8216 - val_loss: 0.6910 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4893 - acc: 0.8178 - val_loss: 0.7032 - val_acc: 0.7198 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4841 - acc: 0.8196 - val_loss: 0.6676 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4845 - acc: 0.8223 - val_loss: 0.6681 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4880 - acc: 0.8232 - val_loss: 0.6806 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4816 - acc: 0.8252 - val_loss: 0.7465 - val_acc: 0.7140 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4857 - acc: 0.8221 - val_loss: 0.6592 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4936 - acc: 0.8154 - val_loss: 0.6939 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4876 - acc: 0.8221 - val_loss: 0.6752 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4894 - acc: 0.8192 - val_loss: 0.6827 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4813 - acc: 0.8252 - val_loss: 0.6967 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4897 - acc: 0.8127 - val_loss: 0.6902 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4819 - acc: 0.8192 - val_loss: 0.6742 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4913 - acc: 0.8205 - val_loss: 0.6812 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4843 - acc: 0.8187 - val_loss: 0.6547 - val_acc: 0.7568 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4836 - acc: 0.8198 - val_loss: 0.6672 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4861 - acc: 0.8176 - val_loss: 0.6724 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4858 - acc: 0.8225 - val_loss: 0.7126 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4756 - acc: 0.8216 - val_loss: 0.6634 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4874 - acc: 0.8223 - val_loss: 0.6869 - val_acc: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4907 - acc: 0.8158 - val_loss: 0.6658 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4799 - acc: 0.8263 - val_loss: 0.6791 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4875 - acc: 0.8166 - val_loss: 0.6769 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4839 - acc: 0.8252 - val_loss: 0.6690 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4814 - acc: 0.8249 - val_loss: 0.6774 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4902 - acc: 0.8132 - val_loss: 0.6698 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4821 - acc: 0.8249 - val_loss: 0.6718 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4834 - acc: 0.8161 - val_loss: 0.6959 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4833 - acc: 0.8212 - val_loss: 0.6918 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4880 - acc: 0.8227 - val_loss: 0.6938 - val_acc: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4904 - acc: 0.8143 - val_loss: 0.6713 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4810 - acc: 0.8189 - val_loss: 0.6874 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4897 - acc: 0.8187 - val_loss: 0.6795 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4838 - acc: 0.8212 - val_loss: 0.6928 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4833 - acc: 0.8218 - val_loss: 0.7139 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4786 - acc: 0.8289 - val_loss: 0.6918 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4861 - acc: 0.8183 - val_loss: 0.6733 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4847 - acc: 0.8198 - val_loss: 0.6738 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4866 - acc: 0.8264 - val_loss: 0.6664 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4846 - acc: 0.8156 - val_loss: 0.7189 - val_acc: 0.7160 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4880 - acc: 0.8138 - val_loss: 0.6883 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4769 - acc: 0.8247 - val_loss: 0.6665 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4749 - acc: 0.8258 - val_loss: 0.6774 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4775 - acc: 0.8223 - val_loss: 0.6859 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4856 - acc: 0.8214 - val_loss: 0.6965 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4729 - acc: 0.8223 - val_loss: 0.6676 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4832 - acc: 0.8183 - val_loss: 0.6698 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4858 - acc: 0.8265 - val_loss: 0.6965 - val_acc: 0.7198 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4756 - acc: 0.8245 - val_loss: 0.6768 - val_acc: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4860 - acc: 0.8242 - val_loss: 0.6785 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4766 - acc: 0.8227 - val_loss: 0.6761 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4829 - acc: 0.8196 - val_loss: 0.6604 - val_acc: 0.7568 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4836 - acc: 0.8192 - val_loss: 0.6814 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4825 - acc: 0.8232 - val_loss: 0.6600 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4829 - acc: 0.8201 - val_loss: 0.7049 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4763 - acc: 0.8254 - val_loss: 0.6736 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4783 - acc: 0.8241 - val_loss: 0.6726 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4775 - acc: 0.8241 - val_loss: 0.6653 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4846 - acc: 0.8164 - val_loss: 0.6554 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4836 - acc: 0.8232 - val_loss: 0.6841 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4756 - acc: 0.8234 - val_loss: 0.6641 - val_acc: 0.7549 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4805 - acc: 0.8209 - val_loss: 0.6681 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4860 - acc: 0.8201 - val_loss: 0.6835 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4847 - acc: 0.8187 - val_loss: 0.6748 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4840 - acc: 0.8198 - val_loss: 0.6939 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4807 - acc: 0.8232 - val_loss: 0.6765 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4824 - acc: 0.8185 - val_loss: 0.6715 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4833 - acc: 0.8249 - val_loss: 0.6578 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6161 - acc: 0.7609\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7273 - acc: 0.7173\n",
            "epsilon: 0.003 and test evaluation : 0.7273135185241699, 0.717277467250824\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8089 - acc: 0.6963\n",
            "epsilon: 0.005 and test evaluation : 0.8089032769203186, 0.6963350772857666\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.0350 - acc: 0.6161\n",
            "epsilon: 0.01 and test evaluation : 1.0350041389465332, 0.6160558462142944\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.5272 - acc: 0.4782\n",
            "epsilon: 0.02 and test evaluation : 1.5272483825683594, 0.4781849980354309\n",
            "SNR: 33.76082897186279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5KYPHDImp62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df[\"acc_clean_mean\"]= np.sum(result_df['acc_clean'])/10.0\n",
        "result_df[\"acc_0.003_mean\"]= np.sum(result_df['acc1'])/10.0\n",
        "result_df[\"acc_0.005_mean\"]= np.sum(result_df['acc2'])/10.0\n",
        "result_df[\"acc_0.02_mean\"]= np.sum(result_df['acc3'])/10.0\n",
        "result_df[\"acc_0.01_mean\"]= np.sum(result_df['acc4'])/10.0"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihcS6J2vzv6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5f0fd82f-d7e6-467a-bbe9-231f493f91c1"
      },
      "source": [
        "result_df.head(1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>loss4</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc_clean_mean</th>\n",
              "      <th>acc_0.003_mean</th>\n",
              "      <th>acc_0.005_mean</th>\n",
              "      <th>acc_0.02_mean</th>\n",
              "      <th>acc_0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.574416</td>\n",
              "      <td>0.794066</td>\n",
              "      <td>0.695798</td>\n",
              "      <td>0.739965</td>\n",
              "      <td>0.786916</td>\n",
              "      <td>0.710297</td>\n",
              "      <td>1.042501</td>\n",
              "      <td>0.612565</td>\n",
              "      <td>1.611463</td>\n",
              "      <td>0.460733</td>\n",
              "      <td>0.775218</td>\n",
              "      <td>0.731763</td>\n",
              "      <td>0.700873</td>\n",
              "      <td>0.62164</td>\n",
              "      <td>0.4726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  ...  acc_0.02_mean  acc_0.01_mean\n",
              "0    0.574416   0.794066  ...        0.62164         0.4726\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC_90XJcmu5l",
        "colab_type": "text"
      },
      "source": [
        "# **Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7m-n2RCmyse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Adversarial Training \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "class AdversarialTraining(object):\n",
        "    \"\"\"Adversarial Training  \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def train(self, pretrained_model, X_train, Y_train, X_test, y_test, epochs, BS, epsilon_list, sgd):\n",
        "        init = (32, 32,1)\n",
        "        res_df = pd.DataFrame(columns=['loss_clean','acc_clean',\n",
        "                                 'loss1', 'acc1','loss2', 'acc2','loss3',\n",
        "                                  'acc3','loss4', 'acc4'])\n",
        "\n",
        "        kfold = KFold(n_splits = 10, random_state = 42)\n",
        "        for j, (train, val) in enumerate(kfold.split(X_train)):\n",
        "          x_train, y_train = self.data_augmentation(X_train[train], Y_train[train], BS, pretrained_model, epsilon_list)\n",
        "          x_val, y_val = self.data_augmentation(X_train[val], Y_train[val], BS, pretrained_model, epsilon_list)\n",
        "          model = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "          model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "          hist = model.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=epochs,\n",
        "                          callbacks = [lr_scheduler],\n",
        "                          validation_data=(x_val, y_val),\n",
        "                          validation_steps=x_val.shape[0] // BS,)\n",
        "          loss, acc = model.evaluate(X_test, y_test)\n",
        "          loss1, acc1 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[0]),X_test, y_test, epsilon_list[0])\n",
        "          loss2, acc2 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[1]),X_test, y_test, epsilon_list[1])\n",
        "          loss3, acc3 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[2]),X_test, y_test, epsilon_list[2])\n",
        "          loss4, acc4 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[3]),X_test, y_test, epsilon_list[3])\n",
        "          row = {'loss_clean':loss,'acc_clean':acc, 'loss1':loss1, 'acc1':acc1, 'loss2':loss2,\n",
        "                  'acc2':acc2, 'loss3':loss3, 'acc3':acc3, 'loss4':loss4, 'acc4':acc4}\n",
        "          res_df = res_df.append(row , ignore_index=True)\n",
        "          \n",
        "        return res_df\n",
        "    def mini_batch_train(self, model, X_train,y_train, x_val, y_val, BS, pretrained_model, epsilon):\n",
        "\n",
        "\n",
        "        hist = model.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=1,\n",
        "                   validation_data=(x_val, y_val),\n",
        "                   validation_steps=x_val.shape[0] // BS, shuffle = True)\n",
        "        \n",
        "        ### TODO ###\n",
        "        ## Save hist on file.###\n",
        "\n",
        "\n",
        "    def data_augmentation(self, X_train, Y_train, batch_size, pretrained_model, epsilon_list):\n",
        "      ### divide data 16,16,16,16 for 4 different epsilons and 64 is true image. ### \n",
        "        #start_index = self.data_iteration(X_train, batch_size)\n",
        "        first_half_end = int(len(X_train)/2)\n",
        "        second_half_end = int(len(X_train))\n",
        "        x_clean = X_train[0:first_half_end,:,:,:]\n",
        "        x_adv = self.get_adversarial(X_train[first_half_end:second_half_end,:,:,:], Y_train[first_half_end:second_half_end], epsilon_list)\n",
        "        x_mix = self.merge_data(x_clean, x_adv)\n",
        "        y_mix = Y_train[0:second_half_end]\n",
        "        ### TODO###\n",
        "        # Mixture data for 4 epsilon values\n",
        "\n",
        "        return x_mix, y_mix\n",
        "\n",
        "    def data_iteration(self, X_train, batch_size):\n",
        "        N = X_train.shape[0]\n",
        "        start = np.random.randint(0, N-batch_size)\n",
        "        return start\n",
        "\n",
        "    def merge_data(self, x_clean, x_adv):\n",
        "        x_mix = []\n",
        "        for i in range(len(x_clean)):\n",
        "          x_mix.append(x_clean[i])\n",
        "        for j in range(len(x_adv)):\n",
        "          x_mix.append(x_adv[j])\n",
        "        x_mix = np.array(x_mix)\n",
        "\n",
        "        return x_mix\n",
        "\n",
        "\n",
        "    def get_adversarial(self, X_true, y_true, epsilon_list):\n",
        "\n",
        "        return self.adversarial_example(X_true, y_true, epsilon_list)\n",
        "\n",
        "    def adversarial_example(self, X_true, Y_true, epsilon_list):\n",
        "        size = len(X_true)\n",
        "        X_adv = []\n",
        "        interval = int(size/4)\n",
        "        index_list = [0,interval, interval*2, interval*3, size]\n",
        "        index = 0\n",
        "        for epsilon in epsilon_list:\n",
        "          if index == 4:\n",
        "            break\n",
        "          x_true = X_true[index_list[index]:index_list[index+1],:,:,:]\n",
        "          y_true = Y_true[index_list[index]:index_list[index+1]]\n",
        "\n",
        "          index = index + 1\n",
        "\n",
        "          for i in range(len(x_true)):\n",
        "            random_index = i\n",
        "            original_image = x_true[random_index]\n",
        "            original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "            original_label = y_true[random_index]\n",
        "            original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "            adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "            X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "          \n",
        "        X_adv = np.array(X_adv)\n",
        "        return X_adv\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swjxYRDJm5Iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c4f6f52-d796-466a-b5b1-cf807ba0b23d"
      },
      "source": [
        "epsilon_list = [0.003,0.005,0.01,0.02]\n",
        "adversarial_training =  AdversarialTraining()\n",
        "sgd = SGD(lr=0.1, momentum=0.6)\n",
        "logits_model = tf.keras.Model(parseval_16_2.input, parseval_16_2.layers[-1].output)\n",
        "result_adv_df = adversarial_training.train(logits_model, X_train, Y_train, X_test, y_test, EPOCHS, BS, epsilon_list, sgd)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 1.4454 - acc: 0.3278 - val_loss: 1.3829 - val_acc: 0.3282 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 1.3367 - acc: 0.3735 - val_loss: 1.3751 - val_acc: 0.3592 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3006 - acc: 0.4021 - val_loss: 1.3973 - val_acc: 0.3087 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2785 - acc: 0.4150 - val_loss: 1.2964 - val_acc: 0.4330 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2606 - acc: 0.4436 - val_loss: 1.2949 - val_acc: 0.4854 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2133 - acc: 0.4827 - val_loss: 1.2286 - val_acc: 0.4680 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1576 - acc: 0.5237 - val_loss: 1.2685 - val_acc: 0.5087 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1295 - acc: 0.5344 - val_loss: 1.1104 - val_acc: 0.5748 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0857 - acc: 0.5659 - val_loss: 1.6255 - val_acc: 0.4019 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0783 - acc: 0.5539 - val_loss: 1.1406 - val_acc: 0.5359 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0202 - acc: 0.5921 - val_loss: 1.1262 - val_acc: 0.5786 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9888 - acc: 0.6012 - val_loss: 1.0979 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9455 - acc: 0.6116 - val_loss: 1.6854 - val_acc: 0.3709 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.9212 - acc: 0.6349 - val_loss: 2.0455 - val_acc: 0.4466 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8778 - acc: 0.6507 - val_loss: 1.1014 - val_acc: 0.5592 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8637 - acc: 0.6707 - val_loss: 0.9953 - val_acc: 0.5942 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.8594 - acc: 0.6620 - val_loss: 0.9046 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8264 - acc: 0.6780 - val_loss: 0.8490 - val_acc: 0.6738 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8117 - acc: 0.6818 - val_loss: 0.9459 - val_acc: 0.6291 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7919 - acc: 0.6977 - val_loss: 1.2470 - val_acc: 0.6078 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7913 - acc: 0.6929 - val_loss: 0.8608 - val_acc: 0.6699 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7693 - acc: 0.7071 - val_loss: 0.8203 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7704 - acc: 0.7088 - val_loss: 0.8145 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7377 - acc: 0.7208 - val_loss: 0.7858 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7452 - acc: 0.7157 - val_loss: 0.8303 - val_acc: 0.6524 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7252 - acc: 0.7179 - val_loss: 0.7918 - val_acc: 0.7107 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7052 - acc: 0.7295 - val_loss: 0.9318 - val_acc: 0.6447 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6996 - acc: 0.7344 - val_loss: 0.9309 - val_acc: 0.6738 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7043 - acc: 0.7290 - val_loss: 0.8141 - val_acc: 0.7087 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6969 - acc: 0.7308 - val_loss: 1.1095 - val_acc: 0.5961 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8485 - acc: 0.6525 - val_loss: 0.8767 - val_acc: 0.6602 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.6968 - acc: 0.7177 - val_loss: 0.8179 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6416 - acc: 0.7488 - val_loss: 0.8300 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6243 - acc: 0.7597 - val_loss: 0.8041 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6014 - acc: 0.7692 - val_loss: 0.7891 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6038 - acc: 0.7743 - val_loss: 0.7858 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5846 - acc: 0.7792 - val_loss: 0.7566 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5808 - acc: 0.7812 - val_loss: 0.7625 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5857 - acc: 0.7772 - val_loss: 0.7519 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5713 - acc: 0.7841 - val_loss: 0.7526 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5787 - acc: 0.7805 - val_loss: 0.7687 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5679 - acc: 0.7876 - val_loss: 0.7578 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5699 - acc: 0.7834 - val_loss: 0.7487 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5544 - acc: 0.7885 - val_loss: 0.7649 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5578 - acc: 0.7965 - val_loss: 0.7715 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5526 - acc: 0.7927 - val_loss: 0.7588 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5594 - acc: 0.7863 - val_loss: 0.7394 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5532 - acc: 0.7923 - val_loss: 0.7407 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5542 - acc: 0.7889 - val_loss: 0.7621 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5485 - acc: 0.7947 - val_loss: 0.7820 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5479 - acc: 0.7885 - val_loss: 0.7647 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5350 - acc: 0.7934 - val_loss: 0.7768 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5343 - acc: 0.8025 - val_loss: 0.7577 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5304 - acc: 0.8018 - val_loss: 0.7629 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5337 - acc: 0.7977 - val_loss: 0.7582 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5226 - acc: 0.8049 - val_loss: 0.7658 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5382 - acc: 0.8005 - val_loss: 0.7569 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5195 - acc: 0.8049 - val_loss: 0.7519 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5262 - acc: 0.8027 - val_loss: 0.7633 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5158 - acc: 0.8074 - val_loss: 0.7591 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5171 - acc: 0.8012 - val_loss: 0.7548 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5200 - acc: 0.8038 - val_loss: 0.7659 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5120 - acc: 0.8043 - val_loss: 0.7691 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5109 - acc: 0.8063 - val_loss: 0.7664 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5184 - acc: 0.8080 - val_loss: 0.7384 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5197 - acc: 0.8111 - val_loss: 0.7585 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5140 - acc: 0.8016 - val_loss: 0.7589 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5139 - acc: 0.8079 - val_loss: 0.7573 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5170 - acc: 0.8040 - val_loss: 0.7546 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5192 - acc: 0.8098 - val_loss: 0.7403 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5140 - acc: 0.8056 - val_loss: 0.7726 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5086 - acc: 0.8069 - val_loss: 0.7506 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5216 - acc: 0.8023 - val_loss: 0.7870 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5188 - acc: 0.8040 - val_loss: 0.7455 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5075 - acc: 0.8065 - val_loss: 0.7494 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5208 - acc: 0.7996 - val_loss: 0.7512 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5113 - acc: 0.8058 - val_loss: 0.7629 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5249 - acc: 0.8012 - val_loss: 0.7696 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5137 - acc: 0.8058 - val_loss: 0.7586 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5125 - acc: 0.8049 - val_loss: 0.7568 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5208 - acc: 0.8000 - val_loss: 0.7546 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5165 - acc: 0.8071 - val_loss: 0.7864 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5215 - acc: 0.8012 - val_loss: 0.7412 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5181 - acc: 0.8063 - val_loss: 0.7573 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5183 - acc: 0.8023 - val_loss: 0.7573 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5174 - acc: 0.8094 - val_loss: 0.7494 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5085 - acc: 0.8076 - val_loss: 0.7807 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5227 - acc: 0.8023 - val_loss: 0.7538 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5152 - acc: 0.8025 - val_loss: 0.7871 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5195 - acc: 0.7994 - val_loss: 0.7483 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5109 - acc: 0.8056 - val_loss: 0.7531 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5151 - acc: 0.8040 - val_loss: 0.7588 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5180 - acc: 0.8014 - val_loss: 0.7548 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5115 - acc: 0.8060 - val_loss: 0.7524 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5076 - acc: 0.8125 - val_loss: 0.7808 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5151 - acc: 0.8045 - val_loss: 0.7493 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5186 - acc: 0.8014 - val_loss: 0.7459 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5150 - acc: 0.7994 - val_loss: 0.7797 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5157 - acc: 0.8003 - val_loss: 0.7514 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5126 - acc: 0.8045 - val_loss: 0.7630 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5118 - acc: 0.8043 - val_loss: 0.7605 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5201 - acc: 0.8020 - val_loss: 0.7760 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5202 - acc: 0.8014 - val_loss: 0.7657 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5122 - acc: 0.8051 - val_loss: 0.7536 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5122 - acc: 0.8074 - val_loss: 0.7548 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5149 - acc: 0.8000 - val_loss: 0.7697 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5180 - acc: 0.8051 - val_loss: 0.7636 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5196 - acc: 0.8018 - val_loss: 0.7489 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5170 - acc: 0.7994 - val_loss: 0.7799 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5043 - acc: 0.8147 - val_loss: 0.7550 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5165 - acc: 0.8060 - val_loss: 0.7633 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5071 - acc: 0.8067 - val_loss: 0.7712 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5148 - acc: 0.8016 - val_loss: 0.7455 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5050 - acc: 0.8138 - val_loss: 0.7794 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5149 - acc: 0.8098 - val_loss: 0.7357 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5150 - acc: 0.8063 - val_loss: 0.7879 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5175 - acc: 0.8025 - val_loss: 0.7634 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5109 - acc: 0.8043 - val_loss: 0.7608 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5164 - acc: 0.8051 - val_loss: 0.7715 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5122 - acc: 0.8025 - val_loss: 0.7463 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5046 - acc: 0.8091 - val_loss: 0.7709 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5119 - acc: 0.8071 - val_loss: 0.7548 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5109 - acc: 0.8027 - val_loss: 0.7589 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5123 - acc: 0.8034 - val_loss: 0.7502 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5156 - acc: 0.8089 - val_loss: 0.7416 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5137 - acc: 0.8043 - val_loss: 0.7459 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5131 - acc: 0.8043 - val_loss: 0.7806 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5123 - acc: 0.8058 - val_loss: 0.7652 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5158 - acc: 0.8076 - val_loss: 0.7430 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5108 - acc: 0.8085 - val_loss: 0.7498 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5185 - acc: 0.8049 - val_loss: 0.7476 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5065 - acc: 0.8027 - val_loss: 0.7477 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5094 - acc: 0.8045 - val_loss: 0.7488 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5163 - acc: 0.8023 - val_loss: 0.7286 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5082 - acc: 0.8087 - val_loss: 0.7463 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5009 - acc: 0.8047 - val_loss: 0.7509 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5042 - acc: 0.8111 - val_loss: 0.7466 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5073 - acc: 0.8058 - val_loss: 0.7518 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5116 - acc: 0.8038 - val_loss: 0.7497 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5096 - acc: 0.8089 - val_loss: 0.7548 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5141 - acc: 0.8080 - val_loss: 0.7680 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5220 - acc: 0.8014 - val_loss: 0.7558 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5146 - acc: 0.8038 - val_loss: 0.7767 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5038 - acc: 0.8096 - val_loss: 0.7613 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5070 - acc: 0.8076 - val_loss: 0.7560 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5148 - acc: 0.8025 - val_loss: 0.7933 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5092 - acc: 0.8043 - val_loss: 0.7526 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5137 - acc: 0.8071 - val_loss: 0.7442 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5117 - acc: 0.8083 - val_loss: 0.7426 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5097 - acc: 0.8020 - val_loss: 0.7378 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5108 - acc: 0.8047 - val_loss: 0.7432 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5199 - acc: 0.8063 - val_loss: 0.7472 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5101 - acc: 0.8049 - val_loss: 0.7398 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5059 - acc: 0.8076 - val_loss: 0.7462 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5052 - acc: 0.8038 - val_loss: 0.7421 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5145 - acc: 0.8036 - val_loss: 0.7670 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5195 - acc: 0.7938 - val_loss: 0.7513 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5007 - acc: 0.8103 - val_loss: 0.7740 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5150 - acc: 0.8051 - val_loss: 0.7541 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5135 - acc: 0.8027 - val_loss: 0.7542 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5085 - acc: 0.8012 - val_loss: 0.7562 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5136 - acc: 0.8032 - val_loss: 0.7575 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5130 - acc: 0.8018 - val_loss: 0.7806 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5089 - acc: 0.8034 - val_loss: 0.7386 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5093 - acc: 0.8063 - val_loss: 0.7528 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5081 - acc: 0.8091 - val_loss: 0.7612 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5136 - acc: 0.8025 - val_loss: 0.7500 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5048 - acc: 0.8103 - val_loss: 0.7963 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5125 - acc: 0.8032 - val_loss: 0.7598 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5102 - acc: 0.8029 - val_loss: 0.7543 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5148 - acc: 0.8005 - val_loss: 0.7343 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5032 - acc: 0.8127 - val_loss: 0.7642 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5108 - acc: 0.8032 - val_loss: 0.7437 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5040 - acc: 0.8051 - val_loss: 0.7689 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5108 - acc: 0.8067 - val_loss: 0.7983 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5119 - acc: 0.8034 - val_loss: 0.7536 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5162 - acc: 0.8054 - val_loss: 0.7802 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5006 - acc: 0.8127 - val_loss: 0.7645 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5094 - acc: 0.8071 - val_loss: 0.7914 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5127 - acc: 0.8078 - val_loss: 0.7712 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5133 - acc: 0.8071 - val_loss: 0.7555 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5072 - acc: 0.8089 - val_loss: 0.7782 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5073 - acc: 0.8020 - val_loss: 0.7419 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4970 - acc: 0.8129 - val_loss: 0.7467 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5043 - acc: 0.8065 - val_loss: 0.7585 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5128 - acc: 0.8036 - val_loss: 0.7491 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5086 - acc: 0.8027 - val_loss: 0.7617 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5126 - acc: 0.8040 - val_loss: 0.7652 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5090 - acc: 0.8058 - val_loss: 0.7491 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5079 - acc: 0.8109 - val_loss: 0.7494 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5130 - acc: 0.8007 - val_loss: 0.7413 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5124 - acc: 0.8060 - val_loss: 0.7546 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5004 - acc: 0.8158 - val_loss: 0.7600 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5040 - acc: 0.8038 - val_loss: 0.7477 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5049 - acc: 0.8111 - val_loss: 0.7501 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5070 - acc: 0.8095 - val_loss: 0.7331 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5018 - acc: 0.8071 - val_loss: 0.7945 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5034 - acc: 0.8096 - val_loss: 0.7443 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5026 - acc: 0.8067 - val_loss: 0.7774 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5100 - acc: 0.8073 - val_loss: 0.7421 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5992 - acc: 0.7818\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6248 - acc: 0.7749\n",
            "epsilon: 0.003 and test evaluation : 0.6247574090957642, 0.7748690843582153\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6426 - acc: 0.7679\n",
            "epsilon: 0.005 and test evaluation : 0.6425873041152954, 0.7678883075714111\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6900 - acc: 0.7417\n",
            "epsilon: 0.01 and test evaluation : 0.6899604797363281, 0.7417103052139282\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7961 - acc: 0.7016\n",
            "epsilon: 0.02 and test evaluation : 0.7961367964744568, 0.7015706896781921\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 1.4482 - acc: 0.3160 - val_loss: 1.3740 - val_acc: 0.3495 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3428 - acc: 0.3728 - val_loss: 1.3622 - val_acc: 0.3223 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3087 - acc: 0.3813 - val_loss: 1.3052 - val_acc: 0.3903 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2844 - acc: 0.3835 - val_loss: 1.2825 - val_acc: 0.4272 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2687 - acc: 0.4223 - val_loss: 1.3601 - val_acc: 0.3417 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 1.2373 - acc: 0.4510 - val_loss: 1.2010 - val_acc: 0.4951 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1920 - acc: 0.4951 - val_loss: 1.4625 - val_acc: 0.3903 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1492 - acc: 0.5244 - val_loss: 1.6608 - val_acc: 0.3320 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0844 - acc: 0.5619 - val_loss: 1.0883 - val_acc: 0.5748 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0762 - acc: 0.5519 - val_loss: 1.4797 - val_acc: 0.3670 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0470 - acc: 0.5672 - val_loss: 1.0521 - val_acc: 0.5631 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9786 - acc: 0.6105 - val_loss: 1.0651 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9607 - acc: 0.6198 - val_loss: 0.9504 - val_acc: 0.6427 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.9115 - acc: 0.6365 - val_loss: 0.9501 - val_acc: 0.6214 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8833 - acc: 0.6573 - val_loss: 1.0794 - val_acc: 0.5592 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8686 - acc: 0.6640 - val_loss: 1.1280 - val_acc: 0.5806 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8562 - acc: 0.6693 - val_loss: 0.8426 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8123 - acc: 0.6829 - val_loss: 1.6248 - val_acc: 0.4466 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8512 - acc: 0.6613 - val_loss: 0.9005 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8127 - acc: 0.6882 - val_loss: 0.8177 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7885 - acc: 0.6988 - val_loss: 0.8541 - val_acc: 0.6718 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7832 - acc: 0.7071 - val_loss: 0.8295 - val_acc: 0.6835 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7670 - acc: 0.7035 - val_loss: 0.8941 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7510 - acc: 0.7108 - val_loss: 1.0119 - val_acc: 0.6097 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7515 - acc: 0.7124 - val_loss: 0.8858 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7219 - acc: 0.7246 - val_loss: 0.7822 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.7178 - acc: 0.7289 - val_loss: 0.8120 - val_acc: 0.7010 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7337 - acc: 0.7204 - val_loss: 0.7634 - val_acc: 0.7087 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7081 - acc: 0.7317 - val_loss: 0.8241 - val_acc: 0.6718 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6917 - acc: 0.7364 - val_loss: 0.9503 - val_acc: 0.6291 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9060 - acc: 0.6416 - val_loss: 0.8633 - val_acc: 0.6524 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7462 - acc: 0.7150 - val_loss: 0.7799 - val_acc: 0.6893 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.6643 - acc: 0.7472 - val_loss: 0.7149 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6260 - acc: 0.7685 - val_loss: 0.7032 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6129 - acc: 0.7750 - val_loss: 0.6850 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6060 - acc: 0.7763 - val_loss: 0.7036 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5944 - acc: 0.7781 - val_loss: 0.6912 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5858 - acc: 0.7843 - val_loss: 0.6918 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5847 - acc: 0.7836 - val_loss: 0.6813 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5710 - acc: 0.7918 - val_loss: 0.6847 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5700 - acc: 0.7925 - val_loss: 0.6783 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5699 - acc: 0.7960 - val_loss: 0.6805 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5664 - acc: 0.7947 - val_loss: 0.6711 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5605 - acc: 0.7938 - val_loss: 0.6702 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5706 - acc: 0.7941 - val_loss: 0.6868 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5590 - acc: 0.7980 - val_loss: 0.6947 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5598 - acc: 0.7921 - val_loss: 0.6962 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5420 - acc: 0.8056 - val_loss: 0.6982 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5495 - acc: 0.7994 - val_loss: 0.6949 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5465 - acc: 0.7972 - val_loss: 0.7095 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5460 - acc: 0.7998 - val_loss: 0.7045 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5359 - acc: 0.8087 - val_loss: 0.6964 - val_acc: 0.7282 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5398 - acc: 0.8069 - val_loss: 0.6788 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5334 - acc: 0.8051 - val_loss: 0.7061 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5409 - acc: 0.8023 - val_loss: 0.6773 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5390 - acc: 0.8076 - val_loss: 0.6833 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5264 - acc: 0.8089 - val_loss: 0.6858 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5316 - acc: 0.8108 - val_loss: 0.6775 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5237 - acc: 0.8094 - val_loss: 0.6928 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5224 - acc: 0.8105 - val_loss: 0.6985 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5185 - acc: 0.8129 - val_loss: 0.6941 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5215 - acc: 0.8111 - val_loss: 0.6828 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5165 - acc: 0.8185 - val_loss: 0.6888 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5165 - acc: 0.8158 - val_loss: 0.6745 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5146 - acc: 0.8145 - val_loss: 0.6841 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5193 - acc: 0.8138 - val_loss: 0.6768 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5213 - acc: 0.8109 - val_loss: 0.6831 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5217 - acc: 0.8063 - val_loss: 0.6878 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5186 - acc: 0.8107 - val_loss: 0.6752 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5203 - acc: 0.8089 - val_loss: 0.6898 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5152 - acc: 0.8098 - val_loss: 0.6958 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5249 - acc: 0.8080 - val_loss: 0.7603 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5249 - acc: 0.8120 - val_loss: 0.6893 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5070 - acc: 0.8149 - val_loss: 0.6918 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5265 - acc: 0.8080 - val_loss: 0.7030 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5231 - acc: 0.8091 - val_loss: 0.6761 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5200 - acc: 0.8120 - val_loss: 0.6853 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5206 - acc: 0.8107 - val_loss: 0.6723 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5156 - acc: 0.8178 - val_loss: 0.6756 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5202 - acc: 0.8094 - val_loss: 0.6809 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5227 - acc: 0.8096 - val_loss: 0.7179 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5196 - acc: 0.8145 - val_loss: 0.6982 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5244 - acc: 0.8083 - val_loss: 0.6773 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5258 - acc: 0.8049 - val_loss: 0.7082 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5224 - acc: 0.8056 - val_loss: 0.6793 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5168 - acc: 0.8167 - val_loss: 0.6798 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5140 - acc: 0.8118 - val_loss: 0.6903 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5197 - acc: 0.8105 - val_loss: 0.6946 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5124 - acc: 0.8071 - val_loss: 0.6774 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5225 - acc: 0.8089 - val_loss: 0.6696 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5158 - acc: 0.8154 - val_loss: 0.6793 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5196 - acc: 0.8078 - val_loss: 0.6975 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5165 - acc: 0.8120 - val_loss: 0.6799 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5215 - acc: 0.8085 - val_loss: 0.6989 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5227 - acc: 0.8105 - val_loss: 0.6854 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5131 - acc: 0.8087 - val_loss: 0.6873 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5282 - acc: 0.8000 - val_loss: 0.6863 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5154 - acc: 0.8120 - val_loss: 0.6795 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5265 - acc: 0.8078 - val_loss: 0.6853 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5172 - acc: 0.8171 - val_loss: 0.6776 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5222 - acc: 0.8065 - val_loss: 0.6787 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5227 - acc: 0.8096 - val_loss: 0.6954 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5216 - acc: 0.8060 - val_loss: 0.6890 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5164 - acc: 0.8125 - val_loss: 0.7194 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5226 - acc: 0.8087 - val_loss: 0.6919 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5083 - acc: 0.8105 - val_loss: 0.6796 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5108 - acc: 0.8078 - val_loss: 0.6755 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.5131 - acc: 0.8151 - val_loss: 0.6813 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5279 - acc: 0.8051 - val_loss: 0.6850 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5193 - acc: 0.8111 - val_loss: 0.6743 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5158 - acc: 0.8107 - val_loss: 0.6933 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5193 - acc: 0.8096 - val_loss: 0.6731 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5162 - acc: 0.8116 - val_loss: 0.6880 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5099 - acc: 0.8136 - val_loss: 0.6915 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5212 - acc: 0.8087 - val_loss: 0.6790 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5150 - acc: 0.8123 - val_loss: 0.6829 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5161 - acc: 0.8145 - val_loss: 0.6642 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5196 - acc: 0.8116 - val_loss: 0.6883 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5222 - acc: 0.8088 - val_loss: 0.6729 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5143 - acc: 0.8105 - val_loss: 0.6700 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5248 - acc: 0.8085 - val_loss: 0.6771 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5103 - acc: 0.8134 - val_loss: 0.7113 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5105 - acc: 0.8125 - val_loss: 0.6987 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5251 - acc: 0.8032 - val_loss: 0.6789 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5141 - acc: 0.8107 - val_loss: 0.6832 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5129 - acc: 0.8149 - val_loss: 0.6988 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5090 - acc: 0.8151 - val_loss: 0.6794 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5138 - acc: 0.8109 - val_loss: 0.6931 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5214 - acc: 0.8125 - val_loss: 0.6869 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5064 - acc: 0.8149 - val_loss: 0.6738 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5158 - acc: 0.8054 - val_loss: 0.6778 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5107 - acc: 0.8111 - val_loss: 0.6784 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5237 - acc: 0.8034 - val_loss: 0.6793 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5112 - acc: 0.8160 - val_loss: 0.6980 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5203 - acc: 0.8083 - val_loss: 0.6779 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5070 - acc: 0.8180 - val_loss: 0.6877 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5109 - acc: 0.8118 - val_loss: 0.6860 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5143 - acc: 0.8167 - val_loss: 0.6805 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5207 - acc: 0.8098 - val_loss: 0.6814 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5140 - acc: 0.8145 - val_loss: 0.6845 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5127 - acc: 0.8098 - val_loss: 0.6961 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5157 - acc: 0.8103 - val_loss: 0.6719 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5115 - acc: 0.8085 - val_loss: 0.6681 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5114 - acc: 0.8138 - val_loss: 0.6748 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5100 - acc: 0.8136 - val_loss: 0.6877 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5204 - acc: 0.8063 - val_loss: 0.6790 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5160 - acc: 0.8094 - val_loss: 0.7008 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5179 - acc: 0.8085 - val_loss: 0.6691 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5104 - acc: 0.8138 - val_loss: 0.6859 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5093 - acc: 0.8194 - val_loss: 0.6911 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5156 - acc: 0.8067 - val_loss: 0.6930 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5174 - acc: 0.8087 - val_loss: 0.6772 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5136 - acc: 0.8114 - val_loss: 0.6747 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5148 - acc: 0.8107 - val_loss: 0.6829 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5182 - acc: 0.8109 - val_loss: 0.6765 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5212 - acc: 0.8060 - val_loss: 0.6835 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5161 - acc: 0.8118 - val_loss: 0.6774 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5171 - acc: 0.8116 - val_loss: 0.6845 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5110 - acc: 0.8098 - val_loss: 0.6777 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5144 - acc: 0.8138 - val_loss: 0.6809 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5096 - acc: 0.8149 - val_loss: 0.6694 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5138 - acc: 0.8140 - val_loss: 0.6874 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5159 - acc: 0.8116 - val_loss: 0.6818 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5174 - acc: 0.8136 - val_loss: 0.6775 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5089 - acc: 0.8156 - val_loss: 0.6889 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5183 - acc: 0.8114 - val_loss: 0.6780 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5088 - acc: 0.8180 - val_loss: 0.6757 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5164 - acc: 0.8065 - val_loss: 0.6803 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5096 - acc: 0.8125 - val_loss: 0.6878 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5095 - acc: 0.8171 - val_loss: 0.6911 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5138 - acc: 0.8080 - val_loss: 0.6841 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4982 - acc: 0.8213 - val_loss: 0.6800 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5148 - acc: 0.8065 - val_loss: 0.7965 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5154 - acc: 0.8091 - val_loss: 0.6759 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5167 - acc: 0.8118 - val_loss: 0.6777 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5176 - acc: 0.8094 - val_loss: 0.6847 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5182 - acc: 0.8138 - val_loss: 0.6699 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5127 - acc: 0.8129 - val_loss: 0.6885 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5134 - acc: 0.8116 - val_loss: 0.6793 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5079 - acc: 0.8147 - val_loss: 0.6916 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5214 - acc: 0.8080 - val_loss: 0.6787 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5079 - acc: 0.8191 - val_loss: 0.6852 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5200 - acc: 0.8047 - val_loss: 0.6936 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5113 - acc: 0.8162 - val_loss: 0.6766 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5066 - acc: 0.8156 - val_loss: 0.6850 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5096 - acc: 0.8116 - val_loss: 0.6912 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5260 - acc: 0.8040 - val_loss: 0.6777 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5084 - acc: 0.8207 - val_loss: 0.6822 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5113 - acc: 0.8136 - val_loss: 0.6825 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5116 - acc: 0.8134 - val_loss: 0.6952 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5022 - acc: 0.8138 - val_loss: 0.7012 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5184 - acc: 0.8043 - val_loss: 0.6718 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5143 - acc: 0.8105 - val_loss: 0.7233 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5124 - acc: 0.8098 - val_loss: 0.6676 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5055 - acc: 0.8140 - val_loss: 0.7003 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5169 - acc: 0.8078 - val_loss: 0.6706 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5170 - acc: 0.8076 - val_loss: 0.6665 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4991 - acc: 0.8218 - val_loss: 0.6665 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5070 - acc: 0.8118 - val_loss: 0.6800 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5118 - acc: 0.8134 - val_loss: 0.6664 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5629 - acc: 0.7923\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5841 - acc: 0.7853\n",
            "epsilon: 0.003 and test evaluation : 0.584098756313324, 0.7853403091430664\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5988 - acc: 0.7801\n",
            "epsilon: 0.005 and test evaluation : 0.5987957715988159, 0.7801046967506409\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6375 - acc: 0.7609\n",
            "epsilon: 0.01 and test evaluation : 0.6375014781951904, 0.7609075307846069\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7222 - acc: 0.7312\n",
            "epsilon: 0.02 and test evaluation : 0.7222408652305603, 0.7312390804290771\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 1.4655 - acc: 0.2923 - val_loss: 1.4561 - val_acc: 0.2602 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3669 - acc: 0.3597 - val_loss: 1.3181 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3311 - acc: 0.3711 - val_loss: 1.2786 - val_acc: 0.3942 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3005 - acc: 0.3833 - val_loss: 1.2925 - val_acc: 0.3650 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2707 - acc: 0.4101 - val_loss: 1.2206 - val_acc: 0.4117 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2446 - acc: 0.4390 - val_loss: 1.6321 - val_acc: 0.2951 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2068 - acc: 0.4767 - val_loss: 1.1904 - val_acc: 0.5087 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1627 - acc: 0.5217 - val_loss: 1.3300 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1374 - acc: 0.5304 - val_loss: 1.2163 - val_acc: 0.4835 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 1.0884 - acc: 0.5513 - val_loss: 1.1146 - val_acc: 0.5165 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0606 - acc: 0.5668 - val_loss: 1.4555 - val_acc: 0.3903 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0292 - acc: 0.5857 - val_loss: 0.9507 - val_acc: 0.6136 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.9759 - acc: 0.6023 - val_loss: 0.9001 - val_acc: 0.6699 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.9420 - acc: 0.6234 - val_loss: 0.9126 - val_acc: 0.6291 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.9125 - acc: 0.6383 - val_loss: 0.9325 - val_acc: 0.6117 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8748 - acc: 0.6580 - val_loss: 0.8995 - val_acc: 0.6155 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8581 - acc: 0.6596 - val_loss: 1.0712 - val_acc: 0.5786 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8618 - acc: 0.6651 - val_loss: 0.9845 - val_acc: 0.6272 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8321 - acc: 0.6662 - val_loss: 0.9411 - val_acc: 0.6369 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8028 - acc: 0.6875 - val_loss: 0.7427 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7874 - acc: 0.6906 - val_loss: 0.6934 - val_acc: 0.7437 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7936 - acc: 0.6995 - val_loss: 0.6844 - val_acc: 0.7456 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7686 - acc: 0.7055 - val_loss: 0.8394 - val_acc: 0.6835 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7709 - acc: 0.6991 - val_loss: 0.7489 - val_acc: 0.7087 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7373 - acc: 0.7124 - val_loss: 0.7418 - val_acc: 0.7029 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7500 - acc: 0.7115 - val_loss: 0.8956 - val_acc: 0.6214 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7181 - acc: 0.7199 - val_loss: 0.6482 - val_acc: 0.7495 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7154 - acc: 0.7255 - val_loss: 0.7321 - val_acc: 0.7223 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7160 - acc: 0.7281 - val_loss: 0.7212 - val_acc: 0.7146 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.6895 - acc: 0.7321 - val_loss: 0.8975 - val_acc: 0.6718 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7752 - acc: 0.6915 - val_loss: 0.7231 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6525 - acc: 0.7459 - val_loss: 0.6229 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6245 - acc: 0.7625 - val_loss: 0.6304 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6017 - acc: 0.7694 - val_loss: 0.6064 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5841 - acc: 0.7903 - val_loss: 0.5908 - val_acc: 0.7786 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5941 - acc: 0.7754 - val_loss: 0.5880 - val_acc: 0.7786 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5813 - acc: 0.7807 - val_loss: 0.5868 - val_acc: 0.7748 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5762 - acc: 0.7807 - val_loss: 0.5822 - val_acc: 0.7767 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5746 - acc: 0.7914 - val_loss: 0.6422 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5715 - acc: 0.7881 - val_loss: 0.6157 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5594 - acc: 0.7903 - val_loss: 0.5880 - val_acc: 0.7767 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5686 - acc: 0.7923 - val_loss: 0.5728 - val_acc: 0.7845 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5545 - acc: 0.7967 - val_loss: 0.6410 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5602 - acc: 0.7847 - val_loss: 0.6191 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5525 - acc: 0.7967 - val_loss: 0.5847 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5506 - acc: 0.7956 - val_loss: 0.5801 - val_acc: 0.7845 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5381 - acc: 0.8032 - val_loss: 0.5933 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5478 - acc: 0.8016 - val_loss: 0.6289 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5396 - acc: 0.8025 - val_loss: 0.6101 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5342 - acc: 0.8034 - val_loss: 0.5868 - val_acc: 0.7767 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5431 - acc: 0.7976 - val_loss: 0.6690 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5372 - acc: 0.8023 - val_loss: 0.6109 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5271 - acc: 0.8025 - val_loss: 0.6047 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5359 - acc: 0.8071 - val_loss: 0.6082 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5273 - acc: 0.8065 - val_loss: 0.6430 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5262 - acc: 0.8034 - val_loss: 0.5872 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5218 - acc: 0.8058 - val_loss: 0.6060 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5194 - acc: 0.8076 - val_loss: 0.5993 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5245 - acc: 0.8076 - val_loss: 0.5866 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5121 - acc: 0.8085 - val_loss: 0.5793 - val_acc: 0.7767 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5177 - acc: 0.8058 - val_loss: 0.6208 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5166 - acc: 0.8089 - val_loss: 0.5728 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5208 - acc: 0.8076 - val_loss: 0.5658 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5184 - acc: 0.8118 - val_loss: 0.5725 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5104 - acc: 0.8154 - val_loss: 0.6003 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5145 - acc: 0.8074 - val_loss: 0.5927 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5174 - acc: 0.8084 - val_loss: 0.6144 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5149 - acc: 0.8103 - val_loss: 0.5891 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5136 - acc: 0.8065 - val_loss: 0.6082 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5172 - acc: 0.8063 - val_loss: 0.6117 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5169 - acc: 0.8054 - val_loss: 0.5699 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5102 - acc: 0.8114 - val_loss: 0.6089 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5133 - acc: 0.8083 - val_loss: 0.5827 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5115 - acc: 0.8094 - val_loss: 0.6265 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5044 - acc: 0.8129 - val_loss: 0.5801 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5058 - acc: 0.8054 - val_loss: 0.6108 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5121 - acc: 0.8076 - val_loss: 0.5897 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5083 - acc: 0.8131 - val_loss: 0.5793 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5085 - acc: 0.8105 - val_loss: 0.5671 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5102 - acc: 0.8103 - val_loss: 0.6039 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5179 - acc: 0.8098 - val_loss: 0.5780 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5165 - acc: 0.8100 - val_loss: 0.5605 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5112 - acc: 0.8087 - val_loss: 0.5688 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5077 - acc: 0.8149 - val_loss: 0.5687 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5068 - acc: 0.8105 - val_loss: 0.5733 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5095 - acc: 0.8089 - val_loss: 0.5755 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5104 - acc: 0.8145 - val_loss: 0.5721 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5131 - acc: 0.8131 - val_loss: 0.5841 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5081 - acc: 0.8085 - val_loss: 0.5768 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5177 - acc: 0.8094 - val_loss: 0.5527 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5092 - acc: 0.8036 - val_loss: 0.5839 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5106 - acc: 0.8105 - val_loss: 0.6103 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5114 - acc: 0.8165 - val_loss: 0.5688 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5079 - acc: 0.8116 - val_loss: 0.5594 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5104 - acc: 0.8158 - val_loss: 0.5939 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5125 - acc: 0.8091 - val_loss: 0.5984 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5018 - acc: 0.8131 - val_loss: 0.5928 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5099 - acc: 0.8120 - val_loss: 0.5938 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5147 - acc: 0.8067 - val_loss: 0.5782 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5105 - acc: 0.8129 - val_loss: 0.5514 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5080 - acc: 0.8138 - val_loss: 0.5783 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5114 - acc: 0.8080 - val_loss: 0.6257 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5150 - acc: 0.8069 - val_loss: 0.5942 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5068 - acc: 0.8120 - val_loss: 0.5795 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5220 - acc: 0.8045 - val_loss: 0.5819 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5169 - acc: 0.8116 - val_loss: 0.6040 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5141 - acc: 0.8067 - val_loss: 0.5886 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5102 - acc: 0.8156 - val_loss: 0.6071 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5155 - acc: 0.8058 - val_loss: 0.5904 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5130 - acc: 0.8058 - val_loss: 0.5933 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5081 - acc: 0.8127 - val_loss: 0.5624 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5191 - acc: 0.8080 - val_loss: 0.6562 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5085 - acc: 0.8114 - val_loss: 0.5923 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5088 - acc: 0.8125 - val_loss: 0.5953 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5030 - acc: 0.8100 - val_loss: 0.5758 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5019 - acc: 0.8103 - val_loss: 0.5698 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5197 - acc: 0.8034 - val_loss: 0.5710 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5138 - acc: 0.8078 - val_loss: 0.5832 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5132 - acc: 0.8080 - val_loss: 0.5794 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5053 - acc: 0.8111 - val_loss: 0.6192 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5131 - acc: 0.8058 - val_loss: 0.5577 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5162 - acc: 0.8045 - val_loss: 0.5820 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5164 - acc: 0.8027 - val_loss: 0.5778 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5044 - acc: 0.8098 - val_loss: 0.5816 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5071 - acc: 0.8109 - val_loss: 0.5791 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5066 - acc: 0.8078 - val_loss: 0.6075 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5006 - acc: 0.8200 - val_loss: 0.5783 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5062 - acc: 0.8134 - val_loss: 0.5749 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5126 - acc: 0.8060 - val_loss: 0.6025 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5097 - acc: 0.8100 - val_loss: 0.5779 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5136 - acc: 0.8091 - val_loss: 0.5710 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5008 - acc: 0.8176 - val_loss: 0.6079 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5074 - acc: 0.8136 - val_loss: 0.6609 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5128 - acc: 0.8098 - val_loss: 0.6075 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5052 - acc: 0.8107 - val_loss: 0.5598 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5122 - acc: 0.8036 - val_loss: 0.6237 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5087 - acc: 0.8087 - val_loss: 0.6066 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5187 - acc: 0.8054 - val_loss: 0.5814 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5140 - acc: 0.8080 - val_loss: 0.5811 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5069 - acc: 0.8125 - val_loss: 0.6035 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5154 - acc: 0.8056 - val_loss: 0.6023 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5099 - acc: 0.8058 - val_loss: 0.5853 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5033 - acc: 0.8134 - val_loss: 0.5809 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5137 - acc: 0.8087 - val_loss: 0.6054 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5054 - acc: 0.8145 - val_loss: 0.5706 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5095 - acc: 0.8105 - val_loss: 0.6179 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5095 - acc: 0.8103 - val_loss: 0.5844 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5092 - acc: 0.8027 - val_loss: 0.5546 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5107 - acc: 0.8084 - val_loss: 0.5880 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5159 - acc: 0.8029 - val_loss: 0.5563 - val_acc: 0.7922 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5167 - acc: 0.8063 - val_loss: 0.5822 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5034 - acc: 0.8145 - val_loss: 0.5847 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4986 - acc: 0.8189 - val_loss: 0.5817 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4992 - acc: 0.8189 - val_loss: 0.5846 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5090 - acc: 0.8056 - val_loss: 0.6127 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5168 - acc: 0.8087 - val_loss: 0.5598 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5140 - acc: 0.8058 - val_loss: 0.6143 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5039 - acc: 0.8134 - val_loss: 0.6322 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5059 - acc: 0.8051 - val_loss: 0.5960 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4993 - acc: 0.8116 - val_loss: 0.5652 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5154 - acc: 0.8080 - val_loss: 0.5874 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5034 - acc: 0.8071 - val_loss: 0.5911 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5139 - acc: 0.8083 - val_loss: 0.5976 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5090 - acc: 0.8118 - val_loss: 0.5793 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5033 - acc: 0.8134 - val_loss: 0.6075 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5049 - acc: 0.8151 - val_loss: 0.6561 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5002 - acc: 0.8118 - val_loss: 0.5774 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5069 - acc: 0.8145 - val_loss: 0.5662 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5167 - acc: 0.8049 - val_loss: 0.6049 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5115 - acc: 0.8058 - val_loss: 0.5936 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5101 - acc: 0.8116 - val_loss: 0.5717 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5076 - acc: 0.8060 - val_loss: 0.5990 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5026 - acc: 0.8114 - val_loss: 0.5979 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4986 - acc: 0.8142 - val_loss: 0.5632 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5103 - acc: 0.8165 - val_loss: 0.5629 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5062 - acc: 0.8094 - val_loss: 0.6024 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5055 - acc: 0.8176 - val_loss: 0.5826 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5118 - acc: 0.8049 - val_loss: 0.5537 - val_acc: 0.7961 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5052 - acc: 0.8118 - val_loss: 0.5844 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5037 - acc: 0.8094 - val_loss: 0.6051 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5110 - acc: 0.8083 - val_loss: 0.5983 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5036 - acc: 0.8091 - val_loss: 0.5582 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.4994 - acc: 0.8129 - val_loss: 0.5827 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5072 - acc: 0.8094 - val_loss: 0.5663 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5098 - acc: 0.8087 - val_loss: 0.5599 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5089 - acc: 0.8120 - val_loss: 0.5573 - val_acc: 0.7903 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5054 - acc: 0.8125 - val_loss: 0.5624 - val_acc: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5062 - acc: 0.8118 - val_loss: 0.5653 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5114 - acc: 0.8025 - val_loss: 0.6132 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5006 - acc: 0.8131 - val_loss: 0.6103 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5101 - acc: 0.8138 - val_loss: 0.6039 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5100 - acc: 0.8080 - val_loss: 0.5789 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5035 - acc: 0.8100 - val_loss: 0.5584 - val_acc: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5130 - acc: 0.8094 - val_loss: 0.5723 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4946 - acc: 0.8171 - val_loss: 0.5613 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5048 - acc: 0.8109 - val_loss: 0.6042 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5055 - acc: 0.8134 - val_loss: 0.5679 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5063 - acc: 0.8087 - val_loss: 0.5605 - val_acc: 0.7942 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5022 - acc: 0.8114 - val_loss: 0.5741 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5092 - acc: 0.8096 - val_loss: 0.5590 - val_acc: 0.7883 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5930 - acc: 0.7696\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6168 - acc: 0.7504\n",
            "epsilon: 0.003 and test evaluation : 0.6168121099472046, 0.7504363059997559\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6335 - acc: 0.7452\n",
            "epsilon: 0.005 and test evaluation : 0.6335093379020691, 0.7452006936073303\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6781 - acc: 0.7347\n",
            "epsilon: 0.01 and test evaluation : 0.678102970123291, 0.7347294688224792\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7772 - acc: 0.6998\n",
            "epsilon: 0.02 and test evaluation : 0.7772455811500549, 0.6998254656791687\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 1.4497 - acc: 0.3111 - val_loss: 1.3627 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3504 - acc: 0.3759 - val_loss: 1.3671 - val_acc: 0.3068 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3128 - acc: 0.3768 - val_loss: 1.3982 - val_acc: 0.3340 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3078 - acc: 0.3870 - val_loss: 1.2854 - val_acc: 0.3864 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2800 - acc: 0.3941 - val_loss: 1.2608 - val_acc: 0.4000 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2662 - acc: 0.4046 - val_loss: 1.4082 - val_acc: 0.3631 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2295 - acc: 0.4594 - val_loss: 1.3008 - val_acc: 0.3864 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2090 - acc: 0.4820 - val_loss: 1.1804 - val_acc: 0.4796 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1574 - acc: 0.5209 - val_loss: 1.1185 - val_acc: 0.5456 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1352 - acc: 0.5346 - val_loss: 1.1123 - val_acc: 0.5301 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0927 - acc: 0.5522 - val_loss: 1.1502 - val_acc: 0.5029 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0668 - acc: 0.5555 - val_loss: 1.0759 - val_acc: 0.5495 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0424 - acc: 0.5770 - val_loss: 1.1634 - val_acc: 0.4913 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0292 - acc: 0.5757 - val_loss: 0.9984 - val_acc: 0.5864 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.9874 - acc: 0.6012 - val_loss: 1.0636 - val_acc: 0.5612 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9401 - acc: 0.6234 - val_loss: 1.0058 - val_acc: 0.6214 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9216 - acc: 0.6318 - val_loss: 1.1402 - val_acc: 0.5631 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8770 - acc: 0.6545 - val_loss: 0.9894 - val_acc: 0.6097 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8763 - acc: 0.6505 - val_loss: 1.0006 - val_acc: 0.6117 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8594 - acc: 0.6578 - val_loss: 0.8868 - val_acc: 0.6369 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8370 - acc: 0.6735 - val_loss: 0.7907 - val_acc: 0.7010 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8203 - acc: 0.6815 - val_loss: 0.8359 - val_acc: 0.6641 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7968 - acc: 0.6871 - val_loss: 0.8339 - val_acc: 0.6835 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7666 - acc: 0.6995 - val_loss: 0.7761 - val_acc: 0.7068 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7663 - acc: 0.7051 - val_loss: 0.7519 - val_acc: 0.7126 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7558 - acc: 0.7104 - val_loss: 0.8563 - val_acc: 0.6505 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7389 - acc: 0.7210 - val_loss: 0.8317 - val_acc: 0.6641 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7243 - acc: 0.7150 - val_loss: 0.9461 - val_acc: 0.6311 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7302 - acc: 0.7102 - val_loss: 0.8942 - val_acc: 0.6311 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7255 - acc: 0.7204 - val_loss: 1.0198 - val_acc: 0.6136 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7348 - acc: 0.7193 - val_loss: 0.7997 - val_acc: 0.6796 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6799 - acc: 0.7446 - val_loss: 0.7256 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6566 - acc: 0.7448 - val_loss: 0.7240 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.6368 - acc: 0.7539 - val_loss: 0.7255 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6304 - acc: 0.7590 - val_loss: 0.6922 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6179 - acc: 0.7730 - val_loss: 0.7055 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6200 - acc: 0.7641 - val_loss: 0.7252 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6114 - acc: 0.7676 - val_loss: 0.7020 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6060 - acc: 0.7703 - val_loss: 0.6828 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5955 - acc: 0.7741 - val_loss: 0.7225 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5995 - acc: 0.7688 - val_loss: 0.6992 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5927 - acc: 0.7805 - val_loss: 0.6917 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5813 - acc: 0.7847 - val_loss: 0.7146 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5901 - acc: 0.7792 - val_loss: 0.6814 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5777 - acc: 0.7881 - val_loss: 0.7160 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5809 - acc: 0.7867 - val_loss: 0.6988 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5741 - acc: 0.7865 - val_loss: 0.6865 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5701 - acc: 0.7881 - val_loss: 0.6811 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5764 - acc: 0.7836 - val_loss: 0.6663 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5601 - acc: 0.7901 - val_loss: 0.6999 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5609 - acc: 0.7909 - val_loss: 0.6677 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5649 - acc: 0.7830 - val_loss: 0.6492 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5621 - acc: 0.7925 - val_loss: 0.6908 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5682 - acc: 0.7854 - val_loss: 0.6493 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5609 - acc: 0.7912 - val_loss: 0.6553 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5547 - acc: 0.7925 - val_loss: 0.6449 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5593 - acc: 0.7909 - val_loss: 0.6539 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5547 - acc: 0.7958 - val_loss: 0.6467 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5449 - acc: 0.7907 - val_loss: 0.6473 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5508 - acc: 0.7854 - val_loss: 0.6627 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5391 - acc: 0.8034 - val_loss: 0.6606 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5471 - acc: 0.7949 - val_loss: 0.6630 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5342 - acc: 0.8043 - val_loss: 0.6798 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5390 - acc: 0.7992 - val_loss: 0.6707 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5450 - acc: 0.7972 - val_loss: 0.6538 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5484 - acc: 0.7945 - val_loss: 0.6512 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5432 - acc: 0.7987 - val_loss: 0.6671 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5473 - acc: 0.7938 - val_loss: 0.6550 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5477 - acc: 0.7974 - val_loss: 0.6876 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5500 - acc: 0.7885 - val_loss: 0.6982 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5421 - acc: 0.7974 - val_loss: 0.6667 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5380 - acc: 0.7985 - val_loss: 0.6558 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5469 - acc: 0.7956 - val_loss: 0.6667 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5455 - acc: 0.7921 - val_loss: 0.6700 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5441 - acc: 0.7909 - val_loss: 0.6513 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5410 - acc: 0.7969 - val_loss: 0.6729 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5279 - acc: 0.8034 - val_loss: 0.6465 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5390 - acc: 0.7947 - val_loss: 0.6529 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5420 - acc: 0.7921 - val_loss: 0.6432 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5386 - acc: 0.8020 - val_loss: 0.6722 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5311 - acc: 0.8027 - val_loss: 0.6530 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5481 - acc: 0.7912 - val_loss: 0.6890 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5400 - acc: 0.7938 - val_loss: 0.6615 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5436 - acc: 0.7956 - val_loss: 0.7188 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5427 - acc: 0.7927 - val_loss: 0.6648 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5311 - acc: 0.8009 - val_loss: 0.6876 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5353 - acc: 0.8018 - val_loss: 0.6478 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5508 - acc: 0.7918 - val_loss: 0.7208 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5411 - acc: 0.7978 - val_loss: 0.6883 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5439 - acc: 0.7916 - val_loss: 0.6854 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5466 - acc: 0.8000 - val_loss: 0.6768 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5352 - acc: 0.8040 - val_loss: 0.6599 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5442 - acc: 0.7923 - val_loss: 0.6929 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5372 - acc: 0.8003 - val_loss: 0.6771 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5472 - acc: 0.7943 - val_loss: 0.6743 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5428 - acc: 0.7972 - val_loss: 0.7137 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5427 - acc: 0.7932 - val_loss: 0.6851 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5476 - acc: 0.7918 - val_loss: 0.6877 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5381 - acc: 0.8007 - val_loss: 0.6512 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5415 - acc: 0.7947 - val_loss: 0.6529 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5384 - acc: 0.7987 - val_loss: 0.6525 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5546 - acc: 0.7887 - val_loss: 0.6402 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5417 - acc: 0.7969 - val_loss: 0.7007 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5400 - acc: 0.7947 - val_loss: 0.6509 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5462 - acc: 0.7896 - val_loss: 0.6369 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5433 - acc: 0.7980 - val_loss: 0.6871 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5477 - acc: 0.7889 - val_loss: 0.6374 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5332 - acc: 0.7976 - val_loss: 0.6696 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5359 - acc: 0.7980 - val_loss: 0.6677 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5380 - acc: 0.7943 - val_loss: 0.6413 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5454 - acc: 0.7963 - val_loss: 0.6512 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5359 - acc: 0.7956 - val_loss: 0.6891 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5351 - acc: 0.8023 - val_loss: 0.7001 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5275 - acc: 0.8078 - val_loss: 0.6570 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5398 - acc: 0.7932 - val_loss: 0.6597 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5425 - acc: 0.7934 - val_loss: 0.6663 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5455 - acc: 0.7914 - val_loss: 0.6414 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5394 - acc: 0.7985 - val_loss: 0.6697 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5417 - acc: 0.7923 - val_loss: 0.6593 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5364 - acc: 0.7978 - val_loss: 0.6836 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5383 - acc: 0.7954 - val_loss: 0.6671 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5367 - acc: 0.7987 - val_loss: 0.6572 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5405 - acc: 0.7954 - val_loss: 0.6813 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5374 - acc: 0.7969 - val_loss: 0.6938 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5314 - acc: 0.7984 - val_loss: 0.6563 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5477 - acc: 0.7985 - val_loss: 0.6472 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5463 - acc: 0.7976 - val_loss: 0.6865 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5383 - acc: 0.7969 - val_loss: 0.6363 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5363 - acc: 0.7954 - val_loss: 0.6745 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5357 - acc: 0.7972 - val_loss: 0.6513 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5427 - acc: 0.7960 - val_loss: 0.6580 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5376 - acc: 0.8016 - val_loss: 0.6456 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5425 - acc: 0.7907 - val_loss: 0.6483 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5411 - acc: 0.7989 - val_loss: 0.6431 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5338 - acc: 0.8056 - val_loss: 0.6616 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5419 - acc: 0.7934 - val_loss: 0.6707 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5401 - acc: 0.7932 - val_loss: 0.6618 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5402 - acc: 0.7969 - val_loss: 0.6547 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5323 - acc: 0.7945 - val_loss: 0.6596 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5381 - acc: 0.8038 - val_loss: 0.6711 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5449 - acc: 0.7878 - val_loss: 0.6605 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5353 - acc: 0.7985 - val_loss: 0.6450 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5377 - acc: 0.7960 - val_loss: 0.6414 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5308 - acc: 0.7985 - val_loss: 0.6426 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5397 - acc: 0.7941 - val_loss: 0.6740 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5451 - acc: 0.7907 - val_loss: 0.6454 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5355 - acc: 0.7965 - val_loss: 0.6590 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5354 - acc: 0.7972 - val_loss: 0.6498 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5421 - acc: 0.7992 - val_loss: 0.6894 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5346 - acc: 0.8014 - val_loss: 0.6673 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5388 - acc: 0.7934 - val_loss: 0.6654 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5449 - acc: 0.7963 - val_loss: 0.6439 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5427 - acc: 0.7969 - val_loss: 0.6349 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5416 - acc: 0.7925 - val_loss: 0.6468 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5508 - acc: 0.7909 - val_loss: 0.6796 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5405 - acc: 0.7994 - val_loss: 0.7276 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5334 - acc: 0.7992 - val_loss: 0.6376 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5348 - acc: 0.8007 - val_loss: 0.6797 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5344 - acc: 0.7983 - val_loss: 0.6679 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5302 - acc: 0.7994 - val_loss: 0.6431 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5397 - acc: 0.7972 - val_loss: 0.6356 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5391 - acc: 0.7978 - val_loss: 0.6626 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5334 - acc: 0.7967 - val_loss: 0.6809 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5389 - acc: 0.7972 - val_loss: 0.6808 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5347 - acc: 0.7945 - val_loss: 0.6351 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5371 - acc: 0.7989 - val_loss: 0.6361 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5486 - acc: 0.7852 - val_loss: 0.6641 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5275 - acc: 0.8018 - val_loss: 0.6563 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5398 - acc: 0.7992 - val_loss: 0.6432 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5426 - acc: 0.7938 - val_loss: 0.6884 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5330 - acc: 0.7989 - val_loss: 0.6448 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5348 - acc: 0.7967 - val_loss: 0.6863 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5274 - acc: 0.8014 - val_loss: 0.6428 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5328 - acc: 0.7987 - val_loss: 0.6525 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5412 - acc: 0.7962 - val_loss: 0.6693 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5384 - acc: 0.7918 - val_loss: 0.6370 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5370 - acc: 0.8005 - val_loss: 0.6538 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5293 - acc: 0.8005 - val_loss: 0.6335 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5323 - acc: 0.7934 - val_loss: 0.6426 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5414 - acc: 0.7923 - val_loss: 0.6648 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5394 - acc: 0.7978 - val_loss: 0.6607 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5329 - acc: 0.7932 - val_loss: 0.6686 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5473 - acc: 0.7956 - val_loss: 0.6422 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5403 - acc: 0.7938 - val_loss: 0.6529 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5306 - acc: 0.7969 - val_loss: 0.6646 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5368 - acc: 0.7958 - val_loss: 0.6704 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5381 - acc: 0.7914 - val_loss: 0.6593 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5275 - acc: 0.7989 - val_loss: 0.6536 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5459 - acc: 0.7943 - val_loss: 0.6730 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5376 - acc: 0.7965 - val_loss: 0.6652 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5315 - acc: 0.7972 - val_loss: 0.6323 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5335 - acc: 0.7938 - val_loss: 0.6504 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5341 - acc: 0.7989 - val_loss: 0.6390 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5423 - acc: 0.7912 - val_loss: 0.6678 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5382 - acc: 0.7932 - val_loss: 0.6567 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5273 - acc: 0.8040 - val_loss: 0.6541 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5443 - acc: 0.7925 - val_loss: 0.6566 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5465 - acc: 0.7872 - val_loss: 0.6831 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5345 - acc: 0.7936 - val_loss: 0.6398 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5331 - acc: 0.8003 - val_loss: 0.6301 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6088 - acc: 0.7644\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6287 - acc: 0.7609\n",
            "epsilon: 0.003 and test evaluation : 0.6287286877632141, 0.7609075307846069\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6425 - acc: 0.7574\n",
            "epsilon: 0.005 and test evaluation : 0.6424518823623657, 0.7574170827865601\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6786 - acc: 0.7400\n",
            "epsilon: 0.01 and test evaluation : 0.6786082983016968, 0.7399650812149048\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7568 - acc: 0.7155\n",
            "epsilon: 0.02 and test evaluation : 0.7568461298942566, 0.7155323028564453\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 1.4480 - acc: 0.3316 - val_loss: 1.3589 - val_acc: 0.4000 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3534 - acc: 0.3666 - val_loss: 1.4288 - val_acc: 0.2641 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3202 - acc: 0.3691 - val_loss: 1.3101 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 1.3048 - acc: 0.3879 - val_loss: 1.2922 - val_acc: 0.3806 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2837 - acc: 0.3997 - val_loss: 1.2985 - val_acc: 0.3709 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2841 - acc: 0.4028 - val_loss: 1.2944 - val_acc: 0.3942 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2517 - acc: 0.4245 - val_loss: 1.2531 - val_acc: 0.4272 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2069 - acc: 0.4745 - val_loss: 1.1389 - val_acc: 0.4893 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.1759 - acc: 0.5031 - val_loss: 1.2664 - val_acc: 0.4738 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1280 - acc: 0.5262 - val_loss: 1.2652 - val_acc: 0.4485 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0912 - acc: 0.5473 - val_loss: 1.1590 - val_acc: 0.4932 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0443 - acc: 0.5703 - val_loss: 1.3289 - val_acc: 0.4718 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0073 - acc: 0.5968 - val_loss: 0.9965 - val_acc: 0.5806 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9552 - acc: 0.6147 - val_loss: 0.9723 - val_acc: 0.6252 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9585 - acc: 0.6096 - val_loss: 0.9414 - val_acc: 0.6311 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9136 - acc: 0.6376 - val_loss: 0.9214 - val_acc: 0.6447 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8703 - acc: 0.6540 - val_loss: 0.9287 - val_acc: 0.6447 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8855 - acc: 0.6498 - val_loss: 0.8951 - val_acc: 0.6408 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8503 - acc: 0.6667 - val_loss: 1.0229 - val_acc: 0.6194 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8520 - acc: 0.6704 - val_loss: 0.8123 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8185 - acc: 0.6897 - val_loss: 0.8493 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8026 - acc: 0.6842 - val_loss: 0.8254 - val_acc: 0.6777 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7800 - acc: 0.6968 - val_loss: 0.8374 - val_acc: 0.6699 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8381 - acc: 0.6769 - val_loss: 0.8034 - val_acc: 0.6835 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7742 - acc: 0.7022 - val_loss: 0.7710 - val_acc: 0.7087 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7567 - acc: 0.7075 - val_loss: 0.8985 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7463 - acc: 0.7153 - val_loss: 0.8103 - val_acc: 0.6854 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7453 - acc: 0.7124 - val_loss: 0.7381 - val_acc: 0.7301 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7265 - acc: 0.7219 - val_loss: 0.8814 - val_acc: 0.6524 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7077 - acc: 0.7337 - val_loss: 0.8742 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.8551 - acc: 0.6667 - val_loss: 0.8070 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7753 - acc: 0.7035 - val_loss: 0.7686 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7385 - acc: 0.7195 - val_loss: 0.7383 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7018 - acc: 0.7303 - val_loss: 0.7103 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6885 - acc: 0.7415 - val_loss: 0.7344 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6716 - acc: 0.7492 - val_loss: 0.6877 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.6497 - acc: 0.7567 - val_loss: 0.6915 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6542 - acc: 0.7625 - val_loss: 0.6797 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6371 - acc: 0.7610 - val_loss: 0.6715 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6356 - acc: 0.7532 - val_loss: 0.6795 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6183 - acc: 0.7659 - val_loss: 0.6745 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6172 - acc: 0.7723 - val_loss: 0.6987 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6107 - acc: 0.7732 - val_loss: 0.6633 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6127 - acc: 0.7668 - val_loss: 0.6647 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5991 - acc: 0.7832 - val_loss: 0.6613 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5936 - acc: 0.7739 - val_loss: 0.6626 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6021 - acc: 0.7725 - val_loss: 0.6614 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5940 - acc: 0.7752 - val_loss: 0.6690 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5864 - acc: 0.7854 - val_loss: 0.8039 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5792 - acc: 0.7830 - val_loss: 0.6663 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5744 - acc: 0.7899 - val_loss: 0.6706 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5817 - acc: 0.7774 - val_loss: 0.6775 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.5751 - acc: 0.7801 - val_loss: 0.6615 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5652 - acc: 0.7925 - val_loss: 0.6834 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5757 - acc: 0.7892 - val_loss: 0.6577 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5631 - acc: 0.7876 - val_loss: 0.6546 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5629 - acc: 0.7947 - val_loss: 0.6594 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5529 - acc: 0.7912 - val_loss: 0.6572 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5539 - acc: 0.7923 - val_loss: 0.6455 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5509 - acc: 0.7945 - val_loss: 0.6551 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5399 - acc: 0.8067 - val_loss: 0.6467 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5490 - acc: 0.7925 - val_loss: 0.6495 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5469 - acc: 0.7943 - val_loss: 0.6544 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5423 - acc: 0.7972 - val_loss: 0.6731 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5639 - acc: 0.7923 - val_loss: 0.6698 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5496 - acc: 0.8058 - val_loss: 0.6573 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5549 - acc: 0.7909 - val_loss: 0.6752 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5533 - acc: 0.7907 - val_loss: 0.6535 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5568 - acc: 0.7945 - val_loss: 0.6737 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5461 - acc: 0.7927 - val_loss: 0.6653 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5501 - acc: 0.7994 - val_loss: 0.6503 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5494 - acc: 0.7998 - val_loss: 0.6537 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5488 - acc: 0.7929 - val_loss: 0.6540 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5524 - acc: 0.7898 - val_loss: 0.6476 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5484 - acc: 0.8000 - val_loss: 0.6463 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5485 - acc: 0.7949 - val_loss: 0.6958 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5409 - acc: 0.8020 - val_loss: 0.6549 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5608 - acc: 0.7927 - val_loss: 0.6560 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5522 - acc: 0.7921 - val_loss: 0.6586 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5535 - acc: 0.7907 - val_loss: 0.6612 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5519 - acc: 0.7914 - val_loss: 0.6477 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5506 - acc: 0.7954 - val_loss: 0.6629 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5516 - acc: 0.7969 - val_loss: 0.6711 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5448 - acc: 0.7956 - val_loss: 0.6772 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5452 - acc: 0.7965 - val_loss: 0.6560 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5387 - acc: 0.8036 - val_loss: 0.6480 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5482 - acc: 0.7956 - val_loss: 0.6663 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5473 - acc: 0.7976 - val_loss: 0.6698 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5499 - acc: 0.7960 - val_loss: 0.6554 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5391 - acc: 0.8000 - val_loss: 0.6442 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5418 - acc: 0.7987 - val_loss: 0.6666 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5415 - acc: 0.7963 - val_loss: 0.6477 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5430 - acc: 0.8007 - val_loss: 0.6622 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5521 - acc: 0.7956 - val_loss: 0.6513 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5440 - acc: 0.7916 - val_loss: 0.6494 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5462 - acc: 0.7929 - val_loss: 0.6853 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5512 - acc: 0.7918 - val_loss: 0.6454 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5437 - acc: 0.7934 - val_loss: 0.6415 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5378 - acc: 0.7965 - val_loss: 0.6422 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5400 - acc: 0.8034 - val_loss: 0.6760 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5426 - acc: 0.7896 - val_loss: 0.6582 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5489 - acc: 0.7949 - val_loss: 0.6474 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5461 - acc: 0.8005 - val_loss: 0.6551 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5441 - acc: 0.8036 - val_loss: 0.6581 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5508 - acc: 0.7921 - val_loss: 0.8222 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5430 - acc: 0.8012 - val_loss: 0.6522 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5478 - acc: 0.7945 - val_loss: 0.6588 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5541 - acc: 0.7894 - val_loss: 0.6502 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5442 - acc: 0.7952 - val_loss: 0.6723 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5480 - acc: 0.7941 - val_loss: 0.6555 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5471 - acc: 0.7941 - val_loss: 0.6544 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5372 - acc: 0.8032 - val_loss: 0.6459 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5449 - acc: 0.7938 - val_loss: 0.6471 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5363 - acc: 0.7992 - val_loss: 0.6652 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5400 - acc: 0.7921 - val_loss: 0.6567 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5495 - acc: 0.7989 - val_loss: 0.6520 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5329 - acc: 0.7996 - val_loss: 0.6583 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5459 - acc: 0.7963 - val_loss: 0.6618 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5406 - acc: 0.7989 - val_loss: 0.6476 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5385 - acc: 0.7983 - val_loss: 0.6462 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5417 - acc: 0.7983 - val_loss: 0.6471 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5463 - acc: 0.7932 - val_loss: 0.6773 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5406 - acc: 0.7934 - val_loss: 0.6510 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5473 - acc: 0.7983 - val_loss: 0.6412 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5412 - acc: 0.7976 - val_loss: 0.6594 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5459 - acc: 0.7969 - val_loss: 0.6648 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5474 - acc: 0.7901 - val_loss: 0.6476 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5490 - acc: 0.7945 - val_loss: 0.6506 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5465 - acc: 0.7963 - val_loss: 0.6825 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5451 - acc: 0.7892 - val_loss: 0.6452 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5419 - acc: 0.7972 - val_loss: 0.6504 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5353 - acc: 0.8000 - val_loss: 0.6555 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5411 - acc: 0.7976 - val_loss: 0.6520 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5384 - acc: 0.7985 - val_loss: 0.6463 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5446 - acc: 0.7992 - val_loss: 0.6506 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5456 - acc: 0.7943 - val_loss: 0.6653 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5408 - acc: 0.8036 - val_loss: 0.6458 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5446 - acc: 0.7978 - val_loss: 0.6503 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5389 - acc: 0.8012 - val_loss: 0.6483 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5468 - acc: 0.7969 - val_loss: 0.6520 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5445 - acc: 0.7949 - val_loss: 0.6535 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5450 - acc: 0.7960 - val_loss: 0.6589 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5423 - acc: 0.7929 - val_loss: 0.6470 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5377 - acc: 0.7983 - val_loss: 0.6636 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5384 - acc: 0.7943 - val_loss: 0.6447 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5560 - acc: 0.7892 - val_loss: 0.6404 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5562 - acc: 0.7909 - val_loss: 0.6473 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5493 - acc: 0.7952 - val_loss: 0.6521 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5421 - acc: 0.7980 - val_loss: 0.6403 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5434 - acc: 0.7941 - val_loss: 0.6684 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5478 - acc: 0.7943 - val_loss: 0.6492 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5485 - acc: 0.7929 - val_loss: 0.6449 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5383 - acc: 0.7972 - val_loss: 0.6682 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5490 - acc: 0.7925 - val_loss: 0.6467 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5415 - acc: 0.7976 - val_loss: 0.6526 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5408 - acc: 0.7969 - val_loss: 0.8368 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5469 - acc: 0.7969 - val_loss: 0.6654 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5416 - acc: 0.8000 - val_loss: 0.6974 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5385 - acc: 0.7938 - val_loss: 0.6670 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5432 - acc: 0.7978 - val_loss: 0.6437 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5372 - acc: 0.7945 - val_loss: 0.6409 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5467 - acc: 0.7892 - val_loss: 0.6560 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5399 - acc: 0.7985 - val_loss: 0.6429 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5454 - acc: 0.7916 - val_loss: 0.6413 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5521 - acc: 0.7876 - val_loss: 0.6471 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5335 - acc: 0.7987 - val_loss: 0.6426 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5447 - acc: 0.7912 - val_loss: 0.6527 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5522 - acc: 0.7883 - val_loss: 0.6498 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5363 - acc: 0.7980 - val_loss: 0.6565 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5343 - acc: 0.8058 - val_loss: 0.6640 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5389 - acc: 0.8014 - val_loss: 0.6462 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.5509 - acc: 0.7876 - val_loss: 0.6443 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5332 - acc: 0.7998 - val_loss: 0.6573 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5379 - acc: 0.7996 - val_loss: 0.6613 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5548 - acc: 0.7834 - val_loss: 0.6471 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5421 - acc: 0.7898 - val_loss: 0.6580 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5456 - acc: 0.7921 - val_loss: 0.6414 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5369 - acc: 0.7956 - val_loss: 0.6588 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5462 - acc: 0.7914 - val_loss: 0.6422 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5455 - acc: 0.7932 - val_loss: 0.6458 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5410 - acc: 0.7963 - val_loss: 0.6468 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5293 - acc: 0.7985 - val_loss: 0.6506 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5396 - acc: 0.7896 - val_loss: 0.6487 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5323 - acc: 0.7974 - val_loss: 0.6564 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5341 - acc: 0.8025 - val_loss: 0.6500 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5386 - acc: 0.7954 - val_loss: 0.6431 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5467 - acc: 0.7932 - val_loss: 0.6580 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5416 - acc: 0.7941 - val_loss: 0.6426 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5411 - acc: 0.7947 - val_loss: 0.6553 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5337 - acc: 0.7996 - val_loss: 0.6516 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5418 - acc: 0.7996 - val_loss: 0.6666 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5417 - acc: 0.7980 - val_loss: 0.6456 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5384 - acc: 0.8007 - val_loss: 0.6481 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5348 - acc: 0.7987 - val_loss: 0.6580 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5313 - acc: 0.8036 - val_loss: 0.6451 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5434 - acc: 0.7949 - val_loss: 0.6577 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5431 - acc: 0.7958 - val_loss: 0.6560 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5420 - acc: 0.7952 - val_loss: 0.6592 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5407 - acc: 0.8018 - val_loss: 0.6468 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5374 - acc: 0.8016 - val_loss: 0.6586 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5868 - acc: 0.7731\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6059 - acc: 0.7696\n",
            "epsilon: 0.003 and test evaluation : 0.6058680415153503, 0.7696335315704346\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6191 - acc: 0.7627\n",
            "epsilon: 0.005 and test evaluation : 0.6190576553344727, 0.7626526951789856\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6535 - acc: 0.7452\n",
            "epsilon: 0.01 and test evaluation : 0.6534707546234131, 0.7452006936073303\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7278 - acc: 0.7155\n",
            "epsilon: 0.02 and test evaluation : 0.7278438210487366, 0.7155323028564453\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 1.4637 - acc: 0.3012 - val_loss: 1.4081 - val_acc: 0.3476 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3748 - acc: 0.3577 - val_loss: 1.3270 - val_acc: 0.3689 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3213 - acc: 0.3717 - val_loss: 1.3142 - val_acc: 0.3320 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3040 - acc: 0.3857 - val_loss: 1.3594 - val_acc: 0.3495 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 1.2742 - acc: 0.4059 - val_loss: 1.2793 - val_acc: 0.3864 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 1.2751 - acc: 0.4190 - val_loss: 1.2416 - val_acc: 0.4466 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2138 - acc: 0.4814 - val_loss: 1.1890 - val_acc: 0.4913 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 1.1636 - acc: 0.5169 - val_loss: 1.2047 - val_acc: 0.4874 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1345 - acc: 0.5357 - val_loss: 1.3628 - val_acc: 0.4835 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1184 - acc: 0.5422 - val_loss: 1.0868 - val_acc: 0.5456 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0634 - acc: 0.5668 - val_loss: 1.0383 - val_acc: 0.5767 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0537 - acc: 0.5717 - val_loss: 1.4897 - val_acc: 0.4544 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0157 - acc: 0.5888 - val_loss: 2.9784 - val_acc: 0.4757 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9652 - acc: 0.6161 - val_loss: 1.0487 - val_acc: 0.5709 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.9431 - acc: 0.6265 - val_loss: 1.0709 - val_acc: 0.6019 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9011 - acc: 0.6476 - val_loss: 0.8675 - val_acc: 0.6330 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8826 - acc: 0.6556 - val_loss: 0.9046 - val_acc: 0.6408 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8472 - acc: 0.6682 - val_loss: 0.8607 - val_acc: 0.6447 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8682 - acc: 0.6640 - val_loss: 0.9340 - val_acc: 0.6291 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8133 - acc: 0.6840 - val_loss: 1.0020 - val_acc: 0.6194 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8291 - acc: 0.6753 - val_loss: 0.8789 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7903 - acc: 0.6984 - val_loss: 0.9656 - val_acc: 0.6544 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7815 - acc: 0.6995 - val_loss: 0.8170 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7526 - acc: 0.7106 - val_loss: 2.0112 - val_acc: 0.4252 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7896 - acc: 0.6909 - val_loss: 0.9614 - val_acc: 0.6272 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7423 - acc: 0.7135 - val_loss: 0.8834 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.7361 - acc: 0.7190 - val_loss: 0.8405 - val_acc: 0.6854 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7385 - acc: 0.7155 - val_loss: 0.8243 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7198 - acc: 0.7275 - val_loss: 0.7844 - val_acc: 0.7126 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7000 - acc: 0.7317 - val_loss: 0.8260 - val_acc: 0.7146 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7137 - acc: 0.7208 - val_loss: 0.8114 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6849 - acc: 0.7352 - val_loss: 0.7790 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6616 - acc: 0.7497 - val_loss: 0.7680 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6388 - acc: 0.7639 - val_loss: 0.7563 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6300 - acc: 0.7656 - val_loss: 0.7312 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6176 - acc: 0.7708 - val_loss: 0.7245 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6047 - acc: 0.7730 - val_loss: 0.7056 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6052 - acc: 0.7736 - val_loss: 0.7054 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5902 - acc: 0.7803 - val_loss: 0.7401 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5875 - acc: 0.7825 - val_loss: 0.7248 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5834 - acc: 0.7774 - val_loss: 0.6988 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5872 - acc: 0.7812 - val_loss: 0.7124 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5877 - acc: 0.7856 - val_loss: 0.7172 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5778 - acc: 0.7821 - val_loss: 0.7173 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5665 - acc: 0.7852 - val_loss: 0.7024 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5656 - acc: 0.7874 - val_loss: 0.7054 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5632 - acc: 0.7874 - val_loss: 0.7133 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5608 - acc: 0.7894 - val_loss: 0.6897 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5626 - acc: 0.7889 - val_loss: 0.6866 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5596 - acc: 0.7874 - val_loss: 0.7166 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5629 - acc: 0.7938 - val_loss: 0.7033 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5482 - acc: 0.7934 - val_loss: 0.6962 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5564 - acc: 0.7914 - val_loss: 0.6954 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5582 - acc: 0.7918 - val_loss: 0.7083 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5461 - acc: 0.7962 - val_loss: 0.7011 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5568 - acc: 0.7945 - val_loss: 0.7115 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5482 - acc: 0.7969 - val_loss: 0.7347 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5539 - acc: 0.7938 - val_loss: 0.7426 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5381 - acc: 0.7989 - val_loss: 0.6787 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5337 - acc: 0.7992 - val_loss: 0.6751 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5183 - acc: 0.8089 - val_loss: 0.6907 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5275 - acc: 0.8063 - val_loss: 0.7472 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5401 - acc: 0.7932 - val_loss: 0.7006 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5379 - acc: 0.8009 - val_loss: 0.7160 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5366 - acc: 0.7983 - val_loss: 0.6802 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5411 - acc: 0.7921 - val_loss: 0.7707 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5307 - acc: 0.8036 - val_loss: 0.6878 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5321 - acc: 0.8003 - val_loss: 0.6839 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5334 - acc: 0.8012 - val_loss: 0.7170 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5318 - acc: 0.8018 - val_loss: 0.7213 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5280 - acc: 0.8027 - val_loss: 0.6983 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5413 - acc: 0.7998 - val_loss: 0.6868 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5447 - acc: 0.7945 - val_loss: 0.6786 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5394 - acc: 0.7974 - val_loss: 0.6773 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5339 - acc: 0.8020 - val_loss: 0.7147 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5265 - acc: 0.8065 - val_loss: 0.7020 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5298 - acc: 0.7992 - val_loss: 0.7219 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5286 - acc: 0.8058 - val_loss: 0.7096 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5317 - acc: 0.7969 - val_loss: 0.6895 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5400 - acc: 0.7969 - val_loss: 0.6963 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5400 - acc: 0.7998 - val_loss: 0.7045 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5326 - acc: 0.8034 - val_loss: 0.6745 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5332 - acc: 0.8032 - val_loss: 0.6928 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5312 - acc: 0.7998 - val_loss: 0.7110 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5273 - acc: 0.7998 - val_loss: 0.6791 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5368 - acc: 0.7954 - val_loss: 0.6668 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5287 - acc: 0.7956 - val_loss: 0.7015 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5288 - acc: 0.8005 - val_loss: 0.6901 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5272 - acc: 0.8051 - val_loss: 0.6970 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5312 - acc: 0.8027 - val_loss: 0.7123 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5334 - acc: 0.8029 - val_loss: 0.6855 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5291 - acc: 0.8056 - val_loss: 0.7304 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5256 - acc: 0.8047 - val_loss: 0.6834 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5316 - acc: 0.7996 - val_loss: 0.6799 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5282 - acc: 0.8023 - val_loss: 0.7030 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5282 - acc: 0.7998 - val_loss: 0.7063 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5285 - acc: 0.7996 - val_loss: 0.7062 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5394 - acc: 0.7983 - val_loss: 0.6871 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5257 - acc: 0.8045 - val_loss: 0.7179 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5238 - acc: 0.8071 - val_loss: 0.6779 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5325 - acc: 0.8014 - val_loss: 0.6897 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5379 - acc: 0.7934 - val_loss: 0.6886 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5236 - acc: 0.7998 - val_loss: 0.7036 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5326 - acc: 0.8025 - val_loss: 0.6926 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5342 - acc: 0.7949 - val_loss: 0.6921 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5380 - acc: 0.7963 - val_loss: 0.6796 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5261 - acc: 0.7983 - val_loss: 0.6740 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5319 - acc: 0.8023 - val_loss: 0.6857 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5307 - acc: 0.8007 - val_loss: 0.6946 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5351 - acc: 0.8020 - val_loss: 0.7254 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5342 - acc: 0.8009 - val_loss: 0.6974 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5258 - acc: 0.8056 - val_loss: 0.6884 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5271 - acc: 0.8051 - val_loss: 0.6820 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5300 - acc: 0.7945 - val_loss: 0.6707 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5315 - acc: 0.7996 - val_loss: 0.7057 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5215 - acc: 0.8036 - val_loss: 0.6897 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5217 - acc: 0.8027 - val_loss: 0.6692 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5362 - acc: 0.8012 - val_loss: 0.6687 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5336 - acc: 0.7934 - val_loss: 0.7065 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5308 - acc: 0.8009 - val_loss: 0.6598 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5364 - acc: 0.7998 - val_loss: 0.6944 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5306 - acc: 0.8025 - val_loss: 0.6929 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5294 - acc: 0.8005 - val_loss: 0.6904 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5390 - acc: 0.7992 - val_loss: 0.6814 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5335 - acc: 0.7974 - val_loss: 0.7392 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5276 - acc: 0.8054 - val_loss: 0.6906 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5349 - acc: 0.8027 - val_loss: 0.6928 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5290 - acc: 0.8038 - val_loss: 0.6758 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5229 - acc: 0.8023 - val_loss: 0.6822 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5362 - acc: 0.7994 - val_loss: 0.6849 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5309 - acc: 0.7969 - val_loss: 0.6888 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5409 - acc: 0.7956 - val_loss: 0.6696 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5196 - acc: 0.8085 - val_loss: 0.6746 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5216 - acc: 0.8056 - val_loss: 0.6869 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5265 - acc: 0.8007 - val_loss: 0.6755 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5191 - acc: 0.8056 - val_loss: 0.6863 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5198 - acc: 0.8014 - val_loss: 0.6992 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5278 - acc: 0.8038 - val_loss: 0.6752 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5324 - acc: 0.7994 - val_loss: 0.6806 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5277 - acc: 0.8043 - val_loss: 0.6873 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5270 - acc: 0.8032 - val_loss: 0.7011 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5249 - acc: 0.8078 - val_loss: 0.6719 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5309 - acc: 0.7943 - val_loss: 0.6612 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5347 - acc: 0.7976 - val_loss: 0.6946 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5319 - acc: 0.7958 - val_loss: 0.6874 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5277 - acc: 0.8034 - val_loss: 0.6876 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5283 - acc: 0.8009 - val_loss: 0.7235 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5299 - acc: 0.8014 - val_loss: 0.6933 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5309 - acc: 0.8049 - val_loss: 0.6949 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5264 - acc: 0.7985 - val_loss: 0.6649 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5333 - acc: 0.7972 - val_loss: 0.6638 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5336 - acc: 0.7978 - val_loss: 0.6796 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5337 - acc: 0.7992 - val_loss: 0.6902 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5211 - acc: 0.8056 - val_loss: 0.6731 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5211 - acc: 0.8054 - val_loss: 0.6866 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5363 - acc: 0.7958 - val_loss: 0.6732 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5329 - acc: 0.8027 - val_loss: 0.7180 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5291 - acc: 0.7992 - val_loss: 0.6742 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5292 - acc: 0.8040 - val_loss: 0.6824 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5212 - acc: 0.8056 - val_loss: 0.6825 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5309 - acc: 0.8014 - val_loss: 0.6648 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5333 - acc: 0.7989 - val_loss: 0.6744 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5294 - acc: 0.7985 - val_loss: 0.7052 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5247 - acc: 0.8000 - val_loss: 0.7302 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5318 - acc: 0.8049 - val_loss: 0.7033 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5279 - acc: 0.8043 - val_loss: 0.6693 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5211 - acc: 0.8058 - val_loss: 0.6696 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5329 - acc: 0.8014 - val_loss: 0.6699 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5269 - acc: 0.8027 - val_loss: 0.6890 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5311 - acc: 0.8047 - val_loss: 0.8147 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5320 - acc: 0.7952 - val_loss: 0.7115 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5275 - acc: 0.8012 - val_loss: 0.6614 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5237 - acc: 0.8018 - val_loss: 0.7106 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5296 - acc: 0.8012 - val_loss: 0.6840 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5212 - acc: 0.8067 - val_loss: 0.6793 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5211 - acc: 0.8043 - val_loss: 0.7440 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5291 - acc: 0.7952 - val_loss: 0.7166 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5225 - acc: 0.8018 - val_loss: 0.6871 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5210 - acc: 0.8063 - val_loss: 0.6966 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5197 - acc: 0.8018 - val_loss: 0.7468 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5310 - acc: 0.7980 - val_loss: 0.6846 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5333 - acc: 0.7980 - val_loss: 0.6636 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5248 - acc: 0.8109 - val_loss: 0.6889 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5315 - acc: 0.8047 - val_loss: 0.7013 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5276 - acc: 0.7994 - val_loss: 0.6595 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5137 - acc: 0.8060 - val_loss: 0.6863 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5278 - acc: 0.8003 - val_loss: 0.6679 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5314 - acc: 0.8009 - val_loss: 0.7062 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5301 - acc: 0.7969 - val_loss: 0.6907 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5232 - acc: 0.8080 - val_loss: 0.6841 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5180 - acc: 0.8045 - val_loss: 0.6827 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5293 - acc: 0.8003 - val_loss: 0.7048 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5179 - acc: 0.8058 - val_loss: 0.7262 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5374 - acc: 0.7963 - val_loss: 0.6811 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5283 - acc: 0.7985 - val_loss: 0.7005 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5276 - acc: 0.8020 - val_loss: 0.7084 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5200 - acc: 0.8027 - val_loss: 0.6808 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5319 - acc: 0.7956 - val_loss: 0.7140 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5214 - acc: 0.8045 - val_loss: 0.6711 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5214 - acc: 0.8076 - val_loss: 0.6877 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6494 - acc: 0.7574\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6753 - acc: 0.7400\n",
            "epsilon: 0.003 and test evaluation : 0.6753441095352173, 0.7399650812149048\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6935 - acc: 0.7365\n",
            "epsilon: 0.005 and test evaluation : 0.6935257911682129, 0.7364746928215027\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7418 - acc: 0.7138\n",
            "epsilon: 0.01 and test evaluation : 0.7418321371078491, 0.7137870788574219\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.8464 - acc: 0.6719\n",
            "epsilon: 0.02 and test evaluation : 0.8464072942733765, 0.6719022393226624\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 1.4389 - acc: 0.3249 - val_loss: 1.4132 - val_acc: 0.3340 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3496 - acc: 0.3668 - val_loss: 1.3235 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3236 - acc: 0.3746 - val_loss: 1.3091 - val_acc: 0.3825 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2944 - acc: 0.3897 - val_loss: 1.3306 - val_acc: 0.3107 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2856 - acc: 0.3906 - val_loss: 1.2686 - val_acc: 0.3748 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2553 - acc: 0.4194 - val_loss: 1.3115 - val_acc: 0.4272 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2317 - acc: 0.4345 - val_loss: 1.2204 - val_acc: 0.4078 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1973 - acc: 0.4760 - val_loss: 1.1575 - val_acc: 0.5282 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1901 - acc: 0.4885 - val_loss: 1.3446 - val_acc: 0.4388 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.1565 - acc: 0.5129 - val_loss: 1.3663 - val_acc: 0.4117 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.0790 - acc: 0.5557 - val_loss: 1.2974 - val_acc: 0.4641 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0464 - acc: 0.5735 - val_loss: 1.0015 - val_acc: 0.6019 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0015 - acc: 0.5923 - val_loss: 1.0036 - val_acc: 0.5845 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9681 - acc: 0.6185 - val_loss: 0.9773 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9335 - acc: 0.6340 - val_loss: 0.8739 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8945 - acc: 0.6458 - val_loss: 1.2127 - val_acc: 0.4680 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8882 - acc: 0.6514 - val_loss: 0.8588 - val_acc: 0.6466 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8582 - acc: 0.6602 - val_loss: 0.9427 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8561 - acc: 0.6742 - val_loss: 0.8299 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8177 - acc: 0.6835 - val_loss: 0.8430 - val_acc: 0.7029 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8020 - acc: 0.6904 - val_loss: 0.8444 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7783 - acc: 0.7042 - val_loss: 0.8850 - val_acc: 0.6544 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8023 - acc: 0.6951 - val_loss: 0.8165 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7660 - acc: 0.7051 - val_loss: 0.8339 - val_acc: 0.6757 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7557 - acc: 0.7106 - val_loss: 0.9287 - val_acc: 0.6350 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7551 - acc: 0.7091 - val_loss: 0.7743 - val_acc: 0.6990 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7227 - acc: 0.7210 - val_loss: 0.7861 - val_acc: 0.6990 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7353 - acc: 0.7219 - val_loss: 0.7497 - val_acc: 0.7146 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7153 - acc: 0.7312 - val_loss: 0.7285 - val_acc: 0.7243 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7015 - acc: 0.7344 - val_loss: 0.7998 - val_acc: 0.7146 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7320 - acc: 0.7244 - val_loss: 0.7546 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6599 - acc: 0.7515 - val_loss: 0.7229 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6395 - acc: 0.7632 - val_loss: 0.7156 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6321 - acc: 0.7661 - val_loss: 0.6993 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6191 - acc: 0.7736 - val_loss: 0.7008 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6091 - acc: 0.7708 - val_loss: 0.6984 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6096 - acc: 0.7756 - val_loss: 0.6918 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6011 - acc: 0.7754 - val_loss: 0.6878 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5966 - acc: 0.7801 - val_loss: 0.6888 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5868 - acc: 0.7790 - val_loss: 0.6734 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5935 - acc: 0.7765 - val_loss: 0.6869 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5857 - acc: 0.7838 - val_loss: 0.6783 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5810 - acc: 0.7852 - val_loss: 0.6805 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5768 - acc: 0.7818 - val_loss: 0.6744 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5801 - acc: 0.7832 - val_loss: 0.6679 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5812 - acc: 0.7858 - val_loss: 0.6725 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5790 - acc: 0.7876 - val_loss: 0.6809 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5636 - acc: 0.7909 - val_loss: 0.6791 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5626 - acc: 0.7905 - val_loss: 0.6660 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5659 - acc: 0.7841 - val_loss: 0.6652 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5685 - acc: 0.7923 - val_loss: 0.6624 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5583 - acc: 0.7934 - val_loss: 0.6699 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5594 - acc: 0.7936 - val_loss: 0.6663 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5539 - acc: 0.7934 - val_loss: 0.6991 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5563 - acc: 0.7936 - val_loss: 0.6637 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5485 - acc: 0.7956 - val_loss: 0.6617 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5475 - acc: 0.7980 - val_loss: 0.6686 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5493 - acc: 0.7983 - val_loss: 0.6663 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5546 - acc: 0.7912 - val_loss: 0.6735 - val_acc: 0.7553 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5471 - acc: 0.7936 - val_loss: 0.6654 - val_acc: 0.7573 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5322 - acc: 0.8051 - val_loss: 0.6690 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5286 - acc: 0.8051 - val_loss: 0.6555 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5332 - acc: 0.8007 - val_loss: 0.6660 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5333 - acc: 0.8000 - val_loss: 0.6778 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5478 - acc: 0.7987 - val_loss: 0.6621 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5395 - acc: 0.7958 - val_loss: 0.6725 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5409 - acc: 0.8012 - val_loss: 0.6626 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5389 - acc: 0.8045 - val_loss: 0.6789 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5387 - acc: 0.8038 - val_loss: 0.6709 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5387 - acc: 0.7998 - val_loss: 0.6566 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5433 - acc: 0.7978 - val_loss: 0.6950 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5436 - acc: 0.7972 - val_loss: 0.6836 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5389 - acc: 0.7960 - val_loss: 0.6600 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5427 - acc: 0.7952 - val_loss: 0.6624 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5412 - acc: 0.8003 - val_loss: 0.6697 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5353 - acc: 0.7972 - val_loss: 0.6567 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5303 - acc: 0.8009 - val_loss: 0.6670 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5382 - acc: 0.8000 - val_loss: 0.6664 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5311 - acc: 0.8058 - val_loss: 0.6745 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5354 - acc: 0.8000 - val_loss: 0.6585 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5261 - acc: 0.8032 - val_loss: 0.6669 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5355 - acc: 0.8040 - val_loss: 0.6582 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5353 - acc: 0.8005 - val_loss: 0.6770 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5477 - acc: 0.7965 - val_loss: 0.6711 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5328 - acc: 0.8034 - val_loss: 0.6679 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5334 - acc: 0.8025 - val_loss: 0.6670 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5322 - acc: 0.7960 - val_loss: 0.6699 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5299 - acc: 0.8076 - val_loss: 0.6558 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5313 - acc: 0.8025 - val_loss: 0.6772 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5339 - acc: 0.8025 - val_loss: 0.6836 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5507 - acc: 0.7978 - val_loss: 0.6628 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5340 - acc: 0.8025 - val_loss: 0.6644 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5397 - acc: 0.8032 - val_loss: 0.6641 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5352 - acc: 0.8029 - val_loss: 0.6666 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5324 - acc: 0.7985 - val_loss: 0.6636 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5371 - acc: 0.7998 - val_loss: 0.6913 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5488 - acc: 0.7963 - val_loss: 0.6876 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5312 - acc: 0.7985 - val_loss: 0.6542 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5421 - acc: 0.8012 - val_loss: 0.6688 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5301 - acc: 0.8032 - val_loss: 0.6687 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5311 - acc: 0.7972 - val_loss: 0.6629 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5316 - acc: 0.8032 - val_loss: 0.6671 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5236 - acc: 0.8029 - val_loss: 0.6690 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5316 - acc: 0.8009 - val_loss: 0.6549 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5245 - acc: 0.8089 - val_loss: 0.6769 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5335 - acc: 0.7989 - val_loss: 0.6557 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5437 - acc: 0.7976 - val_loss: 0.6681 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5327 - acc: 0.8027 - val_loss: 0.6667 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5395 - acc: 0.7932 - val_loss: 0.6676 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5400 - acc: 0.7963 - val_loss: 0.6984 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5342 - acc: 0.8032 - val_loss: 0.6742 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5291 - acc: 0.8047 - val_loss: 0.6766 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5398 - acc: 0.8020 - val_loss: 0.6626 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5330 - acc: 0.8007 - val_loss: 0.6631 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5396 - acc: 0.8045 - val_loss: 0.6582 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5359 - acc: 0.7987 - val_loss: 0.6755 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5268 - acc: 0.8083 - val_loss: 0.6674 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5380 - acc: 0.7974 - val_loss: 0.6766 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.5351 - acc: 0.7980 - val_loss: 0.6690 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5439 - acc: 0.8012 - val_loss: 0.6908 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5349 - acc: 0.8018 - val_loss: 0.6564 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5281 - acc: 0.8016 - val_loss: 0.6787 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5346 - acc: 0.7994 - val_loss: 0.6620 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5360 - acc: 0.8043 - val_loss: 0.6577 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5376 - acc: 0.8000 - val_loss: 0.6588 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5288 - acc: 0.8060 - val_loss: 0.6658 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5329 - acc: 0.8038 - val_loss: 0.6782 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5348 - acc: 0.8018 - val_loss: 0.6612 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5195 - acc: 0.8114 - val_loss: 0.6621 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5350 - acc: 0.8016 - val_loss: 0.6616 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5442 - acc: 0.7983 - val_loss: 0.6557 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5267 - acc: 0.8067 - val_loss: 0.6566 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5309 - acc: 0.8023 - val_loss: 0.7010 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5326 - acc: 0.8074 - val_loss: 0.7076 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5354 - acc: 0.7954 - val_loss: 0.6722 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5350 - acc: 0.7965 - val_loss: 0.6699 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5362 - acc: 0.7947 - val_loss: 0.6757 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5355 - acc: 0.8038 - val_loss: 0.6565 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5321 - acc: 0.8034 - val_loss: 0.6702 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5333 - acc: 0.8025 - val_loss: 0.6688 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5237 - acc: 0.8051 - val_loss: 0.6535 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5336 - acc: 0.8038 - val_loss: 0.6729 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5330 - acc: 0.7996 - val_loss: 0.6623 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5314 - acc: 0.8007 - val_loss: 0.6699 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5393 - acc: 0.8032 - val_loss: 0.6612 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5390 - acc: 0.8010 - val_loss: 0.6827 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5263 - acc: 0.8049 - val_loss: 0.6569 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5188 - acc: 0.8109 - val_loss: 0.6608 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5330 - acc: 0.8018 - val_loss: 0.6644 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5317 - acc: 0.7978 - val_loss: 0.6590 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5315 - acc: 0.8045 - val_loss: 0.6621 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5341 - acc: 0.7980 - val_loss: 0.6613 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.5321 - acc: 0.8003 - val_loss: 0.6614 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5265 - acc: 0.8038 - val_loss: 0.6670 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5305 - acc: 0.8003 - val_loss: 0.6620 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5316 - acc: 0.8065 - val_loss: 0.6613 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5313 - acc: 0.7978 - val_loss: 0.6553 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5279 - acc: 0.8000 - val_loss: 0.6759 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5341 - acc: 0.7943 - val_loss: 0.6771 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5284 - acc: 0.7998 - val_loss: 0.6759 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5242 - acc: 0.8067 - val_loss: 0.6629 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5251 - acc: 0.8049 - val_loss: 0.6562 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5407 - acc: 0.7978 - val_loss: 0.7067 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5306 - acc: 0.8096 - val_loss: 0.6734 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5256 - acc: 0.8014 - val_loss: 0.6592 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5275 - acc: 0.8065 - val_loss: 0.6565 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5332 - acc: 0.8023 - val_loss: 0.6612 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5234 - acc: 0.8054 - val_loss: 0.6543 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5369 - acc: 0.7976 - val_loss: 0.6666 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5384 - acc: 0.7969 - val_loss: 0.6630 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5267 - acc: 0.8058 - val_loss: 0.6589 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5245 - acc: 0.8007 - val_loss: 0.6508 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5327 - acc: 0.8018 - val_loss: 0.6653 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5276 - acc: 0.8025 - val_loss: 0.6779 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5259 - acc: 0.8020 - val_loss: 0.6663 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5336 - acc: 0.8038 - val_loss: 0.6803 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5291 - acc: 0.8045 - val_loss: 0.6624 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5332 - acc: 0.7958 - val_loss: 0.6736 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5340 - acc: 0.7976 - val_loss: 0.6662 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5300 - acc: 0.8060 - val_loss: 0.6915 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5279 - acc: 0.8047 - val_loss: 0.6487 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5345 - acc: 0.7963 - val_loss: 0.6674 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5306 - acc: 0.8067 - val_loss: 0.6799 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5285 - acc: 0.8036 - val_loss: 0.6668 - val_acc: 0.7534 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5278 - acc: 0.7983 - val_loss: 0.6547 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5325 - acc: 0.8016 - val_loss: 0.6558 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5366 - acc: 0.8000 - val_loss: 0.6721 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5342 - acc: 0.8016 - val_loss: 0.6553 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5251 - acc: 0.8007 - val_loss: 0.6527 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5307 - acc: 0.8051 - val_loss: 0.6605 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5310 - acc: 0.7938 - val_loss: 0.6582 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5342 - acc: 0.7976 - val_loss: 0.7097 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5303 - acc: 0.8054 - val_loss: 0.6575 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5300 - acc: 0.8034 - val_loss: 0.6579 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5394 - acc: 0.7954 - val_loss: 0.6876 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5296 - acc: 0.8040 - val_loss: 0.6687 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5314 - acc: 0.7949 - val_loss: 0.6644 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5298 - acc: 0.8018 - val_loss: 0.6551 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5265 - acc: 0.8114 - val_loss: 0.6585 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5254 - acc: 0.8051 - val_loss: 0.6557 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6078 - acc: 0.7731\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6323 - acc: 0.7644\n",
            "epsilon: 0.003 and test evaluation : 0.6322989463806152, 0.764397919178009\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6493 - acc: 0.7592\n",
            "epsilon: 0.005 and test evaluation : 0.6492627263069153, 0.7591623067855835\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6942 - acc: 0.7469\n",
            "epsilon: 0.01 and test evaluation : 0.6941565871238708, 0.7469459176063538\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7950 - acc: 0.7155\n",
            "epsilon: 0.02 and test evaluation : 0.7949616312980652, 0.7155323028564453\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 1.4572 - acc: 0.3198 - val_loss: 1.4368 - val_acc: 0.3087 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.3627 - acc: 0.3651 - val_loss: 1.3105 - val_acc: 0.4155 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.3146 - acc: 0.3866 - val_loss: 1.3437 - val_acc: 0.3689 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2994 - acc: 0.3782 - val_loss: 1.3091 - val_acc: 0.4058 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2791 - acc: 0.3937 - val_loss: 1.2371 - val_acc: 0.4369 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 1.2661 - acc: 0.4157 - val_loss: 1.2181 - val_acc: 0.4233 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2467 - acc: 0.4576 - val_loss: 1.2006 - val_acc: 0.5068 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1687 - acc: 0.5146 - val_loss: 1.1152 - val_acc: 0.5612 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.1544 - acc: 0.5160 - val_loss: 1.0944 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0998 - acc: 0.5431 - val_loss: 1.1227 - val_acc: 0.5029 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1039 - acc: 0.5366 - val_loss: 1.2183 - val_acc: 0.4971 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0541 - acc: 0.5706 - val_loss: 0.9993 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0258 - acc: 0.5948 - val_loss: 1.1277 - val_acc: 0.5456 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9975 - acc: 0.5921 - val_loss: 0.9715 - val_acc: 0.6175 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9808 - acc: 0.5985 - val_loss: 1.2566 - val_acc: 0.4563 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9173 - acc: 0.6323 - val_loss: 0.9844 - val_acc: 0.6155 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9040 - acc: 0.6458 - val_loss: 0.8880 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8794 - acc: 0.6482 - val_loss: 0.7689 - val_acc: 0.7010 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8745 - acc: 0.6451 - val_loss: 0.8443 - val_acc: 0.6621 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8537 - acc: 0.6642 - val_loss: 0.8718 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8138 - acc: 0.6809 - val_loss: 0.8020 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8001 - acc: 0.6895 - val_loss: 0.7508 - val_acc: 0.7049 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7890 - acc: 0.6917 - val_loss: 0.8887 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7679 - acc: 0.7102 - val_loss: 0.8652 - val_acc: 0.6427 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7509 - acc: 0.7175 - val_loss: 0.9080 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7538 - acc: 0.7102 - val_loss: 0.7449 - val_acc: 0.7262 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7414 - acc: 0.7117 - val_loss: 0.7994 - val_acc: 0.6738 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7209 - acc: 0.7217 - val_loss: 1.0095 - val_acc: 0.6214 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7317 - acc: 0.7190 - val_loss: 0.6890 - val_acc: 0.7379 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7101 - acc: 0.7277 - val_loss: 0.9636 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7636 - acc: 0.7075 - val_loss: 0.7488 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7297 - acc: 0.7213 - val_loss: 0.7122 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7050 - acc: 0.7299 - val_loss: 0.6988 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6810 - acc: 0.7443 - val_loss: 0.6733 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6659 - acc: 0.7476 - val_loss: 0.6612 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6523 - acc: 0.7570 - val_loss: 0.6518 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6340 - acc: 0.7639 - val_loss: 0.6486 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6374 - acc: 0.7541 - val_loss: 0.6434 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6318 - acc: 0.7617 - val_loss: 0.6459 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6185 - acc: 0.7643 - val_loss: 0.6461 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6095 - acc: 0.7770 - val_loss: 0.6271 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6094 - acc: 0.7732 - val_loss: 0.6277 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6112 - acc: 0.7716 - val_loss: 0.6169 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6048 - acc: 0.7761 - val_loss: 0.6206 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6062 - acc: 0.7723 - val_loss: 0.6143 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5921 - acc: 0.7770 - val_loss: 0.6138 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5914 - acc: 0.7776 - val_loss: 0.6197 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5812 - acc: 0.7821 - val_loss: 0.6101 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5822 - acc: 0.7881 - val_loss: 0.6147 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5832 - acc: 0.7787 - val_loss: 0.6080 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5753 - acc: 0.7903 - val_loss: 0.6102 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5689 - acc: 0.7861 - val_loss: 0.6324 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5766 - acc: 0.7883 - val_loss: 0.6143 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5748 - acc: 0.7901 - val_loss: 0.6188 - val_acc: 0.7650 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5580 - acc: 0.7996 - val_loss: 0.6040 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5678 - acc: 0.7852 - val_loss: 0.6154 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5664 - acc: 0.7872 - val_loss: 0.6027 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5615 - acc: 0.7863 - val_loss: 0.5996 - val_acc: 0.7748 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5579 - acc: 0.7943 - val_loss: 0.6006 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5535 - acc: 0.7974 - val_loss: 0.6044 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5536 - acc: 0.7938 - val_loss: 0.5982 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5405 - acc: 0.7969 - val_loss: 0.6041 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5557 - acc: 0.7954 - val_loss: 0.6074 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5512 - acc: 0.7972 - val_loss: 0.6047 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5540 - acc: 0.7932 - val_loss: 0.5996 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5447 - acc: 0.7992 - val_loss: 0.6055 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5441 - acc: 0.8000 - val_loss: 0.5969 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5502 - acc: 0.7949 - val_loss: 0.5943 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5545 - acc: 0.7992 - val_loss: 0.5925 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5412 - acc: 0.7994 - val_loss: 0.6596 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5482 - acc: 0.7987 - val_loss: 0.6007 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5575 - acc: 0.7921 - val_loss: 0.6009 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5567 - acc: 0.7934 - val_loss: 0.6674 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5461 - acc: 0.7983 - val_loss: 0.5983 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5520 - acc: 0.7952 - val_loss: 0.6064 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5497 - acc: 0.7994 - val_loss: 0.6021 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5519 - acc: 0.7923 - val_loss: 0.6192 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5544 - acc: 0.8000 - val_loss: 0.6000 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5487 - acc: 0.7994 - val_loss: 0.5943 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5550 - acc: 0.7927 - val_loss: 0.5900 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5487 - acc: 0.7912 - val_loss: 0.5965 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5533 - acc: 0.7967 - val_loss: 0.6247 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5551 - acc: 0.7901 - val_loss: 0.5954 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5515 - acc: 0.7938 - val_loss: 0.5972 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5479 - acc: 0.7947 - val_loss: 0.5909 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5472 - acc: 0.7956 - val_loss: 0.5969 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5487 - acc: 0.7978 - val_loss: 0.5959 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5541 - acc: 0.7916 - val_loss: 0.6035 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5509 - acc: 0.7943 - val_loss: 0.5988 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5496 - acc: 0.7976 - val_loss: 0.5964 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5438 - acc: 0.8003 - val_loss: 0.5917 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5500 - acc: 0.7936 - val_loss: 0.6028 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5511 - acc: 0.7914 - val_loss: 0.6179 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5467 - acc: 0.7985 - val_loss: 0.6005 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5514 - acc: 0.7923 - val_loss: 0.6030 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5441 - acc: 0.7943 - val_loss: 0.6122 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5380 - acc: 0.8003 - val_loss: 0.5957 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5512 - acc: 0.7883 - val_loss: 0.6412 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5543 - acc: 0.7949 - val_loss: 0.6263 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5533 - acc: 0.7943 - val_loss: 0.5968 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5346 - acc: 0.7995 - val_loss: 0.6144 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5491 - acc: 0.7936 - val_loss: 0.5961 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5476 - acc: 0.7980 - val_loss: 0.6057 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5448 - acc: 0.7929 - val_loss: 0.5961 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5448 - acc: 0.7934 - val_loss: 0.5998 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5460 - acc: 0.7945 - val_loss: 0.5903 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5453 - acc: 0.7943 - val_loss: 0.6042 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5485 - acc: 0.7921 - val_loss: 0.6056 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5447 - acc: 0.7985 - val_loss: 0.5931 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5469 - acc: 0.7916 - val_loss: 0.6003 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5374 - acc: 0.8003 - val_loss: 0.5967 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5406 - acc: 0.7994 - val_loss: 0.5945 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5501 - acc: 0.7936 - val_loss: 0.6019 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5479 - acc: 0.7952 - val_loss: 0.5904 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5467 - acc: 0.7960 - val_loss: 0.6111 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5396 - acc: 0.7941 - val_loss: 0.6023 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5489 - acc: 0.7912 - val_loss: 0.5916 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5483 - acc: 0.7921 - val_loss: 0.5952 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5434 - acc: 0.7969 - val_loss: 0.5944 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5569 - acc: 0.7892 - val_loss: 0.5945 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5372 - acc: 0.7994 - val_loss: 0.6069 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5491 - acc: 0.7909 - val_loss: 0.5894 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5450 - acc: 0.7923 - val_loss: 0.6302 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5505 - acc: 0.7923 - val_loss: 0.5897 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5511 - acc: 0.7969 - val_loss: 0.5954 - val_acc: 0.7806 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5467 - acc: 0.7918 - val_loss: 0.6026 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5415 - acc: 0.7998 - val_loss: 0.5996 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5434 - acc: 0.7918 - val_loss: 0.6000 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5492 - acc: 0.7903 - val_loss: 0.5891 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5546 - acc: 0.7932 - val_loss: 0.5924 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5490 - acc: 0.7932 - val_loss: 0.5953 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5481 - acc: 0.7941 - val_loss: 0.5908 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5449 - acc: 0.7974 - val_loss: 0.6000 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5492 - acc: 0.7909 - val_loss: 0.5912 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5426 - acc: 0.8025 - val_loss: 0.6052 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5485 - acc: 0.7958 - val_loss: 0.5928 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5404 - acc: 0.7976 - val_loss: 0.6010 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5445 - acc: 0.7954 - val_loss: 0.5977 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5478 - acc: 0.8034 - val_loss: 0.5901 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5432 - acc: 0.7985 - val_loss: 0.5929 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5426 - acc: 0.7976 - val_loss: 0.5962 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5430 - acc: 0.7958 - val_loss: 0.5974 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5475 - acc: 0.7856 - val_loss: 0.6003 - val_acc: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5404 - acc: 0.7976 - val_loss: 0.5979 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5370 - acc: 0.8016 - val_loss: 0.5947 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5446 - acc: 0.7945 - val_loss: 0.5959 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5435 - acc: 0.7969 - val_loss: 0.5944 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5438 - acc: 0.7927 - val_loss: 0.5930 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5440 - acc: 0.8012 - val_loss: 0.5877 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5437 - acc: 0.7932 - val_loss: 0.5913 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5438 - acc: 0.7958 - val_loss: 0.5950 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5388 - acc: 0.7992 - val_loss: 0.5935 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5396 - acc: 0.8029 - val_loss: 0.6073 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5410 - acc: 0.7983 - val_loss: 0.5865 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5366 - acc: 0.8016 - val_loss: 0.5949 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5454 - acc: 0.7954 - val_loss: 0.5965 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5443 - acc: 0.7978 - val_loss: 0.6019 - val_acc: 0.7592 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5383 - acc: 0.7976 - val_loss: 0.5946 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5401 - acc: 0.7978 - val_loss: 0.6045 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5518 - acc: 0.7978 - val_loss: 0.5929 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5438 - acc: 0.7983 - val_loss: 0.6017 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5388 - acc: 0.7985 - val_loss: 0.6287 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5404 - acc: 0.7907 - val_loss: 0.5929 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5406 - acc: 0.7952 - val_loss: 0.5909 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5514 - acc: 0.7949 - val_loss: 0.6108 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5407 - acc: 0.7956 - val_loss: 0.6036 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5341 - acc: 0.8036 - val_loss: 0.6075 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5420 - acc: 0.7936 - val_loss: 0.5965 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5411 - acc: 0.7984 - val_loss: 0.5988 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5365 - acc: 0.7989 - val_loss: 0.5926 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5375 - acc: 0.7972 - val_loss: 0.5941 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5507 - acc: 0.7960 - val_loss: 0.6020 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5402 - acc: 0.7985 - val_loss: 0.5975 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5500 - acc: 0.7949 - val_loss: 0.5939 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5480 - acc: 0.7989 - val_loss: 0.5923 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5495 - acc: 0.7929 - val_loss: 0.5921 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5425 - acc: 0.7967 - val_loss: 0.5992 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5380 - acc: 0.8000 - val_loss: 0.6086 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5423 - acc: 0.7932 - val_loss: 0.5875 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5416 - acc: 0.7960 - val_loss: 0.5951 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5381 - acc: 0.7967 - val_loss: 0.6094 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5444 - acc: 0.7921 - val_loss: 0.5913 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5464 - acc: 0.7927 - val_loss: 0.5912 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5362 - acc: 0.7989 - val_loss: 0.5911 - val_acc: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5455 - acc: 0.8014 - val_loss: 0.5909 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5393 - acc: 0.8007 - val_loss: 0.6010 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5571 - acc: 0.7914 - val_loss: 0.5888 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5369 - acc: 0.8005 - val_loss: 0.5987 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5378 - acc: 0.7960 - val_loss: 0.5940 - val_acc: 0.7612 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5444 - acc: 0.7909 - val_loss: 0.6034 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5463 - acc: 0.8003 - val_loss: 0.5970 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5446 - acc: 0.7949 - val_loss: 0.5909 - val_acc: 0.7573 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5449 - acc: 0.7983 - val_loss: 0.5939 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5390 - acc: 0.7967 - val_loss: 0.5953 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5410 - acc: 0.7932 - val_loss: 0.5898 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5413 - acc: 0.8027 - val_loss: 0.5944 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5419 - acc: 0.7925 - val_loss: 0.6004 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5447 - acc: 0.7907 - val_loss: 0.5881 - val_acc: 0.7728 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5397 - acc: 0.7983 - val_loss: 0.5964 - val_acc: 0.7709 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5391 - acc: 0.7947 - val_loss: 0.5910 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6129 - acc: 0.7539\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6352 - acc: 0.7469\n",
            "epsilon: 0.003 and test evaluation : 0.6352471113204956, 0.7469459176063538\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6507 - acc: 0.7435\n",
            "epsilon: 0.005 and test evaluation : 0.650735080242157, 0.7434554696083069\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6915 - acc: 0.7260\n",
            "epsilon: 0.01 and test evaluation : 0.6914625763893127, 0.7260034680366516\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7808 - acc: 0.6928\n",
            "epsilon: 0.02 and test evaluation : 0.7808474898338318, 0.6928446888923645\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 1.4457 - acc: 0.3318 - val_loss: 1.4170 - val_acc: 0.2971 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3392 - acc: 0.3711 - val_loss: 1.3335 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.3119 - acc: 0.3819 - val_loss: 1.3239 - val_acc: 0.3864 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2927 - acc: 0.3842 - val_loss: 1.3333 - val_acc: 0.3456 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2658 - acc: 0.4132 - val_loss: 1.2725 - val_acc: 0.4583 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.2407 - acc: 0.4523 - val_loss: 1.2513 - val_acc: 0.4466 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2038 - acc: 0.4871 - val_loss: 1.2008 - val_acc: 0.4816 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.1535 - acc: 0.5229 - val_loss: 1.4821 - val_acc: 0.3573 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1250 - acc: 0.5431 - val_loss: 1.2396 - val_acc: 0.4913 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0929 - acc: 0.5559 - val_loss: 1.4298 - val_acc: 0.4252 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.0616 - acc: 0.5726 - val_loss: 1.1498 - val_acc: 0.5126 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0285 - acc: 0.5870 - val_loss: 1.3404 - val_acc: 0.4951 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9777 - acc: 0.6083 - val_loss: 1.0065 - val_acc: 0.6117 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9689 - acc: 0.6152 - val_loss: 0.9813 - val_acc: 0.5903 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9439 - acc: 0.6261 - val_loss: 0.9749 - val_acc: 0.6078 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9004 - acc: 0.6456 - val_loss: 1.0214 - val_acc: 0.6272 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8789 - acc: 0.6456 - val_loss: 0.9239 - val_acc: 0.6524 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8462 - acc: 0.6713 - val_loss: 1.0023 - val_acc: 0.6155 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8355 - acc: 0.6764 - val_loss: 0.7993 - val_acc: 0.6757 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8283 - acc: 0.6826 - val_loss: 1.0522 - val_acc: 0.5670 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7900 - acc: 0.6997 - val_loss: 0.7953 - val_acc: 0.6854 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7797 - acc: 0.6957 - val_loss: 0.8059 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7968 - acc: 0.6968 - val_loss: 0.8012 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7450 - acc: 0.7104 - val_loss: 0.7639 - val_acc: 0.7029 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7598 - acc: 0.7173 - val_loss: 0.7672 - val_acc: 0.7068 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7216 - acc: 0.7221 - val_loss: 0.7775 - val_acc: 0.7029 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7224 - acc: 0.7166 - val_loss: 0.8106 - val_acc: 0.6738 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7351 - acc: 0.7155 - val_loss: 0.9877 - val_acc: 0.6155 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7158 - acc: 0.7250 - val_loss: 0.8158 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7177 - acc: 0.7310 - val_loss: 0.7715 - val_acc: 0.7068 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6937 - acc: 0.7375 - val_loss: 0.8099 - val_acc: 0.6757 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6574 - acc: 0.7517 - val_loss: 0.7766 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6335 - acc: 0.7654 - val_loss: 0.7962 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6303 - acc: 0.7654 - val_loss: 0.7274 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6253 - acc: 0.7628 - val_loss: 0.7443 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.6189 - acc: 0.7683 - val_loss: 0.7683 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6065 - acc: 0.7716 - val_loss: 0.7167 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5969 - acc: 0.7798 - val_loss: 0.7072 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5921 - acc: 0.7821 - val_loss: 0.7067 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5955 - acc: 0.7770 - val_loss: 0.7277 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5856 - acc: 0.7790 - val_loss: 0.7324 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5851 - acc: 0.7858 - val_loss: 0.6994 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5925 - acc: 0.7763 - val_loss: 0.7278 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5840 - acc: 0.7883 - val_loss: 0.7041 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5804 - acc: 0.7801 - val_loss: 0.6824 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5768 - acc: 0.7903 - val_loss: 0.7106 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5735 - acc: 0.7885 - val_loss: 0.7179 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5753 - acc: 0.7841 - val_loss: 0.7215 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5730 - acc: 0.7872 - val_loss: 0.7149 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5710 - acc: 0.7903 - val_loss: 0.7013 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5596 - acc: 0.7954 - val_loss: 0.7080 - val_acc: 0.7282 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5596 - acc: 0.7912 - val_loss: 0.7042 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5558 - acc: 0.7912 - val_loss: 0.7003 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5669 - acc: 0.7823 - val_loss: 0.6950 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5576 - acc: 0.7883 - val_loss: 0.6870 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5541 - acc: 0.7956 - val_loss: 0.6975 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5495 - acc: 0.8003 - val_loss: 0.6855 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5453 - acc: 0.7992 - val_loss: 0.6697 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5527 - acc: 0.7967 - val_loss: 0.6976 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5455 - acc: 0.7923 - val_loss: 0.6998 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5401 - acc: 0.7978 - val_loss: 0.6743 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5472 - acc: 0.7958 - val_loss: 0.6976 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5495 - acc: 0.7949 - val_loss: 0.7102 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5403 - acc: 0.7989 - val_loss: 0.7005 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5428 - acc: 0.7972 - val_loss: 0.6826 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5397 - acc: 0.8038 - val_loss: 0.7321 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5469 - acc: 0.7972 - val_loss: 0.6993 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5528 - acc: 0.7912 - val_loss: 0.6863 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5400 - acc: 0.8009 - val_loss: 0.6951 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5420 - acc: 0.7923 - val_loss: 0.6711 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5409 - acc: 0.7956 - val_loss: 0.6916 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5435 - acc: 0.7952 - val_loss: 0.7752 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5441 - acc: 0.7956 - val_loss: 0.7156 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5391 - acc: 0.7974 - val_loss: 0.7147 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5475 - acc: 0.7965 - val_loss: 0.6850 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5383 - acc: 0.7996 - val_loss: 0.6730 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5467 - acc: 0.7905 - val_loss: 0.7081 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5354 - acc: 0.7980 - val_loss: 0.6952 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5411 - acc: 0.7936 - val_loss: 0.7154 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5475 - acc: 0.8009 - val_loss: 0.7110 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5303 - acc: 0.8009 - val_loss: 0.7076 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5413 - acc: 0.7936 - val_loss: 0.6946 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5410 - acc: 0.7965 - val_loss: 0.6846 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5436 - acc: 0.7927 - val_loss: 0.6748 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5420 - acc: 0.7974 - val_loss: 0.6913 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5427 - acc: 0.7969 - val_loss: 0.6810 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5361 - acc: 0.8020 - val_loss: 0.7035 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5416 - acc: 0.7958 - val_loss: 0.6971 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5363 - acc: 0.7969 - val_loss: 0.6818 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5411 - acc: 0.7978 - val_loss: 0.6902 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5335 - acc: 0.8034 - val_loss: 0.6963 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5322 - acc: 0.8020 - val_loss: 0.7061 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5400 - acc: 0.7952 - val_loss: 0.6776 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5254 - acc: 0.8016 - val_loss: 0.6712 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5361 - acc: 0.8016 - val_loss: 0.6584 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5378 - acc: 0.7980 - val_loss: 0.7126 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5496 - acc: 0.7925 - val_loss: 0.6761 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5378 - acc: 0.7976 - val_loss: 0.6975 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5358 - acc: 0.8029 - val_loss: 0.6891 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5447 - acc: 0.8007 - val_loss: 0.6917 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5385 - acc: 0.7938 - val_loss: 0.6908 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5344 - acc: 0.8018 - val_loss: 0.7049 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5369 - acc: 0.8003 - val_loss: 0.7047 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5403 - acc: 0.7969 - val_loss: 0.7010 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5382 - acc: 0.7965 - val_loss: 0.7160 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5360 - acc: 0.7985 - val_loss: 0.6647 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5401 - acc: 0.7958 - val_loss: 0.6712 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5403 - acc: 0.7943 - val_loss: 0.6838 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5375 - acc: 0.7998 - val_loss: 0.6913 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5374 - acc: 0.8009 - val_loss: 0.6781 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5336 - acc: 0.7989 - val_loss: 0.6954 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5379 - acc: 0.7954 - val_loss: 0.6805 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5340 - acc: 0.8016 - val_loss: 0.6993 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5380 - acc: 0.7956 - val_loss: 0.7306 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5363 - acc: 0.7998 - val_loss: 0.7172 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5334 - acc: 0.8003 - val_loss: 0.7017 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5374 - acc: 0.7972 - val_loss: 0.7187 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5369 - acc: 0.7992 - val_loss: 0.6814 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5448 - acc: 0.7967 - val_loss: 0.6839 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5407 - acc: 0.7949 - val_loss: 0.7007 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5299 - acc: 0.8060 - val_loss: 0.7045 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5426 - acc: 0.7916 - val_loss: 0.6885 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5416 - acc: 0.7958 - val_loss: 0.6766 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5364 - acc: 0.7985 - val_loss: 0.6796 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5350 - acc: 0.7967 - val_loss: 0.7190 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5310 - acc: 0.8038 - val_loss: 0.7143 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5392 - acc: 0.7914 - val_loss: 0.6872 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5309 - acc: 0.7992 - val_loss: 0.6915 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5291 - acc: 0.8051 - val_loss: 0.6940 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5402 - acc: 0.7967 - val_loss: 0.7103 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5399 - acc: 0.7943 - val_loss: 0.6999 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5363 - acc: 0.8014 - val_loss: 0.6951 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5300 - acc: 0.8040 - val_loss: 0.6863 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5385 - acc: 0.7976 - val_loss: 0.6803 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5322 - acc: 0.7992 - val_loss: 0.6817 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5357 - acc: 0.7967 - val_loss: 0.6907 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5310 - acc: 0.7980 - val_loss: 0.6958 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5414 - acc: 0.7958 - val_loss: 0.7080 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5367 - acc: 0.7980 - val_loss: 0.7003 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5353 - acc: 0.8023 - val_loss: 0.7686 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5426 - acc: 0.7952 - val_loss: 0.7107 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5370 - acc: 0.7985 - val_loss: 0.6861 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5349 - acc: 0.7978 - val_loss: 0.6947 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5370 - acc: 0.7909 - val_loss: 0.6813 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5355 - acc: 0.7987 - val_loss: 0.7182 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5314 - acc: 0.8047 - val_loss: 0.7058 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5468 - acc: 0.7883 - val_loss: 0.7306 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5356 - acc: 0.8016 - val_loss: 0.7343 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5407 - acc: 0.7938 - val_loss: 0.6889 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5427 - acc: 0.7983 - val_loss: 0.6884 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5353 - acc: 0.7949 - val_loss: 0.6919 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5361 - acc: 0.7909 - val_loss: 0.7007 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5332 - acc: 0.8007 - val_loss: 0.6917 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5448 - acc: 0.7958 - val_loss: 0.7119 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5330 - acc: 0.8007 - val_loss: 0.6889 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5291 - acc: 0.7992 - val_loss: 0.6849 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5345 - acc: 0.7967 - val_loss: 0.6939 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5427 - acc: 0.7963 - val_loss: 0.6977 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5381 - acc: 0.7974 - val_loss: 0.6989 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5391 - acc: 0.7952 - val_loss: 0.7164 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5310 - acc: 0.7987 - val_loss: 0.6876 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5313 - acc: 0.7987 - val_loss: 0.6967 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5336 - acc: 0.7978 - val_loss: 0.6908 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5294 - acc: 0.8027 - val_loss: 0.7203 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5384 - acc: 0.7954 - val_loss: 0.6903 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5367 - acc: 0.8009 - val_loss: 0.7164 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5407 - acc: 0.7923 - val_loss: 0.7120 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5328 - acc: 0.7969 - val_loss: 0.6814 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5329 - acc: 0.8007 - val_loss: 0.6834 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5326 - acc: 0.8009 - val_loss: 0.6801 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5345 - acc: 0.7985 - val_loss: 0.6922 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5363 - acc: 0.7945 - val_loss: 0.6992 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5294 - acc: 0.8009 - val_loss: 0.7031 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5358 - acc: 0.7969 - val_loss: 0.7054 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5400 - acc: 0.7901 - val_loss: 0.6893 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5345 - acc: 0.7967 - val_loss: 0.6783 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5365 - acc: 0.8029 - val_loss: 0.6800 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5362 - acc: 0.7989 - val_loss: 0.7005 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5325 - acc: 0.7994 - val_loss: 0.6842 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5383 - acc: 0.8018 - val_loss: 0.7226 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5282 - acc: 0.8020 - val_loss: 0.6806 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5400 - acc: 0.7941 - val_loss: 0.6848 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5389 - acc: 0.7972 - val_loss: 0.6744 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5350 - acc: 0.7958 - val_loss: 0.6834 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5368 - acc: 0.7983 - val_loss: 0.7303 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5300 - acc: 0.8034 - val_loss: 0.6856 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5265 - acc: 0.7974 - val_loss: 0.6962 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5381 - acc: 0.7921 - val_loss: 0.6787 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5402 - acc: 0.7985 - val_loss: 0.6935 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5349 - acc: 0.7978 - val_loss: 0.6797 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5350 - acc: 0.7987 - val_loss: 0.6716 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5286 - acc: 0.8023 - val_loss: 0.6624 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5342 - acc: 0.7945 - val_loss: 0.6631 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5311 - acc: 0.7963 - val_loss: 0.6861 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5296 - acc: 0.8040 - val_loss: 0.6737 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5354 - acc: 0.7938 - val_loss: 0.6666 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5322 - acc: 0.7996 - val_loss: 0.7034 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5284 - acc: 0.8029 - val_loss: 0.6608 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5301 - acc: 0.8020 - val_loss: 0.6661 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5375 - acc: 0.7983 - val_loss: 0.6553 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5805 - acc: 0.7923\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6039 - acc: 0.7853\n",
            "epsilon: 0.003 and test evaluation : 0.6038903594017029, 0.7853403091430664\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6203 - acc: 0.7766\n",
            "epsilon: 0.005 and test evaluation : 0.6202670931816101, 0.7766143083572388\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6634 - acc: 0.7557\n",
            "epsilon: 0.01 and test evaluation : 0.6633636951446533, 0.7556719183921814\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7591 - acc: 0.7155\n",
            "epsilon: 0.02 and test evaluation : 0.7591110467910767, 0.7155323028564453\n",
            "SNR: 33.76082897186279\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 1.4515 - acc: 0.3206 - val_loss: 1.4567 - val_acc: 0.2607 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.3506 - acc: 0.3597 - val_loss: 1.3549 - val_acc: 0.3891 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.3095 - acc: 0.3705 - val_loss: 1.4212 - val_acc: 0.3541 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2946 - acc: 0.3912 - val_loss: 1.3130 - val_acc: 0.4125 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2745 - acc: 0.3901 - val_loss: 1.3357 - val_acc: 0.3521 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 1.2577 - acc: 0.4176 - val_loss: 1.3117 - val_acc: 0.3716 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.2442 - acc: 0.4329 - val_loss: 1.2349 - val_acc: 0.4533 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.2119 - acc: 0.4693 - val_loss: 1.2383 - val_acc: 0.4864 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1665 - acc: 0.5057 - val_loss: 1.3747 - val_acc: 0.4494 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.1091 - acc: 0.5369 - val_loss: 1.3045 - val_acc: 0.4844 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0669 - acc: 0.5673 - val_loss: 1.0934 - val_acc: 0.5642 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 1.0244 - acc: 0.5886 - val_loss: 1.0223 - val_acc: 0.5934 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 1.0021 - acc: 0.6035 - val_loss: 1.0365 - val_acc: 0.5973 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.9496 - acc: 0.6197 - val_loss: 0.9519 - val_acc: 0.6265 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9080 - acc: 0.6403 - val_loss: 1.1020 - val_acc: 0.5506 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8976 - acc: 0.6437 - val_loss: 0.9658 - val_acc: 0.6440 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8456 - acc: 0.6719 - val_loss: 1.0543 - val_acc: 0.5914 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.8601 - acc: 0.6625 - val_loss: 0.9350 - val_acc: 0.6907 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8232 - acc: 0.6876 - val_loss: 0.9128 - val_acc: 0.6576 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8018 - acc: 0.6887 - val_loss: 1.0093 - val_acc: 0.6381 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7993 - acc: 0.6903 - val_loss: 0.9105 - val_acc: 0.6751 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7848 - acc: 0.7022 - val_loss: 0.9184 - val_acc: 0.6556 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7892 - acc: 0.6918 - val_loss: 0.8822 - val_acc: 0.6595 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.7529 - acc: 0.7173 - val_loss: 0.8583 - val_acc: 0.6556 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.7491 - acc: 0.7198 - val_loss: 0.8917 - val_acc: 0.6790 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7403 - acc: 0.7160 - val_loss: 0.8508 - val_acc: 0.6654 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7112 - acc: 0.7322 - val_loss: 0.8483 - val_acc: 0.6907 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.7124 - acc: 0.7306 - val_loss: 1.0233 - val_acc: 0.6615 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.7097 - acc: 0.7286 - val_loss: 0.8358 - val_acc: 0.6887 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6879 - acc: 0.7302 - val_loss: 0.9361 - val_acc: 0.6381 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7426 - acc: 0.7149 - val_loss: 0.8884 - val_acc: 0.6556 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6581 - acc: 0.7497 - val_loss: 0.8298 - val_acc: 0.6829 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6260 - acc: 0.7666 - val_loss: 0.8128 - val_acc: 0.6984 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6148 - acc: 0.7746 - val_loss: 0.7876 - val_acc: 0.7043 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5945 - acc: 0.7788 - val_loss: 0.7719 - val_acc: 0.7218 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5890 - acc: 0.7861 - val_loss: 0.7847 - val_acc: 0.7198 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5762 - acc: 0.7863 - val_loss: 0.7919 - val_acc: 0.7101 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5640 - acc: 0.7892 - val_loss: 0.7712 - val_acc: 0.7237 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5630 - acc: 0.7923 - val_loss: 0.8370 - val_acc: 0.6984 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5547 - acc: 0.7941 - val_loss: 0.7708 - val_acc: 0.7276 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5590 - acc: 0.7974 - val_loss: 0.7632 - val_acc: 0.7335 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5490 - acc: 0.7901 - val_loss: 0.7616 - val_acc: 0.7276 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5478 - acc: 0.7934 - val_loss: 0.7521 - val_acc: 0.7374 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5493 - acc: 0.8034 - val_loss: 0.7580 - val_acc: 0.7335 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5446 - acc: 0.8005 - val_loss: 0.7650 - val_acc: 0.7335 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5448 - acc: 0.8016 - val_loss: 0.7869 - val_acc: 0.7490 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5334 - acc: 0.8049 - val_loss: 0.7508 - val_acc: 0.7490 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5326 - acc: 0.8005 - val_loss: 0.7614 - val_acc: 0.7335 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5312 - acc: 0.8036 - val_loss: 0.7636 - val_acc: 0.7315 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5304 - acc: 0.8096 - val_loss: 0.7601 - val_acc: 0.7393 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5244 - acc: 0.8012 - val_loss: 0.7705 - val_acc: 0.7218 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5277 - acc: 0.8079 - val_loss: 0.7661 - val_acc: 0.7276 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5229 - acc: 0.8074 - val_loss: 0.7524 - val_acc: 0.7315 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5183 - acc: 0.8116 - val_loss: 0.7674 - val_acc: 0.7198 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5219 - acc: 0.8094 - val_loss: 0.7309 - val_acc: 0.7412 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5240 - acc: 0.8005 - val_loss: 0.7416 - val_acc: 0.7257 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5152 - acc: 0.8090 - val_loss: 0.7408 - val_acc: 0.7432 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5076 - acc: 0.8158 - val_loss: 0.7658 - val_acc: 0.7354 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5152 - acc: 0.8090 - val_loss: 0.7449 - val_acc: 0.7451 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5069 - acc: 0.8172 - val_loss: 0.7487 - val_acc: 0.7432 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5075 - acc: 0.8085 - val_loss: 0.7420 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5071 - acc: 0.8150 - val_loss: 0.7591 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5070 - acc: 0.8103 - val_loss: 0.7820 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4991 - acc: 0.8167 - val_loss: 0.7432 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5118 - acc: 0.8147 - val_loss: 0.7368 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5090 - acc: 0.8125 - val_loss: 0.7516 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5013 - acc: 0.8145 - val_loss: 0.7322 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5063 - acc: 0.8181 - val_loss: 0.7765 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5030 - acc: 0.8105 - val_loss: 0.7371 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5065 - acc: 0.8112 - val_loss: 0.7725 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5134 - acc: 0.8118 - val_loss: 0.7456 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4917 - acc: 0.8214 - val_loss: 0.7462 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5101 - acc: 0.8143 - val_loss: 0.7632 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5063 - acc: 0.8127 - val_loss: 0.7687 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5005 - acc: 0.8125 - val_loss: 0.7616 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5083 - acc: 0.8123 - val_loss: 0.7380 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5119 - acc: 0.8134 - val_loss: 0.7475 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4988 - acc: 0.8141 - val_loss: 0.7464 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4977 - acc: 0.8156 - val_loss: 0.7327 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5034 - acc: 0.8130 - val_loss: 0.7383 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5088 - acc: 0.8101 - val_loss: 0.7754 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4976 - acc: 0.8170 - val_loss: 0.7422 - val_acc: 0.7568 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5102 - acc: 0.8085 - val_loss: 0.7599 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4982 - acc: 0.8123 - val_loss: 0.7516 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5095 - acc: 0.8099 - val_loss: 0.7545 - val_acc: 0.7198 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5039 - acc: 0.8125 - val_loss: 0.7324 - val_acc: 0.7568 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4947 - acc: 0.8158 - val_loss: 0.7468 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5063 - acc: 0.8110 - val_loss: 0.7520 - val_acc: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5026 - acc: 0.8174 - val_loss: 0.7486 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5126 - acc: 0.8178 - val_loss: 0.7405 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5001 - acc: 0.8099 - val_loss: 0.7404 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5056 - acc: 0.8101 - val_loss: 0.7383 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5049 - acc: 0.8125 - val_loss: 0.7510 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4985 - acc: 0.8150 - val_loss: 0.7761 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5006 - acc: 0.8107 - val_loss: 0.7573 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5021 - acc: 0.8130 - val_loss: 0.7491 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4985 - acc: 0.8201 - val_loss: 0.7643 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4948 - acc: 0.8127 - val_loss: 0.7540 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5028 - acc: 0.8167 - val_loss: 0.7441 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5004 - acc: 0.8118 - val_loss: 0.7378 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5057 - acc: 0.8110 - val_loss: 0.7363 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5016 - acc: 0.8170 - val_loss: 0.7352 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5069 - acc: 0.8125 - val_loss: 0.7393 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5046 - acc: 0.8074 - val_loss: 0.7357 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5079 - acc: 0.8110 - val_loss: 0.7720 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5121 - acc: 0.8087 - val_loss: 0.7459 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4963 - acc: 0.8189 - val_loss: 0.7374 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5009 - acc: 0.8161 - val_loss: 0.7421 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5014 - acc: 0.8079 - val_loss: 0.7425 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4979 - acc: 0.8152 - val_loss: 0.7880 - val_acc: 0.7101 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5001 - acc: 0.8101 - val_loss: 0.7284 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5022 - acc: 0.8145 - val_loss: 0.7353 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4992 - acc: 0.8125 - val_loss: 0.7480 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4999 - acc: 0.8178 - val_loss: 0.7618 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5028 - acc: 0.8123 - val_loss: 0.7468 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5001 - acc: 0.8101 - val_loss: 0.7457 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4945 - acc: 0.8147 - val_loss: 0.7305 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5050 - acc: 0.8166 - val_loss: 0.7292 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5093 - acc: 0.8076 - val_loss: 0.7490 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5029 - acc: 0.8121 - val_loss: 0.7408 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4983 - acc: 0.8121 - val_loss: 0.7610 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5058 - acc: 0.8105 - val_loss: 0.7489 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5077 - acc: 0.8099 - val_loss: 0.7489 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5040 - acc: 0.8170 - val_loss: 0.7378 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5081 - acc: 0.8072 - val_loss: 0.7684 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5040 - acc: 0.8143 - val_loss: 0.7296 - val_acc: 0.7549 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5011 - acc: 0.8183 - val_loss: 0.7526 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5020 - acc: 0.8107 - val_loss: 0.7358 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5031 - acc: 0.8145 - val_loss: 0.7437 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4970 - acc: 0.8163 - val_loss: 0.7335 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4898 - acc: 0.8150 - val_loss: 0.7532 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5048 - acc: 0.8132 - val_loss: 0.7576 - val_acc: 0.7198 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5057 - acc: 0.8092 - val_loss: 0.7648 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.5009 - acc: 0.8114 - val_loss: 0.7478 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4999 - acc: 0.8136 - val_loss: 0.7502 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4944 - acc: 0.8156 - val_loss: 0.7461 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4921 - acc: 0.8155 - val_loss: 0.7331 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5003 - acc: 0.8167 - val_loss: 0.7488 - val_acc: 0.7568 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4934 - acc: 0.8150 - val_loss: 0.7536 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4970 - acc: 0.8118 - val_loss: 0.7457 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5030 - acc: 0.8127 - val_loss: 0.7355 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5041 - acc: 0.8161 - val_loss: 0.7453 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4910 - acc: 0.8147 - val_loss: 0.7357 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4898 - acc: 0.8147 - val_loss: 0.7737 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4994 - acc: 0.8162 - val_loss: 0.7607 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5010 - acc: 0.8103 - val_loss: 0.7470 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4980 - acc: 0.8158 - val_loss: 0.7354 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4954 - acc: 0.8141 - val_loss: 0.7377 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4984 - acc: 0.8174 - val_loss: 0.7391 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4955 - acc: 0.8227 - val_loss: 0.7368 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4986 - acc: 0.8121 - val_loss: 0.7292 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5015 - acc: 0.8154 - val_loss: 0.7347 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5017 - acc: 0.8107 - val_loss: 0.7319 - val_acc: 0.7549 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5012 - acc: 0.8070 - val_loss: 0.7395 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4956 - acc: 0.8152 - val_loss: 0.7390 - val_acc: 0.7549 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4929 - acc: 0.8141 - val_loss: 0.7455 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4964 - acc: 0.8167 - val_loss: 0.7323 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4867 - acc: 0.8218 - val_loss: 0.7737 - val_acc: 0.7257 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4954 - acc: 0.8150 - val_loss: 0.7381 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5007 - acc: 0.8138 - val_loss: 0.7244 - val_acc: 0.7568 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4945 - acc: 0.8174 - val_loss: 0.7333 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5032 - acc: 0.8123 - val_loss: 0.7336 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4994 - acc: 0.8103 - val_loss: 0.7617 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5006 - acc: 0.8152 - val_loss: 0.7315 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4982 - acc: 0.8099 - val_loss: 0.7637 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4953 - acc: 0.8163 - val_loss: 0.7200 - val_acc: 0.7510 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5014 - acc: 0.8099 - val_loss: 0.7303 - val_acc: 0.7529 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4828 - acc: 0.8187 - val_loss: 0.7281 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4972 - acc: 0.8121 - val_loss: 0.7517 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4959 - acc: 0.8112 - val_loss: 0.7491 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5044 - acc: 0.8087 - val_loss: 0.7470 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4997 - acc: 0.8145 - val_loss: 0.7299 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5003 - acc: 0.8127 - val_loss: 0.7842 - val_acc: 0.7276 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4972 - acc: 0.8150 - val_loss: 0.7422 - val_acc: 0.7393 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5032 - acc: 0.8121 - val_loss: 0.7749 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4921 - acc: 0.8165 - val_loss: 0.7333 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4899 - acc: 0.8189 - val_loss: 0.7433 - val_acc: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4959 - acc: 0.8141 - val_loss: 0.7316 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4854 - acc: 0.8225 - val_loss: 0.7440 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4934 - acc: 0.8138 - val_loss: 0.7521 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5033 - acc: 0.8172 - val_loss: 0.7306 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5021 - acc: 0.8143 - val_loss: 0.7353 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.5063 - acc: 0.8096 - val_loss: 0.7490 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4992 - acc: 0.8136 - val_loss: 0.7708 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4940 - acc: 0.8165 - val_loss: 0.7537 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4955 - acc: 0.8165 - val_loss: 0.7679 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.4955 - acc: 0.8145 - val_loss: 0.7339 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5018 - acc: 0.8110 - val_loss: 0.7328 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4955 - acc: 0.8189 - val_loss: 0.7348 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.5040 - acc: 0.8107 - val_loss: 0.7379 - val_acc: 0.7471 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4936 - acc: 0.8121 - val_loss: 0.7437 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4970 - acc: 0.8094 - val_loss: 0.7424 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4983 - acc: 0.8134 - val_loss: 0.7663 - val_acc: 0.7296 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.4963 - acc: 0.8152 - val_loss: 0.7265 - val_acc: 0.7490 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.5036 - acc: 0.8114 - val_loss: 0.7336 - val_acc: 0.7451 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.4969 - acc: 0.8138 - val_loss: 0.7662 - val_acc: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5021 - acc: 0.8125 - val_loss: 0.7594 - val_acc: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.4945 - acc: 0.8178 - val_loss: 0.7419 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4976 - acc: 0.8154 - val_loss: 0.7446 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.4913 - acc: 0.8205 - val_loss: 0.7410 - val_acc: 0.7374 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5931 - acc: 0.7784\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6152 - acc: 0.7749\n",
            "epsilon: 0.003 and test evaluation : 0.6152113080024719, 0.7748690843582153\n",
            "SNR: 50.239319801330566\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6304 - acc: 0.7696\n",
            "epsilon: 0.005 and test evaluation : 0.6304458975791931, 0.7696335315704346\n",
            "SNR: 45.80202579498291\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6706 - acc: 0.7592\n",
            "epsilon: 0.01 and test evaluation : 0.670597493648529, 0.7591623067855835\n",
            "SNR: 39.78142976760864\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7613 - acc: 0.7225\n",
            "epsilon: 0.02 and test evaluation : 0.761305570602417, 0.7225130796432495\n",
            "SNR: 33.76082897186279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjkUsNKHq_L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_adv_df[\"acc_clean_mean\"]= np.sum(result_adv_df['acc_clean'])/10.0\n",
        "result_adv_df[\"acc_0.003_mean\"]= np.sum(result_adv_df['acc1'])/10.0\n",
        "result_adv_df[\"acc_0.005_mean\"]= np.sum(result_adv_df['acc2'])/10.0\n",
        "result_adv_df[\"acc_0.02_mean\"]= np.sum(result_adv_df['acc3'])/10.0\n",
        "result_adv_df[\"acc_0.01_mean\"]= np.sum(result_adv_df['acc4'])/10.0"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iYansuX0T5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6484f8bc-3281-4644-bd9c-8b9fe71998a1"
      },
      "source": [
        "result_adv_df.head(1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>loss4</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc_clean_mean</th>\n",
              "      <th>acc_0.003_mean</th>\n",
              "      <th>acc_0.005_mean</th>\n",
              "      <th>acc_0.02_mean</th>\n",
              "      <th>acc_0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.599231</td>\n",
              "      <td>0.78185</td>\n",
              "      <td>0.624757</td>\n",
              "      <td>0.774869</td>\n",
              "      <td>0.642587</td>\n",
              "      <td>0.767888</td>\n",
              "      <td>0.68996</td>\n",
              "      <td>0.74171</td>\n",
              "      <td>0.796137</td>\n",
              "      <td>0.701571</td>\n",
              "      <td>0.773647</td>\n",
              "      <td>0.765271</td>\n",
              "      <td>0.75986</td>\n",
              "      <td>0.742408</td>\n",
              "      <td>0.708202</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  ...  acc_0.02_mean  acc_0.01_mean\n",
              "0    0.599231    0.78185  ...       0.742408       0.708202\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}