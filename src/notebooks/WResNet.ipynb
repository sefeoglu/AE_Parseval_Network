{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 15 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5413012688141964809\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17328564749574858836\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sefika/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/sefika/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Wide Residual Network-16-2 created.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 68, 100, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 68, 100, 16)  144         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 68, 100, 16)  64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 68, 100, 16)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 68, 100, 32)  4608        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 68, 100, 32)  128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 68, 100, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 68, 100, 32)  9216        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 68, 100, 32)  512         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 68, 100, 32)  0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 68, 100, 32)  128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 68, 100, 32)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 68, 100, 32)  9216        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 68, 100, 32)  128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 68, 100, 32)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 68, 100, 32)  9216        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 68, 100, 32)  0           add_1[0][0]                      \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 68, 100, 32)  128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 68, 100, 32)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 34, 50, 64)   18432       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 34, 50, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 34, 50, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 34, 50, 64)   36864       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 34, 50, 64)   2048        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 34, 50, 64)   0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 34, 50, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 34, 50, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 34, 50, 64)   36864       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 34, 50, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 34, 50, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 34, 50, 64)   36864       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 34, 50, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 34, 50, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 34, 50, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 17, 25, 128)  73728       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 17, 25, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 17, 25, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 17, 25, 128)  147456      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 17, 25, 128)  8192        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 17, 25, 128)  0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 17, 25, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 17, 25, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 17, 25, 128)  147456      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 17, 25, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 17, 25, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 17, 25, 128)  147456      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 17, 25, 128)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 17, 25, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 17, 25, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 3, 128)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            3076        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 694,996\n",
      "Trainable params: 693,172\n",
      "Non-trainable params: 1,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "weight_decay = 0.0005\n",
    "\n",
    "def initial_conv(input):\n",
    "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(input)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def expand_conv(init, base, k, strides=(1, 1)):\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    m = Add()([x, skip])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def conv1_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv2_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    channel_axis = 1 if K.common.image_dim_ordering() == \"th\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv3_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    channel_axis = 1 if K.common.image_dim_ordering() == \"th\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
    "    \"\"\"\n",
    "    Creates a Wide Residual Network with specified parameters\n",
    "\n",
    "    :param input: Input Keras object\n",
    "    :param nb_classes: Number of output classes\n",
    "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
    "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
    "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
    "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
    "    :param k: Width of the network.\n",
    "    :param dropout: Adds dropout if value is greater than 0.0\n",
    "    :param verbose: Debug info to describe created WRN\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.common.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    ip = Input(shape=input_dim)\n",
    "\n",
    "    x = initial_conv(ip)\n",
    "    nb_conv = 4\n",
    "\n",
    "    x = expand_conv(x, 16, k)\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv1_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv2_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv3_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = AveragePooling2D((8, 8))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, x)\n",
    "\n",
    "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from keras.utils import plot_model\n",
    "    from keras.layers import Input\n",
    "    from keras.models import Model\n",
    "\n",
    "    init = (68, 100,1)\n",
    "\n",
    "    wrn_28_10 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.0)\n",
    "\n",
    "    wrn_28_10.summary()\n",
    "\n",
    "   # plot_model(wrn_28_10, \"WRN-16-2.png\", show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5722, 68, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data():\n",
    "    with open(\"data.pz\", 'rb') as file_:\n",
    "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
    "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
    "    return data\n",
    "data = read_data()\n",
    "new_data_X = []\n",
    "Y_data = []\n",
    "for row in data:\n",
    "    new_data_X.append(row['crop'])\n",
    "    Y_data.append(row['label'])\n",
    "new_data_X = np.array(new_data_X)\n",
    "new_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_data_X, Y_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# creating initial dataframe\n",
    "\n",
    "y_train_df = pd.DataFrame(y_train, columns=['Label'])\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "y_train_df['New'] = labelencoder.fit_transform(y_train_df['Label'])\n",
    "y_test_df = pd.DataFrame(y_test, columns=['Label'])\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "y_test_df['New'] = labelencoder.fit_transform(y_test_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.callbacks as callbacks\n",
    "import keras.utils.np_utils as kutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BS = 32\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = X_train[0].shape\n",
    "\n",
    "\n",
    "# transform data set\n",
    "if K.common.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling\n"
     ]
    }
   ],
   "source": [
    "wrn_28_10.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "print(\"Finished compiling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sefika/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 363s 3s/step - loss: 1.8061 - acc: 0.3781 - val_loss: 1.5124 - val_acc: 0.4150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f085294ded0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "wrn_28_10.fit_generator(aug.flow(X_train, to_categorical(y_train_df['New']), batch_size=BS),validation_data=(X_test, to_categorical(y_test_df['New'])), steps_per_epoch=len(X_train) // BS,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.utils.np_utils as kutils\n",
    "yPreds = wrn_28_10.predict(X_test)\n",
    "yPred = np.argmax(yPreds, axis=1)\n",
    "yPred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrue = y_test_df['New']\n",
    "yTrue[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.284011  , 0.04664745, 0.32750654, 0.341835  ],\n",
       "       [0.27181104, 0.3032167 , 0.22935522, 0.19561706],\n",
       "       [0.24150729, 0.27348816, 0.2735964 , 0.21140817],\n",
       "       ...,\n",
       "       [0.2385875 , 0.31058273, 0.24809915, 0.20273064],\n",
       "       [0.29675516, 0.10834967, 0.30923143, 0.2856638 ],\n",
       "       [0.2794652 , 0.09509656, 0.31984615, 0.30559194]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  41.503440974060354\n",
      "Error :  58.496559025939646\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "accuracy = metrics.accuracy_score(yTrue, yPred) * 100\n",
    "error = 100 - accuracy\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Error : \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
