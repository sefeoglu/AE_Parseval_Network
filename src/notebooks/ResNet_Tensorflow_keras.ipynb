{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v2 as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZYgCQ_-FkSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.compat.v2.keras.models import Model\n",
        "from tensorflow.compat.v2.keras.layers import  Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.compat.v2.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.compat.v2.keras.layers import BatchNormalization\n",
        "from tensorflow.compat.v2.keras.regularizers import  l2\n",
        "from tensorflow.compat.v2.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bt9111oHGs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initial_conv(input):\n",
        "  x = Convolution2D(16,(3,3),padding=\"same\", kernel_initializer='he_normal',\n",
        "                    kernel_regularizer=l2(weight_decay),use_bias=False)(input)\n",
        "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2-99bU_HGrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def expand_conv(init, base, k, strides = (1,1)):\n",
        "  x = Convolution2D(base * k, kernel_size=(3,3),padding= \"same\", strides=strides, kernel_initializer=\"he_normal\", kernel_regularizer=l2(weight_decay),\n",
        "                    use_bias=False)(init)\n",
        "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon= 1e-5, gamma_initializer= 'uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  x = Convolution2D(base * k, kernel_size=(3,3), padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(weight_decay),\n",
        "                    use_bias = False)(x)\n",
        "  skip = Convolution2D(base * k, kernel_size=(1,1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                       kernel_regularizer=l2(weight_decay),\n",
        "                       use_bias = False)(init)\n",
        "  m = Add()([x, skip])\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8-3eRVvL3dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv1_block(input, k=1, dropout = 0.0):\n",
        "  init = input\n",
        "  \n",
        "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Convolution2D(16 * k, kernel_size=(3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                    use_bias=False)(x)\n",
        "  if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Convolution2D(16 * k, kernel_size=(3,3), padding='same', kernel_initializer='he_normal',kernel_regularizer=l2(weight_decay),\n",
        "                    use_bias = False)(x)\n",
        "  m = Add()([init, x])\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8Qzpd9HVBXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def  conv2_block(input, k=1, dropout = 0.0):\n",
        "  init = input\n",
        "\n",
        "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Convolution2D(32 * k, kernel_size=(3,3), padding='same', kernel_initializer='he_normal',\n",
        "                    kernel_regularizer = l2(weight_decay), use_bias = False)(x)\n",
        "  \n",
        "  if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Convolution2D(32*k, kernel_size=(3,3), padding='same', kernel_initializer='he_normal',\n",
        "                    kernel_regularizer= l2(weight_decay),\n",
        "                    use_bias = False)(x)\n",
        "  \n",
        "  m = Add()([init, x])\n",
        "  return m\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xydZpkBAYi1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "  init = input\n",
        "\n",
        "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "  x = BatchNormalization(axis=channel_axis, momentum= 0.1, epsilon = 1e-5, gamma_initializer='uniform' )(input)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Convolution2D(64 * k, kernel_size=(3,3), padding='same', kernel_initializer='he_normal',\n",
        "                    kernel_regularizer= l2(weight_decay),\n",
        "                    use_bias = False)(x)\n",
        "  \n",
        "  if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Convolution2D(64 * k, kernel_size=(3,3), padding='same', kernel_initializer='he_normal',\n",
        "                    kernel_regularizer=l2(weight_decay),\n",
        "                    use_bias=False)(x)\n",
        "  m = Add()([init, x])\n",
        "  return m\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_wide_residual_network(input_dim, nb_classes=4, N=2, k=2, dropout = 0.0, verbose=1):\n",
        "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "  ip = Input(shape=input_dim)\n",
        "\n",
        "  x = initial_conv(ip)\n",
        "  nb_conv = 4\n",
        "  x = expand_conv(x, 16, k)\n",
        "  nb_conv +=2\n",
        "\n",
        "  for i in range(N-1):\n",
        "    x = conv1_block(x, k, dropout)\n",
        "    nb_conv +=2\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  x = expand_conv(x, 32, k, strides=(1, 1))\n",
        "  nb_conv += 2\n",
        "  for i in range(N - 1):\n",
        "    x = conv2_block(x, k, dropout)\n",
        "    nb_conv += 2\n",
        "  \n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  \n",
        "  x = expand_conv(x, 64, k, strides=(1, 1))\n",
        "  nb_conv += 2\n",
        "  \n",
        "  for i in range(N - 1):\n",
        "    x = conv3_block(x, k, dropout)\n",
        "    nb_conv += 2\n",
        "    \n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  \n",
        "  x = AveragePooling2D((8, 8))(x)\n",
        "  x = Flatten()(x)\n",
        "  \n",
        "  x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "  \n",
        "  model = Model(ip, x)\n",
        "  \n",
        "  if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bjIRpiBcPSR",
        "colab_type": "code",
        "outputId": "10f7cfe5-44fc-4681-b7c9-25bedf3d11a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from tensorflow.compat.v2.keras.layers import Input\n",
        "    from tensorflow.compat.v2.keras.models import Model\n",
        "\n",
        "    init = (32, 32,1)\n",
        "    wrn16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout = 0.0)\n",
        "    wrn16_2.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wide Residual Network-16-2 created.\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 32, 32, 16)   144         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 32, 32, 16)   64          conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 32, 32, 16)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 32, 32, 32)   4608        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 32, 32, 32)   128         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 32, 32, 32)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 32, 32, 32)   9216        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 32, 32, 32)   512         activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 32, 32, 32)   0           conv2d_82[0][0]                  \n",
            "                                                                 conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 32, 32, 32)   128         add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 32, 32, 32)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 32, 32, 32)   9216        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 32, 32, 32)   128         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 32, 32, 32)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 32)   9216        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 32, 32, 32)   0           add_30[0][0]                     \n",
            "                                                                 conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 32, 32, 32)   128         add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 32, 32, 32)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 64)   18432       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 32, 32, 64)   256         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 32, 32, 64)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 64)   36864       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 64)   2048        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 32, 32, 64)   0           conv2d_87[0][0]                  \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 32, 32, 64)   256         add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 32, 32, 64)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 64)   36864       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 32, 32, 64)   256         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 32, 32, 64)   0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 32, 32, 64)   36864       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 32, 32, 64)   0           add_32[0][0]                     \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 32, 32, 64)   256         add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 32, 32, 64)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 32, 32, 128)  73728       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 32, 32, 128)  512         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 32, 32, 128)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 32, 32, 128)  147456      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 32, 32, 128)  8192        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 32, 32, 128)  0           conv2d_92[0][0]                  \n",
            "                                                                 conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 32, 32, 128)  512         add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 32, 32, 128)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 32, 32, 128)  147456      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 32, 32, 128)  512         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 32, 32, 128)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 32, 32, 128)  147456      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 32, 32, 128)  0           add_34[0][0]                     \n",
            "                                                                 conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 32, 32, 128)  512         add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 32, 32, 128)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 4, 4, 128)    0           activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 2048)         0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4)            8196        flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 700,116\n",
            "Trainable params: 698,292\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS19DfEuH_Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage.util, skimage.transform\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def crop(image: np.ndarray, maxshape):\n",
        "    d = [max(0, image.shape[i] - maxshape[i]) for i in [0, 1]]\n",
        "    if (np.sum(d) == 0):\n",
        "        return image\n",
        "    return image[(d[0] + 1) // 2:image.shape[0] - (d[0] // 2), (d[1] + 1) // 2:\n",
        "                 image.shape[1] - (d[1] // 2)]\n",
        "\n",
        "\n",
        "def pad(image: np.ndarray, padding: int):\n",
        "    pad_width = [[padding] * 2] * 2\n",
        "    if len(image.shape) == 3: pad_width.append((0, 0))\n",
        "    return np.pad(image, pad_width, mode='constant')\n",
        "\n",
        "\n",
        "def pad_to_shape(image: np.ndarray, shape):\n",
        "    d = [shape[i] - image.shape[i] for i in [0, 1]]\n",
        "    pad_width = [((d[0] + 1) // 2, d[0] // 2), ((d[1] + 1) // 2, d[1] // 2)]\n",
        "    if len(image.shape) == 3: pad_width.append((0, 0))\n",
        "    return np.pad(image, pad_width, mode='constant')\n",
        "\n",
        "\n",
        "def adjust_shape(image: np.ndarray, shape):\n",
        "    return pad_to_shape(crop(image, shape), shape)\n",
        "\n",
        "\n",
        "def resize(image: np.ndarray, shape):\n",
        "    return skimage.transform.resize(image, shape, anti_aliasing=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOWFA7tXIDQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def random_crop(im, shape):\n",
        "    d = [im.shape[i] - shape[i] + 1 for i in [0, 1]]\n",
        "    d = list(map(np.random.randint, d))\n",
        "    return im[d[0]:d[0] + shape[0], d[1]:d[1] + shape[1]]\n",
        "\n",
        "\n",
        "def augment_cifar(im):\n",
        "    im = pad(im, 4)\n",
        "    im = random_crop(im, [32,32])\n",
        "    if np.random.rand() > .5:\n",
        "        im = np.fliplr(im)\n",
        "    return im\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "outputId": "6f9adb0f-5813-4723-d1f5-5062b17c719b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(row['crop'])\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "outputId": "14e37fc9-22c9-45ca-8747-ca6ab25b23f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X[0].shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv-A3B72JXDE",
        "colab_type": "code",
        "outputId": "e9c54cc5-8478-4fac-89a0-473b2e2babe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = list(map(augment_cifar, X))\n",
        "X = np.array(X)\n",
        "X.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Z7UDOByArq",
        "colab_type": "code",
        "outputId": "e7f32fe1-c96e-4df3-9313-efb7670a6649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hwq9R2jruF",
        "colab_type": "code",
        "outputId": "2245dd5b-f1c2-4b0e-fb53-02f1002d733e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open             1500\n",
              "closed           1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAYuiEzj4Bp",
        "colab_type": "code",
        "outputId": "471ea5be-b0de-485b-a998-9b7217eca113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v2.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v2.keras.optimizers import SGD\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUHIVZnNwLL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "outputId": "892e9877-b86d-484d-eddb-da732b30409e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HA8PdUYwhsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v2.keras.utils import to_categorical\n",
        "from tensorflow.compat.v2.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 60:\n",
        "        return 0.1\n",
        "    elif epoch < 120:\n",
        "        return 0.02\n",
        "    elif epoch < 160:\n",
        "        return 0.004\n",
        "    else:\n",
        "        return 0.0008\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "generator = tensorflow.compat.v2.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxj3cWeUR1VA",
        "colab_type": "code",
        "outputId": "069da484-a32c-4415-fa35-5edb1401527f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=2, random_state=42, shuffle=False)\n",
        "hist_list = []\n",
        "train_set= []\n",
        "test_set = []\n",
        "for train_index, test_index in cv.split(X):\n",
        "    print(\"Train Index: \", train_index, \"\\n\")\n",
        "    print(\"Test Index: \", test_index)\n",
        "    train_set.append(train_index)\n",
        "    test_set.append(test_index)\n",
        "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y_cat[train_index], y_cat[test_index]\n",
        "    hist = wrn16_2.fit_generator(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks=[lr_scheduler],\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   validation_steps=X_test.shape[0] // BS,)\n",
        "    hist_list.append(hist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Index:  [2861 2862 2863 ... 5719 5720 5721] \n",
            "\n",
            "Test Index:  [   0    1    2 ... 2858 2859 2860]\n",
            "WARNING:tensorflow:From <ipython-input-69-ba5a3465a143>:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/200\n",
            "22/22 [==============================] - 9s 401ms/step - loss: 2.4788 - acc: 0.3132 - val_loss: 2.7075 - val_acc: 0.2478 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 2.3858 - acc: 0.3465 - val_loss: 2.3950 - val_acc: 0.3387 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.3268 - acc: 0.3417 - val_loss: 2.3503 - val_acc: 0.3443 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.2811 - acc: 0.3597 - val_loss: 2.2910 - val_acc: 0.3502 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 2.2260 - acc: 0.3659 - val_loss: 2.2878 - val_acc: 0.3279 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 2.2028 - acc: 0.3674 - val_loss: 2.1918 - val_acc: 0.3656 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.1469 - acc: 0.3659 - val_loss: 2.1597 - val_acc: 0.3810 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 2.0955 - acc: 0.3816 - val_loss: 2.1292 - val_acc: 0.3548 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 2.0567 - acc: 0.3955 - val_loss: 2.1040 - val_acc: 0.3516 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.0275 - acc: 0.3721 - val_loss: 2.0683 - val_acc: 0.3467 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.9764 - acc: 0.4036 - val_loss: 2.0801 - val_acc: 0.3457 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.9568 - acc: 0.3889 - val_loss: 1.9952 - val_acc: 0.3569 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "22/22 [==============================] - 7s 309ms/step - loss: 1.9258 - acc: 0.3970 - val_loss: 1.9644 - val_acc: 0.3586 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.8951 - acc: 0.3875 - val_loss: 2.0590 - val_acc: 0.3300 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.8551 - acc: 0.4047 - val_loss: 1.9879 - val_acc: 0.3418 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.8252 - acc: 0.4058 - val_loss: 1.9573 - val_acc: 0.3618 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.8071 - acc: 0.4043 - val_loss: 1.9235 - val_acc: 0.3681 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.7836 - acc: 0.4036 - val_loss: 1.8828 - val_acc: 0.3740 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 1.7541 - acc: 0.4179 - val_loss: 1.8604 - val_acc: 0.3667 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.7301 - acc: 0.4069 - val_loss: 1.9214 - val_acc: 0.3593 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6994 - acc: 0.4204 - val_loss: 1.8401 - val_acc: 0.3726 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.6771 - acc: 0.4135 - val_loss: 1.9544 - val_acc: 0.3460 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6564 - acc: 0.4182 - val_loss: 1.9034 - val_acc: 0.3537 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6433 - acc: 0.4135 - val_loss: 1.8535 - val_acc: 0.3481 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6161 - acc: 0.4277 - val_loss: 1.8656 - val_acc: 0.3677 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6032 - acc: 0.4292 - val_loss: 1.8052 - val_acc: 0.3387 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 1.5789 - acc: 0.4318 - val_loss: 1.7920 - val_acc: 0.3432 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5710 - acc: 0.4292 - val_loss: 1.7435 - val_acc: 0.3715 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5588 - acc: 0.4321 - val_loss: 1.7470 - val_acc: 0.3544 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5520 - acc: 0.4321 - val_loss: 1.6627 - val_acc: 0.3841 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 1.5244 - acc: 0.4277 - val_loss: 1.7082 - val_acc: 0.3635 - lr: 0.1000\n",
            "Epoch 32/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5116 - acc: 0.4175 - val_loss: 1.7169 - val_acc: 0.3593 - lr: 0.1000\n",
            "Epoch 33/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.4929 - acc: 0.4380 - val_loss: 1.6734 - val_acc: 0.3674 - lr: 0.1000\n",
            "Epoch 34/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4728 - acc: 0.4544 - val_loss: 1.6696 - val_acc: 0.3768 - lr: 0.1000\n",
            "Epoch 35/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4518 - acc: 0.4541 - val_loss: 1.6507 - val_acc: 0.3604 - lr: 0.1000\n",
            "Epoch 36/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4538 - acc: 0.4398 - val_loss: 1.7176 - val_acc: 0.3743 - lr: 0.1000\n",
            "Epoch 37/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.4501 - acc: 0.4383 - val_loss: 1.7382 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 38/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.4470 - acc: 0.4416 - val_loss: 1.5945 - val_acc: 0.3688 - lr: 0.1000\n",
            "Epoch 39/200\n",
            "22/22 [==============================] - 7s 311ms/step - loss: 1.4241 - acc: 0.4418 - val_loss: 1.6168 - val_acc: 0.3775 - lr: 0.1000\n",
            "Epoch 40/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4051 - acc: 0.4475 - val_loss: 1.6400 - val_acc: 0.3551 - lr: 0.1000\n",
            "Epoch 41/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4039 - acc: 0.4523 - val_loss: 1.6152 - val_acc: 0.3799 - lr: 0.1000\n",
            "Epoch 42/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3928 - acc: 0.4457 - val_loss: 1.5882 - val_acc: 0.3729 - lr: 0.1000\n",
            "Epoch 43/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3902 - acc: 0.4416 - val_loss: 1.5187 - val_acc: 0.3974 - lr: 0.1000\n",
            "Epoch 44/200\n",
            "22/22 [==============================] - 7s 310ms/step - loss: 1.3931 - acc: 0.4340 - val_loss: 1.6927 - val_acc: 0.3681 - lr: 0.1000\n",
            "Epoch 45/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3704 - acc: 0.4376 - val_loss: 1.5919 - val_acc: 0.3915 - lr: 0.1000\n",
            "Epoch 46/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3659 - acc: 0.4493 - val_loss: 1.6132 - val_acc: 0.3397 - lr: 0.1000\n",
            "Epoch 47/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3638 - acc: 0.4490 - val_loss: 1.6146 - val_acc: 0.3614 - lr: 0.1000\n",
            "Epoch 48/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3637 - acc: 0.4574 - val_loss: 1.5896 - val_acc: 0.3660 - lr: 0.1000\n",
            "Epoch 49/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3428 - acc: 0.4544 - val_loss: 1.6446 - val_acc: 0.3492 - lr: 0.1000\n",
            "Epoch 50/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3286 - acc: 0.4530 - val_loss: 1.5885 - val_acc: 0.3614 - lr: 0.1000\n",
            "Epoch 51/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3328 - acc: 0.4526 - val_loss: 1.7250 - val_acc: 0.3328 - lr: 0.1000\n",
            "Epoch 52/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3193 - acc: 0.4464 - val_loss: 1.5198 - val_acc: 0.3820 - lr: 0.1000\n",
            "Epoch 53/200\n",
            "22/22 [==============================] - 7s 309ms/step - loss: 1.3217 - acc: 0.4705 - val_loss: 1.5211 - val_acc: 0.3764 - lr: 0.1000\n",
            "Epoch 54/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3056 - acc: 0.4673 - val_loss: 1.5446 - val_acc: 0.3719 - lr: 0.1000\n",
            "Epoch 55/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.2866 - acc: 0.4877 - val_loss: 1.6259 - val_acc: 0.3911 - lr: 0.1000\n",
            "Epoch 56/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3093 - acc: 0.4614 - val_loss: 1.6239 - val_acc: 0.3796 - lr: 0.1000\n",
            "Epoch 57/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.2938 - acc: 0.4523 - val_loss: 1.4958 - val_acc: 0.3831 - lr: 0.1000\n",
            "Epoch 58/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3157 - acc: 0.4435 - val_loss: 1.5481 - val_acc: 0.3736 - lr: 0.1000\n",
            "Epoch 59/200\n",
            "22/22 [==============================] - 7s 305ms/step - loss: 1.2963 - acc: 0.4555 - val_loss: 1.5020 - val_acc: 0.3967 - lr: 0.1000\n",
            "Epoch 60/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.2671 - acc: 0.4746 - val_loss: 1.5300 - val_acc: 0.3778 - lr: 0.1000\n",
            "Epoch 61/200\n",
            "22/22 [==============================] - 7s 309ms/step - loss: 1.2939 - acc: 0.4490 - val_loss: 1.4786 - val_acc: 0.3607 - lr: 0.0200\n",
            "Epoch 62/200\n",
            " 4/22 [====>.........................] - ETA: 3s - loss: 1.2764 - acc: 0.4316"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "outputId": "dd83de1b-f1f9-431c-ee98-33f0aaf1a93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f412da3b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5f0f105-5478-4be1-de1d-37b628f5fdec"
      },
      "source": [
        "\n",
        "hist = wrn16_2.fit(X, y_cat, \n",
        "                        batch_size=BS, epochs=EPOCHS, verbose=2,\n",
        "                        validation_split = 0.25,\n",
        "                         shuffle=False, callbacks=[lr_scheduler])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "34/34 - 11s - loss: 2.4929 - acc: 0.2785 - val_loss: 2.3528 - val_acc: 0.3564 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "34/34 - 9s - loss: 2.4116 - acc: 0.3151 - val_loss: 2.2979 - val_acc: 0.3711 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "34/34 - 9s - loss: 2.3323 - acc: 0.3258 - val_loss: 2.2254 - val_acc: 0.4046 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "34/34 - 9s - loss: 2.2581 - acc: 0.3328 - val_loss: 2.1402 - val_acc: 0.4018 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "34/34 - 9s - loss: 2.1919 - acc: 0.3421 - val_loss: 2.1109 - val_acc: 0.3620 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "34/34 - 9s - loss: 2.1393 - acc: 0.3454 - val_loss: 2.0700 - val_acc: 0.3690 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "34/34 - 9s - loss: 2.0807 - acc: 0.3444 - val_loss: 2.0119 - val_acc: 0.3788 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "34/34 - 9s - loss: 2.0259 - acc: 0.3482 - val_loss: 2.0175 - val_acc: 0.3620 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "34/34 - 9s - loss: 1.9720 - acc: 0.3626 - val_loss: 1.9526 - val_acc: 0.3906 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "34/34 - 9s - loss: 1.9238 - acc: 0.3626 - val_loss: 1.9000 - val_acc: 0.3850 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "34/34 - 9s - loss: 1.8812 - acc: 0.3668 - val_loss: 1.8779 - val_acc: 0.3809 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "34/34 - 9s - loss: 1.8446 - acc: 0.3633 - val_loss: 1.8518 - val_acc: 0.3634 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "34/34 - 9s - loss: 1.8011 - acc: 0.3824 - val_loss: 1.8263 - val_acc: 0.3732 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "34/34 - 9s - loss: 1.7732 - acc: 0.3796 - val_loss: 1.7935 - val_acc: 0.3746 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "34/34 - 9s - loss: 1.7292 - acc: 0.3915 - val_loss: 1.8034 - val_acc: 0.3557 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "34/34 - 9s - loss: 1.6896 - acc: 0.4039 - val_loss: 1.7615 - val_acc: 0.3648 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "34/34 - 9s - loss: 1.6609 - acc: 0.4095 - val_loss: 1.6963 - val_acc: 0.3920 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "34/34 - 9s - loss: 1.6269 - acc: 0.4127 - val_loss: 1.6724 - val_acc: 0.3983 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "34/34 - 9s - loss: 1.5954 - acc: 0.4195 - val_loss: 1.6903 - val_acc: 0.3885 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "34/34 - 9s - loss: 1.5754 - acc: 0.4188 - val_loss: 1.6422 - val_acc: 0.3983 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "34/34 - 9s - loss: 1.5501 - acc: 0.4314 - val_loss: 1.6387 - val_acc: 0.3739 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "34/34 - 9s - loss: 1.5231 - acc: 0.4274 - val_loss: 1.6711 - val_acc: 0.3850 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "34/34 - 9s - loss: 1.4899 - acc: 0.4451 - val_loss: 1.7839 - val_acc: 0.3529 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "34/34 - 9s - loss: 1.4646 - acc: 0.4554 - val_loss: 1.6870 - val_acc: 0.3627 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "34/34 - 9s - loss: 1.4515 - acc: 0.4535 - val_loss: 1.6677 - val_acc: 0.3850 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "34/34 - 9s - loss: 1.4340 - acc: 0.4619 - val_loss: 1.6932 - val_acc: 0.3781 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "34/34 - 9s - loss: 1.4399 - acc: 0.4498 - val_loss: 1.6099 - val_acc: 0.3676 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "34/34 - 9s - loss: 1.4203 - acc: 0.4579 - val_loss: 1.5696 - val_acc: 0.3955 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "34/34 - 9s - loss: 1.3906 - acc: 0.4735 - val_loss: 1.6064 - val_acc: 0.3948 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "34/34 - 9s - loss: 1.3700 - acc: 0.4815 - val_loss: 1.5999 - val_acc: 0.4102 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "34/34 - 9s - loss: 1.3598 - acc: 0.4796 - val_loss: 1.7442 - val_acc: 0.3599 - lr: 0.1000\n",
            "Epoch 32/200\n",
            "34/34 - 9s - loss: 1.3513 - acc: 0.4829 - val_loss: 1.6574 - val_acc: 0.3795 - lr: 0.1000\n",
            "Epoch 33/200\n",
            "34/34 - 9s - loss: 1.3546 - acc: 0.4927 - val_loss: 1.8156 - val_acc: 0.3823 - lr: 0.1000\n",
            "Epoch 34/200\n",
            "34/34 - 9s - loss: 1.3194 - acc: 0.5062 - val_loss: 1.8098 - val_acc: 0.3871 - lr: 0.1000\n",
            "Epoch 35/200\n",
            "34/34 - 9s - loss: 1.3079 - acc: 0.5167 - val_loss: 1.8743 - val_acc: 0.3557 - lr: 0.1000\n",
            "Epoch 36/200\n",
            "34/34 - 9s - loss: 1.3158 - acc: 0.4957 - val_loss: 2.1998 - val_acc: 0.3592 - lr: 0.1000\n",
            "Epoch 37/200\n",
            "34/34 - 9s - loss: 1.3373 - acc: 0.4873 - val_loss: 2.1710 - val_acc: 0.3438 - lr: 0.1000\n",
            "Epoch 38/200\n",
            "34/34 - 9s - loss: 1.3153 - acc: 0.5092 - val_loss: 1.9089 - val_acc: 0.3781 - lr: 0.1000\n",
            "Epoch 39/200\n",
            "34/34 - 9s - loss: 1.2577 - acc: 0.5281 - val_loss: 2.0522 - val_acc: 0.3613 - lr: 0.1000\n",
            "Epoch 40/200\n",
            "34/34 - 9s - loss: 1.2554 - acc: 0.5390 - val_loss: 2.2962 - val_acc: 0.3501 - lr: 0.1000\n",
            "Epoch 41/200\n",
            "34/34 - 9s - loss: 1.2234 - acc: 0.5542 - val_loss: 2.2297 - val_acc: 0.3536 - lr: 0.1000\n",
            "Epoch 42/200\n",
            "34/34 - 9s - loss: 1.2873 - acc: 0.5255 - val_loss: 2.2006 - val_acc: 0.3284 - lr: 0.1000\n",
            "Epoch 43/200\n",
            "34/34 - 9s - loss: 1.2802 - acc: 0.5260 - val_loss: 2.0955 - val_acc: 0.3270 - lr: 0.1000\n",
            "Epoch 44/200\n",
            "34/34 - 9s - loss: 1.2037 - acc: 0.5647 - val_loss: 2.3887 - val_acc: 0.3424 - lr: 0.1000\n",
            "Epoch 45/200\n",
            "34/34 - 9s - loss: 1.1581 - acc: 0.5847 - val_loss: 2.8890 - val_acc: 0.3522 - lr: 0.1000\n",
            "Epoch 46/200\n",
            "34/34 - 9s - loss: 1.1938 - acc: 0.5768 - val_loss: 2.6240 - val_acc: 0.3578 - lr: 0.1000\n",
            "Epoch 47/200\n",
            "34/34 - 9s - loss: 1.2431 - acc: 0.5549 - val_loss: 2.2199 - val_acc: 0.3326 - lr: 0.1000\n",
            "Epoch 48/200\n",
            "34/34 - 9s - loss: 1.2502 - acc: 0.5528 - val_loss: 2.1575 - val_acc: 0.3473 - lr: 0.1000\n",
            "Epoch 49/200\n",
            "34/34 - 9s - loss: 1.1950 - acc: 0.5814 - val_loss: 2.4043 - val_acc: 0.3627 - lr: 0.1000\n",
            "Epoch 50/200\n",
            "34/34 - 9s - loss: 1.1829 - acc: 0.5954 - val_loss: 2.2952 - val_acc: 0.3725 - lr: 0.1000\n",
            "Epoch 51/200\n",
            "34/34 - 9s - loss: 1.1412 - acc: 0.6236 - val_loss: 2.4089 - val_acc: 0.3396 - lr: 0.1000\n",
            "Epoch 52/200\n",
            "34/34 - 9s - loss: 1.2101 - acc: 0.5917 - val_loss: 2.8009 - val_acc: 0.3361 - lr: 0.1000\n",
            "Epoch 53/200\n",
            "34/34 - 9s - loss: 1.2754 - acc: 0.5668 - val_loss: 2.7143 - val_acc: 0.3333 - lr: 0.1000\n",
            "Epoch 54/200\n",
            "34/34 - 9s - loss: 1.2754 - acc: 0.5696 - val_loss: 2.2853 - val_acc: 0.3410 - lr: 0.1000\n",
            "Epoch 55/200\n",
            "34/34 - 9s - loss: 1.2862 - acc: 0.5570 - val_loss: 2.2693 - val_acc: 0.3368 - lr: 0.1000\n",
            "Epoch 56/200\n",
            "34/34 - 9s - loss: 1.2224 - acc: 0.5931 - val_loss: 2.5005 - val_acc: 0.3368 - lr: 0.1000\n",
            "Epoch 57/200\n",
            "34/34 - 9s - loss: 1.2369 - acc: 0.5873 - val_loss: 2.3806 - val_acc: 0.3459 - lr: 0.1000\n",
            "Epoch 58/200\n",
            "34/34 - 9s - loss: 1.2171 - acc: 0.6015 - val_loss: 2.3220 - val_acc: 0.3494 - lr: 0.1000\n",
            "Epoch 59/200\n",
            "34/34 - 9s - loss: 1.2083 - acc: 0.6094 - val_loss: 2.4929 - val_acc: 0.3599 - lr: 0.1000\n",
            "Epoch 60/200\n",
            "34/34 - 9s - loss: 1.1740 - acc: 0.6239 - val_loss: 2.8974 - val_acc: 0.3305 - lr: 0.1000\n",
            "Epoch 61/200\n",
            "34/34 - 9s - loss: 1.3468 - acc: 0.5560 - val_loss: 2.3999 - val_acc: 0.3466 - lr: 0.0200\n",
            "Epoch 62/200\n",
            "34/34 - 9s - loss: 1.0432 - acc: 0.7061 - val_loss: 2.4387 - val_acc: 0.3634 - lr: 0.0200\n",
            "Epoch 63/200\n",
            "34/34 - 9s - loss: 0.9154 - acc: 0.7649 - val_loss: 2.5163 - val_acc: 0.3571 - lr: 0.0200\n",
            "Epoch 64/200\n",
            "34/34 - 9s - loss: 0.8276 - acc: 0.8094 - val_loss: 2.6064 - val_acc: 0.3634 - lr: 0.0200\n",
            "Epoch 65/200\n",
            "34/34 - 9s - loss: 0.7588 - acc: 0.8415 - val_loss: 2.6834 - val_acc: 0.3592 - lr: 0.0200\n",
            "Epoch 66/200\n",
            "34/34 - 9s - loss: 0.6974 - acc: 0.8690 - val_loss: 2.7613 - val_acc: 0.3578 - lr: 0.0200\n",
            "Epoch 67/200\n",
            "34/34 - 9s - loss: 0.6393 - acc: 0.8965 - val_loss: 2.8358 - val_acc: 0.3564 - lr: 0.0200\n",
            "Epoch 68/200\n",
            "34/34 - 9s - loss: 0.5843 - acc: 0.9196 - val_loss: 2.9134 - val_acc: 0.3550 - lr: 0.0200\n",
            "Epoch 69/200\n",
            "34/34 - 9s - loss: 0.5330 - acc: 0.9399 - val_loss: 2.9828 - val_acc: 0.3627 - lr: 0.0200\n",
            "Epoch 70/200\n",
            "34/34 - 9s - loss: 0.4854 - acc: 0.9599 - val_loss: 3.0549 - val_acc: 0.3592 - lr: 0.0200\n",
            "Epoch 71/200\n",
            "34/34 - 9s - loss: 0.4431 - acc: 0.9734 - val_loss: 3.1390 - val_acc: 0.3613 - lr: 0.0200\n",
            "Epoch 72/200\n",
            "34/34 - 9s - loss: 0.4064 - acc: 0.9821 - val_loss: 3.2294 - val_acc: 0.3606 - lr: 0.0200\n",
            "Epoch 73/200\n",
            "34/34 - 9s - loss: 0.3746 - acc: 0.9897 - val_loss: 3.3256 - val_acc: 0.3592 - lr: 0.0200\n",
            "Epoch 74/200\n",
            "34/34 - 9s - loss: 0.3499 - acc: 0.9935 - val_loss: 3.4413 - val_acc: 0.3585 - lr: 0.0200\n",
            "Epoch 75/200\n",
            "34/34 - 9s - loss: 0.3306 - acc: 0.9970 - val_loss: 3.5418 - val_acc: 0.3669 - lr: 0.0200\n",
            "Epoch 76/200\n",
            "34/34 - 9s - loss: 0.3231 - acc: 0.9970 - val_loss: 3.6164 - val_acc: 0.3606 - lr: 0.0200\n",
            "Epoch 77/200\n",
            "34/34 - 9s - loss: 0.3100 - acc: 0.9981 - val_loss: 3.6569 - val_acc: 0.3557 - lr: 0.0200\n",
            "Epoch 78/200\n",
            "34/34 - 9s - loss: 0.2983 - acc: 0.9984 - val_loss: 3.6864 - val_acc: 0.3627 - lr: 0.0200\n",
            "Epoch 79/200\n",
            "34/34 - 9s - loss: 0.2899 - acc: 0.9988 - val_loss: 3.7104 - val_acc: 0.3683 - lr: 0.0200\n",
            "Epoch 80/200\n",
            "34/34 - 9s - loss: 0.2836 - acc: 0.9984 - val_loss: 3.7759 - val_acc: 0.3641 - lr: 0.0200\n",
            "Epoch 81/200\n",
            "34/34 - 9s - loss: 0.2740 - acc: 0.9993 - val_loss: 3.7783 - val_acc: 0.3599 - lr: 0.0200\n",
            "Epoch 82/200\n",
            "34/34 - 9s - loss: 0.2669 - acc: 0.9991 - val_loss: 3.7613 - val_acc: 0.3592 - lr: 0.0200\n",
            "Epoch 83/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-703110824b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                          shuffle=False, callbacks=[lr_scheduler])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7UNUagAV373",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" New model\"\"\"\n",
        "\n",
        "EPOCHS_120 = 120\n",
        "wrn16_4 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout = 0.0, verbose=1)\n",
        "  \n",
        "hist2 = wrn16_4.fit(X_train, y_train_cat, \n",
        "                        batch_size=BS, epochs=EPOCHS, verbose=1,\n",
        "                        validation_data=(X_test,y_test_cat), shuffle=True, callbacks=[lr_scheduler])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdrFWGzfV35Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUmbja_jwwnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hist = wrn28_10.fit(X_train, to_categorical(y_train_df['New']), validation_split=0.33, epochs=EPOCHS, batch_size=BS, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4SrDGNyOAB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNyErPGJOFml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_1 = wrn28_10.fit_generator(aug.flow(X_train, y_train, batch_size=BS),validation_data=(X_test, y_test),callbacks =[lr_scheduler],verbose=1, epochs=EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn28_10.save(\"model_last.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Paxp_UhrduV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = X_train[8]\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO-_q-QUsn-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIs_x5kasn9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(wrn28_10(image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFw-Cjamdsi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnGwju3tsP6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(image):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = tf.image.resize(image, (68, 100))\n",
        "  image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "  image = image[None, ...]\n",
        "  return image\n",
        "\n",
        "# Helper function to extract labels from probability vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIB3X0K0sK9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "image = tf.convert_to_tensor(img)\n",
        "image = preprocess(image)\n",
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7SaMPbmsZdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = wrn28_10.predict(image,batch_size=None,steps=1)\n",
        "\n",
        "label = tf.one_hot(2, probs.shape[-1])\n",
        "label = tf.reshape(label, (1, probs.shape[-1]))\n",
        "label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUX_CF5CsZbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHgf-nCnvvBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn28_10(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_tkKMXgv2X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist_1\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}