{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqbIFJTwXLH",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "outputId": "6470cf29-0c3c-4951-f9a5-911d6fdf23d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "    wrn_16_2.summary()\n",
        "\n"
      ],
      "execution_count": 716,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n",
            "Model: \"model_56\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_33 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 32, 32, 16)   144         input_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 32, 32, 16)   64          conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 32, 32, 16)   0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 32, 32, 32)   4608        activation_416[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 32, 32, 32)   128         conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 32, 32, 32)   0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 32, 32, 32)   9216        activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 32, 32, 32)   512         activation_416[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_192 (Add)                   (None, 32, 32, 32)   0           conv2d_514[0][0]                 \n",
            "                                                                 conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 32, 32, 32)   128         add_192[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 32, 32, 32)   0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 32, 32, 32)   9216        activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 32, 32, 32)   0           conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 32, 32, 32)   128         dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 32, 32, 32)   0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 32, 32, 32)   9216        activation_419[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_193 (Add)                   (None, 32, 32, 32)   0           add_192[0][0]                    \n",
            "                                                                 conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 32, 32, 32)   128         add_193[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 32, 32, 32)   0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 16, 16, 64)   18432       activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_421 (BatchN (None, 16, 16, 64)   256         conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 16, 16, 64)   0           batch_normalization_421[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 16, 16, 64)   36864       activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 16, 16, 64)   2048        activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_194 (Add)                   (None, 16, 16, 64)   0           conv2d_519[0][0]                 \n",
            "                                                                 conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_422 (BatchN (None, 16, 16, 64)   256         add_194[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 16, 16, 64)   0           batch_normalization_422[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 16, 16, 64)   36864       activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 16, 16, 64)   0           conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_423 (BatchN (None, 16, 16, 64)   256         dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 16, 16, 64)   0           batch_normalization_423[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 16, 16, 64)   36864       activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_195 (Add)                   (None, 16, 16, 64)   0           add_194[0][0]                    \n",
            "                                                                 conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_424 (BatchN (None, 16, 16, 64)   256         add_195[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 16, 16, 64)   0           batch_normalization_424[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 8, 8, 128)    73728       activation_424[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_425 (BatchN (None, 8, 8, 128)    512         conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 8, 8, 128)    0           batch_normalization_425[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 8, 8, 128)    147456      activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 8, 8, 128)    8192        activation_424[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_196 (Add)                   (None, 8, 8, 128)    0           conv2d_524[0][0]                 \n",
            "                                                                 conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_426 (BatchN (None, 8, 8, 128)    512         add_196[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 8, 8, 128)    0           batch_normalization_426[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, 8, 8, 128)    147456      activation_426[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 8, 8, 128)    0           conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_427 (BatchN (None, 8, 8, 128)    512         dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 8, 8, 128)    0           batch_normalization_427[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, 8, 8, 128)    147456      activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_197 (Add)                   (None, 8, 8, 128)    0           add_196[0][0]                    \n",
            "                                                                 conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_428 (BatchN (None, 8, 8, 128)    512         add_197[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 8, 8, 128)    0           batch_normalization_428[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 1, 1, 128)    0           activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_32 (Flatten)            (None, 128)          0           average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 4)            516         flatten_32[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 692,436\n",
            "Trainable params: 690,612\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNo5x-Ft9Fe",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepare and Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "outputId": "242e5446-2ad7-4a35-ae63-e85d40c302be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 719,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 719
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "outputId": "90416f52-3a40-48ba-edf6-4e4d80f0b6d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 720,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 720
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQdrnTKuM8c",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hwq9R2jruF",
        "colab_type": "code",
        "outputId": "099ffcbf-8380-40c6-8dfc-eab319cc3b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 723,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open             1500\n",
              "closed           1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 723
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAYuiEzj4Bp",
        "colab_type": "code",
        "outputId": "6855b355-0dea-4177-e130-2d904057d9d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 724,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 724
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kif3Li9NuSnV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "import tensorflow\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 256\n",
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "outputId": "c3ede4d2-63b8-4623-91f2-1a0a2005d1e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": 727,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 80:\n",
        "        return 0.01\n",
        "    elif epoch < 100:\n",
        "        return 0.001\n",
        "    elif epoch < 120:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "outputId": "733be8af-81ff-44af-b9f1-24341e488ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = wrn_16_2.fit_generator(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks=[lr_scheduler],\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": 731,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 2s 106ms/step - loss: 2.5230 - acc: 0.2691 - val_loss: 2.5212 - val_acc: 0.2447 - lr: 0.0100\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.5175 - acc: 0.2501 - val_loss: 2.5164 - val_acc: 0.2602 - lr: 0.0100\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.5107 - acc: 0.2711 - val_loss: 2.5095 - val_acc: 0.2447 - lr: 0.0100\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.4964 - acc: 0.3458 - val_loss: 2.4919 - val_acc: 0.3184 - lr: 0.0100\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.4659 - acc: 0.3730 - val_loss: 2.4589 - val_acc: 0.3417 - lr: 0.0100\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.4315 - acc: 0.3728 - val_loss: 2.4222 - val_acc: 0.3456 - lr: 0.0100\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.4000 - acc: 0.3794 - val_loss: 2.4181 - val_acc: 0.3495 - lr: 0.0100\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3741 - acc: 0.3878 - val_loss: 2.4139 - val_acc: 0.3359 - lr: 0.0100\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.3661 - acc: 0.3844 - val_loss: 2.3813 - val_acc: 0.3534 - lr: 0.0100\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.3540 - acc: 0.3830 - val_loss: 2.3725 - val_acc: 0.3534 - lr: 0.0100\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.3382 - acc: 0.3826 - val_loss: 2.3426 - val_acc: 0.3709 - lr: 0.0100\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3369 - acc: 0.3831 - val_loss: 2.3858 - val_acc: 0.3417 - lr: 0.0100\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.3318 - acc: 0.3828 - val_loss: 2.3510 - val_acc: 0.3670 - lr: 0.0100\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 2.3102 - acc: 0.3922 - val_loss: 2.3449 - val_acc: 0.3806 - lr: 0.0100\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 2.3003 - acc: 0.4002 - val_loss: 2.3129 - val_acc: 0.4117 - lr: 0.0100\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.2925 - acc: 0.4148 - val_loss: 2.3112 - val_acc: 0.4155 - lr: 0.0100\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.2886 - acc: 0.4063 - val_loss: 2.3238 - val_acc: 0.4019 - lr: 0.0100\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.2789 - acc: 0.4091 - val_loss: 2.3021 - val_acc: 0.4311 - lr: 0.0100\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.2673 - acc: 0.4141 - val_loss: 2.2913 - val_acc: 0.4485 - lr: 0.0100\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 2s 97ms/step - loss: 2.2511 - acc: 0.4308 - val_loss: 2.2720 - val_acc: 0.4291 - lr: 0.0100\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 2s 108ms/step - loss: 2.2446 - acc: 0.4434 - val_loss: 2.3027 - val_acc: 0.4019 - lr: 0.0100\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 2s 100ms/step - loss: 2.2324 - acc: 0.4356 - val_loss: 2.2779 - val_acc: 0.4291 - lr: 0.0100\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.2236 - acc: 0.4390 - val_loss: 2.2644 - val_acc: 0.4330 - lr: 0.0100\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.2218 - acc: 0.4545 - val_loss: 2.2499 - val_acc: 0.4466 - lr: 0.0100\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.2107 - acc: 0.4466 - val_loss: 2.2251 - val_acc: 0.4447 - lr: 0.0100\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.2071 - acc: 0.4561 - val_loss: 2.2283 - val_acc: 0.4854 - lr: 0.0100\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.1946 - acc: 0.4596 - val_loss: 2.2114 - val_acc: 0.4544 - lr: 0.0100\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.1921 - acc: 0.4609 - val_loss: 2.2069 - val_acc: 0.4757 - lr: 0.0100\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 2.1859 - acc: 0.4653 - val_loss: 2.2089 - val_acc: 0.4485 - lr: 0.0100\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.1650 - acc: 0.4746 - val_loss: 2.1935 - val_acc: 0.4660 - lr: 0.0100\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.1554 - acc: 0.4847 - val_loss: 2.2353 - val_acc: 0.4583 - lr: 0.0100\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.1540 - acc: 0.5050 - val_loss: 2.1830 - val_acc: 0.4990 - lr: 0.0100\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.1346 - acc: 0.5139 - val_loss: 2.1536 - val_acc: 0.5223 - lr: 0.0100\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.1233 - acc: 0.5187 - val_loss: 2.1274 - val_acc: 0.5243 - lr: 0.0100\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.1064 - acc: 0.5249 - val_loss: 2.1324 - val_acc: 0.4777 - lr: 0.0100\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.0739 - acc: 0.5349 - val_loss: 2.0899 - val_acc: 0.5476 - lr: 0.0100\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.0615 - acc: 0.5420 - val_loss: 2.0890 - val_acc: 0.5379 - lr: 0.0100\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.0794 - acc: 0.5340 - val_loss: 2.0789 - val_acc: 0.5223 - lr: 0.0100\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.0584 - acc: 0.5448 - val_loss: 2.1000 - val_acc: 0.5301 - lr: 0.0100\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.0428 - acc: 0.5557 - val_loss: 2.0701 - val_acc: 0.5068 - lr: 0.0100\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.0297 - acc: 0.5640 - val_loss: 2.0354 - val_acc: 0.5417 - lr: 0.0100\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.0017 - acc: 0.5818 - val_loss: 2.0131 - val_acc: 0.5612 - lr: 0.0100\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 2s 85ms/step - loss: 1.9770 - acc: 0.5815 - val_loss: 1.9985 - val_acc: 0.5806 - lr: 0.0100\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.9794 - acc: 0.5788 - val_loss: 2.0260 - val_acc: 0.5534 - lr: 0.0100\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.9553 - acc: 0.5914 - val_loss: 1.9709 - val_acc: 0.5767 - lr: 0.0100\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.9519 - acc: 0.5914 - val_loss: 2.0287 - val_acc: 0.5437 - lr: 0.0100\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.9262 - acc: 0.6074 - val_loss: 2.0309 - val_acc: 0.5592 - lr: 0.0100\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.9227 - acc: 0.6058 - val_loss: 1.9410 - val_acc: 0.5786 - lr: 0.0100\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 1.9001 - acc: 0.6085 - val_loss: 1.9248 - val_acc: 0.5825 - lr: 0.0100\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.8853 - acc: 0.6156 - val_loss: 1.9481 - val_acc: 0.5864 - lr: 0.0100\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.8873 - acc: 0.6108 - val_loss: 1.9021 - val_acc: 0.5709 - lr: 0.0100\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 2s 85ms/step - loss: 1.8477 - acc: 0.6359 - val_loss: 2.0342 - val_acc: 0.5573 - lr: 0.0100\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.8752 - acc: 0.6053 - val_loss: 1.8947 - val_acc: 0.5806 - lr: 0.0100\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.8368 - acc: 0.6279 - val_loss: 1.8703 - val_acc: 0.6155 - lr: 0.0100\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 1.8220 - acc: 0.6471 - val_loss: 1.9281 - val_acc: 0.5864 - lr: 0.0100\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.8053 - acc: 0.6519 - val_loss: 1.9319 - val_acc: 0.6000 - lr: 0.0100\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.7925 - acc: 0.6515 - val_loss: 1.8706 - val_acc: 0.6155 - lr: 0.0100\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.7781 - acc: 0.6549 - val_loss: 1.8688 - val_acc: 0.6330 - lr: 0.0100\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 1.7762 - acc: 0.6601 - val_loss: 1.8537 - val_acc: 0.6350 - lr: 0.0100\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.7463 - acc: 0.6750 - val_loss: 1.8710 - val_acc: 0.6155 - lr: 0.0100\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.7451 - acc: 0.6706 - val_loss: 1.8653 - val_acc: 0.6233 - lr: 0.0100\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.7494 - acc: 0.6656 - val_loss: 1.8924 - val_acc: 0.5961 - lr: 0.0100\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.7222 - acc: 0.6768 - val_loss: 1.8193 - val_acc: 0.6447 - lr: 0.0100\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.7171 - acc: 0.6846 - val_loss: 1.9057 - val_acc: 0.6175 - lr: 0.0100\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.6968 - acc: 0.6852 - val_loss: 1.8146 - val_acc: 0.6350 - lr: 0.0100\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.6774 - acc: 0.6887 - val_loss: 1.8547 - val_acc: 0.6447 - lr: 0.0100\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 1.6652 - acc: 0.7063 - val_loss: 1.7750 - val_acc: 0.6350 - lr: 0.0100\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.6471 - acc: 0.7072 - val_loss: 1.7724 - val_acc: 0.6427 - lr: 0.0100\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.6499 - acc: 0.7069 - val_loss: 1.8694 - val_acc: 0.6330 - lr: 0.0100\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.6704 - acc: 0.6931 - val_loss: 1.7974 - val_acc: 0.6350 - lr: 0.0100\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.6543 - acc: 0.6953 - val_loss: 1.7170 - val_acc: 0.6621 - lr: 0.0100\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.6179 - acc: 0.7111 - val_loss: 1.6916 - val_acc: 0.6835 - lr: 0.0100\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.6496 - acc: 0.7067 - val_loss: 1.6866 - val_acc: 0.6816 - lr: 0.0100\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.6139 - acc: 0.7165 - val_loss: 2.0306 - val_acc: 0.5845 - lr: 0.0100\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.6458 - acc: 0.7040 - val_loss: 1.7361 - val_acc: 0.6485 - lr: 0.0100\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.5945 - acc: 0.7161 - val_loss: 1.7098 - val_acc: 0.6718 - lr: 0.0100\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 1.5803 - acc: 0.7274 - val_loss: 1.6954 - val_acc: 0.6874 - lr: 0.0100\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.5759 - acc: 0.7227 - val_loss: 1.7583 - val_acc: 0.6563 - lr: 0.0100\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.5816 - acc: 0.7218 - val_loss: 1.6746 - val_acc: 0.6718 - lr: 0.0100\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.5586 - acc: 0.7360 - val_loss: 1.6529 - val_acc: 0.6932 - lr: 0.0100\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.6500 - acc: 0.6855 - val_loss: 1.7652 - val_acc: 0.6505 - lr: 0.0010\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.5814 - acc: 0.7229 - val_loss: 1.7360 - val_acc: 0.6777 - lr: 0.0010\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.5389 - acc: 0.7414 - val_loss: 1.7418 - val_acc: 0.6583 - lr: 0.0010\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.5258 - acc: 0.7540 - val_loss: 1.6481 - val_acc: 0.6990 - lr: 0.0010\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.5228 - acc: 0.7524 - val_loss: 1.6558 - val_acc: 0.6854 - lr: 0.0010\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.5026 - acc: 0.7579 - val_loss: 1.6413 - val_acc: 0.6854 - lr: 0.0010\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.5063 - acc: 0.7556 - val_loss: 1.6317 - val_acc: 0.6932 - lr: 0.0010\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4953 - acc: 0.7559 - val_loss: 1.6295 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4842 - acc: 0.7630 - val_loss: 1.6261 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 1.4885 - acc: 0.7597 - val_loss: 1.6363 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4820 - acc: 0.7661 - val_loss: 1.6224 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 1.4821 - acc: 0.7675 - val_loss: 1.6345 - val_acc: 0.6990 - lr: 0.0010\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4813 - acc: 0.7586 - val_loss: 1.6241 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4740 - acc: 0.7670 - val_loss: 1.6348 - val_acc: 0.6990 - lr: 0.0010\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4658 - acc: 0.7734 - val_loss: 1.6607 - val_acc: 0.6893 - lr: 0.0010\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4803 - acc: 0.7615 - val_loss: 1.6513 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4659 - acc: 0.7704 - val_loss: 1.6534 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4721 - acc: 0.7624 - val_loss: 1.6342 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4689 - acc: 0.7597 - val_loss: 1.6449 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4685 - acc: 0.7650 - val_loss: 1.6220 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4702 - acc: 0.7677 - val_loss: 1.6309 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4658 - acc: 0.7707 - val_loss: 1.6262 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4671 - acc: 0.7693 - val_loss: 1.6376 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 1.4656 - acc: 0.7719 - val_loss: 1.6359 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4625 - acc: 0.7714 - val_loss: 1.6399 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 1.4771 - acc: 0.7611 - val_loss: 1.6533 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4545 - acc: 0.7734 - val_loss: 1.6125 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4557 - acc: 0.7679 - val_loss: 1.6312 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4539 - acc: 0.7752 - val_loss: 1.6445 - val_acc: 0.6932 - lr: 0.0010\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4455 - acc: 0.7787 - val_loss: 1.6383 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4403 - acc: 0.7759 - val_loss: 1.6279 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4464 - acc: 0.7782 - val_loss: 1.6160 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4474 - acc: 0.7702 - val_loss: 1.6181 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4506 - acc: 0.7757 - val_loss: 1.6310 - val_acc: 0.6990 - lr: 0.0010\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4440 - acc: 0.7755 - val_loss: 1.6132 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4472 - acc: 0.7693 - val_loss: 1.6152 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4407 - acc: 0.7837 - val_loss: 1.6139 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4432 - acc: 0.7734 - val_loss: 1.6238 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4473 - acc: 0.7714 - val_loss: 1.6213 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4346 - acc: 0.7750 - val_loss: 1.6275 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4399 - acc: 0.7800 - val_loss: 1.6235 - val_acc: 0.7340 - lr: 1.0000e-04\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4349 - acc: 0.7725 - val_loss: 1.6242 - val_acc: 0.7087 - lr: 1.0000e-04\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 1.4435 - acc: 0.7768 - val_loss: 1.6252 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4279 - acc: 0.7819 - val_loss: 1.6407 - val_acc: 0.7126 - lr: 1.0000e-04\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4307 - acc: 0.7839 - val_loss: 1.6903 - val_acc: 0.6893 - lr: 1.0000e-04\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 1.4257 - acc: 0.7837 - val_loss: 1.6234 - val_acc: 0.7165 - lr: 1.0000e-04\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4294 - acc: 0.7796 - val_loss: 1.6131 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4328 - acc: 0.7794 - val_loss: 1.6197 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4283 - acc: 0.7812 - val_loss: 1.6088 - val_acc: 0.7262 - lr: 1.0000e-04\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 2s 85ms/step - loss: 1.4277 - acc: 0.7723 - val_loss: 1.6209 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4310 - acc: 0.7771 - val_loss: 1.6195 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4298 - acc: 0.7803 - val_loss: 1.6119 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4197 - acc: 0.7796 - val_loss: 1.6186 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4403 - acc: 0.7748 - val_loss: 1.6149 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4334 - acc: 0.7750 - val_loss: 1.6403 - val_acc: 0.7087 - lr: 1.0000e-04\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 1.4272 - acc: 0.7852 - val_loss: 1.6266 - val_acc: 0.7165 - lr: 1.0000e-04\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4296 - acc: 0.7816 - val_loss: 1.6081 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4294 - acc: 0.7755 - val_loss: 1.6139 - val_acc: 0.7165 - lr: 1.0000e-04\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4337 - acc: 0.7734 - val_loss: 1.6203 - val_acc: 0.7165 - lr: 1.0000e-04\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4346 - acc: 0.7798 - val_loss: 1.6235 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4244 - acc: 0.7873 - val_loss: 1.6322 - val_acc: 0.7087 - lr: 1.0000e-04\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4187 - acc: 0.7876 - val_loss: 1.6403 - val_acc: 0.7049 - lr: 1.0000e-04\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 1.4295 - acc: 0.7791 - val_loss: 1.6263 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4230 - acc: 0.7797 - val_loss: 1.6334 - val_acc: 0.7068 - lr: 1.0000e-04\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4256 - acc: 0.7796 - val_loss: 1.6218 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4230 - acc: 0.7814 - val_loss: 1.6166 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4262 - acc: 0.7844 - val_loss: 1.6213 - val_acc: 0.7087 - lr: 1.0000e-04\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4309 - acc: 0.7771 - val_loss: 1.6194 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4268 - acc: 0.7803 - val_loss: 1.6354 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4176 - acc: 0.7837 - val_loss: 1.6086 - val_acc: 0.7301 - lr: 1.0000e-04\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4223 - acc: 0.7855 - val_loss: 1.6347 - val_acc: 0.7126 - lr: 1.0000e-04\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4312 - acc: 0.7778 - val_loss: 1.6186 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4192 - acc: 0.7846 - val_loss: 1.6189 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4263 - acc: 0.7851 - val_loss: 1.6175 - val_acc: 0.7301 - lr: 1.0000e-04\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4345 - acc: 0.7762 - val_loss: 1.6187 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4235 - acc: 0.7839 - val_loss: 1.6174 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 1.4260 - acc: 0.7784 - val_loss: 1.6298 - val_acc: 0.7068 - lr: 1.0000e-04\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4217 - acc: 0.7752 - val_loss: 1.6069 - val_acc: 0.7320 - lr: 1.0000e-04\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4307 - acc: 0.7780 - val_loss: 1.6103 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4297 - acc: 0.7812 - val_loss: 1.6084 - val_acc: 0.7262 - lr: 1.0000e-04\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 1.4280 - acc: 0.7757 - val_loss: 1.6153 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4221 - acc: 0.7814 - val_loss: 1.6205 - val_acc: 0.7126 - lr: 1.0000e-04\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4271 - acc: 0.7787 - val_loss: 1.6273 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 1.4296 - acc: 0.7787 - val_loss: 1.6193 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4256 - acc: 0.7819 - val_loss: 1.6251 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4187 - acc: 0.7828 - val_loss: 1.6239 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4194 - acc: 0.7860 - val_loss: 1.6113 - val_acc: 0.7243 - lr: 1.0000e-04\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4343 - acc: 0.7816 - val_loss: 1.6073 - val_acc: 0.7282 - lr: 1.0000e-04\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4255 - acc: 0.7810 - val_loss: 1.7967 - val_acc: 0.6796 - lr: 1.0000e-04\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4278 - acc: 0.7839 - val_loss: 1.6204 - val_acc: 0.7223 - lr: 1.0000e-04\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4326 - acc: 0.7784 - val_loss: 1.6132 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4247 - acc: 0.7819 - val_loss: 1.6197 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4270 - acc: 0.7807 - val_loss: 1.6133 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4247 - acc: 0.7851 - val_loss: 1.6119 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4173 - acc: 0.7835 - val_loss: 1.6147 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4231 - acc: 0.7816 - val_loss: 1.6028 - val_acc: 0.7243 - lr: 1.0000e-04\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4305 - acc: 0.7730 - val_loss: 1.6011 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4293 - acc: 0.7778 - val_loss: 1.6259 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4230 - acc: 0.7844 - val_loss: 1.6156 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4263 - acc: 0.7741 - val_loss: 1.6060 - val_acc: 0.7262 - lr: 1.0000e-04\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4202 - acc: 0.7917 - val_loss: 1.6166 - val_acc: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4225 - acc: 0.7880 - val_loss: 1.6147 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4171 - acc: 0.7862 - val_loss: 1.6271 - val_acc: 0.7165 - lr: 1.0000e-04\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4280 - acc: 0.7825 - val_loss: 1.6264 - val_acc: 0.7029 - lr: 1.0000e-04\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 1.4162 - acc: 0.7862 - val_loss: 1.6363 - val_acc: 0.7126 - lr: 1.0000e-04\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4112 - acc: 0.7803 - val_loss: 1.6383 - val_acc: 0.7049 - lr: 1.0000e-04\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4230 - acc: 0.7853 - val_loss: 1.6416 - val_acc: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4193 - acc: 0.7828 - val_loss: 1.6159 - val_acc: 0.7243 - lr: 1.0000e-04\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4227 - acc: 0.7885 - val_loss: 1.6812 - val_acc: 0.7010 - lr: 1.0000e-04\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4143 - acc: 0.7869 - val_loss: 1.6241 - val_acc: 0.7165 - lr: 1.0000e-04\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4218 - acc: 0.7821 - val_loss: 1.6109 - val_acc: 0.7262 - lr: 1.0000e-04\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4221 - acc: 0.7828 - val_loss: 1.6190 - val_acc: 0.7223 - lr: 1.0000e-04\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4344 - acc: 0.7805 - val_loss: 1.6320 - val_acc: 0.7087 - lr: 1.0000e-04\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4243 - acc: 0.7846 - val_loss: 1.6079 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4220 - acc: 0.7835 - val_loss: 1.6137 - val_acc: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4208 - acc: 0.7864 - val_loss: 1.6192 - val_acc: 0.7204 - lr: 1.0000e-04\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 1.4144 - acc: 0.7860 - val_loss: 1.6291 - val_acc: 0.7049 - lr: 1.0000e-04\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4177 - acc: 0.7828 - val_loss: 1.6361 - val_acc: 0.7049 - lr: 1.0000e-04\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 1.4216 - acc: 0.7860 - val_loss: 1.6194 - val_acc: 0.7243 - lr: 1.0000e-04\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.4302 - acc: 0.7791 - val_loss: 1.6291 - val_acc: 0.7049 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.save(\"model_wrn_last.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djH4uwAnvkfb",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "outputId": "b29d26fb-b41d-4c33-e4b7-0f280250a971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 733,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "outputId": "715418d3-5202-4025-83b3-26a3d9c84bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "wrn_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 734,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5513 - acc: 0.7295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5512733459472656, 0.7294939160346985]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 734
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmZpcppX5u_C",
        "colab_type": "code",
        "outputId": "b6cc5aad-996f-47c0-df01-86560f9f7d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "wrn_16_2.evaluate(X_train,y_train)"
      ],
      "execution_count": 735,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "145/145 [==============================] - 1s 6ms/step - loss: 1.4045 - acc: 0.7892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4044981002807617, 0.789167046546936]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 735
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDHJIheU8bm",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QB8zFSSU7Qy",
        "colab_type": "code",
        "outputId": "933eeb18-6759-415a-823b-dd1df2035c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 736,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans from git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.6/dist-packages (from cleverhans) (2.6.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bfZ4G8W_sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(wrn_16_2.input,wrn_16_2.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWIlakqVD_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "40c12b72-c99e-4b2d-e0b3-5614d69aff79"
      },
      "source": [
        "X_adv = []\n",
        "y_adv = []\n",
        "for i in range(len(X)):\n",
        "  random_index = i\n",
        "  original_image = X[random_index]\n",
        "  original_image = tf.convert_to_tensor(original_image.reshape((1,68,100))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "\n",
        "  original_label = y_cat[random_index]\n",
        "\n",
        "  epsilon = 0.5\n",
        "  original_label\n",
        "  adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "  adv_example_targeted_label_pred = wrn_16_2.predict(adv_example_targeted_label)\n",
        "  X_adv.append(adv_example_targeted_label)\n",
        "  y_adv.append(np.argmax(adv_example_targeted_label_pred))"
      ],
      "execution_count": 738,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-738-ec2b7f04f08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mrandom_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0moriginal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1024 into shape (1,68,100)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1DCXV9Tc9B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "my_data = {'image': X_adv,\n",
        "           'label': y_adv_df['Encoded']\n",
        "           }\n",
        "output = open('data_adv_50.pkl', 'wb')\n",
        "pickle.dump(my_data, output)\n",
        "output.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuWpwrKuwmsc",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfF0d5ePbXK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv = np.array(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5I9X-0mboqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df = pd.DataFrame(y_adv, columns=['Encoded'])\n",
        "y_adv_df['Encoded'] = labelencoder.fit_transform(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcxHP-bTcIwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df['Encoded'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1mGBoQbd46-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = []\n",
        "X_adv =my_data['image']\n",
        "for i in range(len(X_adv)):\n",
        "  a = np.array(X_adv[i])\n",
        "  X_new.append(a.reshape(68,100,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdE_WN8Ffgyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X)):\n",
        "  a = np.array(X[i])\n",
        "  X_new.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAnXO0Vfg1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_third = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jH1i_FMA2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dackr68mMA0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UIXimpiKWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_new = []\n",
        "for j in range(0,2):\n",
        "  for i in range(len(y_cat)):\n",
        "    y_new.append(y_cat[i])\n",
        "y_third = np.array(y_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuRIuXcNiKY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_all, y_all = X_third, y_third"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJXveP1Veo7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split( X_all,y_all, test_size = 0.33, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJjEg9qiI0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HibsOpTIcNq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q96wjHqxeTJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n",
        "BS_adv= 100\n",
        "EPOCHS_adv = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jewqs8yxlnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch_train(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.1\n",
        "    elif epoch <20:\n",
        "        return 0.1/2.0\n",
        "    elif epoch < 30:\n",
        "        return 0.1/2.0**2\n",
        "    elif epoch < 40:\n",
        "        return 0.1/2.0**3\n",
        "    else:\n",
        "        return 0.1/2.0**4\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler_train = LearningRateScheduler(lr_sch_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FIn8khEd45J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "hist = wrn_16_2_adv.fit_generator(generator.flow(X_train_adv, y_train_adv, batch_size=BS_adv), steps_per_epoch=len(X_train_adv) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test_adv, y_test_adv),\n",
        "                   validation_steps=X_test_adv.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qXnteSOpFZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.save(\"model_adv_wrn_tensor_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeetxZrNv9oM",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S5IjLivpMbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcU_6z90QSJ",
        "colab_type": "text"
      },
      "source": [
        "**CleanExperiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i5qUE6j0JUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4p2TUIj0csZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQljdkd0he9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_clean = wrn_16_2_clean.fit_generator(generator.flow(X_train, y_train, batch_size=BS_adv), steps_per_epoch=len(X_train) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   validation_steps=X_test.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1acrchBU185p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.save(\"model_adv_train_clean_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9hLRXbmwETE",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pgU_KsH0yVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist_clean\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCKONCZ0Jzfi",
        "colab_type": "text"
      },
      "source": [
        "**Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgpFgWbKeR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhiqvES18c-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHVWy96Llce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqj_Ax7MI4SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXT3YD6iLl0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test_adv,y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fKhEMXgKAnZ",
        "colab_type": "text"
      },
      "source": [
        "**Non_Adversarial_Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouj6OqTD8VdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfkUSeV6KHp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZFJl2D4Hbxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gJh7MDHChHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZuONcAeAwQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test_adv, y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}