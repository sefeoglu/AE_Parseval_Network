{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db157313-7f50-433b-81bc-62e3ed3d49a0"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from tensorflow.keras.utils import plot_model\n",
        "    from tensorflow.keras.layers import Input\n",
        "    from tensorflow.keras.models import Model\n",
        "\n",
        "    init = (68, 100,1)\n",
        "\n",
        "    wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.0)\n",
        "\n",
        "    wrn_16_2.summary()\n",
        "\n",
        "   # plot_model(wrn_28_10, \"WRN-16-2.png\", show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 68, 100, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 68, 100, 16)  144         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 68, 100, 16)  64          conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 68, 100, 16)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 68, 100, 32)  4608        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 68, 100, 32)  128         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 68, 100, 32)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 68, 100, 32)  9216        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 68, 100, 32)  512         activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 68, 100, 32)  0           conv2d_66[0][0]                  \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 68, 100, 32)  128         add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 68, 100, 32)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 68, 100, 32)  9216        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 68, 100, 32)  128         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 68, 100, 32)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 68, 100, 32)  9216        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 68, 100, 32)  0           add_24[0][0]                     \n",
            "                                                                 conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 68, 100, 32)  128         add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 68, 100, 32)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 34, 50, 64)   18432       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 34, 50, 64)   256         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 34, 50, 64)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 34, 50, 64)   36864       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 34, 50, 64)   2048        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 34, 50, 64)   0           conv2d_71[0][0]                  \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 34, 50, 64)   256         add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 34, 50, 64)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 34, 50, 64)   36864       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 34, 50, 64)   256         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 34, 50, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 34, 50, 64)   36864       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 34, 50, 64)   0           add_26[0][0]                     \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 34, 50, 64)   256         add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 34, 50, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 17, 25, 128)  73728       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 25, 128)  512         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 25, 128)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 17, 25, 128)  147456      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 17, 25, 128)  8192        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 17, 25, 128)  0           conv2d_76[0][0]                  \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 25, 128)  512         add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 25, 128)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 17, 25, 128)  147456      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 25, 128)  512         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 25, 128)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 17, 25, 128)  147456      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 17, 25, 128)  0           add_28[0][0]                     \n",
            "                                                                 conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 25, 128)  512         add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 25, 128)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 2, 3, 128)    0           activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 768)          0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            3076        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 694,996\n",
            "Trainable params: 693,172\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "outputId": "8fee32f5-c63d-488d-be8b-7718c5560a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(row['crop'])\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "outputId": "66cccc6a-10ab-4b8d-b54e-183cab7007d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X[0].shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv-A3B72JXDE",
        "colab_type": "code",
        "outputId": "9567db07-ba09-460a-df53-dad3036927d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = list(map(augment_cifar, X))\n",
        "X = np.array(X)\n",
        "X.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Z7UDOByArq",
        "colab_type": "code",
        "outputId": "41ca23b5-cb34-474e-feb2-4d2f48b5788c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hwq9R2jruF",
        "colab_type": "code",
        "outputId": "9cb56fb6-6469-4f1e-a25c-66d8ab52c362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open             1500\n",
              "closed           1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAYuiEzj4Bp",
        "colab_type": "code",
        "outputId": "2d97f91e-f7af-4f80-d896-ee052d4785a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUHIVZnNwLL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "outputId": "2156b483-358b-4833-de40-8572fcfc3333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HA8PdUYwhsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 60:\n",
        "        return 0.1\n",
        "    elif epoch < 120:\n",
        "        return 0.02\n",
        "    elif epoch < 160:\n",
        "        return 0.004\n",
        "    else:\n",
        "        return 0.0008\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxj3cWeUR1VA",
        "colab_type": "code",
        "outputId": "069da484-a32c-4415-fa35-5edb1401527f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=2, random_state=42, shuffle=False)\n",
        "hist_list = []\n",
        "train_set= []\n",
        "test_set = []\n",
        "for train_index, test_index in cv.split(X):\n",
        "    print(\"Train Index: \", train_index, \"\\n\")\n",
        "    print(\"Test Index: \", test_index)\n",
        "    train_set.append(train_index)\n",
        "    test_set.append(test_index)\n",
        "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y_cat[train_index], y_cat[test_index]\n",
        "    hist = wrn16_2.fit_generator(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks=[lr_scheduler],\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   validation_steps=X_test.shape[0] // BS,)\n",
        "    hist_list.append(hist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Index:  [2861 2862 2863 ... 5719 5720 5721] \n",
            "\n",
            "Test Index:  [   0    1    2 ... 2858 2859 2860]\n",
            "WARNING:tensorflow:From <ipython-input-69-ba5a3465a143>:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/200\n",
            "22/22 [==============================] - 9s 401ms/step - loss: 2.4788 - acc: 0.3132 - val_loss: 2.7075 - val_acc: 0.2478 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 2.3858 - acc: 0.3465 - val_loss: 2.3950 - val_acc: 0.3387 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.3268 - acc: 0.3417 - val_loss: 2.3503 - val_acc: 0.3443 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.2811 - acc: 0.3597 - val_loss: 2.2910 - val_acc: 0.3502 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 2.2260 - acc: 0.3659 - val_loss: 2.2878 - val_acc: 0.3279 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 2.2028 - acc: 0.3674 - val_loss: 2.1918 - val_acc: 0.3656 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.1469 - acc: 0.3659 - val_loss: 2.1597 - val_acc: 0.3810 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 2.0955 - acc: 0.3816 - val_loss: 2.1292 - val_acc: 0.3548 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 2.0567 - acc: 0.3955 - val_loss: 2.1040 - val_acc: 0.3516 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 2.0275 - acc: 0.3721 - val_loss: 2.0683 - val_acc: 0.3467 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.9764 - acc: 0.4036 - val_loss: 2.0801 - val_acc: 0.3457 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.9568 - acc: 0.3889 - val_loss: 1.9952 - val_acc: 0.3569 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "22/22 [==============================] - 7s 309ms/step - loss: 1.9258 - acc: 0.3970 - val_loss: 1.9644 - val_acc: 0.3586 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.8951 - acc: 0.3875 - val_loss: 2.0590 - val_acc: 0.3300 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.8551 - acc: 0.4047 - val_loss: 1.9879 - val_acc: 0.3418 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.8252 - acc: 0.4058 - val_loss: 1.9573 - val_acc: 0.3618 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.8071 - acc: 0.4043 - val_loss: 1.9235 - val_acc: 0.3681 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.7836 - acc: 0.4036 - val_loss: 1.8828 - val_acc: 0.3740 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 1.7541 - acc: 0.4179 - val_loss: 1.8604 - val_acc: 0.3667 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.7301 - acc: 0.4069 - val_loss: 1.9214 - val_acc: 0.3593 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6994 - acc: 0.4204 - val_loss: 1.8401 - val_acc: 0.3726 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.6771 - acc: 0.4135 - val_loss: 1.9544 - val_acc: 0.3460 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6564 - acc: 0.4182 - val_loss: 1.9034 - val_acc: 0.3537 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6433 - acc: 0.4135 - val_loss: 1.8535 - val_acc: 0.3481 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6161 - acc: 0.4277 - val_loss: 1.8656 - val_acc: 0.3677 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.6032 - acc: 0.4292 - val_loss: 1.8052 - val_acc: 0.3387 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 1.5789 - acc: 0.4318 - val_loss: 1.7920 - val_acc: 0.3432 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5710 - acc: 0.4292 - val_loss: 1.7435 - val_acc: 0.3715 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5588 - acc: 0.4321 - val_loss: 1.7470 - val_acc: 0.3544 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5520 - acc: 0.4321 - val_loss: 1.6627 - val_acc: 0.3841 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "22/22 [==============================] - 7s 304ms/step - loss: 1.5244 - acc: 0.4277 - val_loss: 1.7082 - val_acc: 0.3635 - lr: 0.1000\n",
            "Epoch 32/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.5116 - acc: 0.4175 - val_loss: 1.7169 - val_acc: 0.3593 - lr: 0.1000\n",
            "Epoch 33/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.4929 - acc: 0.4380 - val_loss: 1.6734 - val_acc: 0.3674 - lr: 0.1000\n",
            "Epoch 34/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4728 - acc: 0.4544 - val_loss: 1.6696 - val_acc: 0.3768 - lr: 0.1000\n",
            "Epoch 35/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4518 - acc: 0.4541 - val_loss: 1.6507 - val_acc: 0.3604 - lr: 0.1000\n",
            "Epoch 36/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4538 - acc: 0.4398 - val_loss: 1.7176 - val_acc: 0.3743 - lr: 0.1000\n",
            "Epoch 37/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.4501 - acc: 0.4383 - val_loss: 1.7382 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 38/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.4470 - acc: 0.4416 - val_loss: 1.5945 - val_acc: 0.3688 - lr: 0.1000\n",
            "Epoch 39/200\n",
            "22/22 [==============================] - 7s 311ms/step - loss: 1.4241 - acc: 0.4418 - val_loss: 1.6168 - val_acc: 0.3775 - lr: 0.1000\n",
            "Epoch 40/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4051 - acc: 0.4475 - val_loss: 1.6400 - val_acc: 0.3551 - lr: 0.1000\n",
            "Epoch 41/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.4039 - acc: 0.4523 - val_loss: 1.6152 - val_acc: 0.3799 - lr: 0.1000\n",
            "Epoch 42/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3928 - acc: 0.4457 - val_loss: 1.5882 - val_acc: 0.3729 - lr: 0.1000\n",
            "Epoch 43/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3902 - acc: 0.4416 - val_loss: 1.5187 - val_acc: 0.3974 - lr: 0.1000\n",
            "Epoch 44/200\n",
            "22/22 [==============================] - 7s 310ms/step - loss: 1.3931 - acc: 0.4340 - val_loss: 1.6927 - val_acc: 0.3681 - lr: 0.1000\n",
            "Epoch 45/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3704 - acc: 0.4376 - val_loss: 1.5919 - val_acc: 0.3915 - lr: 0.1000\n",
            "Epoch 46/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3659 - acc: 0.4493 - val_loss: 1.6132 - val_acc: 0.3397 - lr: 0.1000\n",
            "Epoch 47/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3638 - acc: 0.4490 - val_loss: 1.6146 - val_acc: 0.3614 - lr: 0.1000\n",
            "Epoch 48/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3637 - acc: 0.4574 - val_loss: 1.5896 - val_acc: 0.3660 - lr: 0.1000\n",
            "Epoch 49/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3428 - acc: 0.4544 - val_loss: 1.6446 - val_acc: 0.3492 - lr: 0.1000\n",
            "Epoch 50/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3286 - acc: 0.4530 - val_loss: 1.5885 - val_acc: 0.3614 - lr: 0.1000\n",
            "Epoch 51/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3328 - acc: 0.4526 - val_loss: 1.7250 - val_acc: 0.3328 - lr: 0.1000\n",
            "Epoch 52/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.3193 - acc: 0.4464 - val_loss: 1.5198 - val_acc: 0.3820 - lr: 0.1000\n",
            "Epoch 53/200\n",
            "22/22 [==============================] - 7s 309ms/step - loss: 1.3217 - acc: 0.4705 - val_loss: 1.5211 - val_acc: 0.3764 - lr: 0.1000\n",
            "Epoch 54/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3056 - acc: 0.4673 - val_loss: 1.5446 - val_acc: 0.3719 - lr: 0.1000\n",
            "Epoch 55/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.2866 - acc: 0.4877 - val_loss: 1.6259 - val_acc: 0.3911 - lr: 0.1000\n",
            "Epoch 56/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3093 - acc: 0.4614 - val_loss: 1.6239 - val_acc: 0.3796 - lr: 0.1000\n",
            "Epoch 57/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.2938 - acc: 0.4523 - val_loss: 1.4958 - val_acc: 0.3831 - lr: 0.1000\n",
            "Epoch 58/200\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 1.3157 - acc: 0.4435 - val_loss: 1.5481 - val_acc: 0.3736 - lr: 0.1000\n",
            "Epoch 59/200\n",
            "22/22 [==============================] - 7s 305ms/step - loss: 1.2963 - acc: 0.4555 - val_loss: 1.5020 - val_acc: 0.3967 - lr: 0.1000\n",
            "Epoch 60/200\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 1.2671 - acc: 0.4746 - val_loss: 1.5300 - val_acc: 0.3778 - lr: 0.1000\n",
            "Epoch 61/200\n",
            "22/22 [==============================] - 7s 309ms/step - loss: 1.2939 - acc: 0.4490 - val_loss: 1.4786 - val_acc: 0.3607 - lr: 0.0200\n",
            "Epoch 62/200\n",
            " 4/22 [====>.........................] - ETA: 3s - loss: 1.2764 - acc: 0.4316"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "outputId": "e664586e-ab71-4abd-e70d-bac90c0a0f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "hist = wrn_16_2.fit_generator(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks=[lr_scheduler],\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   validation_steps=X_test.shape[0] // BS,)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-74-99af60e7ca68>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/200\n",
            "29/29 [==============================] - 5s 165ms/step - loss: 2.4583 - acc: 0.3233 - val_loss: 2.3692 - val_acc: 0.3716 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 2.3242 - acc: 0.3879 - val_loss: 2.2560 - val_acc: 0.4214 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 4s 150ms/step - loss: 2.2429 - acc: 0.4016 - val_loss: 2.1912 - val_acc: 0.4383 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 2.1608 - acc: 0.4205 - val_loss: 2.3368 - val_acc: 0.3430 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 2.0869 - acc: 0.4489 - val_loss: 1.9971 - val_acc: 0.5013 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.9923 - acc: 0.4964 - val_loss: 1.9794 - val_acc: 0.4844 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.8914 - acc: 0.5277 - val_loss: 1.8016 - val_acc: 0.5643 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.8197 - acc: 0.5471 - val_loss: 1.7891 - val_acc: 0.5659 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.7621 - acc: 0.5576 - val_loss: 1.7366 - val_acc: 0.6098 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.6862 - acc: 0.5841 - val_loss: 1.7145 - val_acc: 0.5469 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.6205 - acc: 0.5960 - val_loss: 1.7278 - val_acc: 0.5611 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.5842 - acc: 0.6065 - val_loss: 1.5020 - val_acc: 0.6220 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.4989 - acc: 0.6300 - val_loss: 1.5121 - val_acc: 0.6199 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.4372 - acc: 0.6426 - val_loss: 1.3760 - val_acc: 0.6855 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.3826 - acc: 0.6653 - val_loss: 1.3847 - val_acc: 0.6691 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.3488 - acc: 0.6686 - val_loss: 1.3858 - val_acc: 0.6390 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.2847 - acc: 0.6874 - val_loss: 1.3207 - val_acc: 0.6861 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.2780 - acc: 0.6758 - val_loss: 1.6652 - val_acc: 0.5839 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.2201 - acc: 0.7080 - val_loss: 1.2452 - val_acc: 0.6824 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.1572 - acc: 0.7152 - val_loss: 1.1901 - val_acc: 0.6914 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.1581 - acc: 0.7166 - val_loss: 1.0915 - val_acc: 0.7395 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.1008 - acc: 0.7287 - val_loss: 1.0551 - val_acc: 0.7538 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 1.0991 - acc: 0.7271 - val_loss: 1.1889 - val_acc: 0.6887 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.0514 - acc: 0.7409 - val_loss: 1.0854 - val_acc: 0.7290 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.0116 - acc: 0.7595 - val_loss: 1.0365 - val_acc: 0.7470 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 1.0180 - acc: 0.7436 - val_loss: 1.0538 - val_acc: 0.7316 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.9753 - acc: 0.7638 - val_loss: 1.1174 - val_acc: 0.7073 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.9644 - acc: 0.7579 - val_loss: 1.0117 - val_acc: 0.7374 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.9344 - acc: 0.7733 - val_loss: 1.0166 - val_acc: 0.7358 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.8896 - acc: 0.7854 - val_loss: 0.9801 - val_acc: 0.7433 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.8868 - acc: 0.7843 - val_loss: 1.0716 - val_acc: 0.7125 - lr: 0.1000\n",
            "Epoch 32/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.9139 - acc: 0.7606 - val_loss: 0.9254 - val_acc: 0.7538 - lr: 0.1000\n",
            "Epoch 33/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.8862 - acc: 0.7792 - val_loss: 0.9469 - val_acc: 0.7470 - lr: 0.1000\n",
            "Epoch 34/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.8286 - acc: 0.7919 - val_loss: 1.0252 - val_acc: 0.7274 - lr: 0.1000\n",
            "Epoch 35/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.8802 - acc: 0.7692 - val_loss: 0.9116 - val_acc: 0.7565 - lr: 0.1000\n",
            "Epoch 36/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.7888 - acc: 0.8057 - val_loss: 0.9244 - val_acc: 0.7464 - lr: 0.1000\n",
            "Epoch 37/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7904 - acc: 0.8011 - val_loss: 0.9155 - val_acc: 0.7565 - lr: 0.1000\n",
            "Epoch 38/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7732 - acc: 0.8059 - val_loss: 0.9433 - val_acc: 0.7570 - lr: 0.1000\n",
            "Epoch 39/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7784 - acc: 0.8019 - val_loss: 0.9330 - val_acc: 0.7475 - lr: 0.1000\n",
            "Epoch 40/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.7653 - acc: 0.8022 - val_loss: 0.8863 - val_acc: 0.7565 - lr: 0.1000\n",
            "Epoch 41/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7433 - acc: 0.8167 - val_loss: 1.0075 - val_acc: 0.7178 - lr: 0.1000\n",
            "Epoch 42/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.7417 - acc: 0.8175 - val_loss: 0.8850 - val_acc: 0.7665 - lr: 0.1000\n",
            "Epoch 43/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.7094 - acc: 0.8248 - val_loss: 0.8529 - val_acc: 0.7718 - lr: 0.1000\n",
            "Epoch 44/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7165 - acc: 0.8194 - val_loss: 0.9708 - val_acc: 0.7480 - lr: 0.1000\n",
            "Epoch 45/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7200 - acc: 0.8243 - val_loss: 0.9191 - val_acc: 0.7538 - lr: 0.1000\n",
            "Epoch 46/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7111 - acc: 0.8221 - val_loss: 0.9244 - val_acc: 0.7427 - lr: 0.1000\n",
            "Epoch 47/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6932 - acc: 0.8305 - val_loss: 0.9530 - val_acc: 0.7650 - lr: 0.1000\n",
            "Epoch 48/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7219 - acc: 0.8227 - val_loss: 0.8539 - val_acc: 0.7628 - lr: 0.1000\n",
            "Epoch 49/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.7246 - acc: 0.8157 - val_loss: 0.9168 - val_acc: 0.7533 - lr: 0.1000\n",
            "Epoch 50/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.6765 - acc: 0.8354 - val_loss: 0.9098 - val_acc: 0.7623 - lr: 0.1000\n",
            "Epoch 51/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6484 - acc: 0.8448 - val_loss: 0.9178 - val_acc: 0.7676 - lr: 0.1000\n",
            "Epoch 52/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6655 - acc: 0.8356 - val_loss: 0.8690 - val_acc: 0.7665 - lr: 0.1000\n",
            "Epoch 53/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6602 - acc: 0.8378 - val_loss: 0.8895 - val_acc: 0.7623 - lr: 0.1000\n",
            "Epoch 54/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6362 - acc: 0.8470 - val_loss: 0.9183 - val_acc: 0.7591 - lr: 0.1000\n",
            "Epoch 55/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6386 - acc: 0.8486 - val_loss: 0.9824 - val_acc: 0.7337 - lr: 0.1000\n",
            "Epoch 56/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.6469 - acc: 0.8459 - val_loss: 1.0596 - val_acc: 0.7073 - lr: 0.1000\n",
            "Epoch 57/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.7001 - acc: 0.8283 - val_loss: 0.8674 - val_acc: 0.7766 - lr: 0.1000\n",
            "Epoch 58/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6797 - acc: 0.8327 - val_loss: 0.8456 - val_acc: 0.7713 - lr: 0.1000\n",
            "Epoch 59/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6243 - acc: 0.8613 - val_loss: 0.8133 - val_acc: 0.7988 - lr: 0.1000\n",
            "Epoch 60/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6004 - acc: 0.8637 - val_loss: 0.8999 - val_acc: 0.7814 - lr: 0.1000\n",
            "Epoch 61/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.6439 - acc: 0.8497 - val_loss: 0.7842 - val_acc: 0.7999 - lr: 0.0200\n",
            "Epoch 62/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.5126 - acc: 0.8985 - val_loss: 0.7764 - val_acc: 0.8195 - lr: 0.0200\n",
            "Epoch 63/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.4663 - acc: 0.9206 - val_loss: 0.7568 - val_acc: 0.8147 - lr: 0.0200\n",
            "Epoch 64/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.4350 - acc: 0.9320 - val_loss: 0.7388 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 65/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.4124 - acc: 0.9352 - val_loss: 0.7632 - val_acc: 0.8237 - lr: 0.0200\n",
            "Epoch 66/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.4017 - acc: 0.9395 - val_loss: 0.7560 - val_acc: 0.8301 - lr: 0.0200\n",
            "Epoch 67/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.3724 - acc: 0.9552 - val_loss: 0.7793 - val_acc: 0.8290 - lr: 0.0200\n",
            "Epoch 68/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3774 - acc: 0.9468 - val_loss: 0.7793 - val_acc: 0.8258 - lr: 0.0200\n",
            "Epoch 69/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3616 - acc: 0.9582 - val_loss: 0.8027 - val_acc: 0.8184 - lr: 0.0200\n",
            "Epoch 70/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3527 - acc: 0.9592 - val_loss: 0.7673 - val_acc: 0.8290 - lr: 0.0200\n",
            "Epoch 71/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3514 - acc: 0.9536 - val_loss: 0.7648 - val_acc: 0.8327 - lr: 0.0200\n",
            "Epoch 72/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.3502 - acc: 0.9555 - val_loss: 0.7660 - val_acc: 0.8354 - lr: 0.0200\n",
            "Epoch 73/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3517 - acc: 0.9552 - val_loss: 0.8417 - val_acc: 0.8227 - lr: 0.0200\n",
            "Epoch 74/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3459 - acc: 0.9568 - val_loss: 0.7895 - val_acc: 0.8221 - lr: 0.0200\n",
            "Epoch 75/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3274 - acc: 0.9614 - val_loss: 0.8163 - val_acc: 0.8232 - lr: 0.0200\n",
            "Epoch 76/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.3242 - acc: 0.9611 - val_loss: 0.8223 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 77/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3117 - acc: 0.9676 - val_loss: 0.8132 - val_acc: 0.8274 - lr: 0.0200\n",
            "Epoch 78/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3093 - acc: 0.9669 - val_loss: 0.8050 - val_acc: 0.8370 - lr: 0.0200\n",
            "Epoch 79/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2981 - acc: 0.9722 - val_loss: 0.8407 - val_acc: 0.8306 - lr: 0.0200\n",
            "Epoch 80/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2936 - acc: 0.9725 - val_loss: 0.7781 - val_acc: 0.8380 - lr: 0.0200\n",
            "Epoch 81/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2959 - acc: 0.9714 - val_loss: 0.8159 - val_acc: 0.8274 - lr: 0.0200\n",
            "Epoch 82/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2977 - acc: 0.9679 - val_loss: 0.8197 - val_acc: 0.8290 - lr: 0.0200\n",
            "Epoch 83/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.3000 - acc: 0.9690 - val_loss: 0.8131 - val_acc: 0.8385 - lr: 0.0200\n",
            "Epoch 84/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2769 - acc: 0.9760 - val_loss: 0.8082 - val_acc: 0.8364 - lr: 0.0200\n",
            "Epoch 85/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2680 - acc: 0.9768 - val_loss: 0.8410 - val_acc: 0.8295 - lr: 0.0200\n",
            "Epoch 86/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2709 - acc: 0.9771 - val_loss: 0.8307 - val_acc: 0.8295 - lr: 0.0200\n",
            "Epoch 87/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2760 - acc: 0.9717 - val_loss: 0.8322 - val_acc: 0.8327 - lr: 0.0200\n",
            "Epoch 88/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2847 - acc: 0.9725 - val_loss: 0.8627 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 89/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2773 - acc: 0.9752 - val_loss: 0.8034 - val_acc: 0.8370 - lr: 0.0200\n",
            "Epoch 90/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2679 - acc: 0.9784 - val_loss: 0.8512 - val_acc: 0.8301 - lr: 0.0200\n",
            "Epoch 91/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.2648 - acc: 0.9768 - val_loss: 0.8664 - val_acc: 0.8301 - lr: 0.0200\n",
            "Epoch 92/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2703 - acc: 0.9723 - val_loss: 0.8846 - val_acc: 0.8258 - lr: 0.0200\n",
            "Epoch 93/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2634 - acc: 0.9765 - val_loss: 0.9136 - val_acc: 0.8285 - lr: 0.0200\n",
            "Epoch 94/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2579 - acc: 0.9779 - val_loss: 0.8383 - val_acc: 0.8359 - lr: 0.0200\n",
            "Epoch 95/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2414 - acc: 0.9825 - val_loss: 0.8558 - val_acc: 0.8348 - lr: 0.0200\n",
            "Epoch 96/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2573 - acc: 0.9762 - val_loss: 0.8605 - val_acc: 0.8332 - lr: 0.0200\n",
            "Epoch 97/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2671 - acc: 0.9733 - val_loss: 0.8782 - val_acc: 0.8295 - lr: 0.0200\n",
            "Epoch 98/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2688 - acc: 0.9709 - val_loss: 0.8555 - val_acc: 0.8343 - lr: 0.0200\n",
            "Epoch 99/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2777 - acc: 0.9671 - val_loss: 0.8263 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 100/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.2634 - acc: 0.9719 - val_loss: 0.8499 - val_acc: 0.8348 - lr: 0.0200\n",
            "Epoch 101/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2604 - acc: 0.9722 - val_loss: 0.8443 - val_acc: 0.8322 - lr: 0.0200\n",
            "Epoch 102/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2439 - acc: 0.9803 - val_loss: 0.8499 - val_acc: 0.8280 - lr: 0.0200\n",
            "Epoch 103/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.2323 - acc: 0.9830 - val_loss: 0.8826 - val_acc: 0.8311 - lr: 0.0200\n",
            "Epoch 104/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2372 - acc: 0.9816 - val_loss: 0.9028 - val_acc: 0.8295 - lr: 0.0200\n",
            "Epoch 105/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.2489 - acc: 0.9771 - val_loss: 0.9217 - val_acc: 0.8158 - lr: 0.0200\n",
            "Epoch 106/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2406 - acc: 0.9784 - val_loss: 0.9554 - val_acc: 0.8211 - lr: 0.0200\n",
            "Epoch 107/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2456 - acc: 0.9779 - val_loss: 0.8998 - val_acc: 0.8158 - lr: 0.0200\n",
            "Epoch 108/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2461 - acc: 0.9773 - val_loss: 0.8753 - val_acc: 0.8290 - lr: 0.0200\n",
            "Epoch 109/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2450 - acc: 0.9781 - val_loss: 0.8858 - val_acc: 0.8375 - lr: 0.0200\n",
            "Epoch 110/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2291 - acc: 0.9814 - val_loss: 0.9060 - val_acc: 0.8253 - lr: 0.0200\n",
            "Epoch 111/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.2453 - acc: 0.9725 - val_loss: 0.9019 - val_acc: 0.8216 - lr: 0.0200\n",
            "Epoch 112/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2454 - acc: 0.9757 - val_loss: 0.8719 - val_acc: 0.8348 - lr: 0.0200\n",
            "Epoch 113/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2428 - acc: 0.9762 - val_loss: 0.8157 - val_acc: 0.8327 - lr: 0.0200\n",
            "Epoch 114/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2250 - acc: 0.9816 - val_loss: 0.8727 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 115/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2300 - acc: 0.9806 - val_loss: 0.8446 - val_acc: 0.8274 - lr: 0.0200\n",
            "Epoch 116/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.2241 - acc: 0.9819 - val_loss: 0.9036 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 117/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2286 - acc: 0.9784 - val_loss: 0.9548 - val_acc: 0.8290 - lr: 0.0200\n",
            "Epoch 118/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2279 - acc: 0.9787 - val_loss: 0.8604 - val_acc: 0.8301 - lr: 0.0200\n",
            "Epoch 119/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2262 - acc: 0.9816 - val_loss: 0.9540 - val_acc: 0.8142 - lr: 0.0200\n",
            "Epoch 120/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2367 - acc: 0.9773 - val_loss: 1.0116 - val_acc: 0.8242 - lr: 0.0200\n",
            "Epoch 121/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2355 - acc: 0.9779 - val_loss: 0.8868 - val_acc: 0.8306 - lr: 0.0040\n",
            "Epoch 122/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.2035 - acc: 0.9895 - val_loss: 0.8483 - val_acc: 0.8396 - lr: 0.0040\n",
            "Epoch 123/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1935 - acc: 0.9933 - val_loss: 0.8939 - val_acc: 0.8332 - lr: 0.0040\n",
            "Epoch 124/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1834 - acc: 0.9973 - val_loss: 0.8655 - val_acc: 0.8348 - lr: 0.0040\n",
            "Epoch 125/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1815 - acc: 0.9973 - val_loss: 0.8358 - val_acc: 0.8412 - lr: 0.0040\n",
            "Epoch 126/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1811 - acc: 0.9970 - val_loss: 0.8644 - val_acc: 0.8412 - lr: 0.0040\n",
            "Epoch 127/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1810 - acc: 0.9970 - val_loss: 0.8528 - val_acc: 0.8412 - lr: 0.0040\n",
            "Epoch 128/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1815 - acc: 0.9962 - val_loss: 0.8234 - val_acc: 0.8401 - lr: 0.0040\n",
            "Epoch 129/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1796 - acc: 0.9957 - val_loss: 0.8412 - val_acc: 0.8417 - lr: 0.0040\n",
            "Epoch 130/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.1768 - acc: 0.9987 - val_loss: 0.8863 - val_acc: 0.8364 - lr: 0.0040\n",
            "Epoch 131/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1758 - acc: 0.9981 - val_loss: 0.8426 - val_acc: 0.8417 - lr: 0.0040\n",
            "Epoch 132/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1760 - acc: 0.9973 - val_loss: 0.8671 - val_acc: 0.8375 - lr: 0.0040\n",
            "Epoch 133/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1751 - acc: 0.9984 - val_loss: 0.8746 - val_acc: 0.8407 - lr: 0.0040\n",
            "Epoch 134/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1731 - acc: 0.9978 - val_loss: 0.8599 - val_acc: 0.8375 - lr: 0.0040\n",
            "Epoch 135/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1723 - acc: 0.9984 - val_loss: 0.8524 - val_acc: 0.8412 - lr: 0.0040\n",
            "Epoch 136/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1711 - acc: 0.9992 - val_loss: 0.8586 - val_acc: 0.8370 - lr: 0.0040\n",
            "Epoch 137/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1700 - acc: 0.9987 - val_loss: 0.8416 - val_acc: 0.8417 - lr: 0.0040\n",
            "Epoch 138/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.1703 - acc: 0.9981 - val_loss: 0.8438 - val_acc: 0.8428 - lr: 0.0040\n",
            "Epoch 139/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1711 - acc: 0.9992 - val_loss: 0.9540 - val_acc: 0.8327 - lr: 0.0040\n",
            "Epoch 140/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1691 - acc: 0.9992 - val_loss: 0.8586 - val_acc: 0.8370 - lr: 0.0040\n",
            "Epoch 141/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1683 - acc: 0.9987 - val_loss: 0.8501 - val_acc: 0.8375 - lr: 0.0040\n",
            "Epoch 142/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1674 - acc: 0.9995 - val_loss: 0.8923 - val_acc: 0.8380 - lr: 0.0040\n",
            "Epoch 143/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1680 - acc: 0.9987 - val_loss: 0.9081 - val_acc: 0.8412 - lr: 0.0040\n",
            "Epoch 144/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1679 - acc: 0.9978 - val_loss: 0.8757 - val_acc: 0.8396 - lr: 0.0040\n",
            "Epoch 145/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1674 - acc: 0.9987 - val_loss: 0.8339 - val_acc: 0.8422 - lr: 0.0040\n",
            "Epoch 146/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.1663 - acc: 0.9981 - val_loss: 0.8663 - val_acc: 0.8401 - lr: 0.0040\n",
            "Epoch 147/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1666 - acc: 0.9992 - val_loss: 0.8426 - val_acc: 0.8428 - lr: 0.0040\n",
            "Epoch 148/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1658 - acc: 0.9989 - val_loss: 0.8604 - val_acc: 0.8391 - lr: 0.0040\n",
            "Epoch 149/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1675 - acc: 0.9981 - val_loss: 0.8633 - val_acc: 0.8391 - lr: 0.0040\n",
            "Epoch 150/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1640 - acc: 0.9989 - val_loss: 0.8390 - val_acc: 0.8428 - lr: 0.0040\n",
            "Epoch 151/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1649 - acc: 0.9992 - val_loss: 0.9019 - val_acc: 0.8348 - lr: 0.0040\n",
            "Epoch 152/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1648 - acc: 0.9984 - val_loss: 0.8650 - val_acc: 0.8385 - lr: 0.0040\n",
            "Epoch 153/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1641 - acc: 0.9989 - val_loss: 0.8661 - val_acc: 0.8422 - lr: 0.0040\n",
            "Epoch 154/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1646 - acc: 0.9981 - val_loss: 0.8560 - val_acc: 0.8428 - lr: 0.0040\n",
            "Epoch 155/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1613 - acc: 0.9995 - val_loss: 0.8564 - val_acc: 0.8417 - lr: 0.0040\n",
            "Epoch 156/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1620 - acc: 0.9987 - val_loss: 0.8594 - val_acc: 0.8470 - lr: 0.0040\n",
            "Epoch 157/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.1603 - acc: 0.9992 - val_loss: 0.8543 - val_acc: 0.8428 - lr: 0.0040\n",
            "Epoch 158/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1611 - acc: 0.9984 - val_loss: 0.8877 - val_acc: 0.8391 - lr: 0.0040\n",
            "Epoch 159/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1602 - acc: 0.9989 - val_loss: 0.8624 - val_acc: 0.8364 - lr: 0.0040\n",
            "Epoch 160/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1593 - acc: 0.9992 - val_loss: 0.8629 - val_acc: 0.8428 - lr: 0.0040\n",
            "Epoch 161/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1605 - acc: 0.9987 - val_loss: 0.8717 - val_acc: 0.8412 - lr: 8.0000e-04\n",
            "Epoch 162/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.1588 - acc: 0.9992 - val_loss: 0.8668 - val_acc: 0.8417 - lr: 8.0000e-04\n",
            "Epoch 163/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1596 - acc: 0.9992 - val_loss: 0.8819 - val_acc: 0.8433 - lr: 8.0000e-04\n",
            "Epoch 164/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1599 - acc: 0.9992 - val_loss: 0.8631 - val_acc: 0.8433 - lr: 8.0000e-04\n",
            "Epoch 165/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1580 - acc: 0.9997 - val_loss: 0.8982 - val_acc: 0.8454 - lr: 8.0000e-04\n",
            "Epoch 166/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.1599 - acc: 0.9978 - val_loss: 0.8381 - val_acc: 0.8428 - lr: 8.0000e-04\n",
            "Epoch 167/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1595 - acc: 0.9992 - val_loss: 0.8631 - val_acc: 0.8417 - lr: 8.0000e-04\n",
            "Epoch 168/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1578 - acc: 0.9995 - val_loss: 0.8768 - val_acc: 0.8417 - lr: 8.0000e-04\n",
            "Epoch 169/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1584 - acc: 0.9989 - val_loss: 0.8421 - val_acc: 0.8460 - lr: 8.0000e-04\n",
            "Epoch 170/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.1590 - acc: 0.9987 - val_loss: 0.8518 - val_acc: 0.8449 - lr: 8.0000e-04\n",
            "Epoch 171/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1592 - acc: 0.9992 - val_loss: 0.8428 - val_acc: 0.8444 - lr: 8.0000e-04\n",
            "Epoch 172/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1607 - acc: 0.9984 - val_loss: 0.8497 - val_acc: 0.8481 - lr: 8.0000e-04\n",
            "Epoch 173/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.1591 - acc: 0.9992 - val_loss: 0.8468 - val_acc: 0.8433 - lr: 8.0000e-04\n",
            "Epoch 174/200\n",
            "29/29 [==============================] - 4s 143ms/step - loss: 0.1573 - acc: 0.9995 - val_loss: 0.8412 - val_acc: 0.8481 - lr: 8.0000e-04\n",
            "Epoch 175/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1591 - acc: 0.9992 - val_loss: 0.8727 - val_acc: 0.8422 - lr: 8.0000e-04\n",
            "Epoch 176/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1565 - acc: 1.0000 - val_loss: 0.8420 - val_acc: 0.8507 - lr: 8.0000e-04\n",
            "Epoch 177/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1588 - acc: 0.9997 - val_loss: 0.8808 - val_acc: 0.8407 - lr: 8.0000e-04\n",
            "Epoch 178/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1567 - acc: 0.9997 - val_loss: 0.8686 - val_acc: 0.8401 - lr: 8.0000e-04\n",
            "Epoch 179/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1571 - acc: 0.9995 - val_loss: 0.8472 - val_acc: 0.8444 - lr: 8.0000e-04\n",
            "Epoch 180/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1582 - acc: 0.9995 - val_loss: 0.8538 - val_acc: 0.8380 - lr: 8.0000e-04\n",
            "Epoch 181/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1572 - acc: 0.9997 - val_loss: 0.8558 - val_acc: 0.8370 - lr: 8.0000e-04\n",
            "Epoch 182/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1582 - acc: 0.9992 - val_loss: 0.8725 - val_acc: 0.8407 - lr: 8.0000e-04\n",
            "Epoch 183/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1585 - acc: 0.9995 - val_loss: 0.8399 - val_acc: 0.8497 - lr: 8.0000e-04\n",
            "Epoch 184/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1565 - acc: 0.9997 - val_loss: 0.8621 - val_acc: 0.8460 - lr: 8.0000e-04\n",
            "Epoch 185/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1588 - acc: 0.9984 - val_loss: 0.8379 - val_acc: 0.8470 - lr: 8.0000e-04\n",
            "Epoch 186/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1581 - acc: 0.9992 - val_loss: 0.8647 - val_acc: 0.8470 - lr: 8.0000e-04\n",
            "Epoch 187/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1572 - acc: 0.9989 - val_loss: 0.8550 - val_acc: 0.8481 - lr: 8.0000e-04\n",
            "Epoch 188/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.1586 - acc: 0.9987 - val_loss: 0.8598 - val_acc: 0.8460 - lr: 8.0000e-04\n",
            "Epoch 189/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1578 - acc: 0.9984 - val_loss: 0.8640 - val_acc: 0.8401 - lr: 8.0000e-04\n",
            "Epoch 190/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.1566 - acc: 1.0000 - val_loss: 0.8468 - val_acc: 0.8475 - lr: 8.0000e-04\n",
            "Epoch 191/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.1569 - acc: 0.9995 - val_loss: 0.8848 - val_acc: 0.8433 - lr: 8.0000e-04\n",
            "Epoch 192/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1570 - acc: 0.9995 - val_loss: 0.8569 - val_acc: 0.8449 - lr: 8.0000e-04\n",
            "Epoch 193/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1576 - acc: 0.9992 - val_loss: 0.8656 - val_acc: 0.8422 - lr: 8.0000e-04\n",
            "Epoch 194/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1550 - acc: 1.0000 - val_loss: 0.8541 - val_acc: 0.8396 - lr: 8.0000e-04\n",
            "Epoch 195/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1562 - acc: 0.9995 - val_loss: 0.8675 - val_acc: 0.8454 - lr: 8.0000e-04\n",
            "Epoch 196/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1557 - acc: 0.9992 - val_loss: 0.8536 - val_acc: 0.8523 - lr: 8.0000e-04\n",
            "Epoch 197/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1562 - acc: 0.9997 - val_loss: 0.8423 - val_acc: 0.8497 - lr: 8.0000e-04\n",
            "Epoch 198/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.1570 - acc: 0.9987 - val_loss: 0.8640 - val_acc: 0.8428 - lr: 8.0000e-04\n",
            "Epoch 199/200\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 0.1550 - acc: 0.9997 - val_loss: 0.8609 - val_acc: 0.8433 - lr: 8.0000e-04\n",
            "Epoch 200/200\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.1558 - acc: 0.9995 - val_loss: 0.8555 - val_acc: 0.8444 - lr: 8.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn28_10.save(\"model_last.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Paxp_UhrduV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = X_train[8]\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO-_q-QUsn-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIs_x5kasn9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(wrn28_10(image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFw-Cjamdsi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "8b6ca513-0be5-4309-e591-fa5456ab5ffd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "45ed350a-d41e-4ff5-d7ca-6dc03a195842"
      },
      "source": [
        "wrn_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 1s 12ms/step - loss: 0.8555 - acc: 0.8444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8555046319961548, 0.8443620800971985]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmZpcppX5u_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d06a13b9-bf89-4a2d-b924-005c6b2accdf"
      },
      "source": [
        "wrn_16_2.evaluate(X_train,y_train)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - 1s 12ms/step - loss: 0.1524 - acc: 0.9997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1523597091436386, 0.9997391104698181]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}