{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqbIFJTwXLH",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "030355c8-0797-4bb1-a64a-c51b8864b736"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0001\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "    wrn_16_2.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 32, 32, 16)   144         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 32, 32, 16)   64          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 32, 32, 16)   0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 32, 32, 32)   4608        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 32, 32, 32)   128         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 32, 32, 32)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 32, 32, 32)   9216        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 32, 32, 32)   512         activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 32, 32, 32)   0           conv2d_98[0][0]                  \n",
            "                                                                 conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 32, 32, 32)   128         add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 32, 32, 32)   0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 32, 32, 32)   9216        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 32, 32, 32)   0           conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 32, 32, 32)   128         dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 32, 32, 32)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 32, 32, 32)   9216        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 32, 32, 32)   0           add_36[0][0]                     \n",
            "                                                                 conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 32, 32, 32)   128         add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 32, 32, 32)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   18432       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 16, 16, 64)   256         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 16, 16, 64)   0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 64)   36864       activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 64)   2048        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 16, 16, 64)   0           conv2d_103[0][0]                 \n",
            "                                                                 conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 16, 16, 64)   256         add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 16, 16, 64)   0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 64)   36864       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 64)   0           conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 16, 16, 64)   256         dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 16, 16, 64)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   36864       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 16, 16, 64)   0           add_38[0][0]                     \n",
            "                                                                 conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 16, 16, 64)   256         add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 16, 16, 64)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 8, 8, 128)    73728       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 128)    512         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 128)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 8, 8, 128)    147456      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 8, 8, 128)    8192        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 8, 8, 128)    0           conv2d_108[0][0]                 \n",
            "                                                                 conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 128)    512         add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 128)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 8, 8, 128)    147456      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 8, 8, 128)    0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 128)    512         dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 128)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 8, 8, 128)    147456      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 8, 8, 128)    0           add_40[0][0]                     \n",
            "                                                                 conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 128)    512         add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 128)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 1, 1, 128)    0           activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 128)          0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 4)            516         flatten_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 692,436\n",
            "Trainable params: 690,612\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNo5x-Ft9Fe",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepare and Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRh7YDqiuqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('data_set.pickle', 'rb') as f:\n",
        "    x = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONi_4KtjjNE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train,X_test, y_test, X_val, y_val = x['X_train'], x['y_train'], x['X_test'], x['y_test'], x['X_val'], x['y_val']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8a89af9-b15e-428f-81f2-ba981804c810"
      },
      "source": [
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2266e79c-ba96-48fd-9247-86b41b5c9362"
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQdrnTKuM8c",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hwq9R2jruF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "fde82827-16be-4fb3-93a9-d908e5350f28"
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "closed           1500\n",
              "open             1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAYuiEzj4Bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0289812a-6ff3-4727-9b99-fe5276b85a17"
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kif3Li9NuSnV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "import tensorflow\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 128\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fe43458-2453-4180-aaf7-fed9fecc1983"
      },
      "source": [
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 30:\n",
        "        return 0.1\n",
        "    elif epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch < 60:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "667112ab-7e45-43b4-fbf6-95adc9b26425"
      },
      "source": [
        "hist = wrn_16_2.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 1.5968 - acc: 0.2887 - val_loss: 1.5523 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.5177 - acc: 0.3644 - val_loss: 1.4944 - val_acc: 0.3553 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.4817 - acc: 0.3686 - val_loss: 1.5421 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.4696 - acc: 0.3806 - val_loss: 1.4461 - val_acc: 0.3825 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.4390 - acc: 0.3946 - val_loss: 1.4198 - val_acc: 0.4311 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.4277 - acc: 0.4203 - val_loss: 1.4223 - val_acc: 0.4272 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.4161 - acc: 0.4265 - val_loss: 1.4206 - val_acc: 0.4039 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4081 - acc: 0.4239 - val_loss: 1.3780 - val_acc: 0.4563 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.3903 - acc: 0.4543 - val_loss: 1.3802 - val_acc: 0.4757 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.3719 - acc: 0.4916 - val_loss: 1.3552 - val_acc: 0.5146 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.3420 - acc: 0.5138 - val_loss: 1.3238 - val_acc: 0.5359 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.3060 - acc: 0.5348 - val_loss: 1.3135 - val_acc: 0.5437 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.2819 - acc: 0.5464 - val_loss: 1.2836 - val_acc: 0.5282 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.2473 - acc: 0.5690 - val_loss: 1.1906 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.2211 - acc: 0.5839 - val_loss: 1.2597 - val_acc: 0.5612 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.2297 - acc: 0.5857 - val_loss: 1.3231 - val_acc: 0.5359 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.1772 - acc: 0.6021 - val_loss: 1.2012 - val_acc: 0.6039 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.1467 - acc: 0.6134 - val_loss: 1.0857 - val_acc: 0.6291 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.0990 - acc: 0.6347 - val_loss: 1.1452 - val_acc: 0.6175 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.1167 - acc: 0.6358 - val_loss: 1.0988 - val_acc: 0.6544 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.0698 - acc: 0.6571 - val_loss: 1.2731 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.0429 - acc: 0.6671 - val_loss: 1.0747 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.0128 - acc: 0.6707 - val_loss: 1.0902 - val_acc: 0.6641 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.9995 - acc: 0.6829 - val_loss: 1.0860 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.9993 - acc: 0.6873 - val_loss: 1.0466 - val_acc: 0.6660 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.9876 - acc: 0.6944 - val_loss: 1.0822 - val_acc: 0.6777 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.9469 - acc: 0.7151 - val_loss: 1.0636 - val_acc: 0.6583 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.9556 - acc: 0.6984 - val_loss: 1.2248 - val_acc: 0.5864 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.9447 - acc: 0.7093 - val_loss: 1.0476 - val_acc: 0.6874 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.9273 - acc: 0.7162 - val_loss: 1.0054 - val_acc: 0.7126 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.9330 - acc: 0.7155 - val_loss: 1.0164 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8916 - acc: 0.7315 - val_loss: 0.9829 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8717 - acc: 0.7452 - val_loss: 0.9727 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8591 - acc: 0.7428 - val_loss: 0.9755 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8520 - acc: 0.7530 - val_loss: 0.9420 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8618 - acc: 0.7412 - val_loss: 0.9673 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8464 - acc: 0.7565 - val_loss: 0.9583 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8496 - acc: 0.7492 - val_loss: 0.9766 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8583 - acc: 0.7479 - val_loss: 0.9616 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8413 - acc: 0.7550 - val_loss: 0.9530 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8426 - acc: 0.7557 - val_loss: 0.9700 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8416 - acc: 0.7577 - val_loss: 1.0036 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8365 - acc: 0.7583 - val_loss: 0.9554 - val_acc: 0.7282 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8367 - acc: 0.7521 - val_loss: 0.9684 - val_acc: 0.7282 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8276 - acc: 0.7583 - val_loss: 0.9664 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8347 - acc: 0.7577 - val_loss: 0.9624 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8262 - acc: 0.7557 - val_loss: 0.9999 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8343 - acc: 0.7563 - val_loss: 0.9543 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8225 - acc: 0.7672 - val_loss: 0.9584 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8357 - acc: 0.7592 - val_loss: 0.9463 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8240 - acc: 0.7659 - val_loss: 0.9806 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8276 - acc: 0.7628 - val_loss: 0.9786 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8230 - acc: 0.7583 - val_loss: 0.9576 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8202 - acc: 0.7605 - val_loss: 0.9977 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8235 - acc: 0.7577 - val_loss: 0.9706 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8274 - acc: 0.7648 - val_loss: 0.9679 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8248 - acc: 0.7643 - val_loss: 0.9601 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8291 - acc: 0.7550 - val_loss: 0.9697 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8257 - acc: 0.7592 - val_loss: 0.9721 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8238 - acc: 0.7597 - val_loss: 0.9525 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8157 - acc: 0.7656 - val_loss: 0.9548 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8202 - acc: 0.7734 - val_loss: 0.9813 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8244 - acc: 0.7674 - val_loss: 1.0269 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8208 - acc: 0.7641 - val_loss: 0.9356 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8165 - acc: 0.7699 - val_loss: 0.9475 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8198 - acc: 0.7590 - val_loss: 0.9709 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8248 - acc: 0.7523 - val_loss: 0.9383 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8140 - acc: 0.7676 - val_loss: 0.9767 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8219 - acc: 0.7581 - val_loss: 0.9592 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8173 - acc: 0.7592 - val_loss: 0.9639 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8253 - acc: 0.7603 - val_loss: 1.0317 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8215 - acc: 0.7617 - val_loss: 0.9433 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8257 - acc: 0.7565 - val_loss: 0.9764 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8219 - acc: 0.7579 - val_loss: 0.9653 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8274 - acc: 0.7590 - val_loss: 0.9451 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8168 - acc: 0.7645 - val_loss: 0.9433 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8254 - acc: 0.7617 - val_loss: 0.9492 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8291 - acc: 0.7545 - val_loss: 0.9667 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8319 - acc: 0.7552 - val_loss: 0.9548 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8132 - acc: 0.7683 - val_loss: 0.9632 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8241 - acc: 0.7599 - val_loss: 0.9503 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8167 - acc: 0.7643 - val_loss: 0.9461 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8292 - acc: 0.7572 - val_loss: 0.9554 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8178 - acc: 0.7621 - val_loss: 0.9811 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8127 - acc: 0.7617 - val_loss: 0.9585 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8310 - acc: 0.7550 - val_loss: 0.9397 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8241 - acc: 0.7625 - val_loss: 0.9679 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8161 - acc: 0.7681 - val_loss: 0.9554 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8245 - acc: 0.7594 - val_loss: 0.9493 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8273 - acc: 0.7581 - val_loss: 0.9752 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8202 - acc: 0.7619 - val_loss: 0.9543 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8211 - acc: 0.7605 - val_loss: 0.9515 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8206 - acc: 0.7594 - val_loss: 0.9616 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8181 - acc: 0.7610 - val_loss: 0.9832 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8210 - acc: 0.7581 - val_loss: 0.9653 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8208 - acc: 0.7608 - val_loss: 0.9679 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8114 - acc: 0.7694 - val_loss: 1.0202 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8193 - acc: 0.7654 - val_loss: 1.0054 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8214 - acc: 0.7594 - val_loss: 0.9813 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8264 - acc: 0.7559 - val_loss: 0.9565 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8155 - acc: 0.7665 - val_loss: 0.9903 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8274 - acc: 0.7550 - val_loss: 0.9495 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8211 - acc: 0.7597 - val_loss: 0.9556 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8216 - acc: 0.7672 - val_loss: 0.9650 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8309 - acc: 0.7523 - val_loss: 0.9620 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8197 - acc: 0.7623 - val_loss: 0.9702 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8139 - acc: 0.7600 - val_loss: 0.9466 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8250 - acc: 0.7581 - val_loss: 0.9471 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8277 - acc: 0.7554 - val_loss: 0.9412 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8201 - acc: 0.7570 - val_loss: 0.9765 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8374 - acc: 0.7548 - val_loss: 1.0087 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8243 - acc: 0.7577 - val_loss: 0.9867 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8215 - acc: 0.7583 - val_loss: 0.9459 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8283 - acc: 0.7574 - val_loss: 0.9566 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8232 - acc: 0.7612 - val_loss: 1.0302 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8221 - acc: 0.7585 - val_loss: 0.9567 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8168 - acc: 0.7636 - val_loss: 0.9622 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8219 - acc: 0.7585 - val_loss: 0.9395 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8246 - acc: 0.7579 - val_loss: 0.9636 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8255 - acc: 0.7621 - val_loss: 0.9751 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8189 - acc: 0.7654 - val_loss: 0.9534 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8086 - acc: 0.7703 - val_loss: 0.9455 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8219 - acc: 0.7599 - val_loss: 0.9766 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8258 - acc: 0.7590 - val_loss: 0.9628 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8340 - acc: 0.7474 - val_loss: 0.9701 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8183 - acc: 0.7632 - val_loss: 0.9518 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8187 - acc: 0.7630 - val_loss: 0.9420 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8164 - acc: 0.7552 - val_loss: 0.9631 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8228 - acc: 0.7643 - val_loss: 0.9613 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8151 - acc: 0.7636 - val_loss: 0.9393 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8272 - acc: 0.7590 - val_loss: 0.9679 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8128 - acc: 0.7603 - val_loss: 0.9667 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8289 - acc: 0.7563 - val_loss: 0.9771 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8142 - acc: 0.7650 - val_loss: 0.9595 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8142 - acc: 0.7672 - val_loss: 1.0081 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8151 - acc: 0.7641 - val_loss: 0.9560 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8259 - acc: 0.7559 - val_loss: 0.9873 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8209 - acc: 0.7612 - val_loss: 0.9568 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8167 - acc: 0.7672 - val_loss: 1.0281 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8255 - acc: 0.7583 - val_loss: 0.9460 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8235 - acc: 0.7605 - val_loss: 0.9558 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8253 - acc: 0.7663 - val_loss: 0.9547 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8154 - acc: 0.7632 - val_loss: 0.9716 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8248 - acc: 0.7581 - val_loss: 0.9702 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8187 - acc: 0.7561 - val_loss: 1.0131 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8141 - acc: 0.7659 - val_loss: 0.9837 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8238 - acc: 0.7610 - val_loss: 0.9577 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8209 - acc: 0.7674 - val_loss: 0.9721 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8233 - acc: 0.7572 - val_loss: 0.9446 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8220 - acc: 0.7654 - val_loss: 1.0010 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8227 - acc: 0.7641 - val_loss: 1.0108 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8217 - acc: 0.7624 - val_loss: 0.9991 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8217 - acc: 0.7603 - val_loss: 0.9715 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8250 - acc: 0.7603 - val_loss: 0.9812 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8185 - acc: 0.7643 - val_loss: 0.9540 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8154 - acc: 0.7663 - val_loss: 1.0014 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8147 - acc: 0.7621 - val_loss: 0.9904 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8160 - acc: 0.7656 - val_loss: 0.9494 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8146 - acc: 0.7568 - val_loss: 0.9552 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8248 - acc: 0.7605 - val_loss: 0.9637 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8158 - acc: 0.7661 - val_loss: 0.9546 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8204 - acc: 0.7672 - val_loss: 0.9502 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8224 - acc: 0.7636 - val_loss: 0.9616 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8275 - acc: 0.7590 - val_loss: 0.9497 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8148 - acc: 0.7676 - val_loss: 0.9971 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8242 - acc: 0.7628 - val_loss: 1.0037 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8200 - acc: 0.7605 - val_loss: 0.9506 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8207 - acc: 0.7561 - val_loss: 0.9521 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8263 - acc: 0.7599 - val_loss: 0.9576 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8309 - acc: 0.7550 - val_loss: 0.9760 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8197 - acc: 0.7669 - val_loss: 0.9619 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8139 - acc: 0.7661 - val_loss: 0.9476 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8285 - acc: 0.7537 - val_loss: 0.9710 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8095 - acc: 0.7654 - val_loss: 0.9612 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8188 - acc: 0.7632 - val_loss: 0.9594 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8256 - acc: 0.7603 - val_loss: 0.9764 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8252 - acc: 0.7581 - val_loss: 0.9657 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8207 - acc: 0.7672 - val_loss: 0.9590 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8195 - acc: 0.7672 - val_loss: 1.0009 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8266 - acc: 0.7621 - val_loss: 0.9478 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8277 - acc: 0.7594 - val_loss: 0.9561 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8187 - acc: 0.7639 - val_loss: 0.9513 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8182 - acc: 0.7688 - val_loss: 0.9759 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8178 - acc: 0.7634 - val_loss: 0.9547 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8124 - acc: 0.7659 - val_loss: 0.9600 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8169 - acc: 0.7588 - val_loss: 0.9453 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8182 - acc: 0.7652 - val_loss: 0.9683 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8249 - acc: 0.7612 - val_loss: 0.9651 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8266 - acc: 0.7603 - val_loss: 0.9585 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8204 - acc: 0.7559 - val_loss: 0.9419 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8191 - acc: 0.7674 - val_loss: 0.9580 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8224 - acc: 0.7621 - val_loss: 0.9820 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8167 - acc: 0.7671 - val_loss: 0.9617 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8195 - acc: 0.7648 - val_loss: 0.9558 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8130 - acc: 0.7656 - val_loss: 0.9745 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8225 - acc: 0.7574 - val_loss: 0.9459 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8183 - acc: 0.7650 - val_loss: 0.9645 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.8204 - acc: 0.7623 - val_loss: 0.9580 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8118 - acc: 0.7665 - val_loss: 0.9901 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8252 - acc: 0.7588 - val_loss: 0.9659 - val_acc: 0.7262 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.save(\"wrn_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djH4uwAnvkfb",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "c692763a-8f23-4947-878b-52264d50539d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a2fcea8a-df01-41c4-9566-5129f8c87150"
      },
      "source": [
        "wrn_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 0.9431 - acc: 0.7225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9430834054946899, 0.7225130796432495]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDHJIheU8bm",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QB8zFSSU7Qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f1f16779-09b8-41ff-9675-923a506e900f"
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans from git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.6/dist-packages (from cleverhans) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bfZ4G8W_sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "\n",
        "logits_model = tf.keras.Model(wrn_16_2.input,wrn_16_2.layers[-1].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWIlakqVD_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv = []\n",
        "epsilon_list = [0.02]\n",
        "for j in range(len(epsilon_list)):\n",
        "  epsilon = epsilon_list[j]\n",
        "  for i in range(len(X_test)):\n",
        "    random_index = i\n",
        "    original_image = X_test[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_test[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8XZJIGBkUku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d01098ea-f914-4b38-bb45-379668d68add"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 1.0489 - acc: 0.6911\n",
            "epsilon: 0.003 and test evalution : [1.0489426851272583, 0.6910994648933411]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB2PbXrudUWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1095dfa1-7b14-4bd0-c803-233f6984270a"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.228538513183594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1DCXV9Tc9B0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "492ad00d-dbd5-462a-8cf8-917b151bf2f7"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 1.1244 - acc: 0.6614\n",
            "epsilon: 0.005 and test evalution : [1.124449372291565, 0.661431074142456]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGgsDCDodU_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3686bfaa-b695-4e0b-e6d4-352d3be899b4"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.79124450683594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Ah3eA2kYBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "28105974-2f9c-475d-dfab-d5a402d223f0"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 1.3272 - acc: 0.5689\n",
            "epsilon: 0.01 and test evalution : [1.3272491693496704, 0.5689354538917542]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjfdNA70dVoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "823284d4-c58c-40dd-88a1-3857d942695c"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.77065086364746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xed10n0QmMqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b80f9c7d-4342-4724-d02d-ee56a1eb2b24"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 1.7637 - acc: 0.4642\n",
            "epsilon: 0.02 and test evalution : [1.7636723518371582, 0.46422338485717773]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbqrQrSZdWX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "149bfd90-9342-47ea-a757-4796ebd05a8d"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.75005006790161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuWpwrKuwmsc",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p3bOQqOO5yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adversarial_example(epsilon):\n",
        "  X_adv = []\n",
        "  for i in range(len(X_test)):\n",
        "    random_index = i\n",
        "    original_image = X_test[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_test[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "  return X_adv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOvOBknOPTHx",
        "colab_type": "text"
      },
      "source": [
        "**Mini batch training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDxVNgZvPRHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Adversarial Training \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "class AdversarialTraining(object):\n",
        "    \"\"\"Adversarial Training  \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def train(self, model, X_train, pretrained_model, Y_train, epochs, batch_size, epsilon, model_type= \"Parseval\"):\n",
        "        \n",
        "        step_on_epoch = len(X_train[0]/batch_size)\n",
        "        for epoch in range(0, epochs):\n",
        "            for j in range(0, step_on_epoch):\n",
        "                self.mini_batch_train(model,X_train, Y_train, batch_size, pretrained_model)\n",
        "            ###TODO###\n",
        "            ### add validation test\n",
        "\n",
        "\n",
        "    def mini_batch_train(self, model, X_train,Y_train, batch_size, pretrained_model):\n",
        "\n",
        "        x_train, y_train = self.data_augmentation(X_train, Y_train, batch_size, start_index)\n",
        "        hist = model.fit(x_train, y_train, batch_size=batch_size, epochs = 1, steps_per_epoch=1)\n",
        "        ### TODO ###\n",
        "        ## Save hist on file.###\n",
        "\n",
        "\n",
        "    def data_augmentation(self, X_train, Y_train, batch_size, pretrained_model):\n",
        "      ### divide data 16,16,16,16 for 4 different epsilons and 64 is true image. ### \n",
        "        start_index = data_iteration(X_train, batch_size)\n",
        "        first_half_end = start_index+batch_size/2\n",
        "        second_half_end = start_index+batch_size\n",
        "        x_clean, y_clean = X_train[start_index:first_half_end,:,:,:], Y_train[start_index:first_half_end]\n",
        "        x_adv, y_adv = self.get_adversarial(X_train[first_half_end:second_half_end),:,:,:], Y_train[first_half_end:second_half_end], epsilon), Y_train[first_half_end:second_half_end]\n",
        "        ### TODO###\n",
        "        # Mixture data for 4 epsilon values\n",
        "        return x_mix, y_mix\n",
        "\n",
        "    def data_iteration(self, X_train, batch_size):\n",
        "        N = x_train.shape[0]\n",
        "        start = np.random.randint(0, N-batch_size)\n",
        "        return start\n",
        "\n",
        "    def get_adversarial(self, X_true, y_true, epsilon):\n",
        "\n",
        "        return self.adversarial_example(X_true, y_true, epsilon)\n",
        "\n",
        "    def adversarial_example(self, X_true, y_true, epsilon):\n",
        "      X_adv = []\n",
        "      for i in range(len(X_true)):\n",
        "        random_index = i\n",
        "        original_image = X_true[random_index]\n",
        "        original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "        original_label = y_true[random_index]\n",
        "        original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "        adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "        X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "      return X_adv\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}