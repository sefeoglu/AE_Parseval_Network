{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "46069cb5-e53e-4366-ece5-864d38ca4138"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "import tensorflow\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tensorflow Version: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqbIFJTwXLH",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d0d786cb-11c0-4657-f92e-2e1973111cf4"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0001\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "if __name__ == \"__main__\":\n",
        "  init = (32, 32,1)\n",
        "  wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNo5x-Ft9Fe",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepare and Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c57bf881-6dc1-41bf-b55c-09f588254505"
      },
      "source": [
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74275ae5-54c8-4513-cfec-48e0fe831f54"
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQdrnTKuM8c",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb5M1kDQnX5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "x_train, X_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kif3Li9NuSnV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 30:\n",
        "        return 0.1\n",
        "    elif epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch < 60:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import  KFold\n",
        "\n",
        "class Non_adversarial(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train_iterate(self, X_train, Y_train, X_test, y_test, epochs, BS,sgd, epsilon_list):\n",
        "          init = (32, 32,1)\n",
        "          res_df = pd.DataFrame(columns=['loss_clean','acc_clean',\n",
        "                                  'loss1', 'acc1','loss2', 'acc2','loss3',\n",
        "                                    'acc3','loss4', 'acc4'])\n",
        "          kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
        "          \n",
        "          for j, (train, val) in enumerate(kf.split(X_train)):\n",
        "            x_train, y_train,  x_val, y_val = X_train[train], Y_train[train], X_train[val], Y_train[val]\n",
        "            model = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "            model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "            hist = model.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=epochs,\n",
        "                            callbacks = [lr_scheduler],\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            validation_steps=x_val.shape[0] // BS,)\n",
        "            loss, acc = model.evaluate(X_test, y_test)\n",
        "            loss1, acc1 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[0]),X_test, y_test, epsilon_list[0])\n",
        "            loss2, acc2 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[1]),X_test, y_test, epsilon_list[1])\n",
        "            loss3, acc3 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[2]),X_test, y_test, epsilon_list[2])\n",
        "            loss4, acc4 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[3]),X_test, y_test, epsilon_list[3])\n",
        "            row = {'loss_clean':loss,'acc_clean':acc, 'loss1':loss1, 'acc1':acc1, 'loss2':loss2,\n",
        "                    'acc2':acc2, 'loss3':loss3, 'acc3':acc3, 'loss4':loss4, 'acc4':acc4}\n",
        "            res_df = res_df.append(row , ignore_index=True)\n",
        "            \n",
        "          return res_df"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFgKVWiHKYsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "9d6f97c1-66c6-4ef8-c237-d20a8dc292f9"
      },
      "source": [
        "\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans from git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.6/dist-packages (from cleverhans) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-14-21b906498791>:8: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6HjbpvKslU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "def get_adversarial_examples(pretrained_model, X_true, y_true, epsilon):\n",
        "  #The attack requires the model to ouput the logits\n",
        "   \n",
        "  logits_model = tf.keras.Model(pretrained_model.input,pretrained_model.layers[-1].output)\n",
        "  X_adv = []\n",
        "  for i in range(len(X_true)):\n",
        "    random_index = i\n",
        "    original_image = X_true[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_true[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "  X_adv = np.array(X_adv)\n",
        "  return X_adv\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_graph(hist):\n",
        "  history = hist\n",
        "  print(history.history.keys())\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  plt.savefig(\"wrn_tensor.png\")\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnbbLi83NyVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_test(model,X_adv, X_test, y_test, epsilon):\n",
        "  loss, acc = model.evaluate(X_adv,y_test)\n",
        "  print(\"epsilon: {} and test evaluation : {}, {}\".format(epsilon,loss, acc))\n",
        "  SNR = 20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))\n",
        "  print(\"SNR: {}\".format(SNR))\n",
        "  return loss, acc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNDNAa6MWu7",
        "colab_type": "text"
      },
      "source": [
        "**Train a Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200\n",
        "BS = 128\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41277f2a-7443-424b-9fc8-3289dbb5f02e"
      },
      "source": [
        "#wrn_16_2.summary()\n",
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n",
        "\n",
        "hist = wrn_16_2.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   validation_steps=X_val.shape[0] // BS,)\n",
        "wrn_16_2.save(\"wrn_model.h5\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n",
            "Epoch 1/200\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 1.5944 - acc: 0.3012 - val_loss: 1.5481 - val_acc: 0.3515 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.5057 - acc: 0.3788 - val_loss: 1.4811 - val_acc: 0.3612 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.4745 - acc: 0.3837 - val_loss: 1.4660 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.4571 - acc: 0.3990 - val_loss: 1.4769 - val_acc: 0.3573 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.4468 - acc: 0.3988 - val_loss: 1.4503 - val_acc: 0.3845 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.4385 - acc: 0.4128 - val_loss: 1.4649 - val_acc: 0.3786 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 1.4205 - acc: 0.4172 - val_loss: 1.4570 - val_acc: 0.4000 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.3957 - acc: 0.4627 - val_loss: 1.4432 - val_acc: 0.4058 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 1.3552 - acc: 0.5126 - val_loss: 1.4077 - val_acc: 0.4641 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.3222 - acc: 0.5275 - val_loss: 1.4302 - val_acc: 0.4699 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.3090 - acc: 0.5366 - val_loss: 1.3101 - val_acc: 0.5165 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.2812 - acc: 0.5464 - val_loss: 1.3773 - val_acc: 0.5398 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 1.2622 - acc: 0.5502 - val_loss: 1.8886 - val_acc: 0.3126 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.2319 - acc: 0.5737 - val_loss: 1.2704 - val_acc: 0.5515 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.2157 - acc: 0.5748 - val_loss: 1.2947 - val_acc: 0.5146 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.2085 - acc: 0.5830 - val_loss: 1.3546 - val_acc: 0.4680 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.1762 - acc: 0.5861 - val_loss: 1.4340 - val_acc: 0.5165 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 1.1683 - acc: 0.5961 - val_loss: 1.3265 - val_acc: 0.5670 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.1406 - acc: 0.6141 - val_loss: 1.5974 - val_acc: 0.4718 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.1449 - acc: 0.6063 - val_loss: 1.3350 - val_acc: 0.5845 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.1298 - acc: 0.6176 - val_loss: 1.1942 - val_acc: 0.6039 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.0912 - acc: 0.6409 - val_loss: 1.3420 - val_acc: 0.5068 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.0924 - acc: 0.6374 - val_loss: 1.3718 - val_acc: 0.5184 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.0542 - acc: 0.6569 - val_loss: 1.1643 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 1.0416 - acc: 0.6633 - val_loss: 1.1731 - val_acc: 0.6117 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.0227 - acc: 0.6680 - val_loss: 1.1753 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.0149 - acc: 0.6700 - val_loss: 1.1354 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.9858 - acc: 0.6855 - val_loss: 1.3545 - val_acc: 0.5709 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.9784 - acc: 0.6933 - val_loss: 1.0641 - val_acc: 0.6835 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.9778 - acc: 0.6931 - val_loss: 1.1372 - val_acc: 0.6524 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.9648 - acc: 0.6955 - val_loss: 1.1117 - val_acc: 0.6641 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.9205 - acc: 0.7175 - val_loss: 1.0862 - val_acc: 0.6854 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.9154 - acc: 0.7230 - val_loss: 1.0784 - val_acc: 0.6738 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8992 - acc: 0.7352 - val_loss: 1.0708 - val_acc: 0.6874 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8876 - acc: 0.7281 - val_loss: 1.0697 - val_acc: 0.6757 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8864 - acc: 0.7383 - val_loss: 1.0524 - val_acc: 0.6757 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8886 - acc: 0.7357 - val_loss: 1.0848 - val_acc: 0.6718 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8824 - acc: 0.7368 - val_loss: 1.0616 - val_acc: 0.6718 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8767 - acc: 0.7397 - val_loss: 1.0765 - val_acc: 0.6757 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8891 - acc: 0.7321 - val_loss: 1.0533 - val_acc: 0.6816 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8835 - acc: 0.7395 - val_loss: 1.0418 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8686 - acc: 0.7401 - val_loss: 1.0542 - val_acc: 0.6816 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8701 - acc: 0.7381 - val_loss: 1.0384 - val_acc: 0.6893 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8654 - acc: 0.7494 - val_loss: 1.0499 - val_acc: 0.6893 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8714 - acc: 0.7455 - val_loss: 1.0519 - val_acc: 0.6835 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8757 - acc: 0.7335 - val_loss: 1.0552 - val_acc: 0.6893 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8680 - acc: 0.7399 - val_loss: 1.0423 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8615 - acc: 0.7439 - val_loss: 1.0348 - val_acc: 0.6874 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8697 - acc: 0.7435 - val_loss: 1.1287 - val_acc: 0.6874 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8669 - acc: 0.7463 - val_loss: 1.0831 - val_acc: 0.6777 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8634 - acc: 0.7530 - val_loss: 1.0452 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8608 - acc: 0.7483 - val_loss: 1.0432 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8549 - acc: 0.7494 - val_loss: 1.0460 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8545 - acc: 0.7514 - val_loss: 1.0291 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8536 - acc: 0.7521 - val_loss: 1.0595 - val_acc: 0.6893 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8510 - acc: 0.7534 - val_loss: 1.0436 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8476 - acc: 0.7541 - val_loss: 1.0594 - val_acc: 0.6874 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8470 - acc: 0.7514 - val_loss: 1.0518 - val_acc: 0.6816 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8543 - acc: 0.7470 - val_loss: 1.0244 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8552 - acc: 0.7514 - val_loss: 1.0661 - val_acc: 0.6777 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8492 - acc: 0.7486 - val_loss: 1.0329 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8538 - acc: 0.7501 - val_loss: 1.0372 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8512 - acc: 0.7521 - val_loss: 1.0140 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8482 - acc: 0.7568 - val_loss: 1.0552 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8414 - acc: 0.7517 - val_loss: 1.0528 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8487 - acc: 0.7550 - val_loss: 1.0518 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8527 - acc: 0.7530 - val_loss: 1.0542 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8480 - acc: 0.7552 - val_loss: 1.0746 - val_acc: 0.6874 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8578 - acc: 0.7477 - val_loss: 1.0525 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8475 - acc: 0.7494 - val_loss: 1.0585 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8512 - acc: 0.7501 - val_loss: 1.0591 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8481 - acc: 0.7559 - val_loss: 1.0571 - val_acc: 0.6874 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8583 - acc: 0.7488 - val_loss: 1.0383 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8475 - acc: 0.7577 - val_loss: 1.0399 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8473 - acc: 0.7532 - val_loss: 1.0420 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.8422 - acc: 0.7585 - val_loss: 1.0524 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8552 - acc: 0.7492 - val_loss: 1.0172 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8438 - acc: 0.7532 - val_loss: 1.0366 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8499 - acc: 0.7577 - val_loss: 1.0322 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8563 - acc: 0.7523 - val_loss: 1.0559 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8517 - acc: 0.7537 - val_loss: 1.0487 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8399 - acc: 0.7572 - val_loss: 1.0280 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8464 - acc: 0.7563 - val_loss: 1.0163 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8477 - acc: 0.7534 - val_loss: 1.1438 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8502 - acc: 0.7463 - val_loss: 1.1648 - val_acc: 0.6485 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8486 - acc: 0.7461 - val_loss: 1.0381 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8488 - acc: 0.7499 - val_loss: 1.0327 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8504 - acc: 0.7506 - val_loss: 1.0472 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8547 - acc: 0.7437 - val_loss: 1.0443 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8602 - acc: 0.7426 - val_loss: 1.0465 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8569 - acc: 0.7486 - val_loss: 1.0379 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8497 - acc: 0.7543 - val_loss: 1.0291 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8573 - acc: 0.7450 - val_loss: 1.0278 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8502 - acc: 0.7523 - val_loss: 1.0636 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8571 - acc: 0.7468 - val_loss: 1.0416 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8580 - acc: 0.7437 - val_loss: 1.0655 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8470 - acc: 0.7532 - val_loss: 1.0399 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8510 - acc: 0.7481 - val_loss: 1.0631 - val_acc: 0.6835 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8458 - acc: 0.7479 - val_loss: 1.0396 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8550 - acc: 0.7521 - val_loss: 1.0872 - val_acc: 0.6835 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8504 - acc: 0.7466 - val_loss: 1.0285 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8473 - acc: 0.7565 - val_loss: 1.0498 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8517 - acc: 0.7532 - val_loss: 1.0358 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8462 - acc: 0.7523 - val_loss: 1.0523 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8530 - acc: 0.7493 - val_loss: 1.0300 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8510 - acc: 0.7543 - val_loss: 1.0484 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8524 - acc: 0.7557 - val_loss: 1.0442 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8565 - acc: 0.7441 - val_loss: 1.0750 - val_acc: 0.6874 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8506 - acc: 0.7514 - val_loss: 1.0712 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8523 - acc: 0.7501 - val_loss: 1.0243 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8464 - acc: 0.7486 - val_loss: 1.0447 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8585 - acc: 0.7430 - val_loss: 1.0413 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 0.8511 - acc: 0.7466 - val_loss: 1.0583 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8535 - acc: 0.7437 - val_loss: 1.0596 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8535 - acc: 0.7401 - val_loss: 1.0516 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8442 - acc: 0.7528 - val_loss: 1.0477 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8418 - acc: 0.7528 - val_loss: 1.0376 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8475 - acc: 0.7545 - val_loss: 1.0469 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8582 - acc: 0.7477 - val_loss: 1.0348 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8463 - acc: 0.7577 - val_loss: 1.0336 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8541 - acc: 0.7499 - val_loss: 1.0397 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8506 - acc: 0.7499 - val_loss: 1.0227 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8500 - acc: 0.7514 - val_loss: 1.0608 - val_acc: 0.6854 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8573 - acc: 0.7479 - val_loss: 1.0580 - val_acc: 0.6835 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.8495 - acc: 0.7397 - val_loss: 1.0306 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8431 - acc: 0.7508 - val_loss: 1.0516 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8542 - acc: 0.7497 - val_loss: 1.0883 - val_acc: 0.6854 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8573 - acc: 0.7392 - val_loss: 1.0503 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8574 - acc: 0.7501 - val_loss: 1.0602 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8502 - acc: 0.7537 - val_loss: 1.0363 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8477 - acc: 0.7581 - val_loss: 1.0506 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8477 - acc: 0.7448 - val_loss: 1.0539 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8452 - acc: 0.7521 - val_loss: 1.0370 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8608 - acc: 0.7452 - val_loss: 1.0335 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8444 - acc: 0.7556 - val_loss: 1.0807 - val_acc: 0.6874 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8566 - acc: 0.7457 - val_loss: 1.0756 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8475 - acc: 0.7528 - val_loss: 1.0516 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8445 - acc: 0.7514 - val_loss: 1.0453 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8517 - acc: 0.7499 - val_loss: 1.0475 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8505 - acc: 0.7483 - val_loss: 1.0212 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8559 - acc: 0.7554 - val_loss: 1.0770 - val_acc: 0.6874 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8549 - acc: 0.7443 - val_loss: 1.0446 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8574 - acc: 0.7455 - val_loss: 1.0443 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8521 - acc: 0.7437 - val_loss: 1.0668 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8507 - acc: 0.7459 - val_loss: 1.0450 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8545 - acc: 0.7448 - val_loss: 1.0736 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8564 - acc: 0.7517 - val_loss: 1.0471 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8491 - acc: 0.7552 - val_loss: 1.0464 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8497 - acc: 0.7528 - val_loss: 1.0273 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8565 - acc: 0.7461 - val_loss: 1.0624 - val_acc: 0.6835 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8421 - acc: 0.7592 - val_loss: 1.0287 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8585 - acc: 0.7455 - val_loss: 1.0368 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8508 - acc: 0.7474 - val_loss: 1.0209 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8556 - acc: 0.7486 - val_loss: 1.0375 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8433 - acc: 0.7532 - val_loss: 1.0417 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8611 - acc: 0.7554 - val_loss: 1.0434 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8505 - acc: 0.7526 - val_loss: 1.0347 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8556 - acc: 0.7472 - val_loss: 1.0677 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8493 - acc: 0.7526 - val_loss: 1.0362 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8414 - acc: 0.7541 - val_loss: 1.0287 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8517 - acc: 0.7439 - val_loss: 1.0657 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8561 - acc: 0.7490 - val_loss: 1.0383 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8476 - acc: 0.7483 - val_loss: 1.0371 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8516 - acc: 0.7530 - val_loss: 1.0346 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8484 - acc: 0.7483 - val_loss: 1.0169 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8561 - acc: 0.7468 - val_loss: 1.0270 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8488 - acc: 0.7488 - val_loss: 1.0391 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8501 - acc: 0.7486 - val_loss: 1.0500 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8524 - acc: 0.7490 - val_loss: 1.0361 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8507 - acc: 0.7483 - val_loss: 1.0250 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8467 - acc: 0.7541 - val_loss: 1.0561 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8500 - acc: 0.7499 - val_loss: 1.0492 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8482 - acc: 0.7510 - val_loss: 1.0450 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8437 - acc: 0.7625 - val_loss: 1.0494 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8452 - acc: 0.7559 - val_loss: 1.0467 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8475 - acc: 0.7526 - val_loss: 1.0699 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8490 - acc: 0.7483 - val_loss: 1.0470 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8547 - acc: 0.7519 - val_loss: 1.0869 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8428 - acc: 0.7563 - val_loss: 1.0399 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8540 - acc: 0.7503 - val_loss: 1.0319 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8518 - acc: 0.7450 - val_loss: 1.0395 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8557 - acc: 0.7457 - val_loss: 1.0282 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8562 - acc: 0.7472 - val_loss: 1.0566 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8477 - acc: 0.7455 - val_loss: 1.0443 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8573 - acc: 0.7468 - val_loss: 1.0650 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8395 - acc: 0.7568 - val_loss: 1.0381 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8515 - acc: 0.7508 - val_loss: 1.0369 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8573 - acc: 0.7430 - val_loss: 1.0423 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8566 - acc: 0.7430 - val_loss: 1.0194 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8457 - acc: 0.7528 - val_loss: 1.0599 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8481 - acc: 0.7483 - val_loss: 1.0501 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8542 - acc: 0.7492 - val_loss: 1.0604 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8494 - acc: 0.7523 - val_loss: 1.0713 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8522 - acc: 0.7552 - val_loss: 1.0594 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8507 - acc: 0.7470 - val_loss: 1.0311 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8530 - acc: 0.7501 - val_loss: 1.0384 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.8522 - acc: 0.7510 - val_loss: 1.0412 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8601 - acc: 0.7410 - val_loss: 1.0328 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.8455 - acc: 0.7545 - val_loss: 1.0640 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.8528 - acc: 0.7506 - val_loss: 1.0524 - val_acc: 0.7010 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvd1NVKvpH0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "1f11b8f9-c2e5-4e50-f74e-a8b58dfd0172"
      },
      "source": [
        "show_graph(hist)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5gUVdaH3zs5wGTSDGHIWXLGgBED5kVBjLvmsO6qa/hc0+4a15zRxQQiiIooqIACgpLzkMPAJCbn3OF+f5zu6Z7IgNOTuO/z9NNdVbeqblVX3d8959ygtNYYDAaD4dTFq6kzYDAYDIamxQiBwWAwnOIYITAYDIZTHCMEBoPBcIpjhMBgMBhOcYwQGAwGwymOEQLDKYVS6mOl1L/rmfaIUupcT+fJYGhqjBAYDAbDKY4RAoOhBaKU8mnqPBhaD0YIDM0Oh0vmIaXUDqVUkVLqf0qpDkqpH5RSBUqp5UqpcLf0lyqldimlcpVSK5VS/d22DVNKbXHsNw8IqHKuS5RS2xz7/q6UOq2eebxYKbVVKZWvlEpUSj1VZftEx/FyHdtvcqwPVEq9rJQ6qpTKU0qtcaw7SymVVMN9ONfx+yml1AKl1GylVD5wk1JqtFJqreMcx5RSbyml/Nz2H6iUWqaUylZKpSmlHlNKdVRKFSulIt3SDVdKZSilfOtz7YbWhxECQ3PlKuA8oA8wBfgBeAxohzy39wEopfoAc4H7HduWAN8ppfwcheJC4DMgAvjScVwc+w4DZgG3A5HA+8AipZR/PfJXBNwAhAEXA3cqpS53HLebI79vOvI0FNjm2O+/wAhgvCNP/wDs9bwnlwELHOecA9iAvwFRwDjgHOAuRx7aAsuBH4FooBfws9Y6FVgJTHU77vXAF1prSz3zYWhlGCEwNFfe1Fqnaa2TgdXAeq31Vq11KfANMMyR7hpgsdZ6maMg+y8QiBS0YwFf4DWttUVrvQDY6HaO24D3tdbrtdY2rfUnQJljvzrRWq/UWu/UWtu11jsQMTrTsXk6sFxrPddx3iyt9TallBdwC/BXrXWy45y/a63L6nlP1mqtFzrOWaK13qy1Xqe1tmqtjyBC5szDJUCq1vplrXWp1rpAa73ese0TYAaAUsobmIaIpeEUxQiBobmS5va7pIblNo7f0cBR5wattR1IBGIc25J15ZEVj7r97gY84HCt5CqlcoEujv3qRCk1Rim1wuFSyQPuQGrmOI5xqIbdohDXVE3b6kNilTz0UUp9r5RKdbiLnq1HHgC+BQYopbojVlee1nrDSebJ0AowQmBo6aQgBToASimFFILJwDEgxrHOSVe334nAf7TWYW6fIK313Hqc93NgEdBFax0KvAc4z5MI9Kxhn0ygtJZtRUCQ23V4I24ld6oOFfwusBforbUOQVxn7nnoUVPGHVbVfMQquB5jDZzyGCEwtHTmAxcrpc5xBDsfQNw7vwNrAStwn1LKVyl1JTDabd8PgDsctXullAp2BIHb1uO8bYFsrXWpUmo04g5yMgc4Vyk1VSnlo5SKVEoNdVgrs4BXlFLRSilvpdQ4R0xiPxDgOL8v8DhwvFhFWyAfKFRK9QPudNv2PdBJKXW/UspfKdVWKTXGbfunwE3ApRghOOUxQmBo0Wit9yE12zeRGvcUYIrWulxrXQ5ciRR42Ug84Wu3fTcBtwJvATnAQUfa+nAX8IxSqgB4AhEk53ETgIsQUcpGAsVDHJsfBHYisYps4AXAS2ud5zjmh4g1UwRUakVUAw8iAlSAiNo8tzwUIG6fKUAqcACY5Lb9NyRIvUVr7e4uM5yCKDMxjcFwaqKU+gX4XGv9YVPnxdC0GCEwGE5BlFKjgGVIjKOgqfNjaFqMa8hgOMVQSn2C9DG434iAAYxFYDAYDKc8xiIwGAyGU5wWN3BVVFSUjo2NbepsGAwGQ4ti8+bNmVrrqn1TgBYoBLGxsWzatKmps2EwGAwtCqVUrc2EjWvIYDAYTnGMEBgMBsMpjhECg8FgOMVpcTGCmrBYLCQlJVFaWtrUWfEoAQEBdO7cGV9fM3+IwWBoOFqFECQlJdG2bVtiY2OpPNBk60FrTVZWFklJSXTv3r2ps2MwGFoRrcI1VFpaSmRkZKsVAQClFJGRka3e6jEYDI1PqxACoFWLgJNT4RoNBkPj02qEwGAwGP4Iq/ZnsDslv6mz0SQYIWgAcnNzeeedd054v4suuojc3FwP5MhgaBnY7ZrmMN5ZmdXGXbM3c+eczZRb7U2dnUbHCEEDUJsQWK3WOvdbsmQJYWFhnspWs+OPvPD70wpIyCoG4M2fD/D+Ktd0vHa7ZsXedEottop15VY7R7OKmkUh40nySiz8uj/jDx3j94OZfLkp8fgJG5iiMiuj/rOcLzcfb/4dz/P7oSyKym0czSpm3saEP3y8lvbcGSFoAB555BEOHTrE0KFDGTVqFKeffjqXXnopAwYMAODyyy9nxIgRDBw4kJkzZ1bsFxsbS2ZmJkeOHKF///7ceuutDBw4kPPPP5+SkpKmuhyPsDc1nzHP/lzxkh1IK6C43IrWmvWHs8grsVTb5/P1Caw9lEW51c70D9Zx+Tu/8cWGBF5etp9Xl++noFT2eW35fm7+eCNPLdoFQF6xhave/Z0zX1rJyH8v57O1RxrtxbTaJK+vLN1X7Zw2u2b1gQxm/noIq+3ka51a64r93/j5ADfM2sCOpJOzLPem5vOXTzfx+MK4SkIKcCSziPnHEYjicisLtyZjtx///qbklrAt0ZXP9fFZZBWV81Ncaq3pF2xOwvIH7lV9WbY7jWA/b0Z0C+f1nw+QVVhWafvB9EJumLWB/WnHH7X707VHmPjCCnKLy+t17nKrnbWHsmp9RhvDamoVzUfdefq7XQ3u5xsQHcKTUwbWuv35558nLi6Obdu2sXLlSi6++GLi4uIqmnnOmjWLiIgISkpKGDVqFFdddRWRkZGVjnHgwAHmzp3LBx98wNSpU/nqq6+YMWNGg17HibLxSDY9ooKJbFN56txyq51f9qaxdFcau4/lMyA6hKcuHUhIQM39GwpKLdw5ewvpBWU8uWgX8ZnFvLfqEO3b+tOzXRvWHs5iypBo3pw2rGKf3w9l8tg3O2nf1p+HJ/cjs7AcHy/FI1/vJKqNP5mFZXy/4xjhQb688ctBokMD+GJjItFhgSzZeYzDGUU8cF4f1sVn8c9vd7E3tYB/Xz6oXgH3DfHZ3Dd3K7P/MoZe7dtQarER4OtdsX13Sj7JuSWcN6BDxTqtNUopfjuUxe+OT2JOCdNGd2V41zCsds01769le1IeAD3bteGc/h2qnbs2covLWXc4i/xSK5/8foT0gjJ+uv8MFm1PAWDmr4d5a/rweh8PIL2glNs+3YzVpim32dl8NIcJvaIqtv936T6+33GMkd3CiQ4LZEdSHsO7huHj7ao/vvHzQd5bdYjwYD/O7FPjeGYAHEwv4NqZ68ksLOO6MV355yUD+HV/JgDr47Ox2uyVjjt73VGeXbKH4nIbX21O4u3rhhMR7Edafimz1sTz26FM3psxgs7hQRX72O2alfvTGdsjkiC/uou2pbtS+d+aeN6cNoyoNv4s353GmX3bcceZPZn6/lr+9P5aZv95DNFhgeSVWLjt000czizi/8qtzL99XK3PkdaaT9ceJTm3hJeX7udflw+q2Gaza/anFdC/U0jFuuyicu74bDMbjmTz+rVDuWxoTLVjvrxsH0t2pjL31rF0DA2o87pOFmMReIDRo0dXauv/xhtvMGTIEMaOHUtiYiIHDhyotk/37t0ZOnQoACNGjODIkSONld0a2ZWSx5/eW8v1/9tAqcWGza6ZtzGBy95aw6CnfuKO2VtYtT+DqDb+fLsthUveWENSTjHJuSXcO3crWxNyAFh7KItr3l9HQnYxb04bRoCvN++tOsSkvu2ICQ9kV0oeo7tHsHhHCkcyiwARjscXxhEW5Et6QRmPL4wjJiyQmTeMoFtkEB/eOJI+Hdrw3qpD3D9vG0O7hPHj386gV/s2vLJsPznF5cy8YQT3ntObz24Zwy0TujPHYV04KSm3sflodjW3SrnVzmPf7CQ1v5TP1yew6Ug2w55Zxvc7UirSPPbNTm7/bBMbj2QDUsiNe+4XPv4tnm+3JhMS4MNdZ/Vk4bZkpr6/lqnvr+WfC+PYnpTHvy4fRBt/H5btTiMlt4Q7Z29mzvqjFJbV7UZ8bsle7pi9hX8s2EF+qYWMgjJu/2wTGQVl9O8UwpKdx4hLzmPz0Wz+Pn8bn609UumavtiQwO6U/IqaZXpBKdNmriOjoIyPbh6Fj5di9YFMXlm6j7NfXklOUTk/70kHYOG2FJ5dsoep76/l9BdX8Nry/aTmlZJVWManjvP8tKvmWj1AZmEZ185cD8CMsV2Zsz6BV5btZ/WBDAJ9vSkss7IjOa8i/Y9xx3h8YRwjuoXz5JQBbE7I4bZPN5FXbOGKt3/jwzXxxCXns6CKS+mdlQe55eNNPPjl9jpr0LnF5Tz69U7Wx2fzl083MWf9UdILyjhvQAdO6xzGp7eMISO/jBkfrictv5R7Pt9CQnYx08d0ZeORHL7ZmlzrsXel5HMwvZAuEYHMWX+UOLfr+nD1YS58fTXzN4qVdSCtgMvf/o1tSblEtfFn1m9yL/ccy+fD1YdZuisVrTULt6YQn1nETR9tIL+0uuXcELQ6i6CumntjERwcXPF75cqVLF++nLVr1xIUFMRZZ51VY18Af39Xrdvb29tjrqH3Vx1iX1oBz195Gn4+tdcDXvxxH0F+3uw+ls8NszaQUVBGfGYRg2JCuHFcNyb0imJiryh8vL3YfDSbm2Zt5PbPNqMUxCXn81NcKn06tiEuOZ/o0ADenj6cyYM60r6tPxuPZHPHmT0raoDpBaVMfGEF/7dwJ/klVuJS8tAaPrllNO+sOMj6+Gymje7C2f06cHY/qUVPHdmFfy/eQ2xkEP+7cSQhAb589ufRxGcWMaZ7JN5eUmPz8lL8Y3Jfluw8xqvL9zOuZyTxmUVcO3Md6QVi/s/+8xgm9paa8Kzf4jmYXkhsZBDfbE1iV0oeJRYbT3y7i/E9o8guKmdbYi5eCv4+fxtPXzqQJxftIjW/lOd+2IuXUlw+LJp/TO7HbWf04Me4VJ76bhdbEnK5eUIs14/txvrDWSzfk47NrvkhLpUf4lJ5dvEerhgewyMX9qeNf+XXUmvNL/vSOadfex6+sB89ooK5f942vt9xjLYBPsy8fgTnvLyKS95cA4CPl+LrLckUldu448yeLNyazCNf7wTgTyM689KfhvB/38SRklvKRzePYmyPSIZ3DeenXamk5pVSYrFx++zNlFhstGvrz/yNiWQXlXNGn3ZorXlt+QHe/OUgsZFBlFpsDOkcytJdqfzrskEV992dt1ccJKe4nMX3TaRfxxBKyu18/NsRym127jqrJ++sPMTaQ1n07xjCqv0ZPPTlDoZ0CePDG0fi7+NNaKAvf5+/nSlvrSE1v5Qv7xjPSz/tZdG2FK4b043/LN5NsL8PczckEBsZxJKdqbz1y0HuOKsnP+1KZd3hLIL8fMguKqek3EZ2UTm5JRYeuqAv/126jx1JeXSLDKp4tkZ3j2DWzaO47oP1nPXSSkqtNl686jSuGt6ZXSn5/GfxHs7s066apQywcGsyvt6KOX8ey2Vvr+HVZfv5302j0FpXCNfjC+PYcCSbn+JS8ff1Zt5tY9mRlMeTi3Zxz+db+H7HMQDa+Pvw9V3jSc4t4eLTOvFTXCpfbEjgtjN61udVPyFanRA0BW3btqWgoGbfYV5eHuHh4QQFBbF3717WrVvXyLlzYbXZeW/VIXKKLdjtmlemDsWrhhd35b50Vu3P4NEL+1FUbuPtFQcZ0z2CB8/vy0WDO1Yzi0d0i+D1aUP58ycyPPgrU4fw7bYUEnOKeWrKAK4d3bXCtTKmRyRjelR2i7VvG8CfRnRmzvoEerQL5v5z+jC2RwRjekQSFujLk4t2cc2orpX2mTqqCym5pdw0PrbihewUGkin0MBq1xPg681dk3ryxLe7eOLbXfy8Jw2bXfPudcP51/e7+e/SfUzoFUlKXimvLz/Auf07MGNsV276aCPr47OZOrIz32xN5pGvdtA1IghvL8Xb04dx79yt3PLxJvx9vHj/+hE8+OV2CkqtFeZ9WJAf147uyqCYUH6IO8a9Z/cG4LwBHfh+xzG+3JzEDeO6cdnQGD5fn8Dn6xOwa3jo/L688csBrh7RmYHRoew5VkBGQRmTB3WkT4e2APztvD78EJfKxYM70SUiiI9vGcWh9ELaBPhwdr8OPL4wjud/2Muo2HB+3JVKTFggo2LD+WZrMvee3ZuV+9K5aXwsYx3/xcTeUbyybD9KQb+ObdkQn02HEH8eOK8v//hqB77eimevGETn8CASsoqZvf4oX2xI4E8jujCxdxT3zt3KhvhsukUG0Sk0gHKbnd8OZhIa6MecdQlcPbwz/TqKS+Tv5/fhO4eFddnQGFbsy+Dz9QnM/PUweSUWOoYE8Pb0Yfj7yDNzxbAYluxMZfmeNO48qycjuoVz2dAYHv16JzfM2sCBtAK8lKJPh7YsuHM8D325nZeX7ee9VYcoKrfR1t+HcpudiGA/fL29SMgu5s6zenL3pF4M6xqGt1KMjI2oJGKjYiN44erBPPZ1HC9cdRp/GtkFgBeuGsyUN9fwxLe7uOfsXizZeYzvdxxjVGw4I2Mj+HprMmf1bU/XyCBuHB/La8sPcCCtgFKLnQPphTx0QV8WbE7ip7hUxveK5IkpA4kJC6R3h7b89ydxxU0b3YWxPSL56xfbeOa73fJ/n9uHO8/sycBol1upITFC0ABERkYyYcIEBg0aRGBgIB06uHy/kydP5r333qN///707duXsWPHNlk+Nx7JIafYwviekSzclsK5AzpwyWnRgJipS3dLAfnWLwfpERXMjeNjCfD15u5JPSteyto4u18HXrtmKFrD5cNiuHJ45xPK22MX9efCQZ0Y1zOy0gs5pEsYC++eUC19SIAvT0wZUO/jXzOqC99vP8bcDQmEB/vx6Z9HMzA6lNwSC49+vZPPNyTw6/4MNJonpwwgOiyQjiEBlFltPDllIH07hvCv7+WlPKdfeyYP6sSah8NJyimmQ0gAncODsNo0321PYXRsRKVzD4oJZVBMaMXyWX3b4+OlUApuP7MnMWGBjOgWTkSwLx+sjue3g5kczSpm7oYEXrp6CIk50lrK3Qffs10bvrpzPN0jxfoc3zOK8T1d/v3nrxzMyn3pvPHzQdYeyuKGcd24fFgMC7el8NCC7VhsmgsHd6pI7xSCiwZ34s8Tu3PlO79z8eBoLhzckX99v5vLh8VU+OO7Rgbx2EX9eXhyPxRQbLHh5+PFjP+tx2bXjOwWTnZxOYczxNXn5+3Ffef2rjhXTFggd5zZk2W70+jToQ1n9Ini/VWHOb13FLed0YMx3SMrWatKKV66+jS+25HCNaOkQL5wUEee+DaOPcfyeeKSAVw/rhsK8PH24q3pw/l5TxqLdx5jQs8orhrRudIzVWqx4e84vvs9q8oVwzoz5bToSrGLfh1D+Os5vfnv0v0s3nkMpUQ0Fm5LYf6mJDqHB3LPpF4A3DAulvdWHeKtFQcJ8vPGz9uLGWO6cdsZPfBSqlKe2vj78OLVp5FfamHqyC7YNfxn8R7WHMykY0gAPdsFe7RDaYubs3jkyJG66sQ0e/bsoX///k2Uo8blj1zr09/tYs76BDY/fi5nvbSSCb2ieGPaMA5lFHL1u7+TUyz+x4m9onhr+jDCgvwaMuvNAq01WlNhCVlsdqa8uYa9qWLRPXRBX+52vMibj2Zj1/KiAyzYnMST38bxzowRdQZG68PT3+0iNNCX+8/tU7GupNzGBa/9Slp+KS9efRpz1iWw8Wg2UW38iWrjzw9/Pf2EzvHskj3M/PUwAF/dOY7hXcM5++VVxGcW0Sk0gN8ePrviPtjtmndXHeKKYTFEhwWy+kAGp8WEERrkS1p+KeFBfnW6Et/65QD70grp074Nczck4OfjxQPn9yUlt4ROYYFcOiS61n2Ly63EZxYxMDq01jQ18ejXO8gpsvDOdcNrtGw9hdVmZ/a6o4QH+zGiWzidw4NILyjlWG4pg2NCK+XlyW/j+GStzAdz0eCOvHPdiHqf5z+Ld/PB6niuHB7DK1OH/uF8K6U2a61H1rjNCEHLouq1lpRL7cb58G1JyOGrzUk8elF/bDbNcz/sYVtiLh1DA9h7rIBBMSF8eOMoHvxyO0t3pfLrPyZxyZtrKCm3Mfe2sQT5eRMdGtioL1ZTU2qxseZAJgczCrllQvc6Czy7XXv03hzLK6GozFbRWunWTzex+kAmd57Vk4cn9zuhYyXlFHPGiyuIauPPukfPwctL8fLSfbz5y0FunhDbLOJprZ2CUgu/7E1Ha5jQK4p2bavHFWpjz7F8Ln5jNW9MG1Zhuf8R6hIC4xpqwVhsds59ZRXhwb78+/LBbIzP5qWf9lFus9MlIojsonLmb0rkjD7t2J6YS06xhb+fJzXQc/q1Z8HmJO6YvZmknBIW3DGuwv98qhHg6825AzpwLsdvzulpgXSPcQT4evPBDSP5+PcjXHWCrjaAzuFB3H9uH6La+Ffk+6rhEu/404guDZZnQ+20DfCtsUlofejfKYQ1D59NJw81GXXHWAQtjD179vDBjjIuPq0TXl6Kmz/aiK+3wmKT//GMPu0otdg4nFFIcbmN8wd04LVrh5FXYmHlvnQuGtwJX28vCsusDHtmKRab5vKh0bx27bDjnNlgMLRkjEXQirDY7Hy9NZmNR7MZ2iWckAAfvr1nImsOZDAyNoJ+Hduy9nAW0z9Yj1Jwz9ni7w4NrFwzaePvw9gekayPz+bBC/o21eUYDIZmgBGCFoZzGIDE7BISs0uYOrIz3aOC6R7l6rswrkckZ/RpR6eQAHq1r93d88xlg0jPL63UO9NgMJx6GCFoYZRa7AyKCUGh2Jmcx6VDqvsflVJ8esvo4x6rqoAYDIZTEzPERANwssNQA7z22msUFxfXK63VZqfcaufsvu15+rKBTB3ZmbE9Io6/o8FgMNSBEYIGoLGEoKDMigYm9WvP8K7hvHj1kEqdXQwGg+FkMK6hBsB9GOrzzjuP9u3bM3/+fMrKyrjiiit4+umnKSoqYurUqSQlJWGz2fjnP/9JWloaKSkpTJo0iaioKFasWFHrOex2TXp+GT5eiiGdT505DAwGg+dpfULwwyOQurNhj9lxMFz4fK2b3YehXrp0KQsWLGDDhg1orbn00kv59ddfycjIIDo6msWLFwMyBlFoaCivvPIKK1asICqq9q7uAOkFZZRZbYQF+Z5Snb0MBoPnMX6FBmbp0qUsXbqUYcOGMXz4cPbu3cuBAwcYPHgwy5Yt4+GHH2b16tWEhta/O73NrskoLCM8yK/SuPgGg8HQELQ+i6COmntjoLXm0Ucf5fbbb6+2bcuWLSxZsoTHH3+cc845hyeeeKJexyyz2tBaExLoS2FDZ9jQMtEaPpkCwe3gnH9CRI+GPb61DLz9wIMDnRmaD8YiaADch6G+4IILmDVrFoWFUmQnJyeTnp5OSkoKQUFBzJgxg4ceeogtW7ZU27c2Si0yVV9AHWPgGBqRklzI89A8u8XZkH/s+OnyU+DIatj1NbwzHo7+3nB5KCuEl/vCts8b7piGZo0pWRoA92Goly1bxvTp0xk3bhyDBw/m6quvpqCggJ07dzJ69GiGDh3K008/zeOPPw7AbbfdxuTJk5k0aVKtxy+z2lBK1TkYWrMmaTMkrG/882oNuxZCUWbDHnfZE/DpZQ17TCff3g1zrzl+uow98n3V/yC0M3x+bcPFxpI3QUmOfLdEsg7B3iVg9/xcx60GGZa35XxGjBihq7J79+5q61oT8RmFel9qvta6Ca913ftaH113YvuUl2g973qtnwzR+rmuWttsDZef8mKtlz+jddKm2tP88h8598oXGu68Wms96yKtnwzV2lJ64vsWpGn987+0tpZX32azav1sZ62fjtDaUlb3cX57U66tMFPrnAStX+6v9Yu9tM46dOJ5qsqK5+XYn1z6x49VlfJiuf6co1rb7VqveknrlO1y7atf0frYjuMfoyRX6+VPa11WKM/Yqhe1zkuWbXa71u+dIfl/d6Lcm6qsfUfrYzsb9rqOx7r3tU7cePx0JXlaL3tS66KsBs8CsEnXUq56tIqplJqslNqnlDqolHqkhu2vKqW2OT77lVK5nsxPS6XU6ppIo0nITYAfHoIFN4vbACD7MMy73rVcE9tmw+5vofsZUJoLmftOPg+rXoLfXnct7/8JVv8XPjgbvvtr9drf9i9g1QuOvMaf/HlroiAF0NXdQ/G/wqL7xBJJ2gRfXAfxqyunWfk8/PoSJLpZSOvehd/fhPQ9UJYPdqvc37rI2CPxgeBICOsC138j+312JViqT4V6QiQ6ZtE7Xh5OFJsFvrxZrn/nAig4Br/8S6yrr/4My5+C+TceP//b58Hql6XWv28x/PJv+OwKcavF/wrHtsGQ6ZC+Gzb9D2xW+OpWOLpWnoUfH4G1bzXstVW7VqtYd3FfwYHl8v64P7+18cu/YM2rsPkjz+avCh4rXZRS3sDbwIXAAGCaUqrSlFJa679prYdqrYcCbwJfeyo/LRW7XVNutXu2tVB5kRReta3fMU+W85Nh5XPye+dXsGdRZd+0zSIfALsNfn8LYkbCxa/KusSTdA9lHYIV/xGXzJrXXMfyCYCxd8Hmj+VFyzkihYjW8tJ1GgKdR0Pu0crHK8qED86BpY9L2rJC2dfpQkqNg9eHQsb+6nnRWvzzADlVBGbHPNjyCWQegE2zYO/38Mklch+c5902x3UO5z1b+RyseBYO/ew6ltP1U5WyQslD+l5o5zY/Qbu+cPF/JU+pO+q4mW4UpMK7E6VQdmK3QeJGUF4idNayyvuUFzvuVVbl9dZy138Pkub1IZDgEJVj26Ww3v8DePlC1kG5TwBlBbDrG+h7EWQfqrnA1FrSgRT+APEr4fAq8A0S0Zp1gTwjwe3hkleh8yjZnrgeds4X8dj/o+ybcJwpYy2lck3u1/NSL/h3R/j0cnk36mLD+7B1tgjQwjtlXcq2uqXbNWsAACAASURBVPdJ2QobP5R7v22u651c/TK8NxF2L6r5PW0APFnNHA0c1Fof1lqXA18AdTlWpwFzT/ZkuoUNp11fyqwyyJy/j5dnrjH/mDzgcV9VXm+3yYu84GapXXebCMNvlNprfoqr1piy1bXPglvkA7DnOymUJtwHkT0hKEriBKX5UvOtis3qKhiq8vub4O0rBcXyJ6W2nbgeoofD5Odg/L3yAr0+BN4dLy95+m4YfoOcO+eI61hlBTD7KkjeLMf9Yjq83E/2/W8f8bNv+p/kfc2r1fNSkgNWR40156hcj9PiSN8r34dXyqfPZLlv694Vi2XDTNnXNwjSHP78hLVQmgeWYlj9CgRGSEGQvldquO55L0iDV/rD729Axr7KQgAiulD/WMG2zyUf39wu9+/AMrm35QXQYxJou1yj+7W/Ncpxr3rBwruhMEO2zb4SXh0EWz6Vwirua8n7d38VoZl5FqTFwZTXoetYyNwvH4AZC+DSN+Haz2HglWLpHVkjhe2B5WJVfnoZvBAreTyyxnGfV0H8Ksnr9HkiRMe2wZjbwTcAup8py9sdQe9DP0vhDPL/FqbLb5u18j0rSIV3xsJrgytfT1EGDLlWzjlvBuz7EXITq9/XvGQR9p5nQ/RQKEqXZyEvoeZ4ld0OGz6AOX8SK++8f0HWAUjeImK09m15Z+ZfL/+9B/CkEMQA7ncpybGuGkqpbkB34Jdatt+mlNqklNqUkZFRbXtAQABZWVmtUgzKrOLy8PfxIisri4CABp6kYt9iKYT2Lq68PjdBHvxd30jtbci1UvvWNkmbuFHSpUjrJ7SWVixJjvXbPoewrtDvEmmC2GWMFHrzr5eXbO70yjXuNa/CWyNFdNwpzJBjDZkGV86UQnTDB1LD7DpG0pz3L5g2D87/j9Qov5gutc6BV0J4rAiXs2a7dY4UDtPmwtAZsG8J9DgTLnsbfANh1Ysiil6+UovMS66cH6c1AFLQ/fw0fDBJCpMMh+tr80diPfU+H0beDPlJ0rpn3XsiZl3GuCyCvUvA21/uVWkuxE6QPGfsgW/vgZmTXO63De+L62jVi1JYt68iBGFdwT9UClwnKdsgbVf1/11rudfRw6DDQFj8AMy5Gj6+WLYPmSbf7u6hn58Rt9iFL8GYO+T+LP6bCNaRNSJyi+4VS3HfDxAQBhl7xe3TeRTctw1G3ARRvUX0sw6Cb7AU2MNvkOfk4pchvDvMnQZvjoA5V8H8G6SgDoyQ33YrDJ4KeYnyH/Q4UwrduzfAjK9gwl8lvz3OFDHb9jlE9ZHfaXEQ65jy02mhrn9XatzJm0WUZ18lIhHaufL1dBoKU14TMTv0iwT1350gwpEdDwcdFt2qF0SULn4Frl8If14ulRWoXHFy/g8/PARLHoSovpL/4deLtbttDhxcDsVZMPVTEcsh06v/lw1Ac+lHcC2wQGttq2mj1nomMBNkYpqq2zt37kxSUhI1iURLRmtNTrGFknIbPgWBBAYE0Lnzic9UVSf7fpDv+F+lZuLlqBtkHZTvPpOl5jbgMvBvKy/p2regLA/82sqD7XSXlOTIPmUFUiPvMga8HC6trmNEdHLipTCM/1UEYeydcP6/pdYHsPAusR56nyvL22aDrQzG3SPn7z8FdjjEostY+VYK+k6W3xl7Yetnki4oAsK6AVpqblG9oDBV2sf3mQy9L4CzHhEfO0ity+k7vuQ1KRx/ex0uelHMcksJBIa77l3uUam5l+TAgaVSOPsGy7UD9DgLQqLBP8TlHjjvGXFlbfhAxGPfEkkXMwJWPivXZLdD4gYRYrtVarHDrpNae2Qv13/TrspkTEpJoe4UGa0lTlGSAzcugs5uc5KkbJWYzZTXpdBP2yUFzuqX5Tp7ni3pnEKQsA42fST/15jbZJ3NInk7sEzu8bWfw7d3wS//kWdm0mPi1ss6IDX2QMfQKJG9RfQS1sl/4t5XISgCrv8aPr4E2rSXwi8oUsTj8CqYd53Ums94UIQIREgAfPyg17muY8WMlP/DUiRWwrbPpbA/61H4bIOcv98lUjkA+O0N+X/T94iV0v1MESPn9Zz1qKQbfoOISfYhEaxv7xahKkyXCsb2uTDseojo7nhORzncWkrue+/zXHlc+Zz8r+Pvk2fDeS8GXSXPyZE1cr29zxer2EN4UgiSAff58Do71tXEtcDdJ3siX19funfvfrK7Nzs+W3uEOesTKC63kZBdzA3juvHMeA/MwFZWIAVySIzUYNN3Q8dBss3pprnsbXkRnQ9ov4tdheWw62D9exL0q1oLzUuEETe61jkL7ehhcM1sKZyWPi7H6niauCjOfBj2fC+1sHs2gF8bqbV2GQvtHJO8D7nWFbPoUsNQ2+c9I7WzcffIcnisfOcckUKnOFtedqXkE+b2iI69U64nKEpe9mPbpRZuLZECL7idqzBoP0Cu0xl/2PyxK3+b/gchnaWTl1Iiols/gzMekgKt42ARt11fy/6n/11e9MMr5f4WZ7n84OGx4hpI3Sm11RlfS+0xZSu0r+GZ6DhICja7XQqq/CTw8pHa/p2/i9tpwS1yP7z9YcDl4OMPMcNlf2chpTUEhMoxMvZLgRfW1XX9AP0ugo0fSGHm10b+j/H3ioAC9L0QOjieJ/fCPqq3fB/bBoOurn4NoZ3hvq3VO7P1uxhG/lnyEdUH2kZLLb9dLRMr+fhBt/FwcBn0uRDadpJ703WcPIeJ6+U/ztgj99lZGRl7l0sIx98Li//uul4nEd3lM/FvYgEEhotwzZsheRpXpTjzbyt5drcI1r8v+w6bUVkEAC58QQQpZYvkx4MiAJ51DW0Eeiuluiul/JDCflHVREqpfkA4sNaDeWkxFJZZeemnfZRabMRGBfPOdcN55rJBJ3ew1J3iz806JMsFqVLDc7pJDv4MtnI49ylZPrzStW/WATHt3UUApDYPUigOvFJ+J2+p7GPd+718u9dYY4bD6Nvg8vfESgiOEtM5KBK+v1/SnHYNXPqGCMvK56WgyNgrhauT7mdKARDVV2qPVQmKgJsXix8aILybfOceke+SnMq1endCO8Pk5yXu4OUNF74oBcKWT8EnEArTHG3rlRR6FUFoJYUNSM0TxC3hvG8T7pcC7HRHAeksHBc/IIVt/0vFcrjlBylcnAV8pyFwwXPiW942R9wxnUeKa+b0B2u+/g6DpAacE+/6P6+dK7GMtW9LXCRhnaQ77xlXLb0qSomQJa6XIK+Xj7RMCghxpek2UaydnHjoNkEKq6HXyX8a2lXO4RRcdyJ7uX47RaGm89e07pJXYOL98vu8p+XZrav388T74ezHITRGhGTa52L1dh0jhfIP/xALcdo8yX/bTjDJTeyGTpeKQWgX1/9W6fh/l4L6+m/kubFbxRqN7Fk9bfQwsUjS98KSh+Tc/S6BS16vfg3+beG6BfKfOys1HsRjFoHW2qqUugf4CfAGZmmtdymlnkHaszpF4VrgC90aHfwnwRcbEsgvtfLJLaMZ1rWWAitjvzzYfseZVGbTLKn5bflEakQfOdwnHQbBrb9I4RIYIQX6qhfEFxrVW8zezAPyu+oD2mWMvBjdxkvNVnnLC5V9SArowlSp1UPlGqu3L1z0UuVj+QWJOKx8TmpLzpdnxI1SaO1dLLXWgZe79vHyhqv/V/d1u9OmoxzDGXStSwgARt/q+u3jB1M/E5dCRHepVe/7Adp0cBVmXj7Q8xw48JO0VmnXVzp5ubthonpJAVax3EdiEGX50rqlaoHecbB8D5kuLqxLXhU3R6fTZH2XUfKpCadFlxYnQc3QLlLLd7oaAAZeUb97GNFD4iX+IXDT4uqFm9MVs+trET6QOMvUT+V3bQV0WFf5T2xllUXhRDlt6vHTxE6UT1XG3CkVmCOrxWJr30/cOm07SSHsxDcQpn4iv2u6Ht8AEQCQGILNKq6+mug8Utya74yR92bkLSL03rUUw8GRYhk0Ah6NEWitlwBLqqx7osryU57MQ0vCYrMza008Y7pHVBeBPd+5al3vny41zMnP1nGwUldLoB3zxQccFAXj7pKg3+fXwOEVEmj19hHXxLp34POpUnPNOugyj93x9pFCITBMCvKOg8Wktlul1p+2S2qIPgEut0xdjLpVCv0BboX9Bc+Kq2HDTCm0qhbc3cYf/7hOvLyk4KkQgtzK7qDj4d9GfOKWEin0i7OktVKYw9LoeBr0nCRC4AzeDq7B3eGOj5/cK61h+E3Vt7fvL/e4y1jJ/8hb6p/f9gPE/ZOwXtx+/aZIATbhPpdPfcJ99TtWx8EixtPmukSoKoOuhN0LK/vmayp43fHyFlFJ3y2i2BSEdIIbv5PGDc5xmtyvwZ3jXY8TpWBIHb3Ch14nz7LdKsHzmqyGJqK5BIsNwJajOaTklfLK2BLxjTtdIoXp4nsce7fUvKylIgwX/Kf2Wtf+H8WnPOImqQkWHINJ/yeF/LHtUni3HyB+cRATe8i14rff8pk0eauttubeWmXSYyIeIK4dW7kIQVRvV6C4LoIjpTWJu8vBL1iu7fQHpEb2RwmPdTWDLMmpvVCrC99AKaBTd4obxylyXceKlQTVg7d1cd0CuT9etXhn61v41JTPbhNg3duy7KypdxwsYqvt4nKqD+PulaBncB1DpPe7BP6+B9p2PLF8RvYSIWjKwlCpmuNMnsIv6PiVhCaihQ5e0zrZdFRa3QxP/wp+esy1wdkKZd9iaTkB4jeuqVmgk62fiavmgufED+0bBKP+ItsmPy+1n8vecgWhfPylgBhxk4gA1O6/dafPBVIYgLglIh37nEihGBxZczAsKKKBhKBbZSGoyzVUF9HD5DskWmqyvc6FwX8Sq6DvxTDg0vofKyDk+K69k+W6L+Hcp6VHt3std+oncM1n9T+Ot0/dIgBSmJ6oCIC4qobN8Nw9MJwQxiJoRmw+mkOv9m3w0+XigrCUSEHo7KiUc0SaprUfCOm7pOlhxxoCWAeWS/vjc56UWsjkFwDt8kWHREt75Zroe5H4hMvyXYX68bjov+I373GWNHmE2ltyNAWhXaS5a1GWBFJrC5Aej+jhEjgOiRbfsPs9nNaMRur0DZQg6cT7mzontTPw8sqxH0OTYiyCZoLdrtl8NIeR3cJdrXqcnZky9kqNHqAkW/yyMSOlt+PexeL3dmIpgSUPSCHubMI2dJq0fqgPvoHil/cJcLWDPh4hnSQY6t9WRAqkltxcCHH0Y0x3WFCBNbS2qQ+dHQHa+sQ+DIYWhBGCZsKhjELySiyM6BbuGsIg3zGoWcZecdvEjJDlHpOkNpWxR3rRzrpA2sfbbdJxKeeI9ND08T+5zJz/b7jlp5Pbv8touPmHyp1mmpqQaPl2utJO1jXUcZDcl35TGiZfBkMzwbiGmgnO+MCIbuGwzWkRJDkGGNsjtfROp8mgX52GyBgmPc+WZp5f3wofXSitgo6ukfbhziDhyRAQIsc/GZQ6sVY9jUGFEDg6vZ2sEICrf4LB0IowQtAMSMwuZv6mRCKD/egeFeyyCPKSpRNTaa60WBl5S+WmhB0GysfbT4avLTgmnWecY60YhLad5PuPWgQGQyvFCEETs/5wFtfP2sD9XvM4v5sXSp3nFiNIdI3UWVfwtd9Flbu/GyrjGyC9XZ330giBwVAJIwRNSHpBKffM3UrnsED+EnwYvxKHJVARI0iW+ACcWHNMQ3VCol3DYBghMBgqYYLFTcg/FuygoNTCOzOG41eQJIObQWXXUMpW8f23ad90GW0NOFsOKe/KQwgYDAZjETQVq/ZnsHJfBo9f3J9+4V7Sb0A5dLlCCBKlc1fvC+oeWMtwfJxxAufIowaDoQJjETQBNrvm2cV76BYZxA3jYmUSGHDN1WotkwCwpVh6whr//x/HaREYt5DBUA0jBE3AmoOZ7Esr4IHz++Ln4+UazthSLM1FraUyAQyIINQ0+JvhxHA2Ia1p6GaD4RTHCEETEJecB8Ckvu1khdMi0DbXpNjOAd+6n2l82g1BiJtryGAwVMIIQROw+1g+XSICaRvgGGjNKQTgmu6xfX8Z5mHQVY2fwdaIcQ0ZDLVigsVNwJGUVB73/QYs42RsH+dY+SCdx0BqsA/slVnCDH8cp2vICIHBUA1jETQyJeU2OuRs4YK8+TJlINRsEfgEmBYuDYl/Wxn2uDmNgWQwNBOMRdDI7E8rwFdbZKEwTb5zj0pfgeJM10iiPgFNk8HWzGVvN3UODIZmibEIGolSi41lu9PYlZKPP1ZZWZAqBX9pHrRzzPrldA2d7MihBoPBcIIYi6CR+CHuGH+bt522AT5c6mOTlYXpLrdQu74ycqi7a8hgMBgaAWMRNBL70woBKCi10iXUob+FqZWFANxcQ8YiMBgMjYOxCBqJwxmF9GwXzK2n92Bk2h7YDBSkuTqTVQiBsQgMBkPjYiyCRuJwRhE92rXh2tFd6RXh6D/gtAj82rrauRshMBgMjYwRgkbAarNzNKuYHu2CHSvK5bswHXKOQlhX6U8ARggMBkOjY4SgEUjKKaHcZqdnVBtZYXNMPFOWL/MNhHUFH4cQmFZDBoOhkTFC0AgczpRAscsiKHNtzImH8G4yixaYfgQGg6HRMULQCBzOkIHkerZzWgTllRO4WwSm1ZDBYGhkjBA0AocyCgkP8iU82E9WuFsEAGHdwMsLvP2hTEYmNRaBwWBoLIwQNAKHHC2GKrCVuywAEIsAXAFjMBaBwWBoNIwQeJhyq509Kfn06eA2p4C1DNp2AC9HN46qQuDtbwabMxgMjYbpUOYh7p6zhYm9o4gOC6SgzMo5/dwmn7eViUUQ3B4sRRDoGGra6Q4ybiGDwdCIGCHwADlF5SzeeYx1h7M4q297gvy8mdg7ypXAWg4+fmIV2K2u9b5Bjm8jBAaDofEwQuAB4lIk4JtVVM5XW5K4aHBHAny9XQmspeL+Of0BQLvWOwXAxAcMBkMjYoTAA+x0zEncp0Mb9qcVcsHAjpUT2MqlsO87ufJ6p0VgXEMGg6ER8WiwWCk1WSm1Tyl1UCn1SC1ppiqldiuldimlPvdkfhqLuOQ8ukYE8c9LBjAwOoRz/XZC2m5XAmsZePtV39HHWAQGg6Hx8ZhFoJTyBt4GzgOSgI1KqUVa691uaXoDjwITtNY5Sqn2NR+tZbEzOY/BMaGc3rsdp/eKghe6QZ/JcOVMSeC0CKribDVkLAKDwdCIeNIiGA0c1Fof1lqXA18Al1VJcyvwttY6B0Brne7B/DQKucXlJGaXMCgmVFbkJcoMZOVFrkS1WQRGCAwGQxPgSSGIARLdlpMc69zpA/RRSv2mlFqnlKriNBeUUrcppTYppTZlZGR4KLsNw66UfAAGO4UgNU6+LSWuRLaymi0C4xoyGAxNQFN3KPMBegNnAdOAD5RSYVUTaa1naq1Haq1HtmvXrpGzeGJsPJINwKBohxCkOYTAWupKZK3NNWSCxQaDofHxpBAkA13cljs71rmTBCzSWlu01vHAfkQYWiRaaxZtT2FM9wjXuEKpO+W7qkXgXZMQGIvAYDA0Pp4Ugo1Ab6VUd6WUH3AtsKhKmoWINYBSKgpxFR32YJ48SlxyPoczirh8mJsHLK0G15CxCAwGQzPCY0KgtbYC9wA/AXuA+VrrXUqpZ5RSlzqS/QRkKaV2AyuAh7TWWZ7Kk6f5Zmsyft5eXDSok6woK4TsePltrWoR1NV81AiBwWBoPDzaoUxrvQRYUmXdE26/NfB3x6dFE59ZxMJtyUzq147QIMecxOm7Ae0YU8gRI7DbZVgJ03zUYDA0E5o6WNwqiEvO48p3fgPgvnPcQhwZ++Q7ZrjLNeScprLO5qMmRmAwGBoPM8REA/DcD3vw9vJiwR3jiI0Kdm0olykqadPB5RpyTkpTZ/NRYxEYDIbGw1gEf5B9qQX8djCLmyfEVhYBcDUZDQyX3sR2m2uayhotAmew2FgEBoOh8aiXECilvlZKXayUMsJRhY9/j8ffx4vpo7tW3+is/TvnG7CU1G0R+BqLwGAwND71LdjfAaYDB5RSzyul+nowTy2C7Ym5zPhwPfM2JnLFsBhXvwF3rKXg5Qu+wa7lCougJteQiREYDIbGp15CoLVerrW+DhgOHAGWK6V+V0rdrJTy9WQGmysf/RbPloQcbjujJ49e1L/mRNYyqd07g8CWYjeLwIw1ZDAYmgf1dvUopSKBm4C/AFuB1xFhWOaRnDVz4jOLGN41nEcu7EdoYC1aaC2V2n2FEJS6tRqqodYfEiMiENHDM5k2GAyGGqhvjOAbYDUQBEzRWl+qtZ6ntb4XaOPJDDZHtNYcziiiR7vg6hvTdsPSx0HrWiwCh2uoJougTTt4LAW6jvFc5g0Gg6EK9bUI3tBaD9BaP6e1Pua+QWs90gP5atZkFJZRUGalR9VWQgB7FsHvb8rQ006LwOnqsR7HIgDw8q55vcFgMHiI+grBAPdRQZVS4UqpuzyUp2bP4QyZW6BHuxqMoZIc+baWikXgG+hqFmopcbMITEDYYDA0D+orBLdqrXOdC46JZG71TJaaP04h6F6TRVAsw1CLG8gZI3BYBJaSunsWGwwGQxNQ357F3kop5RgbyDkN5SlbksVnFuLv40VMWGD1jU6LwFLqihE4m4VaSwAlv41FYDAYmgn1FYIfgXlKqfcdy7c71p2SHM4oontUMF5eqvrGCiEoEYvAv61bsLgEvBy33FgEBoOhmVBfIXgYKfzvdCwvAz70SI5aAIczi+jfqW3NG0vcXEOWUghuV1kInAJgLAKDwdBMqG+HMrvW+l2t9dWOz/taa5unM9ccKbPaSMgu5k/li+D9M6snqBQsrtKP4Hg9iw0Gg6EJqJdFoJTqDTwHDAAqur1qrU+pnk92u+bRr3Zis2v6+KbB0e1gs4K34zbabVDiiKk7exG7xwgs7jEC4xoyGAzNg/q2GvoIeBewApOAT4HZnspUc+XNXw7y9dZkHjy/DzEhvoCGonRXgtI8WQeuGIGPvwiFl2+VVkPGIjAYDM2D+gpBoNb6Z0BprY9qrZ8CLvZctpof5VY7n6w9wrn923P3pF4y0xhAQaorkdMtBK6RRp2dyXwDK/cjMMFig8HQTKhvsLjMMQT1AaXUPUAyp9jQEiv2pZNdVMa00V1RSsl0kwCFbhZBNSEorTzZjLUEbAFiHXiZEb0NBkPzoL6l0V+RcYbuA0YAM4AbPZWp5siXm5J4KmgBk9b/WVZUCIGbReDsTAYSI7BVtQhKxSIwLYYMBkMz4rgWgaPz2DVa6weBQuBmj+eqmZFRUMaKfek8FXEQrxxHMNgpBAVproTuFkGpI52z0PcNdIhDG+MWMhgMzYrjWgSOZqITGyEvzZaFW5Ox2TWdLIkuAajJIihxswicouBuETjHHzIWgcFgaEbUN0awVSm1CPgSKHKu1Fp/7ZFcNSO01ny5OZHTYxTeWbng45h7wO7oRlHNIlAyNWVJFYvAxxEstpUbi8BgMDQr6isEAUAWcLbbOg20eiHYkZTH/rRCHjzLInfAaQk4+9MVuglBcTYEhIJfGzchcLMISvOMRWAwGJod9RICrfUpFxdw8tWWJPx9vJgY5nD1OC2BCtdQFYsgMBy8fd1cQ24xgsI0h0VghMBgMDQf6tuz+CMqekq50Frf0uA5amasPpDJxF5RBOX/LiuqxQjSZDYypSRGEBQBNgsUZcr2Sq2G3IamNhgMhmZCfV1D37v9DgCuAFIaPjvNi/SCUuIzi5g2ugskH5SVFULgsAxs5VL7D4pwfEdCWWH1YLFPgGk+ajAYmiX1dQ195b6slJoLrPFIjpoRG+OlMB8VGwHbD8jKqhYBiFUQFCExgsjeIhLWEtnmW8UisJVJDMFgMBiaCSfbvbU30L4hM9Ic2Xgkm0BfbwZ1DIKceFBeoO0yvITd5hpMzjnMREmuxAh83Sasqdp81FJiLAKDwdCsqJcQKKUKlFL5zg/wHTJHQatmfXw2w7uF4VuQJBZAeHfZoG2yHBojy4VpMgppWZ5YBpWEwK35qLUU0vdAh4GNeyEGg8FQB/Wdj6Ct1jrE7dOnqruotZFXYmFvaj6jYyOhKENWOgt+u1UsgradZLkwzdWTODDcZSlAZYsARET6nlLj9RkMhmZOfS2CK5RSoW7LYUqpyz2XraZnf1oBWsNpXUKhOEtWtukg33arfAJCpXNYcZYrOBxYi0XgXNemI0QPa5yLMBgMhnpQ3xjBk1rrPOeC1joXeNIzWWoeZBfJcNHt2vi7BpMLdoRFnELg7SuthIqzXWnqihEA9J1sRh41GAzNivqWSDWlq2/T0xZJXrEFgNBAXzeLwCkEjhiBl49YAMXZbhZBVSFwWgRB8m3cQgaDoZlRXyHYpJR6RSnV0/F5Bdh8vJ2UUpOVUvuUUgeVUo/UsP0mpVSGUmqb4/OXE70AT5FbIhZBeLDD9eMTAP6OCevtVvH1e/k4mo1muQacC6rFIuh9Hkx+Hnq6j9JhMBgMTU99heBeoByYB3wBlAJ317WDY/jqt4ELkbmOpymlBtSQdJ7Weqjj82G9c+5hcoot+Hgpgv28pZAPjBBXELiCxV7e4hoqqWIRVASLlWuAuYBQGHuna35jg8FgaCbUt0NZEVCtRn8cRgMHtdaHAZRSXwCXAbtP8DhNQm6xhbAgX5mNrDhbCnwv5yT1jhiB8nZZBMXZ0s/AP9RlEfgEyNATBoPB0Iypb6uhZUqpMLflcKXUT8fZLQZIdFtOcqyrylVKqR1KqQVKqS61nP82pdQmpdSmjIyM+mT5D5NXUk5YkKM2X+wYQ6hCCNxiBEGRYg0UZ0FAmASCnfEA03HMYDC0AOrrGopytBQCQGudQ8P0LP4OiNVanwYsAz6pKZHWeqbWeqTWemS7du0a4LTHJ6fIQligwxVUnOUQAm9ZdloEzmCxtkPOEUkDrmElnPEBg8FgaMbUVwjsSqmuzgWlVCw1jEZahWTAvYbf2bGuAq11lta6zLH4ITIfcrMgt0RcM6nyxQAAEj1JREFUQ4BDCKq6huwuiwAg65DEB8DNNWQsAoPB0PyprxD8H7BGKfWZUmo2sAp49Dj7bAR6K6W6K6X8gGuBRe4JlFKd3BYvBfbUMz8eJ6/Y4Rqy26TXcGBE9RiBM1gMkJcoacAVLDYWgcFgaAHUN1j8o1JqJHAbsBVYCJQcZx+rUuoe4CfAG5iltd6llHoG2KS1XgTcp5S6FLAC2cBNJ30lDUxOscM1VJonrp+agsVePtJcFABtLAKDwdAiqe/ENH8B/oq4d7YBY4G1VJ66shpa6yXAkirrnnD7/SjHtywanVKLjRKLTVxDzs5kQZGuGIGtBosA3GIEzmCxsQgMBkPzp76uob8Co4CjWutJwDAgt+5dWi75JdKrOCzIzzV0RFC4yyKwlQO6cowA3CwCZ7DYWAQGg6H5U18hKNValwIopfy11nuBvp7LVtOSWyEEVS0CR/DY6ohve3nLJDPO9RVCYCwCg8HQcqhvN9ckRz+ChcAypVQOcNRz2WpachwDzoUF+kGhczC5CJlmEmSWMRCLQCkRicJUlxBUDDRnhMBgMDR/6hssvsLx8yml1AogFPjRY7lqYipZBOluFoFzQnprqXw7XUVVhcDXtBoyGAwthxMe+EZrvcoTGWlOOEcerXANefuDX7ArWOx0DSnHsjNI7Pz29hV3kYkRGAyGFoAZGL8GcoodriFnsDgoQlxATgugmkXgEACnRQAiHM5YgcFgMDRjzFCYNZBbYsHXWxHs6wVpuyA4SjZUCIFbsBhcLYecHcoArngPovo0ToYNBoPhD2CEoAZyiy2EBvqhds6HlC1wyWuyoZoQOJYjekJQlGu+AoC+FzZehg0Gg+EPYISgBnKLy4kOtMDSx6HzKBh+o2yoGiNwCsGY22HodDPktMFgaJGYGEEN5BZbGOpzFIoy4Ix/uOYYri1G4O3rihMYDAZDC8MIQQ3kFJfT3s9R62/jNtp2bTECg8FgaMEYIaiB7KJy2vk4av0Boa4N1SwCIwQGg6HlY4SgClprcorLifRxDK5aSQhqiREYDAZDC8YIQRUKy6xYbJowL4cQ+Ie4NlYMOmeEwGAwtB6MEFQhp0h6FYeoYhlQztutsK8tWGwwGAwtGCMEVch29Cpuo4squ4XABIsNBkOrxAhBFZwjjwbZ6xICh0WgjBAYDIaWjxGCKmQ7hMDfVlg5PgCO/gTKBIsNBkOrwghBFZwDzvlZ8qtbBCCFvxECg8HQijBCUIXsonJ8vBRe5QVGCAwGwymBEYIq5BSXEx7shyrNg4CQ6gm8fEyHMoPB0KowQlCF7KJyIgJ9oTSvFovA21gEBoOhVWGEoAo5RRY6BtlA2+pwDRmLwGAwtB6MEFQhu7ic6EDHJPUmRmAwGE4BjBBUIaeonI7OkUerNh8FKfxtpkOZwWBoPRghcMNulwHn2vs6CvraYgR2q+O3sQgMBkPLxwiBG/mlFuwaIiuGoA6rnsirhrGHDAaDoQVjhMANZ6/iCG/nENS1uIacmCEmDAZDK8AIgRtOIQhVxbKitmBxTb8NBoOhhWKEwIHVZufV5fvx8/aivZ+j1VCNwWLvmn8bDAZDC8UIgYOXl+3nt4NZ/PuKQYSqIvAJAN+A6gmNRWAwGFoZRggAm10zZ91RLj6tE1NHdpFexTVZA2CEwGAwtDqMEAB7juWTX2rl/AEdZEVtw0uAEQKDwdDq8KgQKKUmK6X2KaUOKqUeqSPdVUoprZQa6cn81MbaQ1kAjOsRKStKcusQAhMjMBgMrQuPCYFSyht4G7gQGABMU0oNqCFdW+CvwHpP5eV4/H4okx7tgmkfEgDpe+DIaug0pObETitAeYFSjZdJg8Fg8BCetAhGAwe11oe11uXA/7d3/0FWlfcdx98fVpZkgQRWQPwBLBiSiok/kKBGTW21KRojtrWVNLWp7YyTGZ2Jk2Sq1tQ45i/T1mQ641TphIlpTTRptd1EMqZxUhwzQ2Sl/JAgiggDlF+JiLAIy+5++8d5Fq7LvQvL7rl3e87nNbOz9z733Hu/+9yzz/c+z3POc54EFlbZ7uvAQ8ChHGOpqbunlxWb9/KJc0+HCHj2y9lF63/nb6o/oS8ReFjIzAoiz0RwNrC14v62VHaUpLnAtIh4Nsc4avr75zawaPFyDhzu5vJZk+DNF2DLL+Dar8HYSdWf5ERgZgXTsMliSaOAh4Evn8S2t0vqkNSxZ8+eYXn/Q0d6eOyFN/jft99l/sxWrpw9CXauyR6cc1PtJ/bNCzgRmFlB5NmabQemVdw/J5X1GQ98FPhvZWPtU4F2STdGREflC0XEYmAxwLx582I4glu99W2O9ARfv+mjXHNeOlpo96swdjK0tNZ+4tEegSeKzawY8uwRrABmS5opqRlYBLT3PRgR+yJiUkS0RUQbsBw4LgnkpWPLXgAumTHxWOGe9TD5twZ+YtPo7LfXGTKzgsgtEUREN3An8BywHvhBRKyT9KCkG/N635O1YvNbzJ4yjgktzVlBBOzZAFPOG/iJniMws4LJtTWLiKXA0n5l99fY9uo8Y6nU2xu8vGUvN1xw1rHCfdug68CJewSeIzCzgilla/ba7v3sP9TNx9smwqF3YM1T8IF0QNNJ9wg8NGRmxVDKRPCDFdsA+HhbK6x/GpZ+BVpnZQ+esEfgoSEzK5bSrTX08w27WfKLN7n1shlMa22Bt97MHnhrE4ydMvARQ+BEYGaFU7rW7IH2dXzkjPHc9+k0BLR3M7y/FboPnXhYCDw0ZGaFU7pEsGPfIW67oo33jU4N+dtbYOrH4Op7q1+asr+jk8VOBGZWDKUaGjrS00tXdy+n6wB0LMkOGd27GSbOgBmXwxnnn/hFPDRkZgVTqtbsYFcPAPN3fh+WfxumzIHOPTCx7eRfxInAzAqmVD2Cg13dALT9ellWsOap7PeEGSf/Ik4EZlYwJUsEPUzXLiYc2JgVrHsm+z1x5sm/SN/cgJeYMLOCKFciONzD7416Obtz1sXwbrbe0KkNDTkRmFkxlCoRdHZ1c+2olXRO+DBccEtW2DzuxOcOVPLQkJkVTKkSQfe+7cwftZ79bQtg2qVZ4cS2wV1y0onAzAqmVK1Z6xvtNCk4dN7NMHUOjG4Z3EQxeNE5Myuc8rRmEZy15T9Y2fshpkyZnV1X4IZvDW5+ADxHYGaFU56hoZ1rmbD/dZ7uuYqxzakxv/AWmH7p4F7HicDMCqY8ieDVZ+nRaH7UczktY4bQiHuOwMwKpjyt2W/fzXf2XkhnBzQ3DSH/ORGYWcGUp0cwahRbT5tBS3MTGsxRQse9jhedM7NiKU8iIFtioqV5iN/k3SMws4IpVSLo7OoZ2vwAOBGYWeGUKhEcPNx97IihU9WXALzWkJkVRLkSQVcPLc1D7RH4hDIzKxYngsHyeQRmVjClSgSdXd20jPFksZlZpVIlgoOHexg7bD0CJwIzK4ZSJYLOYTl81OcRmFmxlCYRRATvdvUwdtgOH3UiMLNiKE0i6Orppbs3fEKZmVk/pUkEBw/3AAzjUUNOBGZWDKVJBJ1d3QDDd0KZE4GZFURpEsHBrtQjGPIcgU8oM7NiKV8iGK6hIZWm6sys4ErTmh08nA0NDXmyePyZcMltMOvqIcdkZjYSlGZ8ozP1CIY+R9AEn/nWMERkZjYy5NojkLRA0gZJGyXdU+XxL0haK2mVpBclzckrloNpsnjIcwRmZgWTWyKQ1AQ8AlwHzAE+W6Wh/15EfCwiLgK+ATycVzzDNkdgZlYwefYI5gMbI2JTRHQBTwILKzeIiHcq7o4FIq9gOodrjsDMrGDybBXPBrZW3N8GXNp/I0l3AF8CmoHfrfZCkm4HbgeYPn36KQUzvbWFBedPdY/AzKyfhh81FBGPRMS5wN3AV2tsszgi5kXEvMmTJ5/S+3zq/Kk8eusljG5q+J9sZjai5NkqbgemVdw/J5XV8iRwU47xmJlZFXkmghXAbEkzJTUDi4D2yg0kza64+2ng9RzjMTOzKnKbI4iIbkl3As8BTcCSiFgn6UGgIyLagTslXQscAfYCn88rHjMzqy7XQ2giYimwtF/Z/RW3v5jn+5uZ2Yl55tTMrOScCMzMSs6JwMys5JwIzMxKThG5reqQC0l7gC2n+PRJwK+HMZzhNFJjc1yD47gGb6TGVrS4ZkRE1TNy/98lgqGQ1BER8xodRzUjNTbHNTiOa/BGamxlistDQ2ZmJedEYGZWcmVLBIsbHcAARmpsjmtwHNfgjdTYShNXqeYIzMzseGXrEZiZWT9OBGZmJVeaRCBpgaQNkjZKuqeBcUyT9HNJv5K0TtIXU/kDkrZLWpV+rm9AbJslrU3v35HKWiX9l6TX0++JdY7pIxV1skrSO5LualR9SVoiabekVyrKqtaRMv+Y9rk1kubWOa6/k/Rqeu9nJE1I5W2S3q2ou0frHFfNz07Svam+Nkj6/bziGiC2pyri2ixpVSqvS50N0D7ku49FROF/yJbBfgOYRXZJzNXAnAbFciYwN90eD7wGzAEeAL7S4HraDEzqV/YN4J50+x7goQZ/jjuBGY2qL+CTwFzglRPVEXA98BNAwGXAL+sc16eA09LthyriaqvcrgH1VfWzS/8Hq4ExwMz0P9tUz9j6Pf4PwP31rLMB2odc97Gy9AjmAxsjYlNEdJFdDW1hIwKJiB0RsTLd3g+sJ7u+80i1EHg83X6cxl5F7hrgjYg41TPLhywiXgDe6ldcq44WAt+NzHJggqQz6xVXRPw0IrrT3eVkVwmsqxr1VctC4MmIOBwRbwIbyf536x6bJAF/Anw/r/evEVOt9iHXfawsieBsYGvF/W2MgMZXUhtwMfDLVHRn6t4tqfcQTBLATyW9LOn2VHZGROxIt3cCZzQgrj6LeO8/ZqPrq0+tOhpJ+91fkn1z7DNT0v9IWibpqgbEU+2zG0n1dRWwKyIqr5pY1zrr1z7kuo+VJRGMOJLGAf8O3BUR7wD/BJwLXATsIOuW1tuVETEXuA64Q9InKx+MrC/akOONlV3u9Ebgh6loJNTXcRpZR7VIug/oBp5IRTuA6RFxMfAl4HuSPlDHkEbkZ9fPZ3nvl4661lmV9uGoPPaxsiSC7cC0ivvnpLKGkDSa7EN+IiKeBoiIXRHRExG9wD+TY5e4lojYnn7vBp5JMezq62qm37vrHVdyHbAyInalGBteXxVq1VHD9ztJfwHcAHwuNSCkoZffpNsvk43Ff7heMQ3w2TW8vgAknQb8IfBUX1k966xa+0DO+1hZEsEKYLakmemb5SKgvRGBpLHHbwPrI+LhivLKcb0/AF7p/9yc4xoraXzfbbKJxlfI6qnvWtKfB/6znnFVeM83tEbXVz+16qgd+PN0ZMdlwL6K7n3uJC0A/hq4MSIOVpRPltSUbs8CZgOb6hhXrc+uHVgkaYykmSmul+oVV4VrgVcjYltfQb3qrFb7QN77WN6z4CPlh2x2/TWyTH5fA+O4kqxbtwZYlX6uB/4FWJvK24Ez6xzXLLIjNlYD6/rqCDgdeB54HfgZ0NqAOhsL/Ab4YEVZQ+qLLBntAI6Qjcf+Va06IjuS45G0z60F5tU5ro1k48d9+9mjads/Sp/xKmAl8Jk6x1XzswPuS/W1Abiu3p9lKv8O8IV+29alzgZoH3Ldx7zEhJlZyZVlaMjMzGpwIjAzKzknAjOzknMiMDMrOScCM7OScyIwqyNJV0v6caPjMKvkRGBmVnJOBGZVSPozSS+ltecfk9Qk6YCkb6Z14p+XNDlte5Gk5Tq27n/fWvEfkvQzSaslrZR0bnr5cZL+Tdm1Ap5IZ5OaNYwTgVk/ks4DbgGuiIiLgB7gc2RnOHdExPnAMuBr6SnfBe6OiAvIzu7sK38CeCQiLgQ+QXYWK2QrSt5Fts78LOCK3P8oswGc1ugAzEaga4BLgBXpy/r7yRb56uXYQmT/Cjwt6YPAhIhYlsofB36Y1m06OyKeAYiIQwDp9V6KtI6NsitgtQEv5v9nmVXnRGB2PAGPR8S97ymU/rbfdqe6Psvhits9+P/QGsxDQ2bHex64WdIUOHq92Blk/y83p23+FHgxIvYBeysuVHIrsCyyq0ttk3RTeo0xklrq+leYnSR/EzHrJyJ+JemrZFdrG0W2OuUdQCcwPz22m2weAbJlgR9NDf0m4LZUfivwmKQH02v8cR3/DLOT5tVHzU6SpAMRMa7RcZgNNw8NmZmVnHsEZmYl5x6BmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyf0fC6uEPhDIHvIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDHJIheU8bm",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cydHkZ8pauMe",
        "colab_type": "text"
      },
      "source": [
        "**Non_Adversarial Training Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkjbXCV6KFcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon_list = [0.003,0.005,0.01,0.02]\n",
        "train_object = Non_adversarial()\n",
        "sgd = SGD(lr=0.1, momentum=0.6)\n",
        "result_df = train_object.train_iterate(X_train, Y_train, X_test, y_test, EPOCHS, BS,sgd, epsilon_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IkS-pL3EkeO",
        "colab_type": "text"
      },
      "source": [
        "# **Show Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH9uGMSFVwwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df[\"acc_clean_mean\"]= np.sum(result_df['acc_clean'])/3.0\n",
        "result_df[\"acc_0.003_mean\"]= np.sum(result_df['acc1'])/3.0\n",
        "result_df[\"acc_0.005_mean\"]= np.sum(result_df['acc2'])/3.0\n",
        "result_df[\"acc_0.01_mean\"]= np.sum(result_df['acc3'])/3.0\n",
        "result_df[\"acc_0.02_mean\"]= np.sum(result_df['acc4'])/3.0"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvrbKwan2yV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "210af884-83ed-4c28-c575-7b434c46bb2e"
      },
      "source": [
        "result_df.head(1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>loss4</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc_clean_mean</th>\n",
              "      <th>acc_0.003_mean</th>\n",
              "      <th>acc_0.005_mean</th>\n",
              "      <th>acc_0.02_mean</th>\n",
              "      <th>acc_0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.006274</td>\n",
              "      <td>0.65445</td>\n",
              "      <td>1.087387</td>\n",
              "      <td>0.619546</td>\n",
              "      <td>1.143842</td>\n",
              "      <td>0.603839</td>\n",
              "      <td>1.29054</td>\n",
              "      <td>0.549738</td>\n",
              "      <td>1.596286</td>\n",
              "      <td>0.455497</td>\n",
              "      <td>0.691681</td>\n",
              "      <td>0.662595</td>\n",
              "      <td>0.643979</td>\n",
              "      <td>0.585806</td>\n",
              "      <td>0.477022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  ...  acc_0.02_mean  acc_0.01_mean\n",
              "0    1.006274    0.65445  ...       0.585806       0.477022\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuWpwrKuwmsc",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDxVNgZvPRHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Adversarial Training \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "class AdversarialTraining(object):\n",
        "    \"\"\"Adversarial Training  \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def train(self, pretrained_model, X_train, Y_train, X_test, y_test, epochs, BS, epsilon_list, sgd):\n",
        "        init = (32, 32,1)\n",
        "        res_df = pd.DataFrame(columns=['loss_clean','acc_clean',\n",
        "                                 'loss1', 'acc1','loss2', 'acc2','loss3',\n",
        "                                  'acc3','loss4', 'acc4'])\n",
        "\n",
        "        kfold = KFold(n_splits = 3, random_state = 42, shuffle=False)\n",
        "        for j, (train, val) in enumerate(kfold.split(X_train)):\n",
        "          x_train, y_train = self.data_augmentation(X_train[train], Y_train[train], BS, pretrained_model, epsilon_list)\n",
        "          x_val, y_val = self.data_augmentation(X_train[val], Y_train[val], BS, pretrained_model, epsilon_list)\n",
        "          model = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "          model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "          hist = model.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=epochs,\n",
        "                          callbacks = [lr_scheduler],\n",
        "                          validation_data=(x_val, y_val),\n",
        "                          validation_steps=x_val.shape[0] // BS,)\n",
        "          loss, acc = model.evaluate(X_test, y_test)\n",
        "          loss1, acc1 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[0]),X_test, y_test, epsilon_list[0])\n",
        "          loss2, acc2 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[1]),X_test, y_test, epsilon_list[1])\n",
        "          loss3, acc3 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[2]),X_test, y_test, epsilon_list[2])\n",
        "          loss4, acc4 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[3]),X_test, y_test, epsilon_list[3])\n",
        "          row = {'loss_clean':loss,'acc_clean':acc, 'loss1':loss1, 'acc1':acc1, 'loss2':loss2,\n",
        "                  'acc2':acc2, 'loss3':loss3, 'acc3':acc3, 'loss4':loss4, 'acc4':acc4}\n",
        "          res_df = res_df.append(row , ignore_index=True)\n",
        "          \n",
        "        return res_df\n",
        "    def mini_batch_train(self, model, X_train,y_train, x_val, y_val, BS, pretrained_model, epsilon):\n",
        "\n",
        "\n",
        "        hist = model.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=1,\n",
        "                   validation_data=(x_val, y_val),\n",
        "                   validation_steps=x_val.shape[0] // BS, shuffle = True)\n",
        "        \n",
        "        ### TODO ###\n",
        "        ## Save hist on file.###\n",
        "\n",
        "\n",
        "    def data_augmentation(self, X_train, Y_train, batch_size, pretrained_model, epsilon_list):\n",
        "      ### divide data 16,16,16,16 for 4 different epsilons and 64 is true image. ### \n",
        "        #start_index = self.data_iteration(X_train, batch_size)\n",
        "        first_half_end = int(len(X_train)/2)\n",
        "        second_half_end = int(len(X_train))\n",
        "        x_clean = X_train[0:first_half_end,:,:,:]\n",
        "        x_adv = self.get_adversarial(pretrained_model,X_train[first_half_end:second_half_end,:,:,:], Y_train[first_half_end:second_half_end], epsilon_list)\n",
        "        x_mix = self.merge_data(x_clean, x_adv)\n",
        "        y_mix = Y_train[0:second_half_end]\n",
        "        ### TODO###\n",
        "        # Mixture data for 4 epsilon values\n",
        "\n",
        "        return x_mix, y_mix\n",
        "\n",
        "    def data_iteration(self, X_train, batch_size):\n",
        "        N = X_train.shape[0]\n",
        "        start = np.random.randint(0, N-batch_size)\n",
        "        return start\n",
        "\n",
        "    def merge_data(self, x_clean, x_adv):\n",
        "        x_mix = []\n",
        "        for i in range(len(x_clean)):\n",
        "          x_mix.append(x_clean[i])\n",
        "        for j in range(len(x_adv)):\n",
        "          x_mix.append(x_adv[j])\n",
        "        x_mix = np.array(x_mix)\n",
        "\n",
        "        return x_mix\n",
        "\n",
        "\n",
        "    def get_adversarial(self,logits_model, X_true, y_true, epsilon_list):\n",
        "\n",
        "        return self.adversarial_example(logits_model,X_true, y_true, epsilon_list)\n",
        "\n",
        "    def adversarial_example(self,logits_model, X_true, Y_true, epsilon_list):\n",
        "        size = len(X_true)\n",
        "        X_adv = []\n",
        "        interval = int(size/4)\n",
        "        index_list = [0,interval, interval*2, interval*3, size]\n",
        "        index = 0\n",
        "        for epsilon in epsilon_list:\n",
        "          if index == 4:\n",
        "            break\n",
        "          x_true = X_true[index_list[index]:index_list[index+1],:,:,:]\n",
        "          y_true = Y_true[index_list[index]:index_list[index+1]]\n",
        "\n",
        "          index = index + 1\n",
        "\n",
        "          for i in range(len(x_true)):\n",
        "            random_index = i\n",
        "            original_image = x_true[random_index]\n",
        "            original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "            original_label = y_true[random_index]\n",
        "            original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "            adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "            X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "          \n",
        "        X_adv = np.array(X_adv)\n",
        "        return X_adv\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW5vG0s9PAmw",
        "colab_type": "text"
      },
      "source": [
        "Adversarial Training Second Wide ResNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3373MWPvSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon_list = [0.003,0.005,0.01,0.02]\n",
        "adversarial_training =  AdversarialTraining()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2LxFwajOiI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits_model = tf.keras.Model(wrn_16_2.input, wrn_16_2.layers[-1].output)\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i82EfjWHP2mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_adv_df = adversarial_training.train(logits_model, X_train, Y_train, X_test, y_test, EPOCHS, BS, epsilon_list, sgd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xBzRKS8IoCR",
        "colab_type": "text"
      },
      "source": [
        "# **Show Result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2KYCUfIFW6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_adv_df[\"acc_clean_mean\"]= np.sum(result_adv_df['acc_clean'])/3.0\n",
        "result_adv_df[\"acc_0.003_mean\"]= np.sum(result_adv_df['acc1'])/3.0\n",
        "result_adv_df[\"acc_0.005_mean\"]= np.sum(result_adv_df['acc2'])/3.0\n",
        "result_adv_df[\"acc_0.02_mean\"]= np.sum(result_adv_df['acc3'])/3.0\n",
        "result_adv_df[\"acc_0.01_mean\"]= np.sum(result_adv_df['acc4'])/3.0"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgmnwxkO5xdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "b8b1ff5e-7890-4dff-b1df-4f4f76b80bae"
      },
      "source": [
        "result_adv_df.head(1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>loss4</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc_clean_mean</th>\n",
              "      <th>acc_0.003_mean</th>\n",
              "      <th>acc_0.005_mean</th>\n",
              "      <th>acc_0.02_mean</th>\n",
              "      <th>acc_0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.957502</td>\n",
              "      <td>0.708551</td>\n",
              "      <td>0.969366</td>\n",
              "      <td>0.703316</td>\n",
              "      <td>0.977373</td>\n",
              "      <td>0.696335</td>\n",
              "      <td>0.997614</td>\n",
              "      <td>0.684119</td>\n",
              "      <td>1.039549</td>\n",
              "      <td>0.670157</td>\n",
              "      <td>0.710878</td>\n",
              "      <td>0.706806</td>\n",
              "      <td>0.703898</td>\n",
              "      <td>0.685864</td>\n",
              "      <td>0.66783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  ...  acc_0.02_mean  acc_0.01_mean\n",
              "0    0.957502   0.708551  ...       0.685864        0.66783\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}