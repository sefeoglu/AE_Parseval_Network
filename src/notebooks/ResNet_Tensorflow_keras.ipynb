{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqbIFJTwXLH",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "outputId": "1d65b1c9-1d0e-4bc7-a2b0-3dbdb0e5ae14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "    wrn_16_2.summary()\n",
        "\n"
      ],
      "execution_count": 634,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n",
            "Model: \"model_50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 32, 32, 16)   144         input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 32, 32, 16)   64          conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 32, 32, 16)   0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 32, 32, 32)   4608        activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 32, 32, 32)   128         conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 32, 32, 32)   0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 32, 32, 32)   9216        activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 32, 32, 32)   512         activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_168 (Add)                   (None, 32, 32, 32)   0           conv2d_450[0][0]                 \n",
            "                                                                 conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 32, 32, 32)   128         add_168[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 32, 32, 32)   0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 32, 32, 32)   9216        activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 32, 32, 32)   0           conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 32, 32, 32)   128         dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 32, 32, 32)   0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 32, 32, 32)   9216        activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_169 (Add)                   (None, 32, 32, 32)   0           add_168[0][0]                    \n",
            "                                                                 conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 32, 32, 32)   128         add_169[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 32, 32, 32)   0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 16, 16, 64)   18432       activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 16, 16, 64)   256         conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 16, 16, 64)   0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 16, 16, 64)   36864       activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 16, 16, 64)   2048        activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_170 (Add)                   (None, 16, 16, 64)   0           conv2d_455[0][0]                 \n",
            "                                                                 conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 16, 16, 64)   256         add_170[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 16, 16, 64)   0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 16, 16, 64)   36864       activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 16, 16, 64)   0           conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 16, 16, 64)   256         dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 16, 16, 64)   0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 16, 16, 64)   36864       activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_171 (Add)                   (None, 16, 16, 64)   0           add_170[0][0]                    \n",
            "                                                                 conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 16, 16, 64)   256         add_171[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 16, 16, 64)   0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 8, 8, 128)    73728       activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 8, 8, 128)    512         conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 8, 8, 128)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 8, 8, 128)    147456      activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 8, 8, 128)    8192        activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_172 (Add)                   (None, 8, 8, 128)    0           conv2d_460[0][0]                 \n",
            "                                                                 conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 8, 8, 128)    512         add_172[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 8, 8, 128)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 8, 8, 128)    147456      activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 8, 8, 128)    0           conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 8, 8, 128)    512         dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 8, 8, 128)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 8, 8, 128)    147456      activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_173 (Add)                   (None, 8, 8, 128)    0           add_172[0][0]                    \n",
            "                                                                 conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 8, 8, 128)    512         add_173[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 8, 8, 128)    0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 1, 1, 128)    0           activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_28 (Flatten)            (None, 128)          0           average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 4)            516         flatten_28[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 692,436\n",
            "Trainable params: 690,612\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNo5x-Ft9Fe",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepare and Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "outputId": "89c1ee35-8d22-42c6-a68d-22513686f8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 637,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 637
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "outputId": "18c4ae99-6ef8-4481-fbc5-ab4bf15137ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 638,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 638
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQdrnTKuM8c",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hwq9R2jruF",
        "colab_type": "code",
        "outputId": "c8189adc-91ec-4a1f-b202-5746c55b708f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 641,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open             1500\n",
              "closed           1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 641
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAYuiEzj4Bp",
        "colab_type": "code",
        "outputId": "7b75301d-c4eb-4206-aeed-ca0a07b77ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 642,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 642
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kif3Li9NuSnV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "import tensorflow\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 256\n",
        "sgd = SGD(lr=0.1, momentum=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "outputId": "a61a6ff6-f89e-439d-ace0-91fccbf781b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": 645,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 80:\n",
        "        return 0.01\n",
        "    elif epoch < 120:\n",
        "        return 0.001\n",
        "    elif epoch < 160:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "outputId": "f3d6be8c-4df6-4229-ac93-f29b07968073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = wrn_16_2.fit_generator(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks=[lr_scheduler],\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 2s 108ms/step - loss: 2.5267 - acc: 0.2508 - val_loss: 2.5251 - val_acc: 0.2951 - lr: 0.0100\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 2.5237 - acc: 0.3026 - val_loss: 2.5224 - val_acc: 0.2951 - lr: 0.0100\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.5208 - acc: 0.2995 - val_loss: 2.5197 - val_acc: 0.2621 - lr: 0.0100\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.5178 - acc: 0.3122 - val_loss: 2.5167 - val_acc: 0.2893 - lr: 0.0100\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.5140 - acc: 0.3198 - val_loss: 2.5126 - val_acc: 0.2990 - lr: 0.0100\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.5092 - acc: 0.3253 - val_loss: 2.5061 - val_acc: 0.3146 - lr: 0.0100\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.5027 - acc: 0.3378 - val_loss: 2.4996 - val_acc: 0.3359 - lr: 0.0100\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.4945 - acc: 0.3646 - val_loss: 2.4879 - val_acc: 0.3495 - lr: 0.0100\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.4845 - acc: 0.3595 - val_loss: 2.4751 - val_acc: 0.3456 - lr: 0.0100\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.4727 - acc: 0.3625 - val_loss: 2.4690 - val_acc: 0.3398 - lr: 0.0100\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.4594 - acc: 0.3595 - val_loss: 2.4528 - val_acc: 0.3417 - lr: 0.0100\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.4461 - acc: 0.3634 - val_loss: 2.4432 - val_acc: 0.4097 - lr: 0.0100\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 2.4359 - acc: 0.3635 - val_loss: 2.4249 - val_acc: 0.3767 - lr: 0.0100\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 2.4260 - acc: 0.3801 - val_loss: 2.4227 - val_acc: 0.3748 - lr: 0.0100\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.4157 - acc: 0.3751 - val_loss: 2.4191 - val_acc: 0.3612 - lr: 0.0100\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 2.4084 - acc: 0.3716 - val_loss: 2.4119 - val_acc: 0.3864 - lr: 0.0100\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.3994 - acc: 0.3805 - val_loss: 2.3890 - val_acc: 0.4291 - lr: 0.0100\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.3919 - acc: 0.3762 - val_loss: 2.3806 - val_acc: 0.4155 - lr: 0.0100\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3847 - acc: 0.3751 - val_loss: 2.4001 - val_acc: 0.3728 - lr: 0.0100\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3799 - acc: 0.3840 - val_loss: 2.4039 - val_acc: 0.3825 - lr: 0.0100\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.3719 - acc: 0.3938 - val_loss: 2.3812 - val_acc: 0.3592 - lr: 0.0100\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3622 - acc: 0.3952 - val_loss: 2.3437 - val_acc: 0.4039 - lr: 0.0100\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 2.3652 - acc: 0.3947 - val_loss: 2.3538 - val_acc: 0.3845 - lr: 0.0100\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 2.3590 - acc: 0.3933 - val_loss: 2.3452 - val_acc: 0.4058 - lr: 0.0100\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 2.3481 - acc: 0.3894 - val_loss: 2.3595 - val_acc: 0.3883 - lr: 0.0100\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 2.3497 - acc: 0.3858 - val_loss: 2.3562 - val_acc: 0.3981 - lr: 0.0100\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 2.3430 - acc: 0.4054 - val_loss: 2.3459 - val_acc: 0.3748 - lr: 0.0100\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.3514 - acc: 0.4041 - val_loss: 2.3200 - val_acc: 0.4272 - lr: 0.0100\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 2.3312 - acc: 0.4102 - val_loss: 2.3125 - val_acc: 0.4136 - lr: 0.0100\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3254 - acc: 0.4022 - val_loss: 2.3199 - val_acc: 0.4078 - lr: 0.0100\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3246 - acc: 0.4141 - val_loss: 2.3040 - val_acc: 0.4136 - lr: 0.0100\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 2.3257 - acc: 0.4045 - val_loss: 2.3177 - val_acc: 0.4117 - lr: 0.0100\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 2.3141 - acc: 0.4114 - val_loss: 2.3030 - val_acc: 0.3864 - lr: 0.0100\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3124 - acc: 0.4173 - val_loss: 2.2947 - val_acc: 0.4039 - lr: 0.0100\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3028 - acc: 0.4125 - val_loss: 2.3800 - val_acc: 0.3767 - lr: 0.0100\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 2.3127 - acc: 0.4054 - val_loss: 2.2902 - val_acc: 0.4097 - lr: 0.0100\n",
            "Epoch 37/200\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 2.2924 - acc: 0.4069"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.save(\"model_wrn_last.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djH4uwAnvkfb",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmZpcppX5u_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.evaluate(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDHJIheU8bm",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QB8zFSSU7Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bfZ4G8W_sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(wrn_16_2.input,wrn_16_2.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWIlakqVD_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv = []\n",
        "y_adv = []\n",
        "for i in range(len(X)):\n",
        "  random_index = i\n",
        "  original_image = X[random_index]\n",
        "  original_image = tf.convert_to_tensor(original_image.reshape((1,68,100))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "\n",
        "  original_label = y_cat[random_index]\n",
        "\n",
        "  epsilon = 0.5\n",
        "  original_label\n",
        "  adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "  adv_example_targeted_label_pred = wrn_16_2.predict(adv_example_targeted_label)\n",
        "  X_adv.append(adv_example_targeted_label)\n",
        "  y_adv.append(np.argmax(adv_example_targeted_label_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1DCXV9Tc9B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "my_data = {'image': X_adv,\n",
        "           'label': y_adv_df['Encoded']\n",
        "           }\n",
        "output = open('data_adv_50.pkl', 'wb')\n",
        "pickle.dump(my_data, output)\n",
        "output.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuWpwrKuwmsc",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfF0d5ePbXK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv = np.array(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5I9X-0mboqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df = pd.DataFrame(y_adv, columns=['Encoded'])\n",
        "y_adv_df['Encoded'] = labelencoder.fit_transform(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcxHP-bTcIwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df['Encoded'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1mGBoQbd46-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = []\n",
        "X_adv =my_data['image']\n",
        "for i in range(len(X_adv)):\n",
        "  a = np.array(X_adv[i])\n",
        "  X_new.append(a.reshape(68,100,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdE_WN8Ffgyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X)):\n",
        "  a = np.array(X[i])\n",
        "  X_new.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAnXO0Vfg1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_third = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jH1i_FMA2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dackr68mMA0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UIXimpiKWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_new = []\n",
        "for j in range(0,2):\n",
        "  for i in range(len(y_cat)):\n",
        "    y_new.append(y_cat[i])\n",
        "y_third = np.array(y_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuRIuXcNiKY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_all, y_all = X_third, y_third"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJXveP1Veo7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split( X_all,y_all, test_size = 0.33, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJjEg9qiI0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HibsOpTIcNq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q96wjHqxeTJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n",
        "BS_adv= 100\n",
        "EPOCHS_adv = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jewqs8yxlnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch_train(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.1\n",
        "    elif epoch <20:\n",
        "        return 0.1/2.0\n",
        "    elif epoch < 30:\n",
        "        return 0.1/2.0**2\n",
        "    elif epoch < 40:\n",
        "        return 0.1/2.0**3\n",
        "    else:\n",
        "        return 0.1/2.0**4\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler_train = LearningRateScheduler(lr_sch_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FIn8khEd45J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "hist = wrn_16_2_adv.fit_generator(generator.flow(X_train_adv, y_train_adv, batch_size=BS_adv), steps_per_epoch=len(X_train_adv) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test_adv, y_test_adv),\n",
        "                   validation_steps=X_test_adv.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qXnteSOpFZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.save(\"model_adv_wrn_tensor_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeetxZrNv9oM",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S5IjLivpMbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcU_6z90QSJ",
        "colab_type": "text"
      },
      "source": [
        "**CleanExperiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i5qUE6j0JUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4p2TUIj0csZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQljdkd0he9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_clean = wrn_16_2_clean.fit_generator(generator.flow(X_train, y_train, batch_size=BS_adv), steps_per_epoch=len(X_train) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   validation_steps=X_test.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1acrchBU185p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.save(\"model_adv_train_clean_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9hLRXbmwETE",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pgU_KsH0yVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist_clean\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCKONCZ0Jzfi",
        "colab_type": "text"
      },
      "source": [
        "**Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgpFgWbKeR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhiqvES18c-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHVWy96Llce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqj_Ax7MI4SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXT3YD6iLl0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test_adv,y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fKhEMXgKAnZ",
        "colab_type": "text"
      },
      "source": [
        "**Non_Adversarial_Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouj6OqTD8VdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfkUSeV6KHp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZFJl2D4Hbxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gJh7MDHChHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZuONcAeAwQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test_adv, y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}