{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/Grid_SearchCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nhsKKJZ02AK"
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from itertools import product\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from wresnet import WideResidualNetwork\n",
        "import tensorflow\n",
        "import cv2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e7tYj3yb3OM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL6uD0ur_1FG"
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    new_data_X = []\n",
        "    Y_data = []\n",
        "    for row in data:\n",
        "        new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "        Y_data.append(row['label'])\n",
        "    new_data_X = np.array(new_data_X)\n",
        "\n",
        "    return new_data_X, Y_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlEfFPS50iBi"
      },
      "source": [
        "def preprocessing():\n",
        "    # creating initial dataframe\n",
        "    X, Y = read_data()\n",
        "    y_df = pd.DataFrame(Y, columns=['Label'])\n",
        "    labelencoder = LabelEncoder()\n",
        "    y_df['Categrory'] = labelencoder.fit_transform(y_df['Label'])\n",
        "\n",
        "\n",
        "    img_rows, img_cols = X[0].shape\n",
        "\n",
        "\n",
        "    # transform data set\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "    Y_cat = to_categorical(y_df['Categrory'])\n",
        "    return X, Y_cat"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9X1E2wybnZj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8U0Vk9t0l3V"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "class ModelSelection(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def KFold_GridSearchCV(self, input_dim, X, Y, X_test, y_test, combinations, filename=\"log.csv\"):\n",
        "         # create containers for resulting data\n",
        "         \n",
        "        \n",
        "        res_df = pd.DataFrame(columns=['momentum','learning rate','batch size',\n",
        "                                      'loss1', 'acc1','loss2', 'acc2','loss3', 'acc3'])\n",
        "        generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)\n",
        "        hist_dict_global = {}\n",
        "        flag = bool\n",
        "        for i, combination in enumerate(combinations):\n",
        "            kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
        "            metrics_dict = {}\n",
        "  \n",
        "            for j, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "               if i<10:\n",
        "                X_train, X_val = X[train_index], X[test_index]\n",
        "                y_train, y_val = Y[train_index], Y[test_index]\n",
        "                wresnet_ins = WideResidualNetwork(combination[2], combination[0], in_dim,combination[4], nb_classes=4, N=2, k=2, dropout=0.0)\n",
        "                model = wresnet_ins.create_wide_residual_network()\n",
        "                opt = tensorflow.keras.optimizers.SGD(learning_rate=combination[0])\n",
        "                model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "                model.fit_generator(generator.flow(X_train, y_train, batch_size=combination[1]), steps_per_epoch=len(X_train) // combination[1], epochs=combination[3],\n",
        "                                    validation_data=(X_val, y_val),\n",
        "                                    validation_steps=len(X_val) // combination[1],)\n",
        "                loss, acc = model.evaluate(X_test, y_test)\n",
        "                metrics_dict[j+1] = {\"loss\": loss, \"acc\": acc, \"epoch_stopped\": combination[3]}\n",
        "            if i >39 and i < 45:\n",
        "              row = {'momentum': combination[4],'learning rate': combination[0],\n",
        "                        'batch size': combination[1], 'reg_penalty': combination[2],\n",
        "                        'epoch_stopped1': metrics_dict[1][\"epoch_stopped\"], \n",
        "                        'loss1': metrics_dict[1][\"loss\"],'acc1': metrics_dict[1][\"acc\"],\n",
        "                        'acc1': metrics_dict[1][\"acc\"],'epoch_stopped2': metrics_dict[2][\"epoch_stopped\"],\n",
        "                        'loss2': metrics_dict[2][\"loss\"],'acc2': metrics_dict[2][\"acc\"],\n",
        "                        'epoch_stopped3': metrics_dict[3][\"epoch_stopped\"],\n",
        "                        'loss3': metrics_dict[3][\"loss\"], 'acc3': metrics_dict[3][\"acc\"]}\n",
        "              res_df = res_df.append(row , ignore_index=True)\n",
        "              res_df.to_csv(filename, sep=\";\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    learning_rate = [0.1, 0.01]\n",
        "    batch_size = [64,128,256]\n",
        "    reg_penalty = [0.01, 0.001, 0.0001]\n",
        "    epochs = [50,100,150]\n",
        "    momentum = [0.9]\n",
        "    in_dim = (32,32,1)\n",
        "    # create list of all different parameter combinations\n",
        "    param_grid = dict(learning_rate = learning_rate, batch_size = batch_size, \n",
        "                      reg_penalty = reg_penalty, epochs = epochs, momentum=momentum)\n",
        "    combinations = list(product(*param_grid.values()))\n",
        "    X, Y = preprocessing()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.1, shuffle=False)\n",
        "    print(combinations)\n",
        "    instance  = ModelSelection()\n",
        "    instance.KFold_GridSearchCV(in_dim,X_train,y_train,X_test, y_test, combinations, \"grid_16_9.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7jnZFbEe95E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgO8xJ0Fe93I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}