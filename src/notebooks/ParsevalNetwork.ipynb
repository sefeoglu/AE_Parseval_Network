{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ParsevalNetwork.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXS1STy_O_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nX1rD7_O_t",
        "colab_type": "code",
        "outputId": "0e364f35-5c52-4cec-e633-41c346cabdaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(row['crop'])\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmyV1MMm_O_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_data_X, Y_data, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRS393n_O_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCu-tWhd_O_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# creating initial dataframe\n",
        "\n",
        "y_train_df = pd.DataFrame(y_train, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_train_df['New'] = labelencoder.fit_transform(y_train_df['Label'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_test_df['New'] = labelencoder.fit_transform(y_test_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ5CHhcF_PAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "img_rows, img_cols = X_train[0].shape\n",
        "\n",
        "\n",
        "# transform data set\n",
        "if K.common.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3g_vzsy_ndF",
        "colab_type": "text"
      },
      "source": [
        "**Parseval Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sllEBqMW_tEz",
        "colab_type": "text"
      },
      "source": [
        "**Constrait**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN76FYUZ_3YA",
        "colab_type": "code",
        "outputId": "7d2b7fe6-d599-46a4-9c18-5851246ffac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.common.image_dim_ordering() == \"th\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.common.image_dim_ordering() == \"th\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.common.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from keras.utils import plot_model\n",
        "    from keras.layers import Input\n",
        "    from keras.models import Model\n",
        "\n",
        "    init = (68, 100,1)\n",
        "\n",
        "    wrn_28_10 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.0)\n",
        "\n",
        "    wrn_28_10.summary()\n",
        "\n",
        "   # plot_model(wrn_28_10, \"WRN-16-2.png\", show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 68, 100, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 68, 100, 16)  144         input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 68, 100, 16)  64          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 68, 100, 16)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 68, 100, 32)  4608        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 68, 100, 32)  128         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 68, 100, 32)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 68, 100, 32)  9216        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 68, 100, 32)  512         activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 68, 100, 32)  0           conv2d_108[0][0]                 \n",
            "                                                                 conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 68, 100, 32)  128         add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 68, 100, 32)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 68, 100, 32)  9216        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 68, 100, 32)  128         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 68, 100, 32)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 68, 100, 32)  9216        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 68, 100, 32)  0           add_40[0][0]                     \n",
            "                                                                 conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 68, 100, 32)  128         add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 68, 100, 32)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 34, 50, 64)   18432       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 34, 50, 64)   256         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 34, 50, 64)   0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 34, 50, 64)   36864       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 34, 50, 64)   2048        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 34, 50, 64)   0           conv2d_113[0][0]                 \n",
            "                                                                 conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 34, 50, 64)   256         add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 34, 50, 64)   0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 34, 50, 64)   36864       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 34, 50, 64)   256         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 34, 50, 64)   0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 34, 50, 64)   36864       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 34, 50, 64)   0           add_42[0][0]                     \n",
            "                                                                 conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 34, 50, 64)   256         add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 34, 50, 64)   0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 17, 25, 128)  73728       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 17, 25, 128)  512         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 17, 25, 128)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 17, 25, 128)  147456      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 17, 25, 128)  8192        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 17, 25, 128)  0           conv2d_118[0][0]                 \n",
            "                                                                 conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 17, 25, 128)  512         add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 17, 25, 128)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 17, 25, 128)  147456      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 17, 25, 128)  512         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 17, 25, 128)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 17, 25, 128)  147456      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 17, 25, 128)  0           add_44[0][0]                     \n",
            "                                                                 conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 17, 25, 128)  512         add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 17, 25, 128)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 2, 3, 128)    0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 768)          0           average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 4)            3076        flatten_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 694,996\n",
            "Trainable params: 693,172\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxyMKoeaBqPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.callbacks as callbacks\n",
        "import keras.utils.np_utils as kutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiFrat1Bv1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200\n",
        "BS = 128\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygMFWH8Bzfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUvPL0dB48O",
        "colab_type": "code",
        "outputId": "d6fa245f-dd5a-4547-dc8f-5a244fd9af7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_28_10.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrJ7xy1Q5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4EpGTMG9jeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 60:\n",
        "        return 0.1\n",
        "    elif epoch < 120:\n",
        "        return 0.02\n",
        "    elif epoch < 160:\n",
        "        return 0.004\n",
        "    else:\n",
        "        return 0.0008\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bu78FGi9jhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0CbPY_24ns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc50169b-7ce0-48f9-c4fb-1dc96b3a9651"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "hist = wrn_28_10.fit_generator(generator.flow(X_train, to_categorical(y_train_df['New']), batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   validation_data=(X_test, to_categorical(y_test_df['New'])), callbacks = [lr_scheduler],\n",
        "                   validation_steps=X_test.shape[0] // BS,)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "29/29 [==============================] - 10s 353ms/step - loss: 1.8237 - acc: 0.3409 - val_loss: 1.8426 - val_acc: 0.3293\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.7304 - acc: 0.4030 - val_loss: 1.6811 - val_acc: 0.4013\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.6917 - acc: 0.4027 - val_loss: 1.6280 - val_acc: 0.4690\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 1.6343 - acc: 0.4410 - val_loss: 1.5885 - val_acc: 0.4457\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 1.5831 - acc: 0.4667 - val_loss: 1.5467 - val_acc: 0.4902\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.4875 - acc: 0.5136 - val_loss: 1.4928 - val_acc: 0.5379\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.4560 - acc: 0.5258 - val_loss: 2.0506 - val_acc: 0.4023\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 1.4540 - acc: 0.5162 - val_loss: 1.4004 - val_acc: 0.5696\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 1.3365 - acc: 0.5819 - val_loss: 1.4789 - val_acc: 0.5437\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 1.2941 - acc: 0.5979 - val_loss: 1.3249 - val_acc: 0.5791\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.2459 - acc: 0.6202 - val_loss: 1.2446 - val_acc: 0.6003\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.2228 - acc: 0.6130 - val_loss: 1.2681 - val_acc: 0.6305\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 1.1894 - acc: 0.6313 - val_loss: 1.2593 - val_acc: 0.6178\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.1213 - acc: 0.6623 - val_loss: 1.2501 - val_acc: 0.6030\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 1.1214 - acc: 0.6564 - val_loss: 1.0889 - val_acc: 0.6797\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 1.0683 - acc: 0.6748 - val_loss: 1.7119 - val_acc: 0.5659\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 1.0478 - acc: 0.6956 - val_loss: 1.1407 - val_acc: 0.6533\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.0053 - acc: 0.7020 - val_loss: 0.9510 - val_acc: 0.7305\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.9950 - acc: 0.6985 - val_loss: 1.4400 - val_acc: 0.5304\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.9718 - acc: 0.7109 - val_loss: 1.0072 - val_acc: 0.6871\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.9132 - acc: 0.7385 - val_loss: 0.9618 - val_acc: 0.7141\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.9500 - acc: 0.7169 - val_loss: 0.9659 - val_acc: 0.7284\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.9164 - acc: 0.7314 - val_loss: 0.9288 - val_acc: 0.7120\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.8893 - acc: 0.7409 - val_loss: 0.9057 - val_acc: 0.7332\n",
            "Epoch 25/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.8839 - acc: 0.7419 - val_loss: 0.8985 - val_acc: 0.7411\n",
            "Epoch 26/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.8461 - acc: 0.7544 - val_loss: 0.8659 - val_acc: 0.7549\n",
            "Epoch 27/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.8520 - acc: 0.7533 - val_loss: 0.9359 - val_acc: 0.7131\n",
            "Epoch 28/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.8318 - acc: 0.7638 - val_loss: 0.9375 - val_acc: 0.7141\n",
            "Epoch 29/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.8295 - acc: 0.7568 - val_loss: 1.1945 - val_acc: 0.5971\n",
            "Epoch 30/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7999 - acc: 0.7741 - val_loss: 0.9531 - val_acc: 0.7168\n",
            "Epoch 31/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.8428 - acc: 0.7660 - val_loss: 0.8895 - val_acc: 0.7422\n",
            "Epoch 32/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.8002 - acc: 0.7692 - val_loss: 0.9167 - val_acc: 0.7194\n",
            "Epoch 33/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7900 - acc: 0.7698 - val_loss: 0.9565 - val_acc: 0.7062\n",
            "Epoch 34/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7421 - acc: 0.7930 - val_loss: 0.8684 - val_acc: 0.7459\n",
            "Epoch 35/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.7632 - acc: 0.7808 - val_loss: 0.7996 - val_acc: 0.7771\n",
            "Epoch 36/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7355 - acc: 0.7965 - val_loss: 0.8084 - val_acc: 0.7618\n",
            "Epoch 37/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.7470 - acc: 0.7907 - val_loss: 0.8744 - val_acc: 0.7549\n",
            "Epoch 38/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7402 - acc: 0.7866 - val_loss: 0.8692 - val_acc: 0.7507\n",
            "Epoch 39/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7221 - acc: 0.8003 - val_loss: 0.7969 - val_acc: 0.7740\n",
            "Epoch 40/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7033 - acc: 0.7990 - val_loss: 0.8776 - val_acc: 0.7284\n",
            "Epoch 41/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7473 - acc: 0.7926 - val_loss: 0.8890 - val_acc: 0.7411\n",
            "Epoch 42/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7070 - acc: 0.8073 - val_loss: 0.8252 - val_acc: 0.7549\n",
            "Epoch 43/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6697 - acc: 0.8200 - val_loss: 0.8026 - val_acc: 0.7755\n",
            "Epoch 44/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.6636 - acc: 0.8192 - val_loss: 1.1505 - val_acc: 0.6506\n",
            "Epoch 45/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7260 - acc: 0.7914 - val_loss: 0.8046 - val_acc: 0.7745\n",
            "Epoch 46/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6979 - acc: 0.8089 - val_loss: 0.8260 - val_acc: 0.7623\n",
            "Epoch 47/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.7029 - acc: 0.8077 - val_loss: 0.7912 - val_acc: 0.7782\n",
            "Epoch 48/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6441 - acc: 0.8327 - val_loss: 0.8684 - val_acc: 0.7522\n",
            "Epoch 49/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6251 - acc: 0.8408 - val_loss: 0.8275 - val_acc: 0.7792\n",
            "Epoch 50/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6762 - acc: 0.8097 - val_loss: 0.8339 - val_acc: 0.7538\n",
            "Epoch 51/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6576 - acc: 0.8278 - val_loss: 0.9084 - val_acc: 0.7528\n",
            "Epoch 52/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6586 - acc: 0.8305 - val_loss: 0.9475 - val_acc: 0.7147\n",
            "Epoch 53/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6365 - acc: 0.8394 - val_loss: 0.8030 - val_acc: 0.7787\n",
            "Epoch 54/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6084 - acc: 0.8432 - val_loss: 0.9844 - val_acc: 0.7305\n",
            "Epoch 55/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6155 - acc: 0.8459 - val_loss: 0.8634 - val_acc: 0.7522\n",
            "Epoch 56/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6301 - acc: 0.8413 - val_loss: 1.0992 - val_acc: 0.7041\n",
            "Epoch 57/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.6502 - acc: 0.8389 - val_loss: 0.8850 - val_acc: 0.7665\n",
            "Epoch 58/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6244 - acc: 0.8356 - val_loss: 0.8128 - val_acc: 0.7824\n",
            "Epoch 59/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.5574 - acc: 0.8761 - val_loss: 0.9873 - val_acc: 0.7422\n",
            "Epoch 60/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6325 - acc: 0.8394 - val_loss: 1.1115 - val_acc: 0.7242\n",
            "Epoch 61/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.6383 - acc: 0.8464 - val_loss: 0.8155 - val_acc: 0.7851\n",
            "Epoch 62/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.4989 - acc: 0.9034 - val_loss: 0.7697 - val_acc: 0.8004\n",
            "Epoch 63/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.4406 - acc: 0.9228 - val_loss: 0.7529 - val_acc: 0.8094\n",
            "Epoch 64/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.4135 - acc: 0.9347 - val_loss: 0.8040 - val_acc: 0.7978\n",
            "Epoch 65/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.4054 - acc: 0.9331 - val_loss: 0.8026 - val_acc: 0.8052\n",
            "Epoch 66/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3847 - acc: 0.9387 - val_loss: 0.7889 - val_acc: 0.8089\n",
            "Epoch 67/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3606 - acc: 0.9511 - val_loss: 0.7613 - val_acc: 0.8200\n",
            "Epoch 68/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3584 - acc: 0.9485 - val_loss: 0.7986 - val_acc: 0.8200\n",
            "Epoch 69/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3449 - acc: 0.9519 - val_loss: 0.7874 - val_acc: 0.8195\n",
            "Epoch 70/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3303 - acc: 0.9582 - val_loss: 0.7888 - val_acc: 0.8152\n",
            "Epoch 71/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3316 - acc: 0.9584 - val_loss: 0.8218 - val_acc: 0.8174\n",
            "Epoch 72/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3190 - acc: 0.9612 - val_loss: 0.7940 - val_acc: 0.8168\n",
            "Epoch 73/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.3167 - acc: 0.9592 - val_loss: 0.8478 - val_acc: 0.8062\n",
            "Epoch 74/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3050 - acc: 0.9671 - val_loss: 0.8153 - val_acc: 0.8195\n",
            "Epoch 75/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.3113 - acc: 0.9628 - val_loss: 0.8692 - val_acc: 0.8078\n",
            "Epoch 76/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.3012 - acc: 0.9660 - val_loss: 0.8520 - val_acc: 0.8131\n",
            "Epoch 77/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2934 - acc: 0.9632 - val_loss: 0.8693 - val_acc: 0.8105\n",
            "Epoch 78/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2816 - acc: 0.9725 - val_loss: 0.8623 - val_acc: 0.8221\n",
            "Epoch 79/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2846 - acc: 0.9679 - val_loss: 0.8506 - val_acc: 0.8216\n",
            "Epoch 80/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2749 - acc: 0.9717 - val_loss: 0.9034 - val_acc: 0.8174\n",
            "Epoch 81/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2732 - acc: 0.9746 - val_loss: 0.8768 - val_acc: 0.8184\n",
            "Epoch 82/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2702 - acc: 0.9717 - val_loss: 0.8615 - val_acc: 0.8211\n",
            "Epoch 83/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.2659 - acc: 0.9746 - val_loss: 0.9684 - val_acc: 0.8004\n",
            "Epoch 84/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.2637 - acc: 0.9719 - val_loss: 0.8997 - val_acc: 0.8200\n",
            "Epoch 85/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.2650 - acc: 0.9763 - val_loss: 0.9719 - val_acc: 0.8036\n",
            "Epoch 86/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2620 - acc: 0.9733 - val_loss: 0.8662 - val_acc: 0.8221\n",
            "Epoch 87/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2491 - acc: 0.9757 - val_loss: 0.9176 - val_acc: 0.8190\n",
            "Epoch 88/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2514 - acc: 0.9749 - val_loss: 0.9147 - val_acc: 0.8110\n",
            "Epoch 89/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2557 - acc: 0.9735 - val_loss: 0.9018 - val_acc: 0.8285\n",
            "Epoch 90/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2428 - acc: 0.9784 - val_loss: 0.9498 - val_acc: 0.8126\n",
            "Epoch 91/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.2435 - acc: 0.9779 - val_loss: 0.9150 - val_acc: 0.8221\n",
            "Epoch 92/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2426 - acc: 0.9762 - val_loss: 0.8967 - val_acc: 0.8248\n",
            "Epoch 93/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2421 - acc: 0.9779 - val_loss: 0.9069 - val_acc: 0.8084\n",
            "Epoch 94/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2481 - acc: 0.9719 - val_loss: 0.9593 - val_acc: 0.7994\n",
            "Epoch 95/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2353 - acc: 0.9806 - val_loss: 0.9216 - val_acc: 0.8205\n",
            "Epoch 96/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.2358 - acc: 0.9793 - val_loss: 0.9178 - val_acc: 0.8105\n",
            "Epoch 97/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2318 - acc: 0.9792 - val_loss: 0.8965 - val_acc: 0.8242\n",
            "Epoch 98/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2332 - acc: 0.9776 - val_loss: 0.9887 - val_acc: 0.8062\n",
            "Epoch 99/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2583 - acc: 0.9698 - val_loss: 0.9413 - val_acc: 0.8142\n",
            "Epoch 100/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.2260 - acc: 0.9827 - val_loss: 0.8915 - val_acc: 0.8179\n",
            "Epoch 101/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2305 - acc: 0.9781 - val_loss: 0.9247 - val_acc: 0.8221\n",
            "Epoch 102/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2298 - acc: 0.9760 - val_loss: 0.8942 - val_acc: 0.8285\n",
            "Epoch 103/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2475 - acc: 0.9735 - val_loss: 0.8930 - val_acc: 0.8216\n",
            "Epoch 104/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2381 - acc: 0.9760 - val_loss: 0.9577 - val_acc: 0.8126\n",
            "Epoch 105/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.2517 - acc: 0.9641 - val_loss: 1.0287 - val_acc: 0.7983\n",
            "Epoch 106/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2473 - acc: 0.9714 - val_loss: 1.0577 - val_acc: 0.7872\n",
            "Epoch 107/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2403 - acc: 0.9727 - val_loss: 0.9093 - val_acc: 0.8200\n",
            "Epoch 108/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2247 - acc: 0.9798 - val_loss: 0.9338 - val_acc: 0.8158\n",
            "Epoch 109/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.2149 - acc: 0.9819 - val_loss: 0.9807 - val_acc: 0.8115\n",
            "Epoch 110/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.2138 - acc: 0.9830 - val_loss: 0.9357 - val_acc: 0.8163\n",
            "Epoch 111/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2099 - acc: 0.9849 - val_loss: 0.9619 - val_acc: 0.8105\n",
            "Epoch 112/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2114 - acc: 0.9841 - val_loss: 0.9282 - val_acc: 0.8057\n",
            "Epoch 113/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2131 - acc: 0.9825 - val_loss: 0.9300 - val_acc: 0.8280\n",
            "Epoch 114/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2035 - acc: 0.9857 - val_loss: 0.9900 - val_acc: 0.8126\n",
            "Epoch 115/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2097 - acc: 0.9825 - val_loss: 0.8925 - val_acc: 0.8295\n",
            "Epoch 116/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2170 - acc: 0.9794 - val_loss: 0.9653 - val_acc: 0.8168\n",
            "Epoch 117/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.2128 - acc: 0.9814 - val_loss: 0.9496 - val_acc: 0.8184\n",
            "Epoch 118/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2228 - acc: 0.9776 - val_loss: 0.9326 - val_acc: 0.8211\n",
            "Epoch 119/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2206 - acc: 0.9792 - val_loss: 0.9642 - val_acc: 0.8089\n",
            "Epoch 120/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2178 - acc: 0.9798 - val_loss: 0.9214 - val_acc: 0.8100\n",
            "Epoch 121/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.2076 - acc: 0.9814 - val_loss: 0.9338 - val_acc: 0.8158\n",
            "Epoch 122/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1861 - acc: 0.9911 - val_loss: 0.8886 - val_acc: 0.8232\n",
            "Epoch 123/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1769 - acc: 0.9951 - val_loss: 0.8973 - val_acc: 0.8211\n",
            "Epoch 124/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1734 - acc: 0.9960 - val_loss: 0.8886 - val_acc: 0.8338\n",
            "Epoch 125/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1697 - acc: 0.9962 - val_loss: 0.8837 - val_acc: 0.8280\n",
            "Epoch 126/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1672 - acc: 0.9987 - val_loss: 0.8800 - val_acc: 0.8280\n",
            "Epoch 127/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1677 - acc: 0.9965 - val_loss: 0.8940 - val_acc: 0.8322\n",
            "Epoch 128/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1657 - acc: 0.9976 - val_loss: 0.9046 - val_acc: 0.8295\n",
            "Epoch 129/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1651 - acc: 0.9973 - val_loss: 0.8959 - val_acc: 0.8274\n",
            "Epoch 130/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1621 - acc: 0.9984 - val_loss: 0.9026 - val_acc: 0.8301\n",
            "Epoch 131/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1647 - acc: 0.9978 - val_loss: 0.9091 - val_acc: 0.8338\n",
            "Epoch 132/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1619 - acc: 0.9981 - val_loss: 0.9135 - val_acc: 0.8301\n",
            "Epoch 133/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1628 - acc: 0.9981 - val_loss: 0.9104 - val_acc: 0.8317\n",
            "Epoch 134/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1591 - acc: 0.9987 - val_loss: 0.8924 - val_acc: 0.8343\n",
            "Epoch 135/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1620 - acc: 0.9970 - val_loss: 0.9126 - val_acc: 0.8285\n",
            "Epoch 136/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1597 - acc: 0.9984 - val_loss: 0.9080 - val_acc: 0.8301\n",
            "Epoch 137/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1605 - acc: 0.9973 - val_loss: 0.9057 - val_acc: 0.8295\n",
            "Epoch 138/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1592 - acc: 0.9984 - val_loss: 0.8882 - val_acc: 0.8306\n",
            "Epoch 139/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1575 - acc: 0.9987 - val_loss: 0.9378 - val_acc: 0.8285\n",
            "Epoch 140/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.1579 - acc: 0.9976 - val_loss: 0.9073 - val_acc: 0.8306\n",
            "Epoch 141/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1551 - acc: 0.9989 - val_loss: 0.9044 - val_acc: 0.8359\n",
            "Epoch 142/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1579 - acc: 0.9978 - val_loss: 0.9055 - val_acc: 0.8295\n",
            "Epoch 143/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1536 - acc: 0.9997 - val_loss: 0.8845 - val_acc: 0.8359\n",
            "Epoch 144/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1552 - acc: 0.9989 - val_loss: 0.9107 - val_acc: 0.8301\n",
            "Epoch 145/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1558 - acc: 0.9978 - val_loss: 0.9232 - val_acc: 0.8311\n",
            "Epoch 146/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1563 - acc: 0.9973 - val_loss: 0.9048 - val_acc: 0.8332\n",
            "Epoch 147/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1534 - acc: 0.9989 - val_loss: 0.8932 - val_acc: 0.8317\n",
            "Epoch 148/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1520 - acc: 0.9995 - val_loss: 0.8948 - val_acc: 0.8332\n",
            "Epoch 149/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1531 - acc: 0.9984 - val_loss: 0.8803 - val_acc: 0.8327\n",
            "Epoch 150/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1525 - acc: 0.9989 - val_loss: 0.9269 - val_acc: 0.8306\n",
            "Epoch 151/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1544 - acc: 0.9978 - val_loss: 0.9029 - val_acc: 0.8306\n",
            "Epoch 152/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1535 - acc: 0.9978 - val_loss: 0.8908 - val_acc: 0.8311\n",
            "Epoch 153/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1517 - acc: 0.9987 - val_loss: 0.9133 - val_acc: 0.8348\n",
            "Epoch 154/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1503 - acc: 0.9995 - val_loss: 0.9045 - val_acc: 0.8322\n",
            "Epoch 155/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1516 - acc: 0.9984 - val_loss: 0.9327 - val_acc: 0.8264\n",
            "Epoch 156/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1500 - acc: 0.9992 - val_loss: 0.9418 - val_acc: 0.8285\n",
            "Epoch 157/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1484 - acc: 0.9995 - val_loss: 0.9035 - val_acc: 0.8269\n",
            "Epoch 158/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.1482 - acc: 0.9989 - val_loss: 0.9080 - val_acc: 0.8364\n",
            "Epoch 159/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1496 - acc: 0.9992 - val_loss: 0.9082 - val_acc: 0.8306\n",
            "Epoch 160/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1480 - acc: 0.9989 - val_loss: 0.9470 - val_acc: 0.8338\n",
            "Epoch 161/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1483 - acc: 0.9986 - val_loss: 0.9242 - val_acc: 0.8258\n",
            "Epoch 162/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1466 - acc: 0.9997 - val_loss: 0.9707 - val_acc: 0.8269\n",
            "Epoch 163/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1471 - acc: 0.9987 - val_loss: 0.9110 - val_acc: 0.8332\n",
            "Epoch 164/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1480 - acc: 0.9992 - val_loss: 0.9215 - val_acc: 0.8332\n",
            "Epoch 165/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1476 - acc: 0.9992 - val_loss: 0.9122 - val_acc: 0.8385\n",
            "Epoch 166/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1474 - acc: 0.9989 - val_loss: 0.9006 - val_acc: 0.8359\n",
            "Epoch 167/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1473 - acc: 0.9992 - val_loss: 0.9563 - val_acc: 0.8290\n",
            "Epoch 168/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1466 - acc: 0.9992 - val_loss: 0.8931 - val_acc: 0.8290\n",
            "Epoch 169/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1467 - acc: 0.9997 - val_loss: 0.9201 - val_acc: 0.8311\n",
            "Epoch 170/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1474 - acc: 0.9992 - val_loss: 0.9320 - val_acc: 0.8311\n",
            "Epoch 171/200\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.1471 - acc: 0.9995 - val_loss: 0.8960 - val_acc: 0.8290\n",
            "Epoch 172/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1463 - acc: 0.9995 - val_loss: 0.9064 - val_acc: 0.8306\n",
            "Epoch 173/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1472 - acc: 0.9989 - val_loss: 0.9220 - val_acc: 0.8375\n",
            "Epoch 174/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1457 - acc: 0.9992 - val_loss: 0.8944 - val_acc: 0.8306\n",
            "Epoch 175/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1462 - acc: 0.9995 - val_loss: 0.8981 - val_acc: 0.8290\n",
            "Epoch 176/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1468 - acc: 0.9989 - val_loss: 0.9209 - val_acc: 0.8370\n",
            "Epoch 177/200\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 0.1466 - acc: 0.9992 - val_loss: 0.8957 - val_acc: 0.8364\n",
            "Epoch 178/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1465 - acc: 0.9995 - val_loss: 0.9273 - val_acc: 0.8338\n",
            "Epoch 179/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1463 - acc: 0.9992 - val_loss: 0.9182 - val_acc: 0.8354\n",
            "Epoch 180/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1463 - acc: 0.9995 - val_loss: 0.9102 - val_acc: 0.8396\n",
            "Epoch 181/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1459 - acc: 0.9995 - val_loss: 0.9164 - val_acc: 0.8359\n",
            "Epoch 182/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.1459 - acc: 0.9995 - val_loss: 0.9140 - val_acc: 0.8290\n",
            "Epoch 183/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1455 - acc: 0.9997 - val_loss: 0.9235 - val_acc: 0.8359\n",
            "Epoch 184/200\n",
            "29/29 [==============================] - 8s 261ms/step - loss: 0.1447 - acc: 1.0000 - val_loss: 0.9168 - val_acc: 0.8280\n",
            "Epoch 185/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1459 - acc: 0.9981 - val_loss: 0.8965 - val_acc: 0.8343\n",
            "Epoch 186/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.1452 - acc: 0.9997 - val_loss: 0.8897 - val_acc: 0.8343\n",
            "Epoch 187/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.1457 - acc: 0.9992 - val_loss: 0.9037 - val_acc: 0.8338\n",
            "Epoch 188/200\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 0.1449 - acc: 0.9995 - val_loss: 0.8952 - val_acc: 0.8295\n",
            "Epoch 189/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1452 - acc: 0.9997 - val_loss: 0.9273 - val_acc: 0.8354\n",
            "Epoch 190/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1452 - acc: 0.9992 - val_loss: 0.9444 - val_acc: 0.8280\n",
            "Epoch 191/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.1446 - acc: 0.9992 - val_loss: 0.9173 - val_acc: 0.8317\n",
            "Epoch 192/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1452 - acc: 0.9989 - val_loss: 0.8796 - val_acc: 0.8295\n",
            "Epoch 193/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1460 - acc: 0.9981 - val_loss: 0.9224 - val_acc: 0.8322\n",
            "Epoch 194/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1452 - acc: 0.9992 - val_loss: 0.8943 - val_acc: 0.8317\n",
            "Epoch 195/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1455 - acc: 0.9992 - val_loss: 0.9088 - val_acc: 0.8322\n",
            "Epoch 196/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.1448 - acc: 0.9997 - val_loss: 0.9310 - val_acc: 0.8348\n",
            "Epoch 197/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.1440 - acc: 0.9989 - val_loss: 0.8993 - val_acc: 0.8322\n",
            "Epoch 198/200\n",
            "29/29 [==============================] - 8s 260ms/step - loss: 0.1449 - acc: 0.9992 - val_loss: 0.9152 - val_acc: 0.8322\n",
            "Epoch 199/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1441 - acc: 0.9997 - val_loss: 0.9113 - val_acc: 0.8391\n",
            "Epoch 200/200\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.1441 - acc: 0.9995 - val_loss: 0.9212 - val_acc: 0.8306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFGjXGymB8cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "hist = wrn_28_10.fit(X_train, to_categorical(y_train_df['New']), validation_data=(X_test,to_categorical(y_test_df['New'])), epochs=EPOCHS, batch_size=BS, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-QerZ4RN91R",
        "colab_type": "code",
        "outputId": "238e0313-03ce-4e8e-eea8-68778f88c346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n",
        "pyplot.savefig(\"deneme.png\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeg6MBf-GSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_err = [1.0-x for x in hist.history['val_acc']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgiKT6i5GiJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2e82bebd-93ad-4fea-bd92-2f0717d9f80e"
      },
      "source": [
        "pyplot.plot(test_err, label='test')\n",
        "pyplot.savefig(\"deneme_err.png\")"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IJ9Z-dQKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "wrn_28_10.save(\"_lst.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqddlwbmEV9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = wrn_28_10.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDVf4J_lEb2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7011c3dc-4678-458d-b63d-716ff47a5c04"
      },
      "source": [
        "y_pred[8]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.8299833e-04, 9.9938881e-01, 2.6950407e-05, 1.1227185e-06],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mcYkI-REb63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a144b844-0e12-43e2-f603-a03886c22bb1"
      },
      "source": [
        "np.argmax(y_pred[8])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ysop6NFDbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b920c9f4-ace6-4d9b-ae6d-48f78b19b7b8"
      },
      "source": [
        "wrn_28_10.evaluate(X_test,to_categorical(y_test_df['New']),batch_size=128,verbose=2)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.921227546644438, 0.8305981755256653]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfXeT5NJFmUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}