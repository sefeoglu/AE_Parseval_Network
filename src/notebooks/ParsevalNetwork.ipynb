{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ParsevalNetwork.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXS1STy_O_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nX1rD7_O_t",
        "colab_type": "code",
        "outputId": "b999757c-7cf3-45d6-cf66-bf6ef66ec0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(row['crop'])\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmyV1MMm_O_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_data_X, Y_data, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRS393n_O_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCu-tWhd_O_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# creating initial dataframe\n",
        "\n",
        "y_train_df = pd.DataFrame(y_train, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_train_df['New'] = labelencoder.fit_transform(y_train_df['Label'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_test_df['New'] = labelencoder.fit_transform(y_test_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ5CHhcF_PAA",
        "colab_type": "code",
        "outputId": "f600cd6a-e6aa-49b4-bfa1-103525f9b3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import backend as K\n",
        "img_rows, img_cols = X_train[0].shape\n",
        "\n",
        "\n",
        "# transform data set\n",
        "if K.common.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3g_vzsy_ndF",
        "colab_type": "text"
      },
      "source": [
        "**Parseval Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sllEBqMW_tEz",
        "colab_type": "text"
      },
      "source": [
        "**Constrait**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN76FYUZ_3YA",
        "colab_type": "code",
        "outputId": "c414ff60-abb0-4008-e62a-d2dfb9b67933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "\n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.common.image_dim_ordering() == \"th\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.common.image_dim_ordering() == \"th\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      W_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.common.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from keras.utils import plot_model\n",
        "    from keras.layers import Input\n",
        "    from keras.models import Model\n",
        "\n",
        "    init = (68, 100,1)\n",
        "\n",
        "    wrn_28_10 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.0)\n",
        "\n",
        "    wrn_28_10.summary()\n",
        "\n",
        "   # plot_model(wrn_28_10, \"WRN-16-2.png\", show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parseval Residual Network-16-2 created.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 68, 100, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 68, 100, 16)  144         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 68, 100, 16)  64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 68, 100, 16)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 68, 100, 32)  4608        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 68, 100, 32)  128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 68, 100, 32)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 68, 100, 32)  9216        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 68, 100, 32)  512         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 68, 100, 32)  0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 68, 100, 32)  128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 68, 100, 32)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 68, 100, 32)  9216        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 68, 100, 32)  128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 68, 100, 32)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 68, 100, 32)  9216        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 68, 100, 32)  0           add_1[0][0]                      \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 68, 100, 32)  128         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 68, 100, 32)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 34, 50, 64)   18432       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 34, 50, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 34, 50, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 34, 50, 64)   36864       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 34, 50, 64)   2048        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 34, 50, 64)   0           conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 34, 50, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 34, 50, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 34, 50, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 34, 50, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 34, 50, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 34, 50, 64)   36864       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 34, 50, 64)   0           add_3[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 34, 50, 64)   256         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 34, 50, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 17, 25, 128)  73728       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 17, 25, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 17, 25, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 17, 25, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 17, 25, 128)  8192        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 17, 25, 128)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 17, 25, 128)  512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 17, 25, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 17, 25, 128)  147456      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 17, 25, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 17, 25, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 17, 25, 128)  147456      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 17, 25, 128)  0           add_5[0][0]                      \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 17, 25, 128)  512         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 17, 25, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 2, 3, 128)    0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 768)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            3076        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 694,996\n",
            "Trainable params: 693,172\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxyMKoeaBqPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.callbacks as callbacks\n",
        "import keras.utils.np_utils as kutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiFrat1Bv1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 60\n",
        "BS = 128\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygMFWH8Bzfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "from keras.optimizers import SGD\n",
        "def step_decay(epoch):\n",
        "  initial_lrate = 0.1\n",
        "  drop = 0.2\n",
        "  epochs_drop = 60\n",
        "  lrate = 0.1\n",
        "  if math.floor((1+epoch)/epochs_drop) !=0:\n",
        "    lrate = initial_lrate*math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
        "  return lrate\n",
        " \n",
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUvPL0dB48O",
        "colab_type": "code",
        "outputId": "55824e60-e5a6-4635-b401-7e76e53bcb15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_28_10.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrJ7xy1Q5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFGjXGymB8cD",
        "colab_type": "code",
        "outputId": "202874ce-d5b8-4798-82b8-17895300219b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# learning schedule callback\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "callbacks_list = [lrate]\n",
        "# Fit the model\n",
        "hist = wrn_28_10.fit(X_train, to_categorical(y_train_df['New']), validation_split=0.33, epochs=EPOCHS, batch_size=BS, verbose=2, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2568 samples, validate on 1265 samples\n",
            "Epoch 1/60\n",
            " - 24s - loss: 1.8528 - acc: 0.3232 - val_loss: 1.9409 - val_acc: 0.2680\n",
            "Epoch 2/60\n",
            " - 18s - loss: 1.7911 - acc: 0.3676 - val_loss: 1.7731 - val_acc: 0.3755\n",
            "Epoch 3/60\n",
            " - 18s - loss: 1.7330 - acc: 0.3956 - val_loss: 1.7786 - val_acc: 0.3731\n",
            "Epoch 4/60\n",
            " - 18s - loss: 1.7176 - acc: 0.4062 - val_loss: 1.6921 - val_acc: 0.4269\n",
            "Epoch 5/60\n",
            " - 18s - loss: 1.6708 - acc: 0.4143 - val_loss: 1.6619 - val_acc: 0.4308\n",
            "Epoch 6/60\n",
            " - 18s - loss: 1.6240 - acc: 0.4517 - val_loss: 1.6473 - val_acc: 0.4213\n",
            "Epoch 7/60\n",
            " - 18s - loss: 1.5854 - acc: 0.4564 - val_loss: 1.6719 - val_acc: 0.4522\n",
            "Epoch 8/60\n",
            " - 18s - loss: 1.5863 - acc: 0.4494 - val_loss: 1.6373 - val_acc: 0.4269\n",
            "Epoch 9/60\n",
            " - 18s - loss: 1.5603 - acc: 0.4607 - val_loss: 1.5830 - val_acc: 0.4601\n",
            "Epoch 10/60\n",
            " - 18s - loss: 1.5128 - acc: 0.4817 - val_loss: 1.5425 - val_acc: 0.4522\n",
            "Epoch 11/60\n",
            " - 18s - loss: 1.4831 - acc: 0.4938 - val_loss: 1.5037 - val_acc: 0.4767\n",
            "Epoch 12/60\n",
            " - 18s - loss: 1.4329 - acc: 0.5144 - val_loss: 1.4427 - val_acc: 0.5115\n",
            "Epoch 13/60\n",
            " - 18s - loss: 1.3829 - acc: 0.5323 - val_loss: 1.4695 - val_acc: 0.4751\n",
            "Epoch 14/60\n",
            " - 18s - loss: 1.3801 - acc: 0.5397 - val_loss: 1.5333 - val_acc: 0.4632\n",
            "Epoch 15/60\n",
            " - 18s - loss: 1.3514 - acc: 0.5452 - val_loss: 1.4395 - val_acc: 0.5091\n",
            "Epoch 16/60\n",
            " - 18s - loss: 1.3120 - acc: 0.5678 - val_loss: 1.3082 - val_acc: 0.5739\n",
            "Epoch 17/60\n",
            " - 18s - loss: 1.2738 - acc: 0.5876 - val_loss: 1.4742 - val_acc: 0.5091\n",
            "Epoch 18/60\n",
            " - 18s - loss: 1.3178 - acc: 0.5580 - val_loss: 1.3703 - val_acc: 0.5289\n",
            "Epoch 19/60\n",
            " - 18s - loss: 1.2343 - acc: 0.5892 - val_loss: 1.2413 - val_acc: 0.5937\n",
            "Epoch 20/60\n",
            " - 18s - loss: 1.1861 - acc: 0.6118 - val_loss: 1.2535 - val_acc: 0.5826\n",
            "Epoch 21/60\n",
            " - 18s - loss: 1.1465 - acc: 0.6351 - val_loss: 1.6176 - val_acc: 0.5083\n",
            "Epoch 22/60\n",
            " - 18s - loss: 1.1554 - acc: 0.6382 - val_loss: 1.3281 - val_acc: 0.5597\n",
            "Epoch 23/60\n",
            " - 18s - loss: 1.1733 - acc: 0.6273 - val_loss: 1.1671 - val_acc: 0.6111\n",
            "Epoch 24/60\n",
            " - 18s - loss: 1.0643 - acc: 0.6752 - val_loss: 1.2371 - val_acc: 0.5802\n",
            "Epoch 25/60\n",
            " - 18s - loss: 1.0517 - acc: 0.6822 - val_loss: 1.4199 - val_acc: 0.5360\n",
            "Epoch 26/60\n",
            " - 18s - loss: 1.0185 - acc: 0.6807 - val_loss: 1.4854 - val_acc: 0.5336\n",
            "Epoch 27/60\n",
            " - 18s - loss: 1.0660 - acc: 0.6554 - val_loss: 1.1441 - val_acc: 0.6379\n",
            "Epoch 28/60\n",
            " - 18s - loss: 0.9569 - acc: 0.7079 - val_loss: 1.3958 - val_acc: 0.5700\n",
            "Epoch 29/60\n",
            " - 18s - loss: 0.9222 - acc: 0.7262 - val_loss: 1.0937 - val_acc: 0.6411\n",
            "Epoch 30/60\n",
            " - 18s - loss: 0.9054 - acc: 0.7251 - val_loss: 1.1262 - val_acc: 0.6419\n",
            "Epoch 31/60\n",
            " - 18s - loss: 0.8942 - acc: 0.7247 - val_loss: 1.2060 - val_acc: 0.6087\n",
            "Epoch 32/60\n",
            " - 18s - loss: 0.9674 - acc: 0.6869 - val_loss: 1.7732 - val_acc: 0.4482\n",
            "Epoch 33/60\n",
            " - 18s - loss: 0.9743 - acc: 0.6928 - val_loss: 1.2196 - val_acc: 0.6000\n",
            "Epoch 34/60\n",
            " - 18s - loss: 0.9379 - acc: 0.7157 - val_loss: 1.1169 - val_acc: 0.6387\n",
            "Epoch 35/60\n",
            " - 18s - loss: 0.9092 - acc: 0.7309 - val_loss: 1.1730 - val_acc: 0.6174\n",
            "Epoch 36/60\n",
            " - 18s - loss: 0.9033 - acc: 0.7259 - val_loss: 1.2921 - val_acc: 0.6213\n",
            "Epoch 37/60\n",
            " - 18s - loss: 0.8538 - acc: 0.7438 - val_loss: 1.1203 - val_acc: 0.6490\n",
            "Epoch 38/60\n",
            " - 18s - loss: 0.8034 - acc: 0.7621 - val_loss: 1.1672 - val_acc: 0.6490\n",
            "Epoch 39/60\n",
            " - 18s - loss: 0.8686 - acc: 0.7461 - val_loss: 1.3639 - val_acc: 0.5715\n",
            "Epoch 40/60\n",
            " - 18s - loss: 0.8481 - acc: 0.7477 - val_loss: 1.0680 - val_acc: 0.6711\n",
            "Epoch 41/60\n",
            " - 18s - loss: 0.7516 - acc: 0.7924 - val_loss: 1.4106 - val_acc: 0.6134\n",
            "Epoch 42/60\n",
            " - 18s - loss: 0.7929 - acc: 0.7706 - val_loss: 1.1485 - val_acc: 0.6403\n",
            "Epoch 43/60\n",
            " - 18s - loss: 0.6921 - acc: 0.8193 - val_loss: 1.1860 - val_acc: 0.6482\n",
            "Epoch 44/60\n",
            " - 18s - loss: 0.7522 - acc: 0.8072 - val_loss: 1.0797 - val_acc: 0.6743\n",
            "Epoch 45/60\n",
            " - 18s - loss: 0.7217 - acc: 0.8107 - val_loss: 1.2606 - val_acc: 0.6506\n",
            "Epoch 46/60\n",
            " - 18s - loss: 0.7123 - acc: 0.8080 - val_loss: 1.3198 - val_acc: 0.6016\n",
            "Epoch 47/60\n",
            " - 18s - loss: 0.6638 - acc: 0.8384 - val_loss: 1.1640 - val_acc: 0.6656\n",
            "Epoch 48/60\n",
            " - 18s - loss: 0.6488 - acc: 0.8419 - val_loss: 1.4193 - val_acc: 0.6316\n",
            "Epoch 49/60\n",
            " - 18s - loss: 0.6404 - acc: 0.8419 - val_loss: 1.2794 - val_acc: 0.6767\n",
            "Epoch 50/60\n",
            " - 18s - loss: 0.5481 - acc: 0.8816 - val_loss: 1.3383 - val_acc: 0.6688\n",
            "Epoch 51/60\n",
            " - 18s - loss: 0.5066 - acc: 0.9026 - val_loss: 1.3716 - val_acc: 0.6743\n",
            "Epoch 52/60\n",
            " - 18s - loss: 0.5864 - acc: 0.8579 - val_loss: 1.3947 - val_acc: 0.6538\n",
            "Epoch 53/60\n",
            " - 18s - loss: 0.5767 - acc: 0.8738 - val_loss: 1.4014 - val_acc: 0.6277\n",
            "Epoch 54/60\n",
            " - 18s - loss: 0.6566 - acc: 0.8411 - val_loss: 1.3863 - val_acc: 0.6174\n",
            "Epoch 55/60\n",
            " - 18s - loss: 0.5728 - acc: 0.8801 - val_loss: 1.2552 - val_acc: 0.6585\n",
            "Epoch 56/60\n",
            " - 18s - loss: 0.4475 - acc: 0.9276 - val_loss: 1.8246 - val_acc: 0.6348\n",
            "Epoch 57/60\n",
            " - 18s - loss: 0.5824 - acc: 0.8801 - val_loss: 2.1888 - val_acc: 0.5328\n",
            "Epoch 58/60\n",
            " - 18s - loss: 0.9595 - acc: 0.7449 - val_loss: 1.3178 - val_acc: 0.6300\n",
            "Epoch 59/60\n",
            " - 18s - loss: 0.7707 - acc: 0.8166 - val_loss: 1.2881 - val_acc: 0.6506\n",
            "Epoch 60/60\n",
            " - 18s - loss: 0.7934 - acc: 0.7932 - val_loss: 1.2901 - val_acc: 0.6435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-QerZ4RN91R",
        "colab_type": "code",
        "outputId": "b3e1bab3-23b7-4356-9a4a-be98a6297f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f35afc8d320>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IJ9Z-dQKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEE8YwWJdeGt",
        "colab_type": "code",
        "outputId": "6f1fad23-0be5-455c-de87-033922e81698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans from git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.6/dist-packages (from cleverhans) (2.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tensorflow Version: 2.0.0-beta1\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "GPU Available:  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzX2YU37gCVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUd-8dJQdsZk",
        "colab_type": "code",
        "outputId": "96732228-ade9-4d81-80dd-039698e0f3c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=(None, 1, 28, 28))\n",
        "y = tf.placeholder(tf.float32, shape=(None, FLAGS.nb_classes))\n",
        "\n",
        "# Define TF model graph\n",
        "model = model_mnist()\n",
        "predictions = model(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-186ef8342c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define TF model graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3021\u001b[0m   \"\"\"\n\u001b[1;32m   3022\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[1;32m   3024\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
          ]
        }
      ]
    }
  ]
}