{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ParsevalNetwork.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_idgCcuZdv0S",
        "colab_type": "text"
      },
      "source": [
        "# **Parseval Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO1kBOuDd2_r",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXS1STy_O_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nX1rD7_O_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e57f843-9142-4def-cae7-6b0b49c0ae97"
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n",
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuUWZk7KeFck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bc0281c-35b8-44a4-e303-b6cf7f8e66f2"
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T0HkiPfeH1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crqYw_LJeJif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuCH_ylOeLLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a2454173-4e88-4d48-dd8a-04ecebbb5c61"
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open             1500\n",
              "closed           1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJGV2GZWeN-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7d397820-9fb0-4fec-a72b-00c5d02f5f6f"
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBVaEoQBeP7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Q7NqR4eYQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "x_train, X_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5d6VfS7mpKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_set.pickle', 'rb') as f:\n",
        "    x = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suqL27vjmsYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train,X_test, y_test, X_val, y_val = x['X_train'], x['y_train'], x['X_test'], x['y_test'], x['X_val'], x['y_val']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTmOEDcMtSQp",
        "colab_type": "text"
      },
      "source": [
        "# Othogonal Constraint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S2jnj2otWlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.constraints import Constraint\n",
        "from tensorflow.python.ops import math_ops, array_ops\n",
        "\n",
        "class TightFrame(Constraint):\n",
        "\n",
        "\n",
        "    def __init__(self, scale, num_passes=1):\n",
        "        self.scale = scale\n",
        "\n",
        "        if num_passes < 1:\n",
        "            raise ValueError(\"Number of passes cannot be non-positive! (got {})\".format(num_passes))\n",
        "        self.num_passes = num_passes\n",
        "\n",
        "\n",
        "    def __call__(self, w):\n",
        "        transpose_channels = (len(w.shape) == 4)\n",
        "\n",
        "        # Move channels_num to the front in order to make the dimensions correct for matmul\n",
        "        if transpose_channels:\n",
        "            w_reordered = array_ops.reshape(w, (-1, w.shape[0]))\n",
        "\n",
        "        else:\n",
        "            w_reordered = w\n",
        "\n",
        "        last = w_reordered\n",
        "        for i in range(self.num_passes):\n",
        "            temp1 = math_ops.matmul(last, last, transpose_a=True)\n",
        "            temp2 = (1 + self.scale) * w_reordered - self.scale * math_ops.matmul(w_reordered, temp1)\n",
        "\n",
        "            last = temp2\n",
        "\n",
        "        # Move channels_num to the back again\n",
        "        if transpose_channels:\n",
        "            return array_ops.reshape(last, w.shape)\n",
        "        else:\n",
        "            return last\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'scale': self.scale, 'num_passes': self.num_passes}\n",
        "\n",
        "\n",
        "# Alias\n",
        "tight_frame = TightFrame"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4VciYzctsSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0001\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3g_vzsy_ndF",
        "colab_type": "text"
      },
      "source": [
        "**Parseval Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN76FYUZ_3YA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f9a9039d-f640-4ce0-8298-cea96bdb4603"
      },
      "source": [
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='Orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_parseval_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, activation='softmax' )(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    parseval_16_2 = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.5)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxyMKoeaBqPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.callbacks as callbacks\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiFrat1Bv1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 70\n",
        "BS = 128\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygMFWH8Bzfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUvPL0dB48O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2905cd-bb86-4a6a-92c9-11aaae3cc419"
      },
      "source": [
        "parseval_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrJ7xy1Q5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4EpGTMG9jeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 30:\n",
        "        return 0.1\n",
        "    elif epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch < 60:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0CbPY_24ns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1a4f4ac-3304-4cfa-b258-cb62c0b4ead8"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "hist = parseval_16_2.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=EPOCHS,\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 1.4368 - acc: 0.3333 - val_loss: 1.4031 - val_acc: 0.3495 - lr: 0.1000\n",
            "Epoch 2/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.3416 - acc: 0.3797 - val_loss: 1.3622 - val_acc: 0.3650 - lr: 0.1000\n",
            "Epoch 3/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.3082 - acc: 0.3930 - val_loss: 1.3394 - val_acc: 0.3728 - lr: 0.1000\n",
            "Epoch 4/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.2888 - acc: 0.3915 - val_loss: 1.3414 - val_acc: 0.3670 - lr: 0.1000\n",
            "Epoch 5/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.2829 - acc: 0.4034 - val_loss: 1.3166 - val_acc: 0.3883 - lr: 0.1000\n",
            "Epoch 6/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.2609 - acc: 0.4303 - val_loss: 1.2423 - val_acc: 0.4718 - lr: 0.1000\n",
            "Epoch 7/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.2070 - acc: 0.4836 - val_loss: 1.4301 - val_acc: 0.4097 - lr: 0.1000\n",
            "Epoch 8/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.1662 - acc: 0.5080 - val_loss: 4.7695 - val_acc: 0.3379 - lr: 0.1000\n",
            "Epoch 9/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.1107 - acc: 0.5415 - val_loss: 1.1018 - val_acc: 0.5534 - lr: 0.1000\n",
            "Epoch 10/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.1281 - acc: 0.5388 - val_loss: 1.2427 - val_acc: 0.4680 - lr: 0.1000\n",
            "Epoch 11/70\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 1.0374 - acc: 0.5755 - val_loss: 1.0068 - val_acc: 0.5922 - lr: 0.1000\n",
            "Epoch 12/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.0169 - acc: 0.5888 - val_loss: 0.9667 - val_acc: 0.5864 - lr: 0.1000\n",
            "Epoch 13/70\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.9783 - acc: 0.6121 - val_loss: 0.9271 - val_acc: 0.6408 - lr: 0.1000\n",
            "Epoch 14/70\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.9467 - acc: 0.6267 - val_loss: 0.8895 - val_acc: 0.6718 - lr: 0.1000\n",
            "Epoch 15/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8990 - acc: 0.6400 - val_loss: 1.2431 - val_acc: 0.4874 - lr: 0.1000\n",
            "Epoch 16/70\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.8817 - acc: 0.6600 - val_loss: 1.2961 - val_acc: 0.4777 - lr: 0.1000\n",
            "Epoch 17/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8526 - acc: 0.6727 - val_loss: 1.2420 - val_acc: 0.5573 - lr: 0.1000\n",
            "Epoch 18/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8256 - acc: 0.6891 - val_loss: 0.7981 - val_acc: 0.6893 - lr: 0.1000\n",
            "Epoch 19/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8428 - acc: 0.6755 - val_loss: 0.7363 - val_acc: 0.7223 - lr: 0.1000\n",
            "Epoch 20/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8018 - acc: 0.6909 - val_loss: 0.7477 - val_acc: 0.7165 - lr: 0.1000\n",
            "Epoch 21/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7811 - acc: 0.7037 - val_loss: 0.8360 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 22/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7806 - acc: 0.7040 - val_loss: 0.7273 - val_acc: 0.7262 - lr: 0.1000\n",
            "Epoch 23/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.7682 - acc: 0.7040 - val_loss: 0.8315 - val_acc: 0.6816 - lr: 0.1000\n",
            "Epoch 24/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.7365 - acc: 0.7193 - val_loss: 0.6896 - val_acc: 0.7709 - lr: 0.1000\n",
            "Epoch 25/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.7296 - acc: 0.7253 - val_loss: 0.8488 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 26/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.7357 - acc: 0.7215 - val_loss: 0.8657 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 27/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.6958 - acc: 0.7350 - val_loss: 1.0139 - val_acc: 0.6019 - lr: 0.1000\n",
            "Epoch 28/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7077 - acc: 0.7273 - val_loss: 1.0993 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 29/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6939 - acc: 0.7372 - val_loss: 0.7062 - val_acc: 0.7456 - lr: 0.1000\n",
            "Epoch 30/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.6818 - acc: 0.7463 - val_loss: 0.8267 - val_acc: 0.6757 - lr: 0.1000\n",
            "Epoch 31/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.8561 - acc: 0.6644 - val_loss: 0.8170 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.7414 - acc: 0.7188 - val_loss: 0.7779 - val_acc: 0.6932 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6932 - acc: 0.7388 - val_loss: 0.6923 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.6681 - acc: 0.7528 - val_loss: 0.7074 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6568 - acc: 0.7521 - val_loss: 0.6841 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6397 - acc: 0.7630 - val_loss: 0.6634 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6271 - acc: 0.7699 - val_loss: 0.6364 - val_acc: 0.7476 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6064 - acc: 0.7818 - val_loss: 0.6772 - val_acc: 0.7456 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.6050 - acc: 0.7712 - val_loss: 0.6929 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5983 - acc: 0.7803 - val_loss: 0.6557 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5969 - acc: 0.7838 - val_loss: 0.6311 - val_acc: 0.7515 - lr: 0.0010\n",
            "Epoch 42/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5965 - acc: 0.7814 - val_loss: 0.6387 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 43/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5862 - acc: 0.7867 - val_loss: 0.5983 - val_acc: 0.7728 - lr: 0.0010\n",
            "Epoch 44/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5775 - acc: 0.7912 - val_loss: 0.6166 - val_acc: 0.7592 - lr: 0.0010\n",
            "Epoch 45/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5778 - acc: 0.7916 - val_loss: 0.6048 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 46/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5717 - acc: 0.7887 - val_loss: 0.5990 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 47/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5663 - acc: 0.7927 - val_loss: 0.5853 - val_acc: 0.7786 - lr: 0.0010\n",
            "Epoch 48/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5579 - acc: 0.7967 - val_loss: 0.6004 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 49/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5529 - acc: 0.7895 - val_loss: 0.5913 - val_acc: 0.7631 - lr: 0.0010\n",
            "Epoch 50/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5567 - acc: 0.7989 - val_loss: 0.5603 - val_acc: 0.7825 - lr: 0.0010\n",
            "Epoch 51/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5511 - acc: 0.7983 - val_loss: 0.6132 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 52/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5541 - acc: 0.7932 - val_loss: 0.5818 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 53/70\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.5507 - acc: 0.8016 - val_loss: 0.5781 - val_acc: 0.7670 - lr: 0.0010\n",
            "Epoch 54/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5407 - acc: 0.8032 - val_loss: 0.5885 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 55/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5386 - acc: 0.8014 - val_loss: 0.6827 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 56/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5398 - acc: 0.8038 - val_loss: 0.6129 - val_acc: 0.7612 - lr: 0.0010\n",
            "Epoch 57/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5307 - acc: 0.8083 - val_loss: 0.5914 - val_acc: 0.7534 - lr: 0.0010\n",
            "Epoch 58/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5413 - acc: 0.7994 - val_loss: 0.5810 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 59/70\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.5376 - acc: 0.8018 - val_loss: 0.5906 - val_acc: 0.7689 - lr: 0.0010\n",
            "Epoch 60/70\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.5321 - acc: 0.8029 - val_loss: 0.5573 - val_acc: 0.7748 - lr: 0.0010\n",
            "Epoch 61/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5309 - acc: 0.8067 - val_loss: 0.6279 - val_acc: 0.7553 - lr: 1.0000e-05\n",
            "Epoch 62/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5259 - acc: 0.8089 - val_loss: 0.5681 - val_acc: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 63/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5298 - acc: 0.8065 - val_loss: 0.5676 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 64/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5285 - acc: 0.8025 - val_loss: 0.5817 - val_acc: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 65/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5245 - acc: 0.8045 - val_loss: 0.5845 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 66/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5273 - acc: 0.8076 - val_loss: 0.5658 - val_acc: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 67/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5226 - acc: 0.8063 - val_loss: 0.5607 - val_acc: 0.7786 - lr: 1.0000e-05\n",
            "Epoch 68/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5257 - acc: 0.8032 - val_loss: 0.6217 - val_acc: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 69/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5305 - acc: 0.8016 - val_loss: 0.5848 - val_acc: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 70/70\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.5247 - acc: 0.8016 - val_loss: 0.5787 - val_acc: 0.7670 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNGXxJTQq-UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAVQ_YwYpeMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0331c24d-295c-40c1-9b61-01389f8a6a9c"
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n",
        "pyplot.title('model accuracy')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'val'], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3hUVfrHP2fSOyGdUELoHaRIsYCoK6jg6iqo6+quveuqa6/r/nbXXd3i2ntFkbWgoi4ooIj03pPQkkB67zOZ8/vj3CGTkMAEGVLm/TzPPDP33PbOnTvne973PedcpbVGEARB8F1sbW2AIAiC0LaIEAiCIPg4IgSCIAg+jgiBIAiCjyNCIAiC4OOIEAiCIPg4IgSCT6GUelMp9aSH2+5VSp3pbZsEoa0RIRAEQfBxRAgEoQOilPJvaxuEzoMIgdDusEIy9yilNimlKpVSrymlEpRSXymlypVSi5RS0W7bz1BKbVVKlSilliilBrmtG6WUWmft9yEQ3ORc5ymlNlj7LldKDffQxnOVUuuVUmVKqUyl1GNN1p9iHa/EWn+VVR6ilHpaKbVPKVWqlFpmlU1WSmU1cx3OtD4/ppSap5R6VylVBlyllBqnlPrJOsdBpdR/lFKBbvsPUUotVEoVKaVylVIPKKUSlVJVSqkYt+1OUkrlK6UCPPnuQudDhEBor1wEnAX0B84HvgIeAOIw9+1tAEqp/sAc4A5r3QLgc6VUoFUpfgq8A3QFPrKOi7XvKOB14HogBngJmK+UCvLAvkrgN0AX4FzgRqXUBdZxe1n2PmvZNBLYYO33d2A0MNGy6Q+A08NrMhOYZ53zPaAeuBOIBSYAU4GbLBsigEXA10A3oC/wrdY6B1gCXOJ23CuAD7TWdg/tEDoZIgRCe+VZrXWu1job+AFYqbVer7WuAT4BRlnbzQK+1FovtCqyvwMhmIp2PBAA/FNrbddazwNWu53jOuAlrfVKrXW91votoNba74horZdorTdrrZ1a600YMTrdWn0ZsEhrPcc6b6HWeoNSygb8Drhda51tnXO51rrWw2vyk9b6U+uc1VrrtVrrFVprh9Z6L0bIXDacB+RorZ/WWtdorcu11iutdW8BvwZQSvkBl2LEUvBRRAiE9kqu2+fqZpbDrc/dgH2uFVprJ5AJJFvrsnXjmRX3uX3uBdxlhVZKlFIlQA9rvyOilDpZKbXYCqmUAjdgWuZYx8hoZrdYTGiquXWekNnEhv5KqS+UUjlWuOj/PLAB4DNgsFKqN8brKtVarzpGm4ROgAiB0NE5gKnQAVBKKUwlmA0cBJKtMhc93T5nAn/SWndxe4Vqred4cN73gflAD611FPAi4DpPJtCnmX0KgJoW1lUCoW7fww8TVnKn6VTBLwA7gH5a60hM6MzdhtTmDLe8qrkYr+AKxBvweUQIhI7OXOBcpdRUK9l5Fya8sxz4CXAAtymlApRSFwLj3PZ9BbjBat0rpVSYlQSO8OC8EUCR1rpGKTUOEw5y8R5wplLqEqWUv1IqRik10vJWXgeeUUp1U0r5KaUmWDmJXUCwdf4A4CHgaLmKCKAMqFBKDQRudFv3BZCklLpDKRWklIpQSp3stv5t4CpgBiIEPo8IgdCh0VrvxLRsn8W0uM8Hztda12mt64ALMRVeESaf8LHbvmuAa4H/AMVAurWtJ9wEPKGUKgcewQiS67j7gekYUSrCJIpHWKvvBjZjchVFwF8Bm9a61DrmqxhvphJo1IuoGe7GCFA5RtQ+dLOhHBP2OR/IAdKAKW7rf8Qkqddprd3DZYIPouTBNILgmyilvgPe11q/2ta2CG2LCIEg+CBKqbHAQkyOo7yt7RHaFgkNCYKPoZR6CzPG4A4RAQHEIxAEQfB5xCMQBEHwcTrcxFWxsbE6JSWlrc0QBEHoUKxdu7ZAa910bArQAYUgJSWFNWvWtLUZgiAIHQqlVIvdhCU0JAiC4OOIEAiCIPg4IgSCIAg+TofLETSH3W4nKyuLmpqatjbFqwQHB9O9e3cCAuT5IYIgHD86hRBkZWURERFBSkoKjSea7DxorSksLCQrK4vevXu3tTmCIHQiOkVoqKamhpiYmE4rAgBKKWJiYjq91yMIwomnUwgB0KlFwIUvfEdBEE48nUYIBEHoPCzalsu+wsq2NqPNqHXUU11Xf8LOJ0JwHCgpKeH5559v9X7Tp0+npKTECxa1P7TWfLHpAKVVP//56AdLq8ksqjriuY5EVZ2D/3yXxtJd+c2uzyquYt7aLOocDc+UX7Izj0/WH+3xAD+f/PLaQ9+txl5PYYWnjzM+nI46j9j3u/K55u013Dpn/RG/g9b6sPX2eidOZ0PZ4h153PffTZRW//z7zv28LZUvTy+gvKb5c63cXchvXl9FXvmRw7taa655aw1nPrOUgp/x+7eGTpEsbmtcQnDTTTc1Knc4HPj7t3yJFyxY4G3T2oz1+4uprqtnYl/zCN2NWaXc8v56zhgYzwu/Pol3ftrHKf1iGZgYyZbsUkID/egdG3bU8NcPafnc9N46qurqmTW2B/dNG0heWS33/XcTt03tR2x4ELNe+onU+HB+NymFmSOT+XhdFh+vy+aZWSPILKri9g82kFVcjVJw+9R+3HpGP6rqHHy4OpPv0wpYlpaPU8PqPUX85aJh1NU7uWfeJooq6xiYGMmgpMgW7at3avxsLX+HBZsP8soPu/nzhcMYmBiJ1pqvt+RQUFlH9y4h3PXRRipqHVx7am8+WZfNwbIapg5M4I4z+zE0OarF43695SCr9xZTUmUnKMDG5qxS0vMqmHfjBIZ0izpkG9CsfaXVdp5fnM7ZQxIZ3Sv6UPnB0mqe/GI7F56UzNRBCYftl55Xwb++TSMkwMaIHl04b1g3okIberXVOZw4nE5CA5v/H1TVOUjLrcDfTzGkWxQlVXXcM28joYF+bMoqZcnOfKYMjKewopb/rsvispN7ER7kT53DyZWvr6KwspanLx5JalwYry/bw38Wp1PrcDJlQByvXTmW/1uwnbS8CtbsK2b22B4MSopkUt9Yfkwv4N0V+3h85hDiI4JbvK7u1NjrufHdtdTYnbx/7cmH7lWtNWl5FTz19Q4Wbc9j8oA43rhqbKN7uarOwV0fbSSruJq75m7krd+OQym4+f11RAQF8JeLhvHm8r3UOpwMTorkh7QCAG59fz3/mDWShMggr4aGO9zso2PGjNFNp5jYvn07gwYNaiOLYPbs2Xz22WcMGDCAgIAAgoODiY6OZseOHezatYsLLriAzMxMampquP3227nuuuuAhukyKioqmDZtGqeccgrLly8nOTmZzz77jJCQkMPO1dbftSlOp2be2iw+33SApy8ZQXxEMB+s2s9Dn27BqTXPXXYS04Yl8acvt/HKD3sA6Nk1lP1FVYQE+HFyaleW7DQt85SYUG6e0pcuoYEcKKnmvOFJLN2Vz9w1mYzqGc2Bkmq+2HSQvnHhjOvdlTmr9tMvIYLKWgf7i6oID/InKiSAunon0aEB7Mqt4Lap/XhpaQa1Difdo0PIK6slqUswf7pgmBGI9dmM7hVNTmkN2SXV9IkL4xdDEqmxO3n9xz08dO4gokICuGfeJgL9bQxKiqRbVDA7csrpExfOvecMoF9CBFprHvp0C4u25/LZzaewp6CS91buY/bYnlTU2lm5p4gau5MPVu9Ha4gND+Lus/uzaHsei7bnHrqevWPD6B4dwg9pBaTGhnHm4AQ+WpNJSbWdc4clMT41hvNHdCMqpKGyfWlpBn/+agchAX5EhwZQba+nV0wYmUVVJEeH8MlNkyirtnPF6yvZX1jFmYMSmDW2B+N6d0UpRVpuOTe8u5aM/Er8bIrbp/bj5il9+SmjkNs+WE9RZR1xEUEsvnsy4UENFXpZjZ2Z//mR/PJaggP8KKioJcBPMSgpklP7xTImpSuPfraVeqfmk5snEhEUwIbMEnLLapgyMJ6yajsz/rOMYstLvGpiCsvSC9hXWMnc6ydw65z1xIQFMveGCVz95hqWpRcwLDmKp341nPdX7uedFfvoGhZIUWXdIZumDU0kItifuWuyuP60VF76fjeXjuvB/7bmUmht99C5g3hhSQaFlXX0jg3jtSvHkBITxg/pBQT52xiX0pWCilrCg/0PCdj+wioe+3wr3+3IM9f8itH8YkgiWw+UctN769hXWEWgv40zBsTz9dYc/nDOAE7vH0d2cTU5ZTWs2lPEF5sOMntsDz5YncktU/rSOzaMuz7aCMApfWNZlm4q/7BAP7qEBnLzlL488MlmAAYmRvDqlWPoHn3osdatRim1Vms9ptl1nU0IHv98K9sOlB3Xcw7uFsmj5w9pcf3evXs577zz2LJlC0uWLOHcc89ly5Yth7p5FhUV0bVrV6qrqxk7dixLly4lJiamkRD07duXNWvWMHLkSC655BJmzJjBr3/968PO1ZZCoLWmotZBRLCphHLLarjl/XWs3lsMwAPTBzKqZzQXv/gTp/WPo6rWwcasEt787Tju+WgjAxIjcDg1K3cX8dB5g/h84wE2ZpZyw+Q+xEcE8eHqTDZnlx46n79N4XBqkruEkFNWQ2iAHxeP6cGdZ/UjIjiAJTvzuOm9ddQ7Nf+aPZJH52+lqLKOD6+fwLDkKK58fRXLMwqJDg3giZlD+cO8TQzvHsVLV4ymS2ggWms+XpfNY/O3EhMeyNOXjGB0r66AEbib31/HV1tyiAz2p1uXEH43qTd/+O8mwoP8mdgnhlV7i4gODeTTmybx4vcZvLAkA6XgpJ7R7Motp7zGcei7BAfYcDrhrMEJ3Di5D795fRVFlXUEB9i466wBTOoby/rMYqYPTSIqJICfdhdyUs9oQgL9KKux8+9FaXy8Ppuiyjp6WYL5v605pOVVsK+wivOGJ/HPWSPx92uI9s7feIDb5qzn7MEJ7C+qYndBJWcPTuD7XfmU1ThIigomPiKIjVmlRIUE8PTFI/hi0wE+3XCAfvHhpOdX0C8+nBtO78Pv527k4tHdiQkPoriyjrp6J1uyS9lTUMmc68Yzplc0Ww+U8eXmg6zbV8zqvUU4NSRFBVNSZSc5OoSSKvuhUMew5ChCA/3YeqCMp341nB/S8pmzKpOYsECevWwUE/vEMm9tFnd/tJHY8CAKKmq5dFwPPlmfTY3dhOyuOaU3t57Rjw9W76dea4Ynd+GUfrE46p2c9Y/v2VNQSWigH6sePJOQAD/Kqu3c9N46ftpdSKC/jSdnDuWPX26jotZBYmQwB0tNyCY00I+qunoGJkbw4XUTuO/jTXy1JQel4LHzh/DW8r0E+tv47aQU/vjFdiKD/bl1aj+mDIgnITKIK99YzffNhB2vmpjCo+cP5p55m5i3Ngt/m2JochTJ0SF8uekgZw9OoHdsGC99v5u/XzyCX43uzvr9xazbX8I/F+0iNNCPt343joGJLXukR0KE4GfSWiF4/PHHWbx48aH1jz32GJ988smhbb/55hvGjx/fSAjOOuss0tLSAPjrX/+K3W7noYceOuxcx0sInE6N7QghDBdzV2fy0vcZPHnBMD5dn83ctZlMH5ZEcpcQPlmfTWWtgydmDuXN5Xvwt9lIjQ1j4bZcVj14Jnank4ueX05WcTXV9nqeuWQE04clUVxVR1JUCPVOTXmNnS6hgYARmh/SCvD3U3QNC+SDVZn07BrKlRNTqKxzEGCzERLo18i+jPwKquvqGZocRXZJNQXltYzo0QWA0io7D3yymVlje3Ba/zhKq+1EBPkf9r3LauwE+dsI8m98bHu9k/s/3sy8tVk8ffEILjwpme925DGqZzRdwwJZubuQS19ZQaC/jRq7k1ljejC0exQPf7qFrmGBzL1+AluyS4kKDeDUvrGNKunSKjv5FTX07BpGoL9nqTqtNav3FnPL++vIK68lMTKYsb27MigpgutOTW10fNf2D3yyhW+25uBnUzz1q+FMGRBPdV098zdmszyjkOziak7rH8dlJ/ckNjwIgE/XZ/PIZ1s4c1ACT/5yKKGB/tz54QY+WZ9NgJ8iJiwIfz9FfEQQV0404bemZBZV8dPuQs4enMDqvcXc8O5aRveK5vrTUqmodXDX3I04nJq/XDiM2eN6Aibs1y8+gsSohlDN/7bm8Nj8rYzt3ZV/zhrJ3sIqNmWVEOhn46zBCYd9Zxf/XZvFXR9tZPbYHvzlouGNrvstc9YxY0Q3Lh7Tg7yyGt5dsY8NWaVcdJL5Hiv3FNE1NJDnl6QTFRJAcZWdW8/oyyVjetCjayifbcjm9g82ADA4KZLXrhpDUlSD915dV8+y9ALqnU4SIoPpHh2Kv00RHdZwn/9jURpv/7SXd68+mdS4ML7anMO5w5MI8reRXVJ9WMt/R04Zv31jNQ9MH8T5I7p5dL805UhCcCjh0lFeo0eP1k3Ztm3bYWUnkj179ughQ4ZorbVevHixPvfccw+tW7x4sZ40aZKurKzUWmt9+umn68WLF2utte7Vq5fOz89vtL/WWv/tb3/Tjz76aLPnOh7fdXd+hR708Fd64dacI26Xlluu+z+4QKfe/6Xude8Xute9X+ir31ythzzyte734AJ98YvL9Y6DZVprrZ9bnKZ73fuF7vfgAn3/x5saHWPww1/pfg8s0KXVdT/b9hON0+nU2w+WaqfT2ez6t5bv0bNeWq6/3nJQ19c7tdPp1C8vzdCbs0q8ZlNBeY3+MT1f1znqvXaO+vrG37esuk4v3JpzzL9haXVdo2u4aFuOfvp/O1u8ru44nU6PtnPH7qjX/1i4U2cWVbbaVhevfJ+he937hX55aUaj8vp6p/54XabemFncaruaHqc1VNbaj/lcWmsNrNEt1KuSLD4OREREUF7e/BP/SktLiY6OJjQ0lB07drBixYoTbJ1pVQGcPSQRgPdW7KOqrp5/LNrFGQPjWbDlIONTYw61CME0EO6au4HQQD8+umEiry3bzage0Vwytge1jnoUqlFLdvrQJJ76eid1DtMydtE3Ppy3rx5HblktkcEdb2oMpdQRXfHfTEjhNxNSGpVde1qqV22KCQ9iottv5Q2aek0RwQGcOfjwZLGnNP3tpw5KaDb53BzHkiT197Nxx5n9Gxc6nVBXAcGehVauOTWVX45KJqbJtbbZFL8c1b3VNjXFE4/cnZYS7scDEYLjQExMDJMmTWLo0KGEhISQkNBwg59zzjm8+OKLDBo0iAEDBjB+/PgTaltplZ3fz92ITcGKfrHYlGLeuiy6hgWy9UAZv35tJcszCkmMDOaPFwwlPiKIYclRrNhdyMasUp66aDh948P584UN7nXTEApASmwYw5KjsNc7Gd69ce8WV9xdENqUbx+HdW/DXTvA3zMhbSQCWsP+nyAgBLqN8pKRbYMIwXHi/fffb7Y8KCiIr776qtl1e/fuBSA2NpYtW7YcKr/77ruPm11vLt9LRa1JWn66/gBhQX6UVNl546qx3P/xZpZnFHLRSd1ZuaeQa982uZfZY3tQVmMnOjSAGSM9j0e+dqUJP3bIEdBlB2DJX+Ccv0DgsffMoLYCvnsShl0M3UcfP/uOFzWlsOgxGHsNJLSc9+p0FO+DFc9DfR0c2AA9T27d/jWl8N7FkLkSwhPg9zvA1nmGYXn1myilzlFK7VRKpSul7mtmfU+l1GKl1Hql1Cal1HRv2tMZWbG7kAMl1YAZjWivNz0qKmsd/JhewBvL9zB1YDyDkyJ5fkk6f/xiGykxoZzeP46nfjWc+6cN5O8XD+er20/lnavHcfnJPflgdSZfb8nh4jE9CA5wa/07nVCQ3qIt8ZHBxDsOwN8HQN52z79EQRrUVZoW16tnwatnws6vj+l6HDNpC2HdW5C+yNiRtQYcdeaVtdaUNUdNqbEfoLoY3p4JK1+AH//ZsI3TCbnbDt/3wAZ4ehBsntdQVpEPJZk/77uUZkOtFap8fxZ8eVfDui0fw5rX4Y1pkLn6553HnfdnwYI/HPv+jjp44RT44vfg9MKI2sX/B1gNlH0/tn7/HV8aERh4HlTkwoF1nu3nqG3+t29neE0IlFJ+wHPANGAwcKlSanCTzR4C5mqtRwGzgdYPz/VhKmod/Ob1VTzx+Ta01sx49kfG/WkRV72xitFPLuTyV1dSY6/njjP7c9WkFLKKqzk9YBtzTsnFZlOc1j+O60/vg1KKiOAATu0Xx6PnD2FwUiRODZdZvTkO8d0f4T+jYd/ylo1KWwgVOWabegcs/RuU57S8fb0DXp5sWuMl+yBrlfnjzJkF2+Yf/SJkfAc/PQfVP3OEtsvG3Yth26fw6lT490j49yh49QzY/nnztr/7K3j9F0YofnreVBCJw2DP9w0V2vq34YUJ8O0TjQVl7RtQfgD+ew2sf8+Uzb/VnLvuGKdXqC6GFyeZ1mv2Otj1Nax/F2qsnnQ7v4LIZAiJhk+ua1ngWoPrPJs/MqLnwl5tRGfdO0c/Rsa3kLsZ1rwG837Xsl07voSMxc2va4mi3bDpQzj5OogdYMI7LVFdDD88ffj9lLEYQmNhxrOg/IwdLZG/E1a+bD7/8DS8dCpUFjSs3/iBuSaOEzNq2BO86RGMA9K11ru11nXAB8DMJttowJW5iQIOeNGeTseytALqHE6W7Mrjp4xCduaW0zMmjIz8Ci4b2ZW3rxjGivunMqx7FBeOSubfs0fyt6A3SPr2DnPDN0Ogv403fzuW9645mZTYsIYVZQeMaw2w8NGW/6gukShIg6zVsPhJmHd1Q6W49k346KqG7csPmgRe2sKGfX+7wMRg599qWrcAXz8A3//NfP7uT2a5ptQc+5sH4JlB8MwQ0zJt4btRmAGf32G8jsKMxuvKD5r3jMWwYY5x/2P7Q2xfU2k2JwTfP2WEq6oQKvMhfwd0TYVJd0BNiWnxA+y1WqA/PA1L/2o+O2ph6ycweCYkjzbfzRWDrshtuNZHoqbs8N9h2T/M99//E3x8Ldj8wVFj7K+tgN1LzDkn3WEqSHfPrbKg5d919xJ4ZSqsfu3wCmzlS+a9ughyNppKdOnf4B9D4Ys7Yf4tsPCRI4vOpg8hNAZOu8cIcZbVRbzeAR/9Fla9Ypa/vg8+vRHq7eY+/PQmsB9lRt5Vr4DND8bfDL0mwP6VDfdjaRZ8dR+8Ps1czzWvG8F+8zzIXmu8M63N90+dDKFdoddE2HmEWQGWPgVf3WO+w8Y54HQ0fJ+8Hcb++bfAv0aaczTHosfhrRlGuE9AF39vCkEy4O7jZlll7jwG/FoplQUsAG5t7kBKqeuUUmuUUmvy85ufH8YX+XZ7LkpBjd3Jg59uIdDfxjtXj+OH20bzSOa1nLbpvkN99P39bMyIOYCtZA84qo/YSovXBUyqt8IGFXnw47/hs5tBO+HUu0zlt72Z1rrWDZV5YRrkWnmPfcvgh2egshD+97CpAMsszS+1bpH87aY8uAskDoeLXjN/9u+eNGGDNa/D909DzhZToa54Dt6+wFQ+v3wZRl0BKadA+rfmT1yea+zZNNdUjnN/A8+Ohg3vmxbbG9Mau+wuISjeA+kLYcSl8JtP4TefwYDpkPaNqXC2fWZa64UZpvKO6Wt93wxTsXbtA71PN2W7vzPv2WtMSGHoReY6lGZB2v+MkJ30GxhygTnvvh+NgARFwbJ/NW5FNqU8F/45zFQqLnK3mkp56K8gph8UpsOY30F0b1PRZnwH9bXm+wyYZvbZ+WWD/c8Mgp/+0/z51r1jvseXvze/oYuKPNjyXxh8gVnO+A7e+aVpAHQbBVd+YfIRP/6r5cqzptRUeEMvgom3gX+wsRfMb731YxM+q62Akv3mt/r2CRN+2/AevPerlsNpteXGIxryS4hMgp4TobYU8raZ8748GVa9BPuXm992xwKI7G6u3StnmGv87RNQmQd9pphjDjzXiH7TxgSYezZtofn82S3GXjDXDsyxAsLgknfAL8BU9ruXNj7G9s9h2TNGJObMNg0ib4TL3GjrbMelwJta6+7AdOAdpdRhNmmtX9Zaj9Faj4mLizvhRrZHnE7N4p15TB+aRNewQPYUVHLGgHgig/xNnLVkn3HXK/Iadtr0ofmTJY82raT/PWziuu4tPHsNvD8b5lxqKu7lz8LCh80f/NS7YfIDED8EPrmxwUUv2g2f3AB7fzB/GFuA8Qhyt5qKfdjFpmJ45wKotUIULsEodZvILe1/0HOCScLF9DGVVfoiOLDeiJejGt6/BNCmkjmwzlR6I2bB9Kfgwpfg8rnGntd/YVrEH19rkqMZS+CUO+COzXDNQkDBh5c3xNLLD0J0ivmsnTD8kga7Bkw3lcaHlxtB+e5JWPWyCRHMeNa6BpYQxPSB8DgTHspYAlVFprz7GDjzcbPtgj/Asn9CWDz0nmxamADLrUr4/H9CXXlDZQiw6xv4n9sAw++fMqKxcQ4s+St8cDm8MAn8gmDqI/CLP0FwFJx8AwyfZUJVX99vvJueEyAi0dwHO6zKedXLJpH6/d+MzS60NuGe3UvMcYZeBJs+MPeM1vDVH8zvMfURSBhqBOzAOpjxH/j1POh9Kpz9J1C2Bg+pKds/N17L8Fmma+eA6UZcdn0DS/8CfoHmXirYabZXNlj+bwjpCuc+A/tXmDDex9cfHo9f97a5506+wSz3mmDedyww4lSZD1cvNAK+4gVTYY++Cm78ES552/xuy54x+6RONu8DzzP3+KLHDm+t711mhCZuoGncBISaxkLWGpOT2fklnHI7DJ4Bv/sGonoYIVvzuvnfvjHdeDlJI+HuNPOfW/8OzL+t+Wt3nPCmEGQDPdyWu1tl7lwNzAXQWv8EBAOxXrSpY1CeY1okR2DFnkIKKuo4e0gCZ1v9u2eM7GZaI1vmwfDZoOtNchBMS2XLf82f7JQ7oXS/ia2vesm0OqqKzB9+4cMmVouGPUtMZd/rFHgwFybfC37+cMXHptJ8/xLTUpv3O1MhfXC5Odeg801LKHuNqRxmPg9DLoScTTDiMtMicsVpXS2mYDMa+NAfFUwLrDLPxI3BVK5l2eY7zH7feAFnPd74wvQ5w7Tiq4tNzPr0++DBHLh3D5z5GEQkQNwAuPgNKN4LX93bcM1TTjXx8/ghjXvU9JliBDR9EQRGGBF1tTK7jzWCsG852KtMaMhlR+ZK09IFSB4DXXrAuGtNZZC3DaY+bOYyIC0AACAASURBVK5n4ghzTXZ9BYHhJnQTP6ShknY6TSW+/FnjzRRmmBDb6KtMpb7k/0wFdNrdcOtaiO4F/X8B9+03wjT6Suh7JnTtbYTcz+osOGC6qbTztpscRY+TTXhk2T/M+pUvmRbx/uVQVQCpU2DkZUYU0xaa1vjWT2DKg+Y8qZNNJZgwDEZe3nD9AoLNdcl3C0NVFTWEpTZ9aNYnW72shs8ynt77l0DcIDjjISOMaYvM+jG/M++n3QNjr4bb1sO464ygvDAB3rvE/B4FaUa0U6eYCh2gS0/oe5a5ZsuftXp3jTHnzNtqthk43XyfwTPholchKNJ4WFHW2IEuPcxvt32+ERp3dn5l7pWLXgOU8R5STjF5lB//aYR4vDU5ZWSSCYMmDjchtPXvmvKUU+BXr5vea1MfhrHXmv9XTSnewpvdR1cD/ZRSvTECMBu4rMk2+4GpwJtKqUEYIej0sZ/w8HAqKipa3sBeBXXNT7OsNVzz1moWbc8jIsif0/vHMTSsjCkHv+b0flPhs3cgLA5mPmdu7E0fwvgbTMikusjc8P3ONjdq97GmFT//VhPPDY83IYqx18LmubDpIyMKZzxs/swuIhLht1+aP9x/rzZlw2eblmJojLn5t34MOZth3PXgH2j+UINnQJ+ppvW9zxKC0iyzT+pkI1Q9JzacJ9VyxTd/ZP6IZzxiKofxN0FkN5jZQhijxzi49jtTEQw4p/ltek00YYgf/2nCXRV55piXvHN499HAMOh/DhzcAJd+CC+fbvIa428w7n10LyMS0CAEo35jWvhf32dasK5+51MeMCLT/xwTbwZTMfcYa1rd3UaZePbA6SYsUlVkQgRFVhhi01zz2S/IVOrKZs496HwICm/+u0Z2M63zpgyeCUv+bDwJXQ/n/NmI3KqXTWNh1SsmdPfxddbvMdncW2FxJsRRtNuI56TbzfoB003j4qzHD+9aGTfQiJiL7/5oxOeqL2DPDzD5PnB1O+471bSUI5Lgsg8bGkVb5hnv4Kw/GtEa8ktT3qWHsf20e2D1q7DyRRP6Cwgz4wUuaJJvmfWuuW8zvjMiBjD8YiMOXXpBvFuflugU07Bo2iV6wq3mun/zoPEQwmKMN71zgblvE4fC5R+Z3zrjOyPcO74wuZlAt9xbaFdz/G2fGoGKaGaQ3ZALYPUrRuwHnnv4+uOA14RAa+1QSt0CfAP4Aa9rrbcqpZ7ADHWeD9wFvKKUuhOTOL7KGgrt22in+WNqp/mju2Gvd7Joex5XjO/Fdael0iU0kC5b/kWfgjmwurcJB4252lQuw2eZcELuNiMIIV3Nn8xmg2G/MgeM7mUqnx//ZRKzUx828d6KnIYEqSs26k5ItImhf367+bNMeRBCupjWU2y/hu1cLWubX8Mft9dE052vqshUNFE94KQrTYun28iGfaOSTcK2YJfxFPqfDX/Y3VCBHomYPuZ1JAbNMEKQ8R2gjcC11Pf/ly+ZpF9QuAmD5GxuaMF27WPyCq7zgkkyj77SuPzxQxoq6cAw06puSs+JRgi6jzXLA6aZMM2ub0wFGJ4Icf1NRVdTAqf9oaHSGHnp0a9Hc8T2g2u+Nb+9K2Q4McS0Pr+40+R5wuKMFxY3yLRgwYTjVr5gvJFZ75rfFiBlUsu/T9wA01p21JmGwf6VJl/x/ixAm5a5C78AuGmFCavYbOBnza1VsMtcy8DQxqE7F6Fd4fQ/wIRbjLey4T0jlpFNxsIEBBu7a8tM+AyMgJ90pfFgm1b6yScdfi6bDab/HZ4fDz/8HSbfDx9cZu7naU+ZbfqdZe1veSPKZvIlTQkKh1GHTzB5iO7jjKhlLO54QgCgtV6ASQK7lz3i9nkbMMmbNpwI7rvvPnr06MHNN98MmEnm/P39Wbx4McXFxdjtdp588klmzmzaaaoFXF3wnPXQZFKtans9/jbF3WcPMPO+u5J1KDNyEhr+JCMuM/Hj/z1oXOVRV5g/WVMShsCFLzcuS51ihCC4i4lXNkdgmGnpu5hm9Yhx7/rY3KClXhMBbUInJZmmQko93byakjrFVAAuT8ETEfCU+IGAakjuRRxh8Jy7RzTh5sbrYiwh8As0oubi9Hth44fQ04PR5KmnmxapK1+QNMq0iBfcY8IiUx4yYY091xkPamKz/SpaT7eRJkzmImEw9D7NtFD9AuHyefDaWaYB4eLU3xvRHHfd4d5TS79P3CDTuClMNy34vG3m3qouMhVlU9F2926CIkxjo3ivEZSjERhqQnDjrm15G6UaRMDFjH8f/djuxA0wFfiqV6zQTRlc+Irx5tyJ7W9+s5RTzXdvLf6BRmR3t7LbbGtO4bUjtxVf3Wdaa8eTxGEw7S8trp41axZ33HHHISGYO3cu33zzDbfddhuRkZEUFBQwfvx4ZsyY4dmoW+0SAkejiltrTXVdPRP6xDQ8/GPtmybJN/M507Mnpm9DGCIsxrjti580y8Nnef6dXV5A6ukNLT5PCQwzPS/Ksk1IoCnJo00LNGOxCQ25VzJNGXqRcamb80p+LoFhJm6+9wezHJF4bMfpalVi0SmNr1VEIty4zFQCR6PneLj+B3OvgWlxnnSlqWAm3wcnX28StNEpJpTl4Xw5x8TJN5jkcv9fGKG4cbkRJRfh8Sbx3hpcFXj+DpNvQJuW85L/M4JyNBKGWkLQzP3Ulky+34Rdk0aYxG5zHqXNBtcsMuMQjpXUKaYzRUnmsYnJUeh8QtAGjBo1iry8PA4cOEB+fj7R0dEkJiZy55138v3332Oz2cjOziY3N5fERA8qG211FXM6GhXXOpw4nJpzhrodY93bJjE56tcm4Rk/qLFrO+EmE/MNDGtImHlCdG8TJx5wjIO94weaVnRzceuAEHNjb5kH9srGreim9DwZfu/FkZkJQ0ysGxpXdq3BlRdwvTe3zhOShjdennK/ebnwC4DbN7bevtbS/xyT23GFsNxDfcdKbD8TGsnfAcWWd9XvLNPjyxMShpgGQXw7E4LIbp7dn625D5ojdbJ5370ETrri5x2rGTqfEByh5e5NLr74YubNm0dOTg6zZs3ivffeIz8/n7Vr1xIQEEBKSgo1NUcZ+OLC3SNwo7CyDoV5uAnQEGM/+XqzfFozcxQFhsEVnxhxaM0cQEqZXjbHyrSnTNK7JQZMM71koKE3RluQMNSEwJQfhB1jiy3GJQRHyUl0FGx+pjvu8SQgxHgz+TtMyLNrauvCfL0mmlBVJ5vszWPiB5n/Y49xXjl85xOCNmLWrFlce+21FBQUsHTpUubOnUt8fDwBAQEsXryYffv2eX4w5+FCUF5jp7CilrAgv4ZnrObvMO9xR3lQTeLQVnyT48TRErUDpsHnCtBecXU9xpXDCE9ofQjMRZdeJvE86LzjZ1dnJG6gCTlpJ/T7Rev2TZ0M9+5t3OPGl1DKeOheoq0HlHUahgwZQnl5OcnJySQlJXH55ZezZs0ahg0bxttvv83AgR66tFoDjYXAqTWZRdUEB/g1elbtoX7YniTQ2hvh8Q09ZI4UGvI2LiGIPMawEBgBmfVOQ6JXaJ7T7zXeX02pSX62Fl8VgROAeATHkc2bG5LUsbGx/PRT85NbHXEMgSs/AIeGlTvqNQ6nk54htWRWWwO/bFa8NTC8bUMrP4cxvzWtQ0+Sqd6iS4rpmnes+QHBc7qNNAnxvO0ds/HSiREhaG+48gNgJtzCjB2IU6WEVxeZrpnpC02Pjvwd5g/VEef/B5OMbK5P/YnEZoOzn+g88f32jlKmi6rQrpDQUHvDfRpfKzRU77CTSBGOwEgzm+TKF836vB3trztdR2TsNd7pnioIHYROIwSdZkCyPlwInI5alAIdEm3ipBnfmYm2KvNECARB+Nl0CiEIDg6msLCwc4iBK0fgF9jQa8hRi9aakvIagiOiwT8E5l5p1okQCILwM+kUOYLu3buTlZVFp3hWgb3aTI3rH2xGkhb7UV1eTEh9GcHxkXTvlWqmx51rDSppbwNsBEHocHQKIQgICKB3795tbcbxYfM8+OZqGPlr2PAu3J/Fkn8/Ru+qFUQ/ao1F6H+2eeDHvh/btuulIAidgk4hBJ2JyopSwoD6qJ74AY7yAqJrsykMTCbafcMeY81LEAThZ9IpcgSdhTd+3MMzX6wD4OHvzZOzvl23jXjHQcpDO+hYAUEQ2j0iBO0ArTX//jaNxz/fxpBYM81Bt579AdizO40EXUhteM+2NFEQhE6MCEEbU+/U3PXRRp5ZuIsLRyVzweAo8AvilhlmCH7ggdXYlG54nq4gCMJxRoSgjVmeUcDH67K5aXIfnr5kBDZHlRkrEJ1CaWhPLlPfABAQ10mS4YIgtDtECNqYDftLUApumNzHPLSmtsLM4W/zo3j8fQQrOwBhicdhTnhBEIRmECFoYzZkltAnLpzIYGtW0boKM5EckDxxNpt1KpU6iK4J0k1UEATvIN1H2xCtNRuzSji9f3xDYV3loel2A/z9eDnhEcqyd/J6eHALRxEEQfh5iBC0Idkl1RRU1DGyh9tDtN2EAGDK+LF8vysFP1sHnWFUEIR2jwjBCWbe2izqHE5mj+3BxsxSAEb2cBsqVldpHtpiceFJ3bnwJBlDIAiC9xAhOIEUVdbxwCebqXM4mb8xmyB/P3r5FzHkx1th2l/NU7Lqyg/lCARBEE4Ekiw+gXy4OpM6h5PbzujLrtwKftiVy4shL2Db/hmkLzIbNQkNCYIgeBsRghNEvVPz7op9jE/tyu/PHsDqB89k+ambGGTfCijI3Wo2FCEQBOEEI6GhE8T6NT/yYtWdHDzrQwD8bIrEPZ9C6mQzdiB3i3k0paNGQkOCIJxQxCM4QZRs+45htr1MjjxoCmoroCANek2ChCHGI6izHmofJEIgCMKJw6tCoJQ6Rym1UymVrpS6r5n1/1BKbbBeu5RSJd6050SyK7ec0ir7oeWagr0ABJZZzxTI2QxoSBoBCUOhuggKM8w6CQ0JgnAC8VpoSCnlBzwHnAVkAauVUvO11ttc22it73Tb/lZglLfsOZForbnkpZ/oHRvGR9dPQClFQHkWKKB4r9no4EbznjSiIRS06yvzHhRxok0WBMGH8aZHMA5I11rv1lrXAR8AM4+w/aXAHC/ac8LIL6+lpMrO+v0lvLAkg/S8ChJ0gVlZtMe8H9wI4QkQkQgJg03Zsn9AcBfoM7VtDBcEwSfxphAkA5luy1lW2WEopXoBvYHvWlh/nVJqjVJqTUd4LvHugkoAeseG8a9v03jrp70kK0sI3D2CpBHmc0g0RCabh9WfdjeEdDnhNguC4Lu0l2TxbGCe1rq+uZVa65e11mO01mPi4uJOsGmtZ48lBM9eOoq4iCD+uzKdOGVGEVO81zygPn9HgxAAJI+GqJ4w9toTb7AgCD6NN4UgG3CfMrO7VdYcs+kkYSGAvQWVBPrbGJQUydMXjyBJFZoVCUOhpgT2LgNd31gIZjwL134HATK5nCAIJxZvCsFqoJ9SqrdSKhBT2c9vupFSaiAQDfzkRVtOKLsLKkmJCcXPppjYN5Y/n2GFelJONe/LnwWbP/Sc2LBTSBcIb//ejiAInQ+vCYHW2gHcAnwDbAfmaq23KqWeUErNcNt0NvCB1lp7y5YTzZ6CSnrHNnQBnRBTZT70toRgz1LoeyaExbSBdYIgCI3x6shirfUCYEGTskeaLD/mTRtONPVOzb7CSs4clNBQWJoFKOjl5gEMv+SE2yYIgtAcMsXEcSa7uBp7vSbVzSOgJBMikkzvoLA4kyzuP63tjBQEQXBDhOA4s7vATBORGucmBKWZ0MXKmw+eCSFdITC0DawTBEE4HBGC48zOnHIAUlweQWWhmVCu71lm+dyn28gyQRCE5mkv4wg6HnuXwfd/b1SkteaT9dkMS44iNjwItIb5t5qppSfe0kaGCoIgHBkRgmNl8zxY8hdwOg8VbcoqZUdOObPHWWGgnV/Bzi/hzMcajxkQBEFoR4gQHCuOGnDaoargUNEHq/cTEuDHjBHdTEHBTvM++qoTb58gCIKHiBAcK/Zq8152AICtB0r5dP0BzhueRERwgFlXWQABoTKttCAI7RoRgmPFUWPeyw6QVVzFVW+sJjo0gLvOHtCwTWUBhMa2jX2CIAgeIr2GjhWXR1B+gDfS91JabefLW08hMcptrqCqAhk9LAhCu0c8gmPFzSPYdqCMwUmR9Eto8kAZ8QgEQegAiBAcK5ZHoMsOsCOnjEFJzTxVrLLAjCQWBEFox4gQHCuWR1BXlEVxlZ2BiZGN12stoSFBEDoEIgTHiiUEjlLziIWBiU08grpKs42EhgRBaOeIEBwrdiMEgRUHAc3AJMsjOLDejCauzDPLYSIEgiC0b0QIjhVHDSgbAc5q+kdpokKssQNpi2Dd25C11iyLRyAIQjtHhOBYsVdDVHcAxsXUNpTXlpn3vT+Yd0kWC4LQzhEhOBac9eC0Y49KBWBEVEXDujrr895l5l2SxYIgtHNECI4Fq+vohqquAJyS4GhYV2umoaYow7xLaEgQhHaOCMGxYPUYWpwTBECSf3nDulo378A/WOYZEgSh3SNCcCxYHkEZ4WbZUdewrtZNFEJjQakTaJggCELrESE4FhwmORwf0xVsAQ3TTQDUuQmBdB0VBKEDIELQGmrKoDwHR20lAIkxXSAgpLEQ1JZDl17mswiBIAgdABGC1vDN/fDOhWQXFAPQPS4a/IOaCEEFdB9jPkuiWBCEDoAIQWvIWgtl2ezLKQSgV0JXkxB2uI8jKIfIbjBgOvQ+tY0MFQRB8Bx5HoGnOGqhYBegycwzQpAY07WxR1DvAEc1BEXCpXPazlZBEIRW4JFHoJT6WCl1rlLKdz2I/J2g60E7KS44CIBfYEhjj8CVKA4MbyMjBUEQWo+nFfvzwGVAmlLqL0qpAUfbodORu/XQx9riHPMhIKSxR+AaQxDUzLMJBEEQ2ikeCYHWepHW+nLgJGAvsEgptVwp9VulVIA3DWw35G459LGL0ySL8Q9u7BG4xhAEiUcgCELHweNQj1IqBrgKuAZYD/wLIwwLj7DPOUqpnUqpdKXUfS1sc4lSaptSaqtS6v1WWX8icfMIEmwl5oPLI3A9v7hOPAJBEDoeHiWLlVKfAAOAd4DztdYHrVUfKqXWtLCPH/AccBaQBaxWSs3XWm9z26YfcD8wSWtdrJSKP/av4mXytqFjB6AKdtI3tApqcPMI8s02Lo8gUIRAEISOg6cewb+11oO11n92EwEAtNZjWthnHJCutd6tta4DPgBmNtnmWuA5rXWxday8Vth+4qgsgIpc8ruOBiDZ35pq2j+4SY5AQkOCIHQ8PBWCwUqpLq4FpVS0Uuqmo+yTDGS6LWdZZe70B/orpX5USq1QSp3T3IGUUtcppdYopdbk5+d7aPJxpGQfACtrzPMHwu2F4BcENhv4h7j1GpLQkCAIHQ9PheBarXWJa8FqwV97HM7vD/QDJgOXAq+4C47b+V7WWo/RWo+Ji2uDB71UmeTw6jJjmqotM94ANO8RSPdRQRA6EJ4KgZ9SDdNoWvH/wKPskw30cFvubpW5kwXM11rbtdZ7gF0YYWhfVJkBZGuLQ3EoK60S4BIC915D4hEIgtDx8FQIvsYkhqcqpaYCc6yyI7Ea6KeU6q2UCgRmA/ObbPMpxhtAKRWLCRXt9tCmE4clBFm1oTj8rUq+WY/A8hT8fKNHrSAInQNPp5i4F7geuNFaXgi8eqQdtNYOpdQtwDeAH/C61nqrUuoJYI3Wer617myl1DagHrhHa114DN/Du1QXoZWNMkIhOArsxabrKJiKv74WtDY5AvEGBEHoYHgkBFprJ/CC9fIYrfUCYEGTskfcPmvg99ar/VJVSLV/FBob/mFRUE5jjwCMV1BbLvkBQRA6HJ6OI+gH/BkYDAS7yrXWqV6yq31RVUiZiqBbVDD+IVGmzN0jAEsIxCMQBKHj4WmO4A2MN+AApgBvA+96y6h2R1URBfXhDEiMMDOLQjMeQa3xCEQIBEHoYHgqBCFa628BpbXep7V+DDjXe2a1A5z1sPZNcNShqwo5YA+lf2IEBFu9W5vzCOokNCQIQsfD02RxrTUFdZqVAM4GOneNl7kSPr8dQmNwVBRQ5BzMoMRIyD2KRxDT/nq/CoIgHAlPPYLbgVDgNmA08GvgSm8Z1S6osGa7KEzHVl1EqYpk8oC4htCQyyNwvR/KEXRufRQEofNxVI/AGjw2S2t9N1AB/NbrVrUHrLEDzgMb8dMOouOS6BIaaLqPQoMnIDkCQRA6OEf1CLTW9cApJ8CW9oUlBPa9KwDo37uXKQ92hYaa5AhqyxseUykIgtCB8DRHsF4pNR/4CKh0FWqtP/aKVe0BSwiCqsxkq4NTU0z5odCQ2xQTABW55j34sKmSBEEQ2jWeCkEwUAic4VamgU4vBC4CI63J7g7zCKzQULn1+MoQEQJBEDoWno4s9o28gDuVBY2XQ2PMuytH0KJHEOV92wRBEI4jno4sfgPjATRCa/27425Re6GqkLrQRAKrXC39aPPe0oAyCQ0JgtBB8TQ09IXb52Dgl8CB429OO6KqkOzwofSuykErG8pVwXfpCcMuhpRTzbJLEMotIZDQkCAIHQxPQ0P/dV9WSs0BlnnFovaA1lBVyN6AWCLoQmyIv3kaGZgppi9ym3j1kEdgeQ7iEQiC0MHwdEBZU/oB7fdB8z8XexU4akivDKIwqAeEdm15W1fS2DUATXIEgiB0MDzNEZTTOEeQg3lGQefEShSnlwcRPfJ6Bgw+wiAxvwBAmWcR+Ac3JJEFQRA6CJ6GhnxruKzVdbRARxA15GwYnNDytkpZj6uslrCQIAgdEo9CQ0qpXyqlotyWuyilLvCeWW2MJQTFOoKTenpQubvyBBIWEgShA+JpjuBRrXWpa0FrXQI86h2T2gGWEIRFJxATHnT07V09h6THkCAIHRBPhaC57TztetrhcFbkA9C7V0/PdjjkEYgQCILQ8fBUCNYopZ5RSvWxXs8Aa71pWFtSUpiDXfsxtLenQmB5BBIaEgShA+KpENwK1AEfAh8ANcDN3jKqrSnKP0gxEYzpfYRuo+64PAIJDQmC0AHxtNdQJXCfl21pN1SX5IGKpE9smGc7HPIIRAgEQeh4eNpraKFSqovbcrRS6hvvmdW2OKuKqQ+KQinl2Q7Sa0gQhA6Mp6GhWKunEABa62I66chie72TenstgUEhnu/kelylhIYEQeiAeCoETqXUocypUiqFZmYj7QzsK6zEj3pCgj3oNupCeg0JgtCB8bQL6IPAMqXUUkABpwLXec2qNiQtt4Ke1BPaKiGQXkOCIHRcPPIItNZfA2OAncAc4C6g2ot2tRm7civwp56wkFbMGSS9hgRB6MB4miy+BvgWIwB3A+8Aj3mw3zlKqZ1KqXSl1GG9jpRSVyml8pVSG6zXNa0z//izK6+cED8nfv6Bnu8kvYYEQejAeJojuB0YC+zTWk8BRgElR9pBKeUHPAdMAwYDlyqlBjez6Yda65HW69Vm1p9Q0nMrCPbTYGvFwGkJDQmC0IHxVAhqtNY1AEqpIK31DmDAUfYZB6RrrXdrreswA9FmHrup3sde72R3QQVBNqc1vbSHhMUZbyDItyZpFQShc+CpEGRZ4wg+BRYqpT4D9h1ln2Qg0/0YVllTLlJKbVJKzVNK9fDQHq+wr7ASe70mUDlb5xGcfD3c+KOZkloQBKGD4enI4l9aHx9TSi0GooCvj8P5PwfmaK1rlVLXA28BZzTdSCl1HVYvpZ49PZz/5xjYX1QFgL+qb50QBIRAVHcvWSUIguBdWv2oSq31Uq31fCvccySyAfcWfnerzP1YhVrrWmvxVWB0C+d8WWs9Rms9Ji4urrUme0xZtQMAm9PRutCQIAhCB+ZYn1nsCauBfkqp3kqpQGA2MN99A6VUktviDGC7F+05KuU1dgBs2tE6j0AQBKED47XaTmvtUErdAnwD+AGva623KqWeANZorecDtymlZgAOoAi4ylv2eEJZjfEIcIoQCILgO3i1ttNaLwAWNCl7xO3z/cD93rShNZTXOAj0s6Hq7RIaEgTBZ/BmaKjDUV5jJzLIBrRyHIEgCEIHRoTAjfIaB9HBVhdQEQJBEHwEEQI3ymvsRAVbl0RCQ4Ig+AgiBG6U1zjo4pp0VDwCQRB8BBECN8prHEQdEgLxCARB8A1ECNwor7ETGWjlCPzEIxAEwTcQIXCjvMZBpISGBEHwMUQILJxOTUWdg8gAV68hCQ0JguAbiBBYVNQ50BoiXc+jEY9AEAQfQYTAotyaXiIiUJsCyREIguAjiBBYuCacC3dFhCQ0JAiCjyBCYOHyCMIOCYF4BIIg+AYiBBYujyDMX0JDgiD4FiIEFod7BBIaEgTBNxAhsHA9iyDUz2kKJDQkCIKPIEJgcXhoSDwCQRB8AxECi/IaBwF+igAlHoEgCL6FCIFFeY2diOAAlNN6XKUIgSAIPoIIgUV5jYOIYH+oNyEiCQ0JguAriBBYHBICZ70pkF5DgiD4CCIEFuU1diKCAsBpeQQ2v7Y1SBAE4QQhQgDszClnS3YZydEh4MoRSGhIEAQfweeFoLzGzg3vriU82J8//GJAQ45AksWCIPgIPl/bfb0lhz0Flbx3zcnERwY3eASSIxAEwUfweY8gLa+CQH8b41NjTMGh0JDPa6QgCD6CzwtBel4FqbFh+NmsJ5NJaEgQBB9DhCCvgr7x4Q0Fh3oNSWhIEATfwKeFoMZeT2ZxVRMhcI0jEI9AEATfwKtCoJQ6Rym1UymVrpS67wjbXaSU0kqpMd60pykZ+RVoTWMhqLeDsoHNpzVSEAQfwmu1nVLKD3gOmAYMBi5VSg1uZrsI4HZgpbdsaYn0vAoA+sVHNBQ6HRIWEgTBp/Bms3cckK613q21rgM+AGY2s90fgb8CNV60pVky8iqIV6X02f58Q0jI6ZDBZIIg+BTeFIJkINNtOcsqO4RS6iSgh9b6btOSuwAAC+NJREFUyyMdSCl1nVJqjVJqTX5+/nEzMD2/gifDPsR/6f9BzmZTWG+X6SUEQfAp2iwQrpSyAc8Adx1tW631y1rrMVrrMXFxccfl/FprqrM2caZjqSmoyDPvEhoSBMHH8KYQZAM93Ja7W2UuIoChwBKl1F5gPDD/RCWMl+zM57KKd9Cu3kEVuebdaZfQkCAIPoU3hWA10E8p1VspFQjMBua7VmqtS7XWsVrrFK11CrACmKG1XuNFm1zn5t/f7mKC33bUsEtMoUsI6h3SdVQQBJ/Ca0KgtXYAtwDfANuBuVrrrUqpJ5RSM7x1Xk9YuaeI3ZnZhFOFLWEwBEU1CQ2JEAiC4Dt4tcbTWi8AFjQpe6SFbSd70xZ3vt6SQ5+AQrPQpSeExzcODYkQCILgQ/jkqKkf0vKZnFBtFqJ7QXhCg0dQLzkCQRB8C58TgoOl1WTkVzKuS7kpOMwjqBePQBAEn8LnhOCHtAIA+gcVm9xASHRjj0BCQ4Ig+Bg+JwTL0gqIDQ8iuu6g8QbAeAR15VBXJSOLBUHwOXxOCFbsLmRS3xhUyX6THwDjEQBU5lndR0UIBEHwHXxKCMpr7OSV1zIwIQJK9rl5BJYQVORZoSGZYkIQBN/Bp4RgX2EVAP0iasFeBV1cHkG8ea/IldCQIAg+h08Jwf4iIwS9/d3GEICbR5BrTTonQiAIgu/gO0KwbT5DFl+Nwkk3bXUVdeUIwmLNw2gq8qyRxRIaEgTBd/AdIagqoFfRjwwMrSCkYr8pc3kENj8IjZHQkCAIPonvCEHXVADGRBRB0W4TDgpyezJZWLzxCOplHIEgCL6FDwlBHwCGBhdA4e5Dy4cIiYbqEmtksXgEgiD4Dj4jBHVhSdToAPr45UJRBsSkNt4gpAvUlFjPIxCPQBAE38Fnarzs0lrqdAI96jJMLqBrEyEI7mI8AgkNCYLgY/hMjbevsJI6nUC/onWmoGloKDgKakpNolhCQ4Ig+BA+ExraX1TF/7d3/7FX1XUcx58vQMCARJGUkB9fDJu0ComZ82dLZ2IlVlqomf3YnJs2nWuJ08y5/tGWbW0sfywWFgazZLFmy3SN5h8ISCD4A0G0CUMoc5pmivjuj/O5cLjc+4Wvcs65+Xk9tu++537u+d77+n7Oued9z+ece+5zcTSD3nmraBjTfoxgNOx8HXa+4bOGzCwr2RSCSWNGcMSE4/c0HN639wzDRxe/d73pzxGYWVayKQRnHDeWC88+o7gx8mgYNnLvGQ4dvWfaQ0NmlpFsCgGw57hA+7AQFMcIWjw0ZGYZyasQjBoHh4zoUgjKewQeGjKzfGRz1hAAgwbBxYvh8Mn73uehITPLVF6FAKDvtM7t5T0CDw2ZWUbyGhrqT/kYgT9QZmYZcSFoOWQ4DBleTLsQmFlGXAjKWsNDLgRmlhEXgrLW8JCPEZhZRlwIylpnDvmsITPLiAtB2e6hIX+OwMzyUWkhkHSOpA2SNkma2+H+KyStk7RG0iOSplWZZ79aewQeGjKzjFRWCCQNBuYBs4BpwEUdNvT3RsTHI2I6cBtwe1V5DkjrGIGHhswsI1XuEZwIbIqIzRHxFrAImF2eISJeLd0cAUSFefbPZw2ZWYaq3OKNB14o3d4CfLp9JklXAtcCQ4HPdnogSZcDlwNMnDjxoAfdbffQkAuBmeWj8YPFETEvIo4FrgNu7DLPXRExMyJmjh07troww33WkJnlp8pCsBWYULp9TGrrZhFwfoV59m/3MQLvEZhZPqosBCuBqZL6JA0F5gBLyzNImlq6+XlgY4V59m/KGXDyd+HD0xuNYWZWp8re+kbE25KuAv4EDAbmR8QTkm4BVkXEUuAqSWcBO4GXgcuqynNAho2Cs3/UaAQzs7pVOgYSEQ8AD7S13VSavrrK5zczs/1r/GCxmZk1y4XAzCxzLgRmZplzITAzy5wLgZlZ5lwIzMwy50JgZpY5RTR7wc+BkvQP4O/v8s+PBP55EOMcTL2azbkGxrkGrlezvd9yTYqIjhdr+78rBO+FpFURMbPpHJ30ajbnGhjnGrhezZZTLg8NmZllzoXAzCxzuRWCu5oO0I9ezeZcA+NcA9er2bLJldUxAjMz21duewRmZtbGhcDMLHPZFAJJ50jaIGmTpLkN5pgg6S+SnpT0hKSrU/vNkrZKWpN+zm0g2/OS1qXnX5XajpD0Z0kb0+/Da8700VKfrJH0qqRrmuovSfMl7ZC0vtTWsY9U+Fla5x6XNKPmXD+W9HR67iWSRqf2yZLeKPXdHTXn6rrsJF2f+muDpM9VlaufbItLuZ6XtCa119Jn/Wwfql3HIuJ9/0PxDWnPAlOAocBaYFpDWcYBM9L0KOAZYBpwM/C9hvvpeeDItrbbgLlpei5wa8PL8UVgUlP9BZwOzADW76+PgHOBPwICTgIerTnX2cCQNH1rKdfk8nwN9FfHZZdeB2uBYUBfes0OrjNb2/0/AW6qs8/62T5Uuo7lskdwIrApIjZHxFvAImB2E0EiYltErE7T/waeAsY3keUAzQYWpOkFwPkNZjkTeDYi3u0ny9+ziPgr8K+25m59NBu4JwrLgdGSxtWVKyIejIi3083lwDFVPPdAc/VjNrAoIt6MiOeATRSv3dqzSRLwVeA3VT1/l0zdtg+VrmO5FILxwAul21vogY2vpMnACcCjqemqtHs3v+4hmCSAByU9Juny1HZURGxL0y8CRzWQq2UOe78wm+6vlm591Evr3bcp3jm29En6m6Rlkk5rIE+nZddL/XUasD0iNpbaau2ztu1DpetYLoWg50gaCfwOuCYiXgV+DhwLTAe2UeyW1u3UiJgBzAKulHR6+c4o9kUbOd9Y0lDgPOC+1NQL/bWPJvuoG0k3AG8DC1PTNmBiRJwAXAvcK+mDNUbqyWXX5iL2ftNRa5912D7sVsU6lksh2ApMKN0+JrU1QtIhFAt5YUTcDxAR2yNiV0S8A9xNhbvE3UTE1vR7B7AkZdje2tVMv3fUnSuZBayOiO0pY+P9VdKtjxpf7yR9E/gCcEnagJCGXl5K049RjMUfV1emfpZd4/0FIGkI8GVgcautzj7rtH2g4nUsl0KwEpgqqS+9s5wDLG0iSBp7/AXwVETcXmovj+t9CVjf/rcV5xohaVRrmuJA43qKfroszXYZ8Ps6c5Xs9Q6t6f5q062PlgLfSGd2nAS8Utq9r5ykc4DvA+dFxH9K7WMlDU7TU4CpwOYac3VbdkuBOZKGSepLuVbUlavkLODpiNjSaqirz7ptH6h6Hav6KHiv/FAcXX+GopLf0GCOUyl26x4H1qSfc4FfAetS+1JgXM25plCcsbEWeKLVR8AY4GFgI/AQcEQDfTYCeAk4rNTWSH9RFKNtwE6K8djvdOsjijM55qV1bh0ws+ZcmyjGj1vr2R1p3q+kZbwGWA18seZcXZcdcEPqrw3ArLqXZWr/JXBF27y19Fk/24dK1zFfYsLMLHO5DA2ZmVkXLgRmZplzITAzy5wLgZlZ5lwIzMwy50JgViNJn5H0h6ZzmJW5EJiZZc6FwKwDSV+XtCJde/5OSYMlvSbpp+k68Q9LGpvmnS5pufZc9791rfiPSHpI0lpJqyUdmx5+pKTfqviugIXp06RmjXEhMGsj6Xjga8ApETEd2AVcQvEJ51UR8TFgGfDD9Cf3ANdFxCcoPt3Zal8IzIuITwInU3yKFYorSl5DcZ35KcAplf9TZv0Y0nQAsx50JvApYGV6s34oxUW+3mHPhch+Ddwv6TBgdEQsS+0LgPvSdZvGR8QSgIj4L0B6vBWRrmOj4huwJgOPVP9vmXXmQmC2LwELIuL6vRqlH7TN926vz/JmaXoXfh1awzw0ZLavh4ELJH0Idn9f7CSK18sFaZ6LgUci4hXg5dIXlVwKLIvi26W2SDo/PcYwSR+o9b8wO0B+J2LWJiKelHQjxbe1DaK4OuWVwOvAiem+HRTHEaC4LPAdaUO/GfhWar8UuFPSLekxLqzx3zA7YL76qNkBkvRaRIxsOofZweahITOzzHmPwMwsc94jMDPLnAuBmVnmXAjMzDLnQmBmljkXAjOzzP0PCH3+B24htdAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-QerZ4RN91R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "74378b67-9c0b-4f9d-c892-cbb564d5c57d"
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n",
        "pyplot.title('model accuracy')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'val'], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeg6MBf-GSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_err = [1.0-x for x in hist.history['val_acc']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC6DagsghRg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "504afc91-1e60-45d7-c8f7-ec034d9cf980"
      },
      "source": [
        "# summarize history for loss\n",
        "pyplot.plot(hist.history['loss'])\n",
        "pyplot.plot(hist.history['val_loss'])\n",
        "pyplot.title('model loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'test'], loc='upper left')\n",
        "pyplot.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3hcxdWH39nVqvdqS7It9957oxfb9FANhpBQk4+QBMIXSIH08KUQQg8ExwQS04sBA8ZgsHED915kW7Yky5Ks3qXdne+Puatd2er2qljnfZ59dvfO3HvP3t2d35xzZuYqrTWCIAhCz8XW2QYIgiAInYsIgSAIQg9HhEAQBKGHI0IgCILQwxEhEARB6OGIEAiCIPRwRAgEoZUopRYppX7XyroZSqkLTvU4gtARiBAIgiD0cEQIBEEQejgiBMIZhRWSeUAptU0pVaGUelEplaSU+kgpVaaUWq6UivGpf7lSaqdSqlgp9YVSarhP2Xil1CZrv9eA4BPOdalSaou17xql1Jh22nyHUipdKVWolFqilEq2tiul1N+UUnlKqVKl1Hal1CirbJ5SapdlW7ZS6iftumCCgAiBcGZyNXAhMAS4DPgI+BmQgPnN3wuglBoCLAZ+ZJUtBd5XSgUqpQKBd4GXgVjgDeu4WPuOBxYCdwFxwD+AJUqpoLYYqpQ6D/gjcB3QGzgMvGoVXwScZX2OKKtOgVX2InCX1joCGAV83pbzCoIvIgTCmciTWutcrXU2sApYr7XerLWuBt4Bxlv1rgc+1Fp/qrWuA/4ChAAzgGmAA3hca12ntX4T+MbnHHcC/9Bar9dau7TWLwE11n5t4SZgodZ6k9a6BngImK6USgPqgAhgGKC01ru11jnWfnXACKVUpNa6SGu9qY3nFYR6RAiEM5Fcn9dVjbwPt14nY3rgAGit3UAmkGKVZeuGqzIe9nndD7jfCgsVK6WKgT7Wfm3hRBvKMb3+FK3158BTwNNAnlLqeaVUpFX1amAecFgp9aVSanobzysI9YgQCD2Zo5gGHTAxeUxjng3kACnWNg99fV5nAr/XWkf7PEK11otP0YYwTKgpG0Br/YTWeiIwAhMiesDa/o3W+gogERPCer2N5xWEekQIhJ7M68AlSqnzlVIO4H5MeGcNsBZwAvcqpRxKqW8BU3z2fQG4Wyk11UrqhimlLlFKRbTRhsXAd5RS46z8wh8woawMpdRk6/gOoAKoBtxWDuMmpVSUFdIqBdyncB2EHo4IgdBj0VrvBRYATwLHMYnly7TWtVrrWuBbwK1AISaf8LbPvhuAOzChmyIg3arbVhuWA78E3sJ4IQOBG6ziSIzgFGHCRwXAn62ym4EMpVQpcDcm1yAI7ULJjWkEQRB6NuIRCIIg9HBECARBEHo4IgSCIAg9HBECQRCEHk5AZxvQVuLj43VaWlpnmyEIgtCt2Lhx43GtdUJjZX4TAqXUQuBSIE9rPaqJOucAj2Om8h/XWp/d0nHT0tLYsGHD6TRVEAThjEcpdbipMn+GhhYBc5oqVEpFA88Al2utRwLX+tEWQRAEoQn8JgRa65WYiThNcSPwttb6iFU/z1+2CIIgCE3TmcniIUCMtQb8RqXULU1VVErdqZTaoJTakJ+f34EmCoIgnPl0ZrI4AJgInI9Z+netUmqd1nrfiRW11s8DzwNMmjTppKnQdXV1ZGVlUV1d7WeTO5/g4GBSU1NxOBydbYogCGcInSkEWUCB1roCqFBKrQTGAicJQYsHysoiIiKCtLQ0Gi4WeWahtaagoICsrCz69+/f2eYIgnCG0JmhofeAWUqpAKVUKDAV2N2eA1VXVxMXF3dGiwCAUoq4uLge4fkIgtBx+HP46GLgHCBeKZUFPIIZJorW+jmt9W6l1MfANswSuv/UWu84hfOdutHdgJ7yOQVB6Dj8JgRa6/mtqPNnvMvqdj5aQ1UhBEeDzd7Z1giCIHQIssSEL85qKD4CNaVt2q24uJhnnnmmzaebN28excXFbd5PEAThdCJC4Iurzjzrtt3sqSkhcDqdze63dOlSoqOj23QuQRCE0023W2vIr7g9QtC2m/U8+OCDHDhwgHHjxuFwOAgODiYmJoY9e/awb98+rrzySjIzM6muruaHP/whd955J+BdLqO8vJy5c+cya9Ys1qxZQ0pKCu+99x4hISGn+xMKgiCcxBknBL9+fye7jrYttFOPq9Y87GVg947TH5EcySOXjWxyt0cffZQdO3awZcsWvvjiCy655BJ27NhRP8Rz4cKFxMbGUlVVxeTJk7n66quJi4trcIz9+/ezePFiXnjhBa677jreeustFixY0L7PIQiC0AbOOCE4NfQJz+1jypQpDcb5P/HEE7zzzjsAZGZmsn///pOEoH///owbNw6AiRMnkpGRcUo2CIIgtJYzTgia67m3SGEGVBdBRG+I6NXuw4SFhdW//uKLL1i+fDlr164lNDSUc845p9F5AEFBQfWv7XY7VVVV7T6/IAhCW5BksS/tzBFERERQVlbWaFlJSQkxMTGEhoayZ88e1q1bd6pWCoIgnFbOOI/glHB7Rvm0TQji4uKYOXMmo0aNIiQkhKSkpPqyOXPm8NxzzzF8+HCGDh3KtGnTTqPBgiAIp47Sbez9djaTJk3SJ96YZvfu3QwfPvzUD56zDbQLwhIhKuXUj+cnTtvnFQShx6CU2qi1ntRYmYSGPGi3EQHArHghCILQMxAh8ODymfzVzbwkQRCEU0GEwIMnUQwiBIIg9ChECDyIRyAIQg9FhMCDxyNQdiRHIAhCT0KEwINn6KjdIR6BIAg9ChECD6464w0oG22dR9DeZagBHn/8cSorK9u1ryAIwulAhMCDu854A8rWZo9AhEAQhO6MzCz24HZZ+QHV5vsR+C5DfeGFF5KYmMjrr79OTU0NV111Fb/+9a+pqKjguuuuIysrC5fLxS9/+Utyc3M5evQo5557LvHx8axYscI/n00QBKEZzjwh+OhBOLa97fvVVYLnfsBagyPUW9ZrNMx9tMldfZehXrZsGW+++SZff/01Wmsuv/xyVq5cSX5+PsnJyXz44YeAWYMoKiqKxx57jBUrVhAfH992mwVBEE4DEhqqRzfxum0sW7aMZcuWMX78eCZMmMCePXvYv38/o0eP5tNPP+WnP/0pq1atIioq6tRNFgRBOA2ceR5BMz33Zjm2A4IjwO2GuipIGtGuw2iteeihh7jrrrtOKtu0aRNLly7lF7/4Beeffz4PP/xw+2wVBEE4jYhH4EG72z1qyHcZ6osvvpiFCxdSXl4OQHZ2Nnl5eRw9epTQ0FAWLFjAAw88wKZNm07aVxAEoTM48zyCJqhzuqmsdRIe7MBuUw0LtTYLzikbKHebRw35LkM9d+5cbrzxRqZPnw5AeHg4r7zyCunp6TzwwAPYbDYcDgfPPvssAHfeeSdz5swhOTlZksWCIHQKPWYZ6uLKWo4UVjI4KYIQh71hodsFx7ZBZDI4a6GqCHqPOd2mnzZkGWpBENqKLEMNBNjNR3W6Ghka6hkuqmzWyKHuJY6CIAinQo8RAocVDnK6Gmnk3dZ9CJTdCEE385IEQRBOhTNGCFoKcQXYLSFwN+YRWEJgs2Muie6yYtDdQnmCIHR9/CYESqmFSqk8pdSOFupNVko5lVLXtPdcwcHBFBQUNNtI2pTCplTjHsFJoSHoiuEhrTUFBQUEBwd3timCIJxB+HPU0CLgKeDfTVVQStmB/wOWncqJUlNTycrKIj8/v9l6+SXVlATYKA4LbFhQVwUV+VBoA2c1VBVD8W5rKGnXIjg4mNTU1M42QxCEMwi/CYHWeqVSKq2Faj8A3gImn8q5HA4H/fv3b7HeQ0+vJjwogFduH9uwYOtr8Mmd8INNsH8NfPIg/O8hCI09FbMEQRC6BZ3W5VVKpQBXAc+2ou6dSqkNSqkNLfX6myMhzMHx8pqTC2pKzXNgONgtb8FVd3I9QRCEM5DOjH08DvxU65aX+tRaP6+1nqS1npSQkNC+sx3dzO9y7mBY6eqTE8G1ZhYwQb5C0IhgCIIgnIF05sziScCryiRn44F5Simn1vpdv5ytrgqHcvO4+1Hcn1Zju+jX3rKacpMPcISKRyAIQo+j0zwCrXV/rXWa1joNeBP4vt9EAKDfDJbOfpuVrtG4d55wmpoyCIwwI4YCLCFwikcgCELPwJ/DRxcDa4GhSqkspdRtSqm7lVJ3++ucLREfFc5q9ygCSjKgstBbUFsOQRHmdb1HUNv6A1eXwLbXT5udgiAIHYk/Rw3Nb0PdW/1lhy/x4UFs1QPNm+xNMPgC87qmzOQHAOxB5rktoaFdS2DJPdBvBkTJ0E5BELoXXW+gvB9JiAhiu7s/GgXZG70FNWVmxBCY+xZD25LFzmrvcQRBELoZPUoI4sODqCCEotABkO2zgumphoY83kNtxekxVBAEoQPpUUIQFhRAaKCdwyHDjEfgGUZaU+4NDQW0Y9SQ22meRQgEQeiG9CghAOMV7A0YApUFUJRhNnpGDYHXI2jLqCG3eASCIHRfepwQ9IsLZXnlEPNm71LzXFt2iqEh8QgEQei+9DghmNA3hs+OR+HqNdYM+dT6hFFD7QkNeTyC8tNrrCAIQgfQ44RgUloMWkNG8qWQswVytpplqANPFII2hIY8olFXeXqNFQRB6AB6nBCM6xONTcFy+yyzrMQ3/zQFJ4WGJFksCELPoMcJQUSwg6G9IlmVY4chc2HzK6bAIwTtWWKiXggkNCQIQvejxwkBwKR+MWw+UoTrsichfrDZeFJoqD3zCCQ0JAhC96NHCsHEfjFU1LrYWWyHBW/DuJugzxRTeErJYgkNCYLQ/eiRQnDWkAQCbIoPt+VAdB+48hkITzSFNjsoe9uSxW6XeZbQkCAI3ZAeKQSxYYGcNSSBJVuP4nY3cpN6e6AsMSEIQo+hRwoBwBXjkskpqebrjMKTCwMC2xcakuGjgiB0Q3qsEFw4IonQQDvvbs4+udAe2LZRQy6ZUCYIQvelxwpBaGAAc0f15oNtOVTUOBsW2tvqEXhyBBIaEgSh+9FjhQBg/pQ+lNc4+XBbDhsPF/HV/uOmoK05Ahk1JAhCN6Yzb17f6UzsF8PgxHCeWpFOXlk1ydEhfH7/OZYQtCc0JDkCQRC6Hz3aI1BKccOUvhwprKS6zk1OcTVa63aEhnxmFutGRiEJgiB0YXq0RwBw/eQ+HC+voarWxaI1GZRWOYkKaGeyGA11VRAY6hdbBUEQ/EGP9ggAwoMC+OmcYUxKiwEgp7SqHTkCn2Sz5AkEQehm9Hgh8NA7KhiAnJLqdoSGfOrWiRAIgtC9ECGw6B0VAsCxeiFoS2hIPAJBELovIgQWCRFB2NQpeARBUea1CIEgCN0MEQILh91GQkQQx0qqrCUm2pgjCPEIgcwuFgSheyFC4EOvqBCvR9CmUUNOCPYIgcwlEASheyFC4EPvyGCTI3CEti3E466D4GjzWkJDgiB0M/wmBEqphUqpPKXUjibKb1JKbVNKbVdKrVFKjfWXLa2lV1Sw8QiCI6GmrPU7uup8PAIJDQmC0L3wp0ewCJjTTPkh4Gyt9Wjgt8DzfrSlVfSOCqa8xkmNPdyMGmpteMjtghDxCARB6J74TQi01iuBRhb7ry9fo7Uust6uA1L9ZUtr6WXNJShxm2eqS1u3o++oIbkngSAI3YyukiO4DfioqUKl1J1KqQ1KqQ35+fl+M8Izl6DQZQlBTSuFwFVnRhoFhEhoSBCEbkenC4FS6lyMEPy0qTpa6+e11pO01pMSEhL8Zku/OLNGUHaltQRTa4RAa+MR2BwQGCahIUEQuh2dKgRKqTHAP4ErtNYFnWkLQFJkML0ig9nlCWi1JmGs3ebZ7jCLzYkQCILQzeg0IVBK9QXeBm7WWu/rLDtOZHzfaLbmW417a3IEnhnINjsEBLdt/oEgCEIXwG/LUCulFgPnAPFKqSzgEcABoLV+DngYiAOeUUoBOLXWk/xlT2sZ1yea/+y0QRCt8wg8C87ZHGAPatuMZEEQhC6A34RAaz2/hfLbgdv9df72Mr5vDM9pkzRuVY7A4xHYHeYhQiAIQjej05PFXY3RKVFU2cLMm9YIgedeBLYACAiS0JAgCN0OEYITCAm0M7BXDLUEti5H4CsEbb2hjSAIQhdAhKARxqRGU0YIujU5ggahIRECQRC6HyIEjTCsVwQl7hBqyotarlzvETis0JAIgSAI3QsRgkYYkhRBOSFUlBW3XLneIwho+53NBEEQugAiBI0wJCmcMh1KXUUrhODEHIF4BIIgdDNECBohLjyImoBwdHVJy5V95xG09c5mgiAIXQARgiYICInEXteKBeQ8N663eyaUSWhIEITuhQhBEwSFRxPsqsDt1s1XrPcIAiRZLAhCt0SEoAnCI2MIp4qswhbuL9AgRyAziwVB6H6IEDRBVEw8NqXZn5XTfMUG8wiCjIfgdvvfQEEQhNOECEETJMTHA7ArI7v5ig3mEQSa1+IVCILQjRAhaIKgMHMP4q3pR5qveOI8ApCEsSAI3QoRgqaw7kFcUFBAVlEzeYITl6EGrzgIgiB0A0QImiIoAoAIVckXe5u5T7LbZZ5tAd7QkKxAKghCN0KEoCmCIwHoF+5qXggkNCQIQjdHhKApgk1o6K6AD6lJ/4LiyiYSwA1CQx4hkNCQIAjdBxGCpojoDRf9niRVxNO2v/D6N4cbr+c7fDTAyhFIaEgQhG6ECEFTKAUz7sFx3s+IVFUsX/MNrsZmGfvmCOqTxTJ8VBCE7oMIQUskDgcgoiydz/fknVzuu8SE3WFeixAIgtCNECFoiYShAIwMOMrq9ONmm+/MYQkNCYLQzWmVECilfqiUilSGF5VSm5RSF/nbuC5BcBREJDMxNI+dR0uMCDwxFr550ZQ3Oo9APAJBELoPrfUIvqu1LgUuAmKAm4FH/WZVVyNxGINVFruOluIuPATFR6Ag3ZQ1yBFYoSFnDVQWQnVp59grCILQBlorBMp6nge8rLXe6bPtzCdhOIk1h6msrSPvwGazrda6V4GrDpQNbDZvaMhVC6/fAkt/0jn2CoIgtIGAVtbbqJRaBvQHHlJKRQA9Z4nNxGEEuKvpo/IpzjhIL4DaClPmrjNhIfCZR1ALpUc7w1JBEIQ201ohuA0YBxzUWlcqpWKB7/jPrC5GwjAAhtuzcOfuMts8QuByekNCdp8lJmrLvV6DIAhCF6a1oaHpwF6tdbFSagHwC6AVN/Q9Q0gYBijOjzhCZKmVG6j3CJxgs5vXAT6LztVWQG0LN7URBEHoArRWCJ4FKpVSY4H7gQPAv5vbQSm1UCmVp5Ta0US5Uko9oZRKV0ptU0pNaJPlHUlwJAw8j4vrVtDLmWm2NRcaclZbHkFFx9sqCILQRlorBE6ttQauAJ7SWj8NRLSwzyJgTjPlc4HB1uNOjNh0XSbcQpTzOAG40TaHT2iozhsa8ngEVUXmWUJDgiB0A1orBGVKqYcww0Y/VErZAEdzO2itVwKFzVS5Avi3NqwDopVSvVtpT8czdB51QbEAlEYPPyE0ZF0Kz3OV9bHFIxAEoRvQWiG4HqjBzCc4BqQCfz7Fc6cAmT7vs6xtJ6GUulMptUEptSE/v5klof1JQCBMWECJDuWwY1DD4aOeHIHNZsSg0hICdx04ZXKZIAhdm1YJgdX4/weIUkpdClRrrZvNEZxOtNbPa60naa0nJSQkdNRpT8JxwcPcHvEsmdVBDT0Cu49zFBDkDQ2BhIcEQejytHaJieuAr4FrgeuA9Uqpa07x3NlAH5/3qda2rovdQXJqPzLLlbe37xsasurUewQAdTJySBCErk1r5xH8HJistc4DUEolAMuBN0/h3EuAe5RSrwJTgRKtdc4pHK9DGJUcRfb2AJMhqS23ksU+l9Ee5M0RgOQJBEHo8rRWCGweEbAooAVvQim1GDgHiFdKZQGPYCWYtdbPAUsxS1akA5V0kwlqI5Mj2Y81Oqi2ouHwUTC5hLJc73sJDQmC0MVprRB8rJT6BFhsvb8e05A3idZ6fgvlGvifVp6/yzAiOZL/6mDzprbCCg35egSBDe9ZLB6BIAhdnFYJgdb6AaXU1cBMa9PzWut3/GdW1yU6NJCIyGioBuoqGi4xAd6lqD2IEAiC0MVprUeA1vot4C0/2tJt6NsrATJA15Sj3HXeiWRgQkO+iBAIgtDFaVYIlFJlQCM36kVhojuRfrGqizMwNREy4NjxAnr7ziwG7zITHkQIBEHo4jQrBFrrlpaR6JEM62smQGcczaO323VyjgDMNrdThEAQhC6P3LO4HfRJMpPasnKPW6OGfITAEyYKsya+iRAIgtDFESFoByooHIDcgoKGi86BN1kcEmO8Axk+KghCF0eEoD04wgCoqSjF6aw9eWYxQGA4BIaJRyAIQpdHhKA92APQ9iDCVA1V1TWNh4YCw4wYiBAIgtDFafXwUaEhKjCMAUFQV1WLtgWgPAWeZHFgmHnUiRAIgtC1EY+gvQSGMyQGQtyV5NU0MmooKAIcoeIRCILQ5REhaC+BYfRxHiZE1bK+LM67vUFoSHIEgiB0fUQI2ktgGPb8XQB8fjzGu70+NBRu5Qhk1JAgCF0bEYL2EhhmJowBnxfGkldWbbY3EALxCARB6PqIELSXQDOXoC40kVLCWXugwGwPOCFZLEIgCEIXR4SgvQSauQQBScOJDA7wCoFnQlmQJzQkdygTBKFrI8NH24slBCphGNNUHGvqPYITk8XloDUo1cSBBEEQOhfxCNqLJQQkDmPmoHiOFFaSnlfuM7M4wqqjoa6q08wUBEFoCRGC9uIRgoRhzB3dC7tN8cbGTG9oyOMRgOQJBEHo0ogQtJewBLPGUMIwEiOCOXdoIm9tzMbpWXcoKNxHCGQIqSAIXRcRgvYyfgHc/RWExgJw/eQ+HC+vYY1zGIxbAPFDxSMQBKFbIELQXhwhkDis/u05QxOIDw/iP7tq4cqnwRFcP8RUPAJBELoyIgSnCYfdxqVjerNibz6l1XVmY6i19ETF8c4zTBAEoQVECE4jl49Lptbp5tOduWZDeKJ5rsjrPKMEQRBaQITgNDK+TzQp0SG8v+2o2eC5XWV5fucZJQiC0AIiBKcRpRSXjU3mq/3HKaqoNXMKQmLEIxAEoUsjQnCaOXtIAk63Znt2idkQlgjlIgSCIHRdRAhOM0OSzEihfbllZkN4IlRIaEgQhK6LX4VAKTVHKbVXKZWulHqwkfK+SqkVSqnNSqltSql5/rSnI4gLDyI+PIi9xywhCEsQj0AQhC6N34RAKWUHngbmAiOA+UqpESdU+wXwutZ6PHAD8Iy/7OlIhiSFsy/PmjsQlmA8gqoiePUmWP8POLQK1j4N1aWda6ggCAL+XX10CpCutT4IoJR6FbgC2OVTRwOR1uso4Kgf7ekwhiRF8PqGTNxujS08AWpKYf+nsOcD8/AQFAkTbu48QwVBEPBvaCgFyPR5n2Vt8+VXwAKlVBawFPhBYwdSSt2plNqglNqQn9/14+1De0VQWesiu7jKJIsB98EvAQW3fgg3LAZlh6IM707b3oDFN4Lb1Sk2C4LQc+nsZPF8YJHWOhWYB7yslDrJJq3181rrSVrrSQkJCR1uZFsZkhQBwN5jZazLswNQtGMZxPaHtFkwbB5EpkDxYe9O+z+BvR/Crnc7w2RBEHow/hSCbKCPz/tUa5svtwGvA2it1wLBQLwfbeoQBlsjhx5ZspM/rjQ3rIlz5uFK8EmRxPSD4iPe96U55vnLP4Pb3VGmCoIg+FUIvgEGK6X6K6UCMcngJSfUOQKcD6CUGo4Rgq4f+2mByGAHyVHBZBdXMXfamPrtx4IHeCtF94MiH4+gNNtMPsvfbTwDQRCEDsJvQqC1dgL3AJ8AuzGjg3YqpX6jlLrcqnY/cIdSaiuwGLhVa639ZVNH8rNLhvP49eO4e970+m3bapO9FWL6Qfkxc/cyraEsB0ZfZ8ry9nSwtYIg9GT8es9irfVSTBLYd9vDPq93ATP9aUNncekYn0Y/KBJqSvm8KIG5nm3R/cxzcSaExYOzGmLSwBYAdXLDe0EQOo7OThb3DMISqFOBfHQ0lDqXFf+P8QjBYSi1Rs1G9gZHqNzjWBCEDkWEoCOITKYieijltZqV+6wUiMcjKMrwEYIUc8Mb8QgEQehARAg6gkseI+jafzAwIYz7Xt/KwfxyCE8yN7ovPgxllhBE9LaEQDwCQRA6DhGCjiBhCCHJI/nXrVOw2xSXP7WaR97fhTsq1YwcKj0KKIjoZYWGxCMQBKHjECHoQPrGhfL6XdO4aEQSL609zBF3gjdHEJ5o7l8gHoEgCB2MX0cNCSczKDGCx64fR355DauO9qJf6QcorSHSGmUkyWJBEDoY8Qg6iZum9mVR5UyU2wnHtplEMUiyWBCEDkeEoJM4f3gSpeED2B800myI6G2eA4LNnAJBEIQOQoSgk3DYbcyf0pfnymabDQ1CQ+IRCILQcYgQdCK3zkjjc/sMtkScDYMuMBtPSBZ/faiQ21/6BqdLFqITBME/iBB0IrFhgVw9dTBXF9xNZtAgs/GEZPH7W4+yfHce+eU1nWSlIAhnOiIEncztswdgtyn+9uk+s8GTLLbW3tt5tASAvFIRAkEQ/IMIQSfTKyqY22f15+3N2WzLKjZCoN3gqsXl1uzOKQMgv0yEQBAE/yBC0AX43jkDiQ8P5Dfv78IdEGI21lVy6HgFVXXm1pUSGhIEwV+IEHQBIoId/HTOMDYcLmL1EWvEUF0VO4+WMNu2jeccf+N4qYwkEgTBP4gQdBGumZjKBcMTeW9nEQALV+xk/6HD/M3xLHPs31BbcLiFIwiCILQPEYIuglKKP35rDFGRUQC8sW4/gzf9jnhlksWUZHaidYIgnMmIEHQhEiKC+OWVEwGYPz6WS21r2BMxDYDAsqzONE0QhDMYEYKuhsMkixcMd2BXmuiRF+BGEVqdc3LdM+P2zoIgdDIiBF0NRzAAttJsAHolp1HhiCe6JgftafjdLvjk5/B//aDsWGdZKgjCGYIIQVfDEWqeLSEgNJaK0GR663zKapxm27vfh7VPQXUJ5O3qHDsFQThjECHoalihIUqsnEBoLHXhqaSqfDOprCwXtr0Gwy9vWFjW82cAACAASURBVE8QBKGdiBB0NTwegaeBD4lFRfeltyokr7gS9nwAaDjrJ4ASITiTcbugpqyzrRB6ACIEXY2TPII4HHH9cCgXZcczYfcSiB0IvcaYexiIEJy5fPNP+Ps4IwiC4EdECLoaniUmKo+DPRACwwhLTANAHdsGh1bBiMtBKYhKlfkFZzJ5u83voKyREWOCcBoRIehq2AOMAACExoFShCUNAGDM/qdAu7z5gahU8QhOB4fXQMbqzrbiZMpzzXOxiL3gX0QIuiKe8FBILAAqqg8ASZXpMH4BJI835VGpUJINbrlpzSnxyc9h2S8624qT8QiBeH2Cn/GrECil5iil9iql0pVSDzZR5zql1C6l1E6l1H/9aU+3wZMwDjVCQGAoRaH9WeaayMFpvzdhIYCoPuCqMeEDof0UZXTN+Rjleea5+Ejn2iGc8fhNCJRSduBpYC4wApivlBpxQp3BwEPATK31SOBH/rKnW+HxCDxCANTc9iV3Oe/j3W153npRqeZZeoztp7oUqgqhIq9reVZa+4SGzmAhyNsDFQWdbUWPx58ewRQgXWt9UGtdC7wKXHFCnTuAp7XWRQBa6zwEr0cQ4hWCXnFRzBgYz3tbsr0zjKNSzLMnT+B2da3GrDtQbK3q6nZCZRdqkKqLwVVrXp8pQq81FB4yOZnaCvN+0TxY8fvOtqzH408hSAF8f8FZ1jZfhgBDlFKrlVLrlFJzGjuQUupOpdQGpdSG/Px8P5nbhWjEIwD41vhUDhdU8uU+6xpYuYN6IXj9Fnj95pOP53aBy+knY7s5RRne1+VdKDzkCQvZAs6cZPHXz8MT4+Bfc2HVX004rrIAju/rbMu6B9kboarIL4fu7GRxADAYOAeYD7yglIo+sZLW+nmt9SSt9aSEhIQONrETqBeCuAabLxubTEp0CH9bvt94BSExxnsoyTYNx96lkP4ZOGsbHu+Tn8E/z+sg49vA3o/g6WlQU955NhT53OehLLfz7DgRT84iaaQR+jNhgcHsjRCeBPFDIHsTHN9rthcebHnfsmPw5CTI76Gi4XLCvy6BL//kl8P7UwiygT4+71Otbb5kAUu01nVa60PAPoww9GwCGo4a8hAYYOOe8waxNbOYz/fkWXMJ+kDudjPRTLvBWQU5W707uepg66tmW1sbOq391wDVlMEHP4b83ZC/1z/naA0NPIIuJAQejyBlkvlOK7rJgIBdS6CuuvGygnRIHA6pUyB3h7dRLz3a9D4esjdCwX44svb02ttdyN9jfgeeEYOnGX8KwTfAYKVUf6VUIHADsOSEOu9ivAGUUvGYUFErugdnOE2EhsDcySwtLpTv/2cTi1YfgrE3wKGV8MX/QaQVeTuyxrvDoZUm3gyQua5tdiycAx83Otjr1PnyT96JUsUZ/jlHayg+DHFW36O50JCztnm3vLbi9IbfPKKUOsk8l3Riwri1nYG83SY0ufMds8+qx4y36jlGQTrEDTJeTkU+ZKzynMCbq2kKj2CfyYnz5ji6yTwnT/DL4f0mBFprJ3AP8AmwG3hda71TKfUbpZQ1I4pPgAKl1C5gBfCA1roLZew6ifrho3EnF9ltvH7XdGYMjONX7+9iY8pNkDTKjHqZcItZfuKwT69p13sQGA4BwXBkvXd7aU7zieXyfCMcm18xjdyp4nbDC+eZ47ldsGEhDL3ElPn2yk+kOBMeG2kaGX9QlAGJwyAosnmPaeWf4K/DTDjrRLSG52a1PumZvfHkxlVrc20qC8378lywB5nvFrx5gvd/CG/cCnuWtu5cHnJ3Nv19VxY2/M344nLCC+fCp4+0fA5PiKf4iHn92a9h4yLrHAVmtdy4QdDL+kz7l3m938JDzR+7Xgi60C1btQZnTcec6+hmCIqC2AF+ObxfcwRa66Va6yFa64Fa699b2x7WWi+xXmut9X1a6xFa69Fa61f9aU+3oX5CWUyjxYmRwTx54wSCAmws2Z4PVzwFiSONd9BvunGf3W4TTtjzAQyZAykTvW71gRXwt5Hw0QPmffZGE4qoLoX37oE9H3q9itpy2P1B2z9D/l7Y8bb3fUG6Oc+epeZPX1sOw+ZBWIL3T95YQ3V4DZRmQcZXTZ/LVQcvfwvSlzddp6YMXlsAX7/g3eZ2mxxBdD8Tu27OIziyDpzV8OpNRlx9Kc02DV99D7cZDq81grjp3w23F6TDe/8Dm14y78vzjE3RngEBmSZXsHGRuYavzm+68T6RggPw7AxY/1zj5csfgUWXNBzGeTzdvN/6X9MIHfi85fN48i0lmd6RTtkbvJ8PjBAkjjSvndUw4Bxr39YKQRfyCNY+DY8N75jZ/dmbIHkc2PzTZHd2slhojGZCQx7CgwI4b1giS3ccY2NdGlfqP7OrKhb6zjChoH+eZ36klQUw/iboMxWObTON8RvfBpvdLGr28UOmYXpiAjx/Dmx+GZb/yiy5EBAC0X1NY9ASWhsB2f2+eb/yz/DW7d7VM7O+Mc85W40dAL1GQ0ya+ZNnrIY/JJ/8p8rbaZ49DUljHN0MBz6DDf9qvLy2Av5zrbFt8yve7eW5ZkJeTBpE9GraI9DaxLRHXWME9Z274dgOn/NvMc/HdpwcHjqyDnK2ed8fXGGe1zzRcDG5XOt4Hs+n/BhEJEFwtFlcMGM17P/UlN32iekkrHu6yUvSAM8x1z1jRNOXuirY+a5ZusTT2Jcdg3/Mhqcnw2e/Ndvy93j3rSmHNU8agfHF00iXZntfZ280glsvBAMhLM58JjAdl8CIlhPGHiEoaoNHcGyH8UJOhebCYltfNf+vJfeaekUZsPW15j3c9uCsMR6dn/IDIELQNfH0UIOimq12yZje5JfVcOvCr9mSWcy9r26mKu186DPNhIMm3w7fXw8Dz4O+081Y+RfOB5sD7vzC5BTWPQMDzoV+M8wM5fELzHC+ra9Cnykw9kY4+CUc39+0Icd2wEuXwas3wtt3mgYje5NpXDKtcFTW1+a5NMs0hrYASBhmPmvRYdj/iUmGHTkhj5Fr3Xjn+H4jKv+57uQw0aGV5vnAisaTjksfMHakTDJ/KI87X2g1ZDFpzXsEZcdMfqDPVLj+ZQiOMj3y0qOmPMcSAmeVdyQMmOvw6k0mKV5v6yoTpitIN6O86j+nJXieGw15PAKlYMx1Joyy5b9GmHuPg4nfMZ5aa0bceBrhksyTvZm9H0FNKSib16P64o/G9vAkK+T4bTOnwfMbWPknsyTHU5NMyMjTWHrCNiXZ3lBWdYm5zgXp5ncX1dds94S84odCbFrzoSGP56bs5jsqPgJ/GWp+l01RWWg6OJ+fwhyFvD0mHPjV304WhIIDZpBG8njTCflDCvx9LLxzJyz5QfvP6XLCRw82/L/l7gB3HaT4Jz8AIgRdk8m3wb2bW3QDzxuWSIjDTmWdiwcuHkp6XjkX/GMXc8p+zvqzXoI5fzTxb4C+04xbPnY+fG+1Sdhd8y+Y9j8wfzHc9Dr87yGY86jJUdSUQL+ZMOk7puF793smb7D7/YYhnDVPmt5j7k4YfS3UVcKhL72NrGcxt6wNXmHb8bYRgYAg0wiXZHnrHdve8EN6GsiC/SY8tP8TMx7dl4xVppGpq4DDX5mwVHWpKdv1Hmz5D8z+Ccy81/yhPL35/cuMIKVM9HoEtZUn9yI9NiSNMPVu+C9UFhnxK8s1HkFQpKnjO2Lr4BdGXHO2GK+kttJ4RpNvNwK49pmTz5G/z3gK5bkQnmi2jVtgRDXraxh0oRGHKXca21f9tbGfRkMK0iE03iTF1z3TsGzbaxCRDCOvMkKQu9OErSbfDnesgO+vg6l3WTbuMA3yuudgxBUw5gZY/ThseNGUe7yAkiwjOspu3mdtMDbE9jeLKoL5/QEkDDFx7xNDQ6U53kSzx3NLmWjeb3zJCIInjNYYez8y++xf1nQdTyhMa/O78/3e3W744Efm3Mt/BZ//ruG+u61xL9e+BDN/BONuhEv+CtO+bzomJ3ZW0j+DHW+1vKT4kbWw/lnjrXvI9m+iGEQIuiY2OwSGtVgtNDCAn80bxqPfGs3/nDuI3181imG9IqiodXL7vzew95jPTU2CI+EHG+GqZ01jBtB3Ksz5gzcUZbNDUASMuNK8T5tp6l7yV9OA/XWoibPvsXIGBQdg+a9NDuLeTXCR1fvyNHABwXB4tenJ5+0yfxYw+YFeo83rmDTTyHliyb5CUFUEZUeNEBVnenuAO9/1himcNSYJPv4mI2Cf/QaemQbPzYQVf4S37zJ/oLP/1/tHOrrJ/Pl3vmO8odBY0/t1VsG/5sDCuQ17gJ7wVKK1QkrKBFjwpvEIlt5vGvqh88AR5g0TAWx73Ty7naYxzFxvhGjAOTD+ZpOH8cwXOLbDJIddVhigssDYBKaxTJ1sXg++yDxH9oZpd5tQ1853G/l1+FBwwIzdH3uDCdV4hqJWl5jGf/Q1MPhiI1r/mmvCUWc9YO6fnTjc7GsPNN/N578zQnTxH01uavDF8NFPjedWdNgryMe2m4Y7MNx8twUHTEfEw4Rb4JyHIKa/eRQd9jaSbrfJWTw+Gt79H6+X1P8s87zVSiXu/diIa2Wh9/sqOGBGeO2yrknRoca9pi//BH8ZBPuXG+F7bhY82hc+uM+Ub/mPaZQv+zuMvs54BeU+k1l3LTHeQEw/uPDXcMlfjHjO/on53X/9vNcmt8t4ym9+F/5xVsPwZ85W2PSy93eQboX/fPNdWRsgLNG7pIwfECHo5tw8PY1rJ5mE4k1T+/HirZNZfMc0Qhx2bvrnOrZkFtfX3Z5VQnVdK25yMvs+Ew5InWLej7oapt8DY643cxs84YVlvzA/+ksfNzHriCQzaunAZ6Z87HzTmzm8xsxxGHSBd9RDvRD08543NM7kDzx/IE9YaNilgIbtb5jGsqoQVv8dHh8Db3zHNOCDLjQNbM5W0+BrDV8+CmmzjMdjd5g/UliCsSl7k+nBjrzKnMMjjjlbTcPvSZCueco0zBG9G+Zs+k4zPcHd75uhkCkTzGfyhIlqyo1gjrwKUKZRyVhlesl9p8Hwy0y9PR+YBrnkCAyxGvnVj1vnmO493/R7TIPcf7Z323kPm8Z2yQ9g/fMm3t8YhQdMbN7TkHoS70fWGZEadIEJH6KMfd9eYuL4HuwOSBhqQlnb34Cpd5vlTWx2uPIZ891u/BfUlnnDF7k7jcgnjzeN5vH9xgYPcQPhnAeNqMQNNALpia17PMr+Z8GWV+DTh812j/2lWeb7qKuAj38KfxlsvLOPHoQnJ8C/rzBhwqHzTP30zxpej70fw4o/mM/7wY/g01+asF/abNjxphGiTS+Z73PCLTDrx6azsuMts3/ZMdOZ8HyHvoTFGWHduAh+lwgf/8yIb+Vx858qPgKv3WxCmFqbPNqSe0w+b8+Hlq3KeFCecFnmOtNp8yw26QdECM5AUmNC+e8d0wgJtHP9P9by2e5c3t6UxWVPfcUPFm/G7W5hXHj8YLj8CQiw7ougFFz8e+NNDL8U9n1i4tN7l8JZ9xsB8NDParxiB8KwS8wf/EPrtpopE6D3WFPu6xF4GH+zaVRLssyf1TN2eoS1RJUnhxEcBZ//FqqKYe+H5thpM80fduKtcMu7cPcquOU9uOkNbyOvlBGJo5tMg2ZzGBvB2/tOm216v9+8aP6ky35uGjJPKMOX6d83IRcwcfvkcaYn7HaZP3VdpeklJo0yPbxtb5iefVCEaVjjBhkh8QjeqKvNZ9nxFoT3MiLmYeSVcM83DT3FgEATmkiyRoD9dZhpeGorTKO6+EaTqC7PNedKHm+8Fs/opoyvzGdNnQzhCXDja3D7cu9340vSaNM4OUJhxr3e7WHxRow8vfR68dJmxNPwy4yXkzrZ+nyN4PHUPAMKNr1kOhbzX4WB51uJdGVyVjaHde3vMb3kTf82nYujW0xIZcgc03C662D2/San4jviye02OZteo4xXV5JpBPTyp0zHpboEcjabjoAnDJc0wlyTbdZnPGAl/Add0PjnOet/TaOfPMGEeDa/bMJ4F/4arnrO/P4+esAI3vF9cO7PIWG48UZyd8AEa5mYA5+Z0GNRhhEqPxLg16MLncagxHDe/f5MvrPoG+56eSN2myI5KphPd+Xymw92cf9FQ4gIdjS6r9Pl5mhxNX3jQk8uHHGF+fO9dZtJ9E37fsPyvjNMuCJlgvnxemLnVz5jetR9p5v4raexiUwxf5LIZBP2WP24aYAz15kEZnC0aZw9pM0yoazd75uGPn+vGaUSEmMaij5TvHUHnHOy/SkTTJ4hf48JgYVYK5qkTjZx91k/NqGOLdboosSRxkPwhIV8CYqA8x82ydVeo40d658zDc+WV4zI9Z1hxPHr583nudqK/SplGsk1T0KKFQZInWKNojpkPAmbvdHvpwHRfeA7H5kQ3IaFJgdQlmMeR9aaZC8YIbA7jC2HLCE4vNoK31jf85CLmz5Pr1GwFZhye0NvAUyD6GnE+830ejRRfUyOyZNjaIrE4eZ3cmSdOdbuD2DKHSY0ddYDpkGMSjXfe1SquT4DzjbDT/d+ZATMWWMa9b7TjMd6aJX5bAPPN6JfW2FENHOdCTde9FvjBc37i/mNJQzxXu+1TxtPqd8Mr41jbjCdgvx95vsNjTfi2Bgx/eCyx02y+Zmp5v+SNtv8RoddYsJHq/4C6Z8bL3jGvcbulywPY+rdJgya/pm3g+JnIRCP4AwmLjyIV26fyoS+McSHB7HkB7O4aWpfFq3JYOofPuOFlQfRWnMwv5wtmcUcLqigzuXme//ZxDl/WcHOo40MvUs7y/TIndUmfhoQdEL5TEzvbarJS/xom0l8e/IDk24zuQrPHAmb3fRoB5zrnWiUuc78cTy94sBQ7wJ7fabChb+Fe7eY5OPQOSa53lqGzjWN7Xm/hCuf9W4PDIV5fzaCNOZ6s23MDcaj6D3OG5s/kYnfhvt2m/2HXWqEbdkvTcJw3AKT8Pc0KDN/ZFx8D8MvNw3OKqsxikw2jSI03XtuDKXMdbpmoRGmnW8bEYju622gPfH5tNlmZFPBAdOL7jezdecYOs9MAJzxw5PLBp7vfZ06yQg7mPO3Bpvd7Jf5tRkZ5a4zPWowwjX4Ym/IKaafuVaJI+Gsn8AdnxmvJCrFNKZgOiuX/MVcl7HzTU7qK0ucdr5rwplDrPUtp9wBY641r2MHmIZ55ztGtH07FaOvNd7TV4+ZQQADz215TH/iMCvkhjdMBXDuz8w1K80yXrAj2IS9hl9ubEgcYX5v6Z/BlsUmHOrxpP2EeARnOJHBDl69cxq1LjfBDju/u3IU107qw1Ofp/P7pbt58atDHCv1DrmMDQuksKKWAJvi5bWHefTqMQ0PGBAI5/7CxGf7TeckYtLgrpXeBu3ESXH2gJOTXt/+wPzJHMEmcVhdAtcuMn94bY1QShhqYqqepbfbS++x8MOtzdcZMgcu/A2Mu8k0Mnc1M0wRvLHbgEATsvjkIUDBuPlm+7DLzAitE2PKKROMV3N8v2kAPF6C2+ldWqKtzPqxNaxVG69i0SXGFk8IzpNjWPIDE/dOa6UQxPaH+U3MJ0mZYL4rtPH6IpJNzqO1QgBmyPMXf4RvXjBi7xntBibHo6xG96wHTLK7tROr+k41jfjqvxuB3/UeDL4QgsJPrqusDszepeZ3EuwzfDsiyXi/Hm/H08C3xOz7Tb7E97u32Y1nuPYpM2rPw9Uvmg6WUma/7W+Y0GefaSd3uE4zSnezVQ0nTZqkN2zY0NlmdHu01rz41SG+2JvP+cMTSYsL40hhJct353LB8CT2HCvlnc3ZrH3wfJxuTUKEf3+I9WR8ZXpsJzaE+fusZOTEjrGjvdRWmNEuydbIos5EazPW31ULP7JGY3mGRW56yfTcHzzSqhFqLfLBfSYRuuBNs0bVkbXw82PeEWktcWAFvGyNVrvyWa8HeTooPWpWLnVWG/G7+kWT0G2Mrx43M62nfg/mPtqwrKYMnpxoci737TYenD/Z8ZYZaTTjXhPKOkWUUhu11o32MEQIhEbZdbSUeU+sIizQTkWti1Epkdx34RDOG5bU8s49naIMM1v2xFh6Z5C10cw0H3R+w+3ZG82wy8EXnp7zaO31jN6524RP7t/T+v1ryszwzcAIs19gI/mpUyFvt8ldFR40vfGmxC9ro5mVP/81E3Y8kf3LTW7lglasvXQ62PWeyat55pScAiIEQrt46O3t5JfVMDY1ine2ZJNVVMXiO6aRWViJzaa4bExvlM+QtlqnmyOFlQTabfSJDWlQJvQgijNNkrqt3ttbt5sBCGc/4B+7WkvebjPh8Qz7/YoQCKdMUUUtlz/9FVlFVfXD/GcPjmdYrwh6R4UwOjWKh97eTnqeucnMry4bwa0z+3eixaePOpcbh13GVQjdm+aEQH7dQquICQvkxW9P5uwhCTwxfzwPXzqC7dklvLzuML/5YBfXPreWoopafn/VKMb1iebZLw/UT16rc7k5Xm7W98kpqaq/1WZFjZOPd+RQYJW53Zp7/ruJh97ejtut+fvy/fzjS7NURX5ZDel5ZY1Y1jRFFbVU1jZ/j4Dm5lRorXlpTQajHvmE/65v/aqX32QUsjuntNX120peWTUvr82gxtmKyYHNkF1cxc0vrmfx1yd/NqfLTWOdxMzCyvrvsq0cLa5i+a6GC/tV1bpanNey9kABq/af2i1qc0qqKK9p2/0inC43723JpqSqruXK3RwZNSS0miFJESz6jndI3XdnmR5/el4Zaw8UcOGIXvSKCiYtLoyb/rmel9ceZkBCGL9fupuD+RWMTY1i97Eyap1u/nzNGD7Zmcvy3bnYFFw1PpW+saF8sM3crGZXTilbM4uxKZg+MI77Xt9Kel45k9NiuHxcCsEBNpbtymVAfBhzR/dmbGoUH+04xtasYu6/cChPrUjnic/Mwl2XjO7NH741miVbj6KAuaN6ERsWyLNfHuCpz9O5++yB3HnWAIor67DZIDokEI3mgTe2sWTrUUID7fzpkz2MTI7kvte3UFrtpF9sKHNG9aJvbChurXFrmNQvhqMl1dz4wjpcbs1ts/qzYFo/+sWFkVlYyaI1GVTVubh0TG/G94khJLAV8wQsSirryC2rpm9sKHe8tIGtWSW8vy2HJ+ePJykyGDCN9BsbMlkwrR+J1jatNR/tOMa/Vh+iuLKOyBAHE/vFEBXi4OW1h8ktq2bV/uMcK6nmRxcMJrOwir8t38cnO48RFhTAeUMTufucgVTVunj6i3SWbs+hV2Qwr981nS8sQV8wtS8ut7kGgQGN9y1zS6u59rm1ZBdX8c9bJnHBiCRySqq4/KnVTB8QxxPzG19Z80hBJd9d9A0ut+bt789gVIp3JM/S7TmsP1jAnFG9SYkOISbM0ejcmOLKWi7+20rCgwJ4YM5Q1h8sZOqAWK4an1pv25oDx7lkdHK9/VprfvneDhZ/ncm0AbH8+7tTcdgVSinyy2q45rk1DO8VyU/nDqN/fPPJ9g0Zhfzp470M7x3Br68wQ6SPlVTzyrrDXD+5D31iW86HaK352TvbmTOqN2cPOf2365XQkHDa0VrzrWfXsPmIWd6iT2wIl49N5ou9+QzrFUlmUSXfZBSiNdxz7iCq61wsXH0It4aLRiQRHerg9Q1ZXDEumRV78nBrKK9x8p2ZaXy5N5+Dx82NcnpHBZNfVoPTrUmJDiG72CyxMDkthm8yirhoRBJ9Y0N5cfUhHDYbtS7vYnkxoQ6KKusYlBheH87yEBZoJzEymEPHK3jg4qGcPSSBy576CptSRIU4uGhEEtuzS9h5tGGvPzTQTlhQAEEBNmYOjOe1DWYFToddUefSOOwKh91GZa0LpWBq/1geuWwkX+zN56v0fCpqXMwYGMfolCjWHyokIjgAh93Gyn35bDpShFtDXFggBRW13Dojjf+uP0Kty01qTAgjkyNZtf84lbUuEiKC+N2VoxiYEMbP3t7B1xmFDEgIY2hSBHllNWzLKqbOpUmOCub5WyaxaE0Gb27M4qrxKXyVfpyqWheXjO5NZZ2L5btyqXW5cbk14UEBXDMxlbc2ZlHjdNdfz+kD4kjPL6eyxsm80b3pExtKRkEF6w8Wct6wRGYPjufRj/eQW1JNYmQwFTVOXvruFH757g42HDZ3ffv9VaPYk1NGSkwId8wegE1BXlkNP3p1CzuySwgLCiDArhibGk2Qw0b/uDAeW76vwZJQQQE2bpzal+/O7E+f2ND6kN5jy/byxOfpDX4jgXYbr941jXc3Z7P46yPUuTTzp/Tltln9eezTvRwtrmZLZjFnDUlg5b58+sSGkFdaw4Jp/cguquLzPXkE2BW1Tjc3T+/H984ZSGKEEd/Pdufy9Ip0Hpw7nFX783ny83SCAmzUON28cttUiqtq+fk7OyipqiMm1MGPLxxCfHgQZw9JICyo8b75otWH+NX7u/jFJcO5fXb7bk4jOQKhw0nPK2fFnjwGJIQxc1A8wQ5v7ze/rIZvPbuaqf3j+PM1Y1BKsfZAAW9szOQXl4wgIjiA9QcLmTYgloWrD/GHpXu4YXIfHr16DFpr0vPKqax1MSY1itJqJ0u2HmXpthxmDY5HKfjTx3sZnBjOkntmERJo55Odx3hl3WHumD2A+PAgVuzN49DxCsb2iWbB1L58sjOX3TmlJEYG4dawO6eU7Vkl3D67P1eMM/MWHnxrGx9uz2HxHdPqe6WZhZWUVNVhU4oap4unPk9n9YHjvHrndMb1iSazsJJlu3I5Xl5DdIiDy8clExXiYNX+4+zMLuGltYfrww6jUiIJcdjZeNg0+CEOe30DPDolinOHJhAXHsTbm7O5eGQS3z9nEPtzy1ixN4+tmSVsyy5mcGIE356RxiPv7SCjoBKAiKAAfnHpcK6Z2Ae7zSQ/nS43TrfGYbdhtym01jz68R7+8eVBkiKDeOW2qQxOigBMGGrhVxmEB9m5eVoaUaEO1h8s4Lcf7uI7M/pTWFHL48v3Mbl/LAnhDbcw3QAACctJREFUQXy4PYfKWheRwQGM6xvDV/vzcWtIiQ7hL9eOJSI4gCufXo3TCgc9dt1YFq4+xI7sUmwK3BoGJoRRVFlHYUUtAI9+azQDE8O55cWvSYgIoqiylrJqJ7MGxfP3G8ax4XARZdVO1h0s4J3N2bjcmj6xIWQXVTGuTzT7c8uZPSSeR68ew8bDRQxODOdbz6whv7wGrWHBtL7YlOLfaw8TGGAjxGFnaFIE0wbE8uMLh/Dclwf5bHcuMWGBfGqFtn46ZxhXT0zhb5/u47VvMrEpxfnDEzl7SCK//WAXNU4XnojXdZNS+dm84Vz59GryymqorHUxrk809104hN99uIt9uaYjkhIdwi3T+1HncjNrcAK1Tje/+WAnoY4AtmQWM3twPP/89qR2D8IQIRC6HE6Xm4BWJGBrnW6Wbs/hopFJhAa2LpL5yc5jjE6JIjm6lWPYW4HbramscxHeRI/NQ63T3WR45ERyS6t58atDXDA8iSn9zYJ2R4uryC6uYmxqNBpNda2bqNDGlwJpiuo6F2sPFrAzu4SrJqSS0srrsGJvXn3yv71orXG6NXalsNkUe46VknG8gvOGJdVflz3HStl7rIz48CBmDornQH45/1p9iO/M7M/WzGJeXneYgQnhjE6JYlRKJBP7xdYfWylFdZ2Lrw8VMqV/bIMOBpi8x5sbsthzrJTUmBDe3XKU4+U1fPTD2QzrFVlfb036cX79/i7+d85Qzh+ehMutuXfxZooqa/nrdWMbvQZaaxatyWB7dgl/unpM/e/3YH45r36TyVsbsyioqCUlOoT/3D6Vf351kLS4MG6b1R+lFKvTj3P3yxu5bXZ/7jl3EAF2W/1yLocLK/jN+7vYf4J32ic2hNjQQGqcbv57xzRiwwLb/d2IEAiC0COpqHFytLiq3sPxJ7VONyv35TO0V0STcX+PmDWGy60prqwlwGbjnc1ZFFXWccdZA1rsfLQWEQJBEIQejgwfFQRBEJpEhEAQBKGHI0IgCILQwxEhEARB6OGIEAiCIPRwRAgEQRB6OCIEgiAIPRwRAkEQhB5Ot5tQppTKBw63c/d44PhpNOd00lVtE7vaRle1C7qubWJX22ivXf201o0uXdrthOBUUEptaGpmXWfTVW0Tu9pGV7ULuq5tYlfb8IddEhoSBEHo4YgQCIIg9HB6mhA839kGNENXtU3sahtd1S7ouraJXW3jtNvVo3IEgiAIwsn0NI9AEARBOAERAkEQhB5OjxECpdQcpdRepVS6UurBTrSjj1JqhVJql1Jqp1Lqh9b2XymlspVSW6zHvE6wLUMptd06/wZrW6xS6lOl1H7rOaYT7Brqc122KKVKlVI/6oxrppRaqJTKU0rt8NnW6DVShies39w2pdSEDrbrz0qpPda531FKRVvb05RSVT7X7bkOtqvJ700p9ZB1vfYqpS72l13N2Paaj10ZSqkt1vaOvGZNtRH++51prc/4B2AHDgADgEBgKzCik2zpDUywXkcA+4ARwK+An3TydcoA4k/Y9ifgQev1g8D/dYHv8hjQrzOuGXAWMAHY0dI1AuYBHwEKmAas72C7LgICrNf/52NXmm+9TrhejX5v1v9gKxAE9Lf+s/aOtO2E8r8CD3fCNWuqjfDb76yneARTgHSt9UGtdS3wKnBFZxiitc7RWm+yXpcBu4GUzrCllVwBvGS9fgm4shNt+f/27u9FqjKO4/j7k5aUllKYiFb+yCCC0oqI1AjsIqO0H1aWmf2ACOxCuijCIugPqCtJiSKt7QeW0tKV6MWGF6ZpmvZTs4uUbQULwyJJ/XbxPKNnx53FzDln4HxesOyZZ8/Mfud7njnfc56ZeQ7ALOCniDjTb5f/LxHxOfBbU3OrHM0FVkWyCRglaWxZcUXEuog4mm9uAsa343//17gGMRf4MCKORMTPwB7Sa7f02JQuLPwg8EG7/n8rg+wj2tbP6lIIxgG/FG7vowN2vpImANOAL3LTs/nU7u0qhmCAANZJ2irp6dw2JiJ68/KvwJgK4iqaT/8XZ9U5g9Y56qR+9yTpqLFhoqSvJPVImllBPANtt07K10ygLyJ2F9pKz1nTPqJt/awuhaDjSBoBfAIsiYg/gDeAycBUoJd0Wlq2GRFxPTAbWCzp1uIfI52HVvZ5Y0nnAXOA1bmpE3LWT9U5GoikpcBRoCs39QKXR8Q04DngfUkXlRhSx223ATxM/wOO0nM2wD7ihLPdz+pSCPYDlxVuj89tlZB0LmkDd0XEGoCI6IuIYxFxHHiTNp4StxIR+/PvA8DaHENf4zQz/z5QdlwFs4FtEdEHnZGzrFWOKu93kh4H7gIW5J0HeejlYF7eShqLv6qsmAbZbpXnC0DSUOA+4KNGW9k5G2gfQRv7WV0KwRZgiqSJ+ahyPtBdRSB57PEt4LuIeK3QXhzTuxfY1XzfNsc1XNKFjWXSG427SHlalFdbBHxaZlxN+h2lVZ2zglY56gYey5/quBk4VDi1bztJdwDPA3Mi4q9C+2hJQ/LyJGAKsLfEuFptt25gvqRhkibmuDaXFVfB7cD3EbGv0VBmzlrtI2hnPyvjXfBO+CG9s/4jqZIvrTCOGaRTuq+B7fnnTuBdYGdu7wbGlhzXJNInNnYA3zRyBFwCbAB2A+uBiyvK23DgIDCy0FZ6zkiFqBf4hzQW+1SrHJE+xbEs97mdwI0lx7WHNHbc6GfL87r35228HdgG3F1yXC23G7A05+sHYHbZ2zK3vwM807RumTlrtY9oWz/zFBNmZjVXl6EhMzNrwYXAzKzmXAjMzGrOhcDMrOZcCMzMas6FwKxEkm6T9FnVcZgVuRCYmdWcC4HZACQ9Kmlznnt+haQhkg5Lej3PEb9B0ui87lRJm3Ry3v/GPPFXSlovaYekbZIm54cfIeljpWsFdOVvkppVxoXArImkq4GHgOkRMRU4Biwgfbv5y4i4BugBXsl3WQW8EBHXkr7Z2WjvApZFxHXALaRvsUKaTXIJaY75ScD0tj8ps0EMrToAsw40C7gB2JIP1s8nTfB1nJMTkb0HrJE0EhgVET25fSWwOs/bNC4i1gJExN8A+fE2R57HRukKWBOAje1/WmYDcyEwO5WAlRHxYr9G6eWm9c50fpYjheVj+HVoFfPQkNmpNgDzJF0KJ64VewXp9TIvr/MIsDEiDgG/Fy5UshDoiXRlqX2S7smPMUzSBaU+C7PT5CMRsyYR8a2kl0hXazuHNDvlYuBP4Kb8twOk9xEgTQm8PO/o9wJP5PaFwApJr+bHeKDEp2F22jz7qNlpknQ4IkZUHYfZ2eahITOzmvMZgZlZzfmMwMys5lwIzMxqzoXAzKzmXAjMzGrOhcDMrOb+BSPwkp+cb0K3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgiKT6i5GiJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "28ac9ee5-c613-42cc-c4e5-1d84feacb597"
      },
      "source": [
        "pyplot.plot(test_err, label='test')\n",
        "pyplot.savefig(\"deneme_err.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd5xU1f3/8deZtr0XWJZtwNKkCCKCAUuCxhZN+cZg9BeNMaaZmJiifpOvX2MS8zUmMc1ETTQaGzZURGxIEcUVlrJ02AK77LJs723a+f1xZ4bZZRsw22Y+z8eDBzN37s6cvXPnPWc/99xzldYaIYQQY59ppBsghBAiMCTQhRAiSEigCyFEkJBAF0KIICGBLoQQQcIyUi+cnJyss7OzR+rlhRBiTNq2bVut1jqlt8dGLNCzs7PJz88fqZcXQogxSSlV2tdjUnIRQoggIYEuhBBBQgJdCCGChAS6EEIECQl0IYQIEhLoQggRJCTQhRAiSAR1oO8qb2RXeeNIN0MIIYZFUAf6/Wv289s1B0a6GUIIMSxG7EzR4dBhd2E2qZFuhhBCDIug7qF3Od043XJFJiFEaAjqHrrd5UYp6aELIUJDcAe6041ZAl0IESKk5CKEEEEiqAPd7nTjcLlHuhlCCDEsgj7QnS7poQshQkNwB7rLjdMtPXQhRGgI2kB3uTUut8YhPXQhRIgI2kC3O42euVNq6EKIEBH8gS6jXIQQISJoA73L5QIk0IUQoWNQga6UukwpdVApVaSUuquXxx9SSu30/DuklBrxKQ67HEYP3eXWaC2hLoQIfgOeKaqUMgMPA5cA5cBWpdQqrfU+7zpa6x/5rf99YN4QtPWU2P1q5w6XxmaRM0aFEMFtMD30hUCR1rpEa20HVgDX9LP+dcDzgWjcmfDW0AEZuiiECAmDCfR04Kjf/XLPspMopbKAHGDdmTftzPgHugxdFEKEgkAfFF0OvKy1dvX2oFLqVqVUvlIqv6amJsAv3Z1/yUWGLgohQsFgAr0CyPC7P9GzrDfL6afcorV+TGu9QGu9ICUlZfCtPA3dSy7SQxdCBL/BBPpWIFcplaOUsmGE9qqeKymlpgMJwMeBbeLp6V5ykR66ECL4DRjoWmsncBvwDrAfeFFrvVcpdZ9S6mq/VZcDK/QoGSPY5d9Dlxq6ECIEDOoCF1rrNcCaHsvu6XH/3sA168x1q6HLKBchRAgI3jNFHSeOy8ooFyFEKAjaQO8+ykUCXQgR/II30P0PikrJRQgRAkIi0F0ybFEIEQJCItBl2KIQIhQEb6BLDV0IEWKCN9Blci4hRIgJ2kDvksm5hBAhJiQCXUouQohQELSBLiUXIUSoCd5Ad7kxm4yrFEnJRQgRCoI30J0uomxmQOZDF0KEhjEb6LvKG6lp6erzcbvTTVSYMfeYQ04sEkKEgDEZ6Fprrv/XJ/xp7aE+17G73ERKD10IEULGZKDXttpp6XRSWNXa5zr+PXQZ5SKECAVjMtDL6tsBKKntP9C9PXSZnEsIEQrGaKC3AUZPvand0es6XU43UTajh+6SHroQIgSMzUCv6/DdLu6jl253uonw9dAl0IUQwW9sBnp9OxbPGPPi6t4DvcvpxmYxYTEpOSgqhAgJYzLQj9a3MzcjHqtZUVLb1us6dpebMIsJi1nhlB66ECIEjMlAL6tvJyc5iqykqD576HanG5vZhNVkkvnQhRAhwTLSDThVnQ4Xx5s7yUyMpLnD0XcP3VtyMSsZtiiECAljrode3mAMWcxMjGRyajSldW291siNkosZi9kkk3MJIULCmAt07xj0jMRIspMicbg0lU2d3dZxuty43BqbxYTVpGRyLiFESBh7gV53ooeeGhsOQHWPOV28l58zSi4mGeUihAgJYy7Qp46P4abzs0mOtpESHQZw0iRd3rnQbWajhi7j0IUQoWDMHRQ9f3Iy509OBiA11hvo3UsuvkC3GKNcpIcuhAgFY66H7i8pKgyTOrmH3uX0L7nIKBchRGgY04FuNimSosP6rKGHeWroUnIRQoSCMR3oACnRYX3W0MM8o1yk5CKECAVjPtBTY3vpofuVXMwmOfVfCBEaBhXoSqnLlFIHlVJFSqm7+ljnWqXUPqXUXqXUc4FtZt967aF7hy2azVhl2KIQIkQMOMpFKWUGHgYuAcqBrUqpVVrrfX7r5AJ3A5/SWjcopVKHqsE9pcSEUdvahdutMXlmYOxy9DgoKj10IUQIGEwPfSFQpLUu0VrbgRXANT3W+SbwsNa6AUBrXR3YZvYtNSYMp1vT0G73Lav33I6NsGAxmeRMUSFESBhMoKcDR/3ul3uW+ZsKTFVKfaSUylNKXdbbEymlblVK5Sul8mtqak6vxT2kxBhni75RcIwFv36P6pZOCqtaMCnISY7CapaDokKI0BCog6IWIBe4CLgO+KdSKr7nSlrrx7TWC7TWC1JSUgLywt6Ti/6xsZjaVjv5RxoorGolOynKb3Iu6aELIYLfYAK9Asjwuz/Rs8xfObBKa+3QWh8GDmEE/JDznv5f1WwcGN1V3sSh6hZyx0UDeCbnkh66ECL4DSbQtwK5SqkcpZQNWA6s6rHOaxi9c5RSyRglmJIAtrNPKTFhvtthFhPbSusprWtn6rgYADlTVAgRMgYMdK21E7gNeAfYD7yotd6rlLpPKXW1Z7V3gDql1D5gPfBTrXXdUDXaX1SYhSibmfhIK1fPncDWIw243JpcX6DLfOhCiNAwqMm5tNZrgDU9lt3jd1sDd3j+DbuzM+OZNSGOrKQoXtpWDsDUbiUX6aELIYLfmJttsTfP3rIIrTV7KpoBY46XnOQoAJkPXQgRMoIi0AGUUkwdH43NbGJiYgRhFjOAzIcuhAgZQRPoAGEWM+dNSmRiQoRvmcyHLoQIFUEV6ABPfn0hyu++2aRwa3C5NQp80wMIIUSwGfOzLfZkNqluoW01G7fvXrmLb/4nf6SaJYQQQy7oeug9WczGd1Z+aQNmJb1zIUTwCroeek8WT2+9vL7DN62uEEIEo6APdKunh253uX0XvhBCiGAU9IFuMZ8os0igCyGCWdAHutV04leUQBdCBLOgD3T/HnqX1NCFEEEsBAK9ew/dmHZGCCGCT9AHurXHiUQyUZcQIlgFfaD799ABGboohAhaIRDoPXrocmBUCBGkgj7QvaNcYsONk2Klhy6ECFZBH+hmTw3dOz+6DF0UQgSroA/0GE/P3HtJui4JdCFEkAr6QD9rQiwrbl3EZ6anAtJDF0IEr6APdKUUiyYlEWY9MaeLEEIEo6APdC+b2bgknfTQhRDBKnQC3eLpoUugCyGCVOgFuss1wi0RQoihETqBbpYeuhAiuIVOoHt66DJsUQgRrEIm0MOkhi6ECHIhE+gnaugS6EKI4BQ6gS41dCFEkAudQJeSixAiyIVMoFulhy6ECHKDCnSl1GVKqYNKqSKl1F29PH6TUqpGKbXT8++WwDf1zFg986I7pIYuhAhSloFWUEqZgYeBS4ByYKtSapXWel+PVV/QWt82BG0MCKUUNotJLhQthAhag+mhLwSKtNYlWms7sAK4ZmibNTTCzCYpuQghgtZgAj0dOOp3v9yzrKcvKaV2KaVeVkpl9PZESqlblVL5Sqn8mpqa02jumbFZJNCFEMErUAdF3wCytdZzgPeAp3pbSWv9mNZ6gdZ6QUpKSoBeevAk0IUQwWwwgV4B+Pe4J3qW+Wit67TWXZ67/wLOCUzzAstmMcmJRUKIoDWYQN8K5CqlcpRSNmA5sMp/BaVUmt/dq4H9gWti4Nikhi6ECGIDjnLRWjuVUrcB7wBm4Amt9V6l1H1AvtZ6FfADpdTVgBOoB24awjafNim5CCGC2YCBDqC1XgOs6bHsHr/bdwN3B7ZpgSclFyFEMAuZM0XBKLkEavrcpnYHrV3OgDyXEEIEQmgFegBLLt95dhv3rtobkOcSQohAGFTJJViEWUzUBSjQa1q6fBN+CSHEaBBSiRTIGrrTrXG6dECeSwghAiG0Aj2AwxYdLrdM9CWEGFVCK9ADWEN3ujROt/TQhRCjR0gFutUcyJKLG6f00IUQo0hIBbrNYsIRsJKLxiE1dCHEKBJygR6o+dClhi6EGG1CKtC986FrfeY9a6mhCyFGm5AKdO+48UCUShxu6aELIUaXkAz0Mz0w6nJrtEbGoQshRpXQCnSzJ9DP8MCot2fudEsPXQgxeoRWoFvMwJkHurd2LqNchBCjSYgFemB66N7x5zIOXQgxmoRmoLtcZ/Q83p65Q0a5CCFGkdAKdE8N/UznRPfWzqWHLoQYTUIq0MMCVnIxeuZuDW7ppQshRomQCvRA1dD9x587ZKSLEGKUCM1AP8NSif8ZojIWXQgxWoRWoAd4HHrP20IIMZJCK9ADVnLRvd4WQoiRFFKBPi42HKVgf2XzGT2P/+gWOVtUCDFahFSgJ0bZOC8nkTd3V57RjIv+vXKpoQshRouQCnSAK2enUVzTxqGq1tN+Dv9eudTQhRCjRcgF+mdnjcek4M1dx077Ofx75TInuhBitAi5QE+NCWdhTiLv7qvq9XGtNZc+tJEX84/2+RwyykUIMRqFXKAD5KbGcLy5s9fHOhwuDlW1su9Y3wdOZRy6EGI0CslAj4+00tzh6PW0/cZ2BwAN7fY+f94ho1yEEKNQSAZ6XIQVt4aWLudJjzV1GIHuDfbeOGUcuhBiFBpUoCulLlNKHVRKFSml7upnvS8ppbRSakHgmhh4cRFWAJp6CW1foHf0E+h+vXIpuQghRosBA10pZQYeBi4HZgLXKaVm9rJeDHA78EmgGxlo8ZE24ER4+zvRQ++v5OLfQ5eSixBidBhMD30hUKS1LtFa24EVwDW9rPcr4AGg96ONo4i3h97YcXJoD67kMrhRLv/5+Ag/eangNFsphBCnZjCBng74j+Er9yzzUUrNBzK01m8GsG1DJj7SE+i9hHazJ9CbOx24+hhj7hjkOPQth+vZcLDmTJoqhBCDdsYHRZVSJuCPwI8Hse6tSql8pVR+Tc3IBV28t4beT8lFa2jp7L2X7hjkmaJdTjdtvRx4FUKIoTCYQK8AMvzuT/Qs84oBZgEblFJHgEXAqt4OjGqtH9NaL9BaL0hJSTn9Vp+h2F4CvdPhQmvdbVlDH2UX5yDnculyuulwuORSdUKIYTGYQN8K5CqlcpRSNmA5sMr7oNa6SWudrLXO1lpnA3nA1Vrr/CFpcQCEW82EW02+A5/NnQ7Ou/99Xtle0S3Q+zowOtjZFrscxsWo2+xndlFqIYQYjAEDXWvtBG4D3gH2Ay9qrfcqpe5TSl091A0cKvERNl94f1hYS1OHg73Hmmhsd2BSxjp9DV10uAc3Dt17MepWKbsIIYaBZTAraa3XAGt6LLunj3UvOvNmDb34SKvvoOj6A9UAHGvsoKnDwYT4CMobOgbXQx+ghg5IHV0IMSxC8kxRMOrojR0OtNZsPGQcoD3W2Elzh4OspEig76GLDpdGeXrx/Y1y6XIapZaWTgl0IcTQC9lAj48w5nPZV9lMdUsXseEWXw89I6H/QHe63URYzcAAJReH9NCFEMMndAPdU3LxjhP/4vyJ1LXZaWi3kxBlIzbc0k/JRfsCfTAlF6mhCyGGQ8gGelyElcYOO1sO1zNtXAxzM+IAcGvjsYQoW98HRV2acG8PfRAlFwl0IcRwCNlAj4+00elws620gflZ8UyIi/A9FhdhJT7C2m/JxWJWWExqwBOLAFqlhi6EGAYhG+je+Vxau5zMy0wgPaF7oMdF2votuVhMCotZ9Vly0Vpjl1EuQohhFPKBDjA/M4FxseG+8edxEVYSIq39lFzcWM0mrCZTnwdFvb1zkJKLEGJ4hGygeyfoiouwMik5CqvZxLjYcN+y/kouvkC3mPo8U1QCXQgx3EI30COMOdHnZcZj8nTNJ8QbZZe4CCvxkbY+Z1x0urWvht7XXC7eA6IggS6EGB6hG+ieHvr8zATfsnRPoMdGWEmOCUNrqG3tOulnHS43VpMJq7mfkovjRA9dauhCiOEQsoE+MSGCX1w5g6+el+lblp0cRYTVTEyYhYmeg6TlDe0n/azT5emhm9WgSi5ypqgQYjgMai6XYKSU4palk7ot++bSHK6YPR6TSZHhC/QOzsnq/rMOtybSbBp0yaXNLoEuhBh6IRvovYkJtzJ9vFGKSY83Tv8vb+g4aT2ny43VpDwll/576LHhFtq6XLg9tXhvvV4IIQItZEsuA4mwmUmOtnUruRyubaOutatHyaX3HnqnZy705OgwWjqd/H1DEVf8ZdOwtF0IEZqkh96P9IRIXw9da83yxz7m4mmpONxuLGYTFtPAPfTEKBuVTZ3kldRTWN2K1hqlpJcuhAg86aH3Y2JCBEfrjR56UXUrVc1d1LQYPXSj5NJPDd0zyiUp2kaHw8WB48243Jp2uXqREGKISKD3Y2JCBBWNHbjdmrySOsC4XJ3TNZgeuhHciVFhANS2GtMI9HZhaiGECAQJ9H5MTIjE4dJUt3SRV1IPGEMQHW6N1VND72u2RW/JJTna1m15c6cEuhBiaEig98M7Fv1oQ/uJHnqH0UO3mk3YzKY+J+fyBnpSVPdAb+pjOgEhhDhTclC0H96x6BsOVlPXZicuwkpLpxMNWEwmz2yLfdXQPSWX6LBuy5vlJCMhxBCRHno/vGPRH91YgtmkWDZjHC1dTuxOt6fkYsIxwJmiyZ4eeoJnqgGpoQshhooEej8ibGbOyUpg9sQ4nvr6QmakxQBgdxkXuLD2e6aoEegJnkA/JysRkEAXQgwdKbkM4JXvnO+7fazpxFmjRsmlvxq6C5vFRKxn3vX5WfGs3V9FswS6EGKISA/9FMSGn/j+s5qNceh9jnJxuAmzmJgQF86vPj+L687NJCbMIj10IcSQkR76KYgNP3GVI+849P5GuYRZzCil+H+LjNm9YiOsMmxRCDFkpId+CmL8A913TdG+Z1sMs3TfvLERVim5CCGGjAT6KYiN8C+5eC5w0c8olzBr980bF2GhuUOGLQohhoYE+inoXnIZ4BJ0DqPk0vPnpYYuhBgqEuinINr/oKh3lItb848Nxfxp7aFu6/ZWcomLkEAXQgwdCfRTYDWbiLQZvW6rRWEzG9PgPr+ljL+8X0hJTatvXeOgaC81dDkoKoQYIhLopyjG00v3jkMHY64Xt4a/rSvyrWfU0LuXXOIirLTbXX3O0CiEEGdiUIGulLpMKXVQKVWklLqrl8e/rZTarZTaqZT6UCk1M/BNHR28dXSrp4YOoDVMiAvntZ0VlNUZ86d3OXoZ5eL5MpCRLkKIoTBgoCulzMDDwOXATOC6XgL7Oa31bK312cDvgD8GvKWjhH8P3Wo+sfm+9+kpuDVsPWJMs2vvpeQSJ/O5CCGG0GB66AuBIq11idbaDqwArvFfQWvd7Hc3Cuh96EcQ8J7K772mqNdF01KxmBTFnjq698Sibj/r6d3LjItCiKEwmDNF04GjfvfLgfN6rqSU+h5wB2ADPt3bEymlbgVuBcjMzDzVto4KMb6Siwmryfg+jLCamRAXTmZSJCU1bYBnlMtJ49Clhy6EGDoBOyiqtX5Yaz0ZuBP4RR/rPKa1XqC1XpCSkhKolx5Wsb6Sy4keelZSJEopJqdEn+ihO3opuXgCXWroQoihMJhArwAy/O5P9Czrywrg82fSqNHM20O3mE+McslJjgJgUkoUpXXtOF3u3ksu0kMXQgyhwQT6ViBXKZWjlLIBy4FV/isopXL97l4JFAauiaOL9/R/q2c+dICsJCPQJydHY3e5Katvx+46uYceH2nFbFIcb+oc3kYLIULCgDV0rbVTKXUb8A5gBp7QWu9VSt0H5GutVwG3KaWWAQ6gAbhxKBs9knw9dJN/D924stHkVCPYDxxvATiphh5mMZObGs2eY03D1VwhRAgZ1PS5Wus1wJoey+7xu317gNs1aqXGGNcIjQm3+OrpueOMKxlNSo4GYN8xY9BPz5ILwKz0ODYcrEZrjVLqpMeFEOJ0yZmip2jZjHGs/O75ZCRGsjAnkVe+s5j5mQmAcbm5xCgb+yq9gX7y5p2dHkdtq53jzVJ2EUIElgT6KTKblC/AlVK+a4V6TUqOYltpA9B7oM9KjwNgV7mUXYQQgSWBHmDfu3gKVs9wRv8LYnjNTIvFpGBPxYlA11qzp6KJpnYZ/SKEOH1yCboAu3h6Kpt+9mk2F9dywdSTx9pH2MxMHRfDJyX1/G1dIbWtdvZUNJFf2sCNi7P45TWzRqDVQohgIIE+BCJsZj4zY1yfj89Kj+PlbeVsLa0nNtxKYpSNcbFhvtExwcTt1phMcvA3VGituXvlbq6aM4Eluckj3ZyQI4E+Ar62OIvoMAs3LMpkSqoxQuanLxWw4VDNSetWt3QSZjb7JvYaS97fX8UdLxbwjxvmc/5k+XCHgvKGDlZsPYrWDGugl9W1kxRtIyrs5EjTWlNc08rklOigH1kmNfQRMGdiPPdefZYvzAEmpURT09LV7QIYLrfmy498zKV/2sjh2raRaOoZ2VxcR1OHg5uf3OqbhVL0rrq5k1e2lY90M87Y9jJjQMDhulPbX50uNy9uPXrax5H+65HN3PzkVtzuk+cFfGV7Bcv++AG/fGMfWgftvIGABPqoMTnFOCnJO7kXwKbCGkrr2mloc7D8sY+pb7P3+fMddhd3vLiTQ1Wjp2yzv7KZySlRxEVYeWRD8Wk9x7oDVdy7am+vH9Rg8rt3DvLjlwo4Wt8+0k05IzvKGgEoPcVAf29fFT97ZRfXP55HY3vf+3lvmtodVLd08cnhep7OK+32mMPl5i/vFxJlM/Pk5iM8tDZoT2IHJNBHjcmpxklJxdUnLmP3/JYykqJs/Pvr51LV3MWmwpNLMl7PflLKyu0VvLqjv2l2ho/Wmv2VzZybncjCnKRejw+02520dvU/lfCjG0t4cvMRnvmktN/1+jJUAam19l3MZCB/W1fI8sc+7valdLTemPMHjLl9Vu86Bpzo4fanpqWLe1ft5bz713LgeHOv69idbmpaugbVvr786IWd3L1y10nL/7T2EF/9Z16vvV1v+6uau2i3O6lp6aLT4RrwtTYcrCHCaubQ8VZuX7Gz33UdLjfHGjt898s873FilI3/e+sADW123G7NrvJGHt1YTFl9O39ePo+lucms2jn0n4/WLueIXWpSAn2UyEyMxGJSlNQagV5c08ra/dX814KJnJeTSKTNzPbSEx/2g8dbfOPd2+1OHtlo9ID91+nNR0W1VDZ19LtOIFS3dNHQ7mD6+BhmpMVQ0djR7c/pDruLq/76Idc+8nGfve+WTgfbShuwmU38ds2BPgO0sd3OPz8o4R8biimqPvHF8cGhGpb+br1vOwXSPzYWc8GD6yk42jjguu/srSKvpJ639hynqLqFG5/YwtLfref37xoXFn99ZwWdDjdmkzrp/et0uHh5W3m3Xut3n93G03mlVDV38c6eql5f865XdrHkgXV8VFR7Wr/fzqONvLqjgtW7Kru9Py635pm8MjYX17GttIGKxg5fR6PT4WLfsWaykoypMEpq2rjyL5v43dsH+30trTUbDlVz8fQUvrE0h4+KamnrclJS08rmXtr/05cKuOSPG2nzdAa8gf7Tz06jw+Hig8Ia3th1jKv/9hG/f/cQcybG8ZkZqczLTKCsvr3fL5ij9e2sO9D7NvVqanfwr00n728Ah2vb+MwfNvS7Xw8lCfRRwmo2kZkUSXF1Gw+8fYDPPvQBYRYT1y/MwmI2MXdiPNvLToTHf7+6m288tZVOh4tn88qobbVzdkY8u8qb+rxm6dYj9dzw+Cfc9tyOgNcSXW7Nb97cR76nVr7fc7bsjLRYZqTFAnTrTf7+3YOU1LSxr7KZt/YcB4yezd0rd/l61R8V1eJ0ax788hwA/r7hxDVb/f19QzG/WbOfB94+wG/XHPAtf2ev8bzv7jt+Wr/P/Wv2+74M/raukA88B60PHm/hofeMMH4mr/+/HOxONwc9f5387p0DXPtoHgXljZw1IZanNh+horGDpz8uZXZ6HOdmJ3R7jwFe3lbOT14qYMkD63l5WznlDe1sPdLAHZdM5awJseSV1J30mkXVLby6swIN3PzkVp7JK8XuNPaJA8eb+dXqfbgGCJs/rzV+v5ZOp29KaIAth+upbTV6/v/efIQbn9jC157YwpbD9eyuaMLp1nxx3kQA3t5znOqWLjYX9/+lsr+yharmLi6amsr5k5NwujXbShv4xWt7uOnJrd0ms3t7TyWv7TxGm93F5mLjd/cG+pVz0kiMsrH+QDWv7zzGhLhwnv7GQp646VyUUkwdF41b0+338dfpcPH1J7dy85P5/KOfEuHTeUf49ZvG/vabN/cDxpfSe/uqWP7YxzS0OzhwvIU3d1f2+3sPBRnlMopMSo5mw6Fq3t7r5gvz0vnZZdNIi4sAYH5WPI9uLKHD7kKjKTjaiNOteXVHBY9+UMySKclce24GP3h+BwcqW5g90Tgj1eFy89V/5pEaG87eiiasJhPbShv4sKiWpbkDz0l//5r9HG/q5C/XzeOv7xfy7r4qblmaw7TxMaREh5EUbcxt8++PDvPPTYcpONrEi99ezP5KI8Smp8XSYTd6RPsrm3luSxnrDlTT0unkq+dlsuVwPX9+/xCXzxrPU5uP8PyWo7R0OvnbV+ez/kANMWEWrpidxkdFtawqOMbPr5zR7YStLqfRg7105jhiwq2sO1Dl+7LacNAI4I0Ha7j78hnkldTxl/cL2V3RRJjFzP9cNYNrzk73PVd9m52v/3sLn5s7AaUUj31QQmVTJ5NTovjDe4eYEBfB2jsu5CcvFRAbbuXc7ETe2HWM86ck8fD6Yn559VkA/Gr1Pv60/Gymj4/lUFULdpebz541jnf2VpEWF87z31yES2su+eNGrvjzJpo7Hfzj+nPYVd7IYx8Y73GEzZgH6OOSOlJiwshIiODeVXu58fwsAK6ak0Z9m51n8krpdLgIt5r5+4Yi3t5zHJvZRITVzKrblnD3yl384rU9PJNXyurvL+GJDw/zYr6xvbqcbm5fsQOnJ9xjw6288K1F1LbaWX+whi/Nn8gr28vZXtbAG7sq2XesiZhwKxFWM5fPHs/K7Ub5IoazVvwAABJ2SURBVCnKxk9fLiAz0eiZf2FeOg+tPcRL24zr4hyqaqG1y0m0ZwRKWV07zZ0O3ig4xnv7qkiIsgFw4bQUYsItWEyKN3dVkldSh1vDIxuLuevy6azYUsZDawuZmRZLaV0bGw5Wc8nMcZTVt5MUZSM23MoFucmsP1hDu93JjYuzu+3juZ5BCIVVrUxKjqa0vo0Iq9k3W+qf1hZSVN3KudkJPPD2ATISI7hiVhpfeexjrpozgRvPzwZg/cEaZqfHMW18DO/tM/a3H79UwMrtFWQlRfLadxdy+4od/Pn9QqakRjMhPsJ3LYShJoE+ikxOjWLt/ipmp8fx4H/N8c3mCDA/MwGnpy5od7lxujVWs+J/V+3F7nRz+7Jc0uLCAaOO6Q309/dXsfWIUbawu9w8dfNC7n5lF79dc4AjC7sfuFo8OYkpqTG+ycUibWYe//AwLrdm2cxx/HV9ESaFr8aZHG3jwzs/zbHGDh585yCx4Ra2HKmnqLqF/ZXNpHt25NhwCwmRVtbsOc6Ww/UszU3m3OxEblmaw9r91fzg+R38+s39rNxRTpjFxJu7K/lWeRMbD9WwdGoyVrOJ6xZm8mJ+OSu3V5CRGEF2UhSTUqJ5d28V9W12rl+UxbHGDl7ZXs7h2jbcWlPR2MHklCgOHG/h3x8d5pdv7CM1JowvzEtnV3kTP3phJ0XVrYyPC+fT01P5zZv7KShvoqC8yXcB8LySOvJK6tEaKho7WP7PPHZXNPH36+eTkRDJ23uP86MXCjCbFDc/uRWloNPh5vFNh3nwy3PZ7Tkj+K7LZ7BkSjIXTUslwxN8nz87nVd3VvDAF+dw2azxWEzK9x6fNykJrTWflNRxQW4Kt144icv+tIm/byhmVnosWUlRLJqUxOMfHqbgaCNzM+J5ZEMxnQ43dpeb71w0mSmp0bz4rcU8nVfKPa/vJa+k3vclt2Z3JSW1bZhNJj4/Lw2t4blPynh4fRHHmzpJiLRy79Uzef9AFRsP1bDuQDWdDqOXf+XsNL6xJIeV2ytYfm4Gn5+XzvLH8qht6eK/r5hOZlIkydFhVDV3YVLg1lBwtJFPTUnmqc1H+N9VewEwKZibEW/sr+lxjIs19t+5GfG8uM0Y+rgwO5HntpTx1p5Kqpq7WJiTyANfmsP9a/az4WANWmuO1rf7tunF01N5badxPOLKOWnd9u+c5CgsJkVhdQtv7anknb1GaeV/rprJvMx4HvugmOXnZvDrz8/iwgc38NqOY2QkRLL1SAMFR5tYPDmJ1JgwdpQ1cNvFU5gQH8HL28rZXdHEGwXH+PI5E7n/i7Oxmk384DO5fP/5HVz+501MSoni3R9eQE1rF9XNXczNiD+DlOifBPoock5mAtFhFn7/5bndwhxgnmf+mG1lDbR1OTGbFN+5cDJ/WVfEkilGQGqtSY0JY3tZg6838ewnZaTFhbP6+0uobOpkVnocP1w2lZ+9sov/eX1vt9eIDrNw+2dy+f27Rs1zVnocVrMiIdLGj14wQvzdOy6korGDPRVN/PatA7y1p5K3dh/HZjGx4tbFXPPwh/x9fTHbyxqYkWb0iJRSzEiLZXNxHRaT4g/XziU1xvjwfm5OGh8X1/HER4cBeOrmhXz3mW1c/fCHaA1XzZkAwNkZ8cxIi+0WBhdOTaG4po2MxAiWTkmm0HNAeXtZo6/m/IsrZ/L1J7fyyzf2MSs9lpe/fT7hVjMddhe3Pp3PX9cZZRxvmP5wWS5lde1sKqrlhvOyeGjtIZ7fUka41URuagwFRxu5ck4aV8w2wmLxpCQcLjd/uHYu3312O25tTKf8xq5j/OKqmewqbyI23EJ2UiQ5ydndtvf9X5zNrRdOYvp4oyQ1P8t4j18vOMbZmfGU1bVT22pn0aQkpo+P5YrZ41mz+7jvtRdmJ6IU5JXUU97QQXOnk+duOQ+rxSjRebf9tQsy+L+3DvDH9w5S3dJFdJiFV3dU0Nzp5EfLpnL7MuNyBlprnvmkDJdb87PLphETbmVeRjxrdhslqx98egqPf3iYr5ybwVkT4njte59iRloMYRYzq7+/hPT4CF9vOyc5ktrWLi6bZbR5e2kDE+Ij+O1b+1mam8xXF2YyIy2W7OQoDte2Ee431fSiSYlsK21gUkoUf7h2Lpf/eRNZSVH86SvzWDw5CYCLpqXw3r4qiqpbKa1vY16Gse2W5qagFEyIi+DsHsFps5jI9sy1tK20gSvnpNHS6eR3bx9gXGw442PD+fmVM7CYTVw8PYWV2yuYNj4apSAyzMyPXyzg/y3Owq3hwmmpvgvG/3VdEQ6X5kvnTPRdOP6qOWnERljZXd7I7989xIqtR3n8w8NUNHSw+gdLmDouhqEggT6KXHrWeHbck+rbKfwlRtnISY5i7b4qXG7NnIlx3PSpHLYeaeCuy6cDxod3fmYCa3ZXkn+kgfMnJ7GpsJYfLsslya88cu25GVx61jjfn9oAje0OvvmffH6zZj/Txxs727bSBm5ZkkN6QgS/fGMf1y6YSHZyFNnJUSyelMTzW8p46L1Cyurb+dGyqcycEMulZ41n5Y4KLCbFnZdN9z3/9PFGoC+bMc4X5t42/+bzs4iPtOJwurlwagp3Xj6dDQdr+ObSSb4PsFKKOy6ZypObD3Pdwkx2lzfx3v4qLCbFdy/OxWRS5KZGExNmYVtpAwePN5ObGs1F01JIiwuntrWL3395LuFWo5QRYTPzn5sXUtdmp7HdwRMfHaap3eGZi8eE0+WmvKGDh9YeYuOhGj41JYkfXzqNh9cVcZ+ntALwzC3nYVJG+1bdtgQwpk9es/s4r++sYE9FE7MnxvV6Qku41ewLc+97fMXs8Tz3SRkfHKphmeds40WTjG3w40unUddq99Wo4yKtzEyL5ZXt5URYzUxKjmLx5KSTXivcaubT01NZvcuo6d5xyVTuW70Ps0nxlXNPXIzsOxdN4fktR4mNtPC1xdmA8Zeht8Rwx6XTuH3ZVMyev178A9M76ZxXVlIUW480cOnM8RRWtfJhUS1rD1RjM5v4/Zfn+nrjcOKKX16LJhklrKtmp5GRGMmOey456TNx0bRUwKjTH2vs5Jq5kb5teOPibHLH9X4S0dRx0b4vqFuW5JAeH8ElD31AWX07T9280FfOu3haKs/klfHkR0eYMzGe7140mW8/s42fv7qb+EgrZ2fEozCm0X5vXxUxYRbO8Xwhg7E/XDg1hQtyk1mz+zj/8/oetIaYMAs/eamAld85/6ROWyBIoI8yvYW517cumMRdK3cD8N2LJpMYZeP5Wxd1W+fbF00mLsJKc6eDV3dUnPSh9YqPtHW7nxwdxvPfXMSzn5Ry0/nZKKV4+mPjdpjVREObnRsWZ/nWN5kUyxdm8n9vHSA23MJNn8oG4KeXTmNSchTXLsjw/RkMMHuiEVzXLzr54uCmHuH/tcXZvkDxd8nMcVwy0wi5q+ZM4O4rZpz0PGdnxvPK9nLsTjf3XXMWSinuu2YWDpe7W3iC8aFLjg4jOTqM+78wu9tjFrOJrKRIxseGc7y5k0U5SczPTODxm87ttp7Zb1oD7+3ZE+OMstnbB+lwuPjG0pyTfpe+PPzV+XxQWMuPXyzgyc1HmBAXTkaicRxlcko0L3xrcbf1f3bZdO58eRdl9e38/IoZfZ4JedWcNFbvquSsCbF85dwMHnznIEtykxkfdyJYx8eF8+CX5xAbYfXVuxdkG7OJXn9e5km/b39yU42e7aJJSXxcXMcL+UcxmxR/v35+tzDvzaJJSfxwWS43LDL2t94+E+nxEZyXk8gjG4txubWvfg9wr98Xbk/GyXzHSY83evBKKf514wIO17Zxod/cS4snJ2Ezm2izu7h4WgqfPWs8D/7XXH76cgEXTU3p9qW2qbCWJbnJvbZTKcUPl+Vy69PbuGFRJosnJfO957bz5OYj3LJ0Ur/b4bRorUfk3znnnKPFqfv3hyV6yn+/qfOP1A+47tH6Nr29dOD1TldNS6c+65639cPrCwdc1+506Y8Ka7Tb7R6y9mit9R/ePaiz7lytv/LoZu1ynflr3f78dp1152q95XDdKf3c4ZpWfet/tuqsO1frDQerT/l1C6ua9bm/fk//7+t7Bly3w+7U6w5UabvT1e865/zqXf23dcZ7tbu8UVc3dw743G63W39wqFo7T3FbtnY6fPvoW7srde5/r9GrC46d0nMMZHNRrc66c7XOunO1/ri4dlA/80ZBhc66c7X+9eq9A657w7/ydNadq/WOsgbfsj0Vjbqhrct3/4+e/W3FltI+n8ftduv8I3W6y2G8P09tPqwb2+yDam9vMK4U12uuSqCPQR1250g3wae5wz7kIX0q9lY06c/9dZMurW0LyPNtPFitv/LoZt+H8VS1djpO+7UdTpd29BPSp6qty3HKwRwoQ7XPfuXRzTrrztW6oqF9UOtXNXfoz/11ky6sahlw3TW7jukb/pXXb8dgf2WTvvpvH+raloG/HAOlv0BXeoTmNliwYIHOz88fkdcWQgSHQ1UtrNp5jB9fOjXoJ97yUkpt01ov6O0xqaELIcasqeNi+Mlnp410M0YNOVNUCCGChAS6EEIECQl0IYQIEhLoQggRJCTQhRAiSEigCyFEkJBAF0KIICGBLoQQQWLEzhRVStUAp3ehSEgGTu/aWkNvtLZN2nVqpF2nbrS2LdjalaW17vXqNCMW6GdCKZXf16mvI220tk3adWqkXadutLYtlNolJRchhAgSEuhCCBEkxmqgPzbSDejHaG2btOvUSLtO3WhtW8i0a0zW0IUQQpxsrPbQhRBC9CCBLoQQQWLMBbpS6jKl1EGlVJFS6q4RbEeGUmq9UmqfUmqvUup2z/J7lVIVSqmdnn9XjEDbjiildnteP9+zLFEp9Z5SqtDzf8JAzxPgNk3z2yY7lVLNSqkfjtT2Uko9oZSqVkrt8VvW6zZShr949rldSqn5w9yuB5VSBzyv/apSKt6zPFsp1eG37R4Z5nb1+d4ppe72bK+DSqnPDlW7+mnbC37tOqKU2ulZPizbrJ98GNp9rK9r043Gf4AZKAYmATagAJg5Qm1JA+Z7bscAh4CZwL3AT0Z4Ox0Bknss+x1wl+f2XcADI/w+HgeyRmp7ARcA84E9A20j4ArgLUABi4BPhrldlwIWz+0H/NqV7b/eCGyvXt87z+egAAgDcjyfWfNwtq3H438A7hnObdZPPgzpPjbWeugLgSKtdYnW2g6sAK4ZiYZorSu11ts9t1uA/UD6SLRlkK4BnvLcfgr4/Ai25TNAsdb6dM8UPmNa6w+A+h6L+9pG1wD/0YY8IF4plTZc7dJav6u1dnru5gETh+K1T7Vd/bgGWKG17tJaHwaKMD67w942ZVxo9Frg+aF6/T7a1Fc+DOk+NtYCPR046ne/nFEQokqpbGAe8Iln0W2eP5ueGO7ShocG3lVKbVNK3epZNk5rXem5fRwYNwLt8lpO9w/YSG8vr7620Wja727G6Ml55SildiilNiqllo5Ae3p770bT9loKVGmtC/2WDes265EPQ7qPjbVAH3WUUtHAK8APtdbNwD+AycDZQCXGn3vDbYnWej5wOfA9pdQF/g9q42+8ERmvqpSyAVcDL3kWjYbtdZKR3EZ9UUr9HHACz3oWVQKZWut5wB3Ac0qp2GFs0qh873q4ju6dh2HdZr3kg89Q7GNjLdArgAy/+xM9y0aEUsqK8WY9q7VeCaC1rtJau7TWbuCfDOGfmn3RWld4/q8GXvW0ocr7J5zn/+rhbpfH5cB2rXWVp40jvr389LWNRny/U0rdBFwFXO8JAjwljTrP7W0Yteqpw9Wmft67Ed9eAEopC/BF4AXvsuHcZr3lA0O8j421QN8K5Cqlcjw9veXAqpFoiKc29ziwX2v9R7/l/nWvLwB7ev7sELcrSikV472NcUBtD8Z2utGz2o3A68PZLj/dekwjvb166GsbrQK+5hmJsAho8vuzecgppS4DfgZcrbVu91ueopQye25PAnKBkmFsV1/v3SpguVIqTCmV42nXluFql59lwAGtdbl3wXBts77ygaHex4b6aG+g/2EcDT6E8c368xFsxxKMP5d2ATs9/64AngZ2e5avAtKGuV2TMEYYFAB7vdsISALeBwqBtUDiCGyzKKAOiPNbNiLbC+NLpRJwYNQrv9HXNsIYefCwZ5/bDSwY5nYVYdRXvfvZI551v+R5j3cC24HPDXO7+nzvgJ97ttdB4PLhfi89y58Evt1j3WHZZv3kw5DuY3LqvxBCBImxVnIRQgjRBwl0IYQIEhLoQggRJCTQhRAiSEigCyFEkJBAF0KIICGBLoQQQeL/A3yJyet75s5XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IJ9Z-dQKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "parseval_16_2.save(\"parseval_OC.h5\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqddlwbmEV9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = parseval_16_2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ysop6NFDbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1dc63a44-a11d-47e2-b009-7fc3fe701bb6"
      },
      "source": [
        "parseval_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 18ms/step - loss: 0.6343 - acc: 0.7644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6342633962631226, 0.764397919178009]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUCxeuFMmMw7",
        "colab_type": "text"
      },
      "source": [
        "# **Adversarial Examples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knp-F1cdmQgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import  KFold\n",
        "\n",
        "class Non_adversarial(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train_iterate(self, X_train, Y_train, X_test, y_test, epochs, BS,sgd, epsilon_list):\n",
        "          init = (32, 32,1)\n",
        "          res_df = pd.DataFrame(columns=['loss_clean','acc_clean',\n",
        "                                  'loss1', 'acc1','loss2', 'acc2','loss3',\n",
        "                                    'acc3','loss4', 'acc4'])\n",
        "          kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
        "          \n",
        "          for j, (train, val) in enumerate(kf.split(X_train)):\n",
        "            x_train, y_train,  x_val, y_val = X_train[train], Y_train[train], X_train[val], Y_train[val]\n",
        "            model = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "            model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "            hist = model.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=epochs,\n",
        "                            callbacks = [lr_scheduler],\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            validation_steps=x_val.shape[0] // BS,)\n",
        "            loss, acc = model.evaluate(X_test, y_test)\n",
        "            loss1, acc1 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[0]),X_test, y_test, epsilon_list[0])\n",
        "            loss2, acc2 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[1]),X_test, y_test, epsilon_list[1])\n",
        "            loss3, acc3 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[2]),X_test, y_test, epsilon_list[2])\n",
        "            loss4, acc4 = print_test(model, get_adversarial_examples(model, X_test, y_test, epsilon_list[3]),X_test, y_test, epsilon_list[3])\n",
        "            row = {'loss_clean':loss,'acc_clean':acc, 'loss1':loss1, 'acc1':acc1, 'loss2':loss2,\n",
        "                    'acc2':acc2, 'loss3':loss3, 'acc3':acc3, 'loss4':loss4, 'acc4':acc4}\n",
        "            res_df = res_df.append(row , ignore_index=True)\n",
        "            \n",
        "          return res_df"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVhO4DCbmWAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "352bf2a9-3fd2-4d36-a19e-0115d932f346"
      },
      "source": [
        "\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans from git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.6/dist-packages (from cleverhans) (2.6.0)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv0ZE8pumboZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "def get_adversarial_examples(pretrained_model, X_true, y_true, epsilon):\n",
        "  #The attack requires the model to ouput the logits\n",
        "   \n",
        "  logits_model = tf.keras.Model(pretrained_model.input,pretrained_model.layers[-1].output)\n",
        "  X_adv = []\n",
        "  for i in range(len(X_true)):\n",
        "    random_index = i\n",
        "    original_image = X_true[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_true[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "  X_adv = np.array(X_adv)\n",
        "  return X_adv\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxeGP9HYmd7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_graph(hist):\n",
        "  history = hist\n",
        "  print(history.history.keys())\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  plt.savefig(\"wrn_tensor.png\")\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Wgf8sOmgMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_test(model,X_adv, X_test, y_test, epsilon):\n",
        "  loss, acc = model.evaluate(X_adv,y_test)\n",
        "  print(\"epsilon: {} and test evaluation : {}, {}\".format(epsilon,loss, acc))\n",
        "  SNR = 20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))\n",
        "  print(\"SNR: {}\".format(SNR))\n",
        "  return loss, acc"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKoVsxZDOxyL",
        "colab_type": "text"
      },
      "source": [
        "**Non-Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DWYnAsDsRJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d78MYsOGOw-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff6bdae8-68fd-4bd4-8a44-71066f34500b"
      },
      "source": [
        "epsilon_list = [0.003,0.005,0.01,0.02]\n",
        "train_object = Non_adversarial()\n",
        "result_df = train_object.train_iterate(X_train, Y_train, X_test, y_test, EPOCHS, BS,sgd, epsilon_list)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/70\n",
            "26/26 [==============================] - 3s 117ms/step - loss: 1.4702 - acc: 0.3084 - val_loss: 1.4531 - val_acc: 0.3063 - lr: 0.1000\n",
            "Epoch 2/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.3925 - acc: 0.3708 - val_loss: 1.3929 - val_acc: 0.3395 - lr: 0.1000\n",
            "Epoch 3/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.3451 - acc: 0.3735 - val_loss: 1.3447 - val_acc: 0.3506 - lr: 0.1000\n",
            "Epoch 4/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.3205 - acc: 0.3786 - val_loss: 1.3240 - val_acc: 0.3652 - lr: 0.1000\n",
            "Epoch 5/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2958 - acc: 0.3795 - val_loss: 1.2610 - val_acc: 0.4123 - lr: 0.1000\n",
            "Epoch 6/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 1.2866 - acc: 0.4078 - val_loss: 1.2721 - val_acc: 0.3838 - lr: 0.1000\n",
            "Epoch 7/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 1.2783 - acc: 0.4044 - val_loss: 1.4502 - val_acc: 0.3331 - lr: 0.1000\n",
            "Epoch 8/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2593 - acc: 0.4310 - val_loss: 1.2677 - val_acc: 0.4176 - lr: 0.1000\n",
            "Epoch 9/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2230 - acc: 0.4805 - val_loss: 1.2882 - val_acc: 0.4054 - lr: 0.1000\n",
            "Epoch 10/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.1848 - acc: 0.5045 - val_loss: 1.1813 - val_acc: 0.4939 - lr: 0.1000\n",
            "Epoch 11/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1347 - acc: 0.5421 - val_loss: 1.2440 - val_acc: 0.4793 - lr: 0.1000\n",
            "Epoch 12/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1047 - acc: 0.5484 - val_loss: 1.6150 - val_acc: 0.4182 - lr: 0.1000\n",
            "Epoch 13/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.0930 - acc: 0.5502 - val_loss: 1.2398 - val_acc: 0.4589 - lr: 0.1000\n",
            "Epoch 14/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.0371 - acc: 0.5832 - val_loss: 1.0125 - val_acc: 0.5935 - lr: 0.1000\n",
            "Epoch 15/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.0162 - acc: 0.5920 - val_loss: 1.3541 - val_acc: 0.4199 - lr: 0.1000\n",
            "Epoch 16/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9779 - acc: 0.6144 - val_loss: 1.7157 - val_acc: 0.3605 - lr: 0.1000\n",
            "Epoch 17/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9520 - acc: 0.6289 - val_loss: 0.9932 - val_acc: 0.5807 - lr: 0.1000\n",
            "Epoch 18/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9126 - acc: 0.6495 - val_loss: 1.5164 - val_acc: 0.4671 - lr: 0.1000\n",
            "Epoch 19/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8800 - acc: 0.6586 - val_loss: 0.9266 - val_acc: 0.6418 - lr: 0.1000\n",
            "Epoch 20/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8797 - acc: 0.6598 - val_loss: 1.2402 - val_acc: 0.5748 - lr: 0.1000\n",
            "Epoch 21/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8626 - acc: 0.6613 - val_loss: 1.1491 - val_acc: 0.5970 - lr: 0.1000\n",
            "Epoch 22/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8263 - acc: 0.6816 - val_loss: 0.9757 - val_acc: 0.6249 - lr: 0.1000\n",
            "Epoch 23/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7792 - acc: 0.7031 - val_loss: 0.8860 - val_acc: 0.6575 - lr: 0.1000\n",
            "Epoch 24/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7822 - acc: 0.7049 - val_loss: 0.9093 - val_acc: 0.6622 - lr: 0.1000\n",
            "Epoch 25/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.7503 - acc: 0.7158 - val_loss: 0.7797 - val_acc: 0.7036 - lr: 0.1000\n",
            "Epoch 26/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7381 - acc: 0.7222 - val_loss: 0.9475 - val_acc: 0.6756 - lr: 0.1000\n",
            "Epoch 27/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7376 - acc: 0.7246 - val_loss: 0.8768 - val_acc: 0.6756 - lr: 0.1000\n",
            "Epoch 28/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7362 - acc: 0.7237 - val_loss: 0.7622 - val_acc: 0.7216 - lr: 0.1000\n",
            "Epoch 29/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6891 - acc: 0.7446 - val_loss: 1.0089 - val_acc: 0.6511 - lr: 0.1000\n",
            "Epoch 30/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6941 - acc: 0.7401 - val_loss: 0.8659 - val_acc: 0.6814 - lr: 0.1000\n",
            "Epoch 31/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8366 - acc: 0.6762 - val_loss: 0.9074 - val_acc: 0.6715 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6912 - acc: 0.7464 - val_loss: 0.8901 - val_acc: 0.6808 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6599 - acc: 0.7539 - val_loss: 0.8053 - val_acc: 0.7024 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6340 - acc: 0.7671 - val_loss: 0.7893 - val_acc: 0.6995 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6101 - acc: 0.7746 - val_loss: 0.7884 - val_acc: 0.7053 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5929 - acc: 0.7857 - val_loss: 0.7748 - val_acc: 0.7129 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5875 - acc: 0.7821 - val_loss: 0.7720 - val_acc: 0.7100 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5753 - acc: 0.7903 - val_loss: 0.7627 - val_acc: 0.7187 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5773 - acc: 0.7903 - val_loss: 0.7491 - val_acc: 0.7187 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5722 - acc: 0.7933 - val_loss: 0.7370 - val_acc: 0.7228 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5637 - acc: 0.7960 - val_loss: 0.7092 - val_acc: 0.7286 - lr: 0.0010\n",
            "Epoch 42/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5674 - acc: 0.7960 - val_loss: 0.7053 - val_acc: 0.7321 - lr: 0.0010\n",
            "Epoch 43/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5474 - acc: 0.8008 - val_loss: 0.7706 - val_acc: 0.7065 - lr: 0.0010\n",
            "Epoch 44/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5618 - acc: 0.7863 - val_loss: 0.7813 - val_acc: 0.7187 - lr: 0.0010\n",
            "Epoch 45/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5534 - acc: 0.8021 - val_loss: 0.6846 - val_acc: 0.7373 - lr: 0.0010\n",
            "Epoch 46/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5568 - acc: 0.7948 - val_loss: 0.7536 - val_acc: 0.7129 - lr: 0.0010\n",
            "Epoch 47/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5413 - acc: 0.8051 - val_loss: 0.6874 - val_acc: 0.7420 - lr: 0.0010\n",
            "Epoch 48/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5410 - acc: 0.8142 - val_loss: 0.7229 - val_acc: 0.7274 - lr: 0.0010\n",
            "Epoch 49/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5466 - acc: 0.7981 - val_loss: 0.7391 - val_acc: 0.7309 - lr: 0.0010\n",
            "Epoch 50/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5361 - acc: 0.8054 - val_loss: 0.7201 - val_acc: 0.7327 - lr: 0.0010\n",
            "Epoch 51/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5331 - acc: 0.8090 - val_loss: 0.7354 - val_acc: 0.7344 - lr: 0.0010\n",
            "Epoch 52/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5435 - acc: 0.8015 - val_loss: 0.7124 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 53/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5245 - acc: 0.8111 - val_loss: 0.7387 - val_acc: 0.7268 - lr: 0.0010\n",
            "Epoch 54/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5214 - acc: 0.8108 - val_loss: 0.7186 - val_acc: 0.7368 - lr: 0.0010\n",
            "Epoch 55/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5214 - acc: 0.8160 - val_loss: 0.7425 - val_acc: 0.7228 - lr: 0.0010\n",
            "Epoch 56/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5257 - acc: 0.8217 - val_loss: 0.6960 - val_acc: 0.7443 - lr: 0.0010\n",
            "Epoch 57/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5244 - acc: 0.8048 - val_loss: 0.7190 - val_acc: 0.7344 - lr: 0.0010\n",
            "Epoch 58/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5239 - acc: 0.8130 - val_loss: 0.7677 - val_acc: 0.7187 - lr: 0.0010\n",
            "Epoch 59/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5223 - acc: 0.8108 - val_loss: 0.6959 - val_acc: 0.7455 - lr: 0.0010\n",
            "Epoch 60/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5154 - acc: 0.8178 - val_loss: 0.7264 - val_acc: 0.7292 - lr: 0.0010\n",
            "Epoch 61/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5153 - acc: 0.8145 - val_loss: 0.6906 - val_acc: 0.7461 - lr: 1.0000e-05\n",
            "Epoch 62/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5172 - acc: 0.8154 - val_loss: 0.7176 - val_acc: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 63/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5199 - acc: 0.8148 - val_loss: 0.6886 - val_acc: 0.7449 - lr: 1.0000e-05\n",
            "Epoch 64/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5145 - acc: 0.8133 - val_loss: 0.7331 - val_acc: 0.7327 - lr: 1.0000e-05\n",
            "Epoch 65/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5273 - acc: 0.8051 - val_loss: 0.7030 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 66/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5131 - acc: 0.8172 - val_loss: 0.7052 - val_acc: 0.7385 - lr: 1.0000e-05\n",
            "Epoch 67/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5105 - acc: 0.8175 - val_loss: 0.7245 - val_acc: 0.7391 - lr: 1.0000e-05\n",
            "Epoch 68/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5204 - acc: 0.8148 - val_loss: 0.7406 - val_acc: 0.7385 - lr: 1.0000e-05\n",
            "Epoch 69/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5231 - acc: 0.8117 - val_loss: 0.7239 - val_acc: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 70/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5085 - acc: 0.8157 - val_loss: 0.6823 - val_acc: 0.7531 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6810 - acc: 0.7539\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.8063 - acc: 0.7086\n",
            "epsilon: 0.003 and test evaluation : 0.8063116669654846, 0.7085514664649963\n",
            "SNR: 50.2353572845459\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.8979 - acc: 0.6824\n",
            "epsilon: 0.005 and test evaluation : 0.8978674411773682, 0.6823734641075134\n",
            "SNR: 45.79806327819824\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.1458 - acc: 0.5951\n",
            "epsilon: 0.01 and test evaluation : 1.1458407640457153, 0.5951134562492371\n",
            "SNR: 39.777467250823975\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.6761 - acc: 0.4590\n",
            "epsilon: 0.02 and test evaluation : 1.6760692596435547, 0.4589877724647522\n",
            "SNR: 33.756866455078125\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/70\n",
            "26/26 [==============================] - 3s 111ms/step - loss: 1.4670 - acc: 0.2877 - val_loss: 1.4154 - val_acc: 0.3625 - lr: 0.1000\n",
            "Epoch 2/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 1.3786 - acc: 0.3755 - val_loss: 1.3472 - val_acc: 0.3735 - lr: 0.1000\n",
            "Epoch 3/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.3241 - acc: 0.3667 - val_loss: 1.3244 - val_acc: 0.3765 - lr: 0.1000\n",
            "Epoch 4/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 1.2961 - acc: 0.3782 - val_loss: 1.3182 - val_acc: 0.3596 - lr: 0.1000\n",
            "Epoch 5/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.2873 - acc: 0.4003 - val_loss: 1.3227 - val_acc: 0.3881 - lr: 0.1000\n",
            "Epoch 6/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.2669 - acc: 0.4209 - val_loss: 1.2963 - val_acc: 0.4184 - lr: 0.1000\n",
            "Epoch 7/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 1.2475 - acc: 0.4451 - val_loss: 1.3801 - val_acc: 0.4167 - lr: 0.1000\n",
            "Epoch 8/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.2263 - acc: 0.4687 - val_loss: 1.6584 - val_acc: 0.3590 - lr: 0.1000\n",
            "Epoch 9/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.1707 - acc: 0.5171 - val_loss: 1.2835 - val_acc: 0.4493 - lr: 0.1000\n",
            "Epoch 10/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1292 - acc: 0.5446 - val_loss: 1.2127 - val_acc: 0.5058 - lr: 0.1000\n",
            "Epoch 11/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.0933 - acc: 0.5529 - val_loss: 1.1559 - val_acc: 0.5344 - lr: 0.1000\n",
            "Epoch 12/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.0461 - acc: 0.5710 - val_loss: 1.1669 - val_acc: 0.5431 - lr: 0.1000\n",
            "Epoch 13/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 1.0224 - acc: 0.5879 - val_loss: 1.1898 - val_acc: 0.5157 - lr: 0.1000\n",
            "Epoch 14/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.9871 - acc: 0.6064 - val_loss: 1.0182 - val_acc: 0.5997 - lr: 0.1000\n",
            "Epoch 15/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.9548 - acc: 0.6109 - val_loss: 1.1741 - val_acc: 0.5664 - lr: 0.1000\n",
            "Epoch 16/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.9146 - acc: 0.6415 - val_loss: 1.3728 - val_acc: 0.5169 - lr: 0.1000\n",
            "Epoch 17/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.9019 - acc: 0.6433 - val_loss: 1.0152 - val_acc: 0.6166 - lr: 0.1000\n",
            "Epoch 18/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8580 - acc: 0.6611 - val_loss: 1.0387 - val_acc: 0.6037 - lr: 0.1000\n",
            "Epoch 19/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8531 - acc: 0.6632 - val_loss: 0.9670 - val_acc: 0.6480 - lr: 0.1000\n",
            "Epoch 20/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8311 - acc: 0.6766 - val_loss: 1.7095 - val_acc: 0.4942 - lr: 0.1000\n",
            "Epoch 21/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8076 - acc: 0.6844 - val_loss: 0.9493 - val_acc: 0.6655 - lr: 0.1000\n",
            "Epoch 22/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8123 - acc: 0.6787 - val_loss: 1.5283 - val_acc: 0.4330 - lr: 0.1000\n",
            "Epoch 23/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.7731 - acc: 0.7044 - val_loss: 1.1996 - val_acc: 0.5688 - lr: 0.1000\n",
            "Epoch 24/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.7415 - acc: 0.7129 - val_loss: 1.0695 - val_acc: 0.6224 - lr: 0.1000\n",
            "Epoch 25/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7724 - acc: 0.7071 - val_loss: 0.8669 - val_acc: 0.6888 - lr: 0.1000\n",
            "Epoch 26/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7360 - acc: 0.7253 - val_loss: 0.8766 - val_acc: 0.6853 - lr: 0.1000\n",
            "Epoch 27/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7425 - acc: 0.7183 - val_loss: 0.7734 - val_acc: 0.7150 - lr: 0.1000\n",
            "Epoch 28/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7315 - acc: 0.7172 - val_loss: 0.8785 - val_acc: 0.6748 - lr: 0.1000\n",
            "Epoch 29/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.7043 - acc: 0.7337 - val_loss: 0.7728 - val_acc: 0.7209 - lr: 0.1000\n",
            "Epoch 30/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.7160 - acc: 0.7192 - val_loss: 0.7804 - val_acc: 0.7179 - lr: 0.1000\n",
            "Epoch 31/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6822 - acc: 0.7356 - val_loss: 0.7640 - val_acc: 0.7179 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6693 - acc: 0.7486 - val_loss: 0.7851 - val_acc: 0.7139 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6337 - acc: 0.7555 - val_loss: 0.7411 - val_acc: 0.7209 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6275 - acc: 0.7604 - val_loss: 0.7541 - val_acc: 0.7261 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6119 - acc: 0.7809 - val_loss: 0.7334 - val_acc: 0.7319 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6012 - acc: 0.7749 - val_loss: 0.7576 - val_acc: 0.7308 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5969 - acc: 0.7809 - val_loss: 0.7298 - val_acc: 0.7337 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5955 - acc: 0.7722 - val_loss: 0.7396 - val_acc: 0.7325 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5957 - acc: 0.7752 - val_loss: 0.7318 - val_acc: 0.7348 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5874 - acc: 0.7858 - val_loss: 0.7291 - val_acc: 0.7401 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5883 - acc: 0.7773 - val_loss: 0.7214 - val_acc: 0.7401 - lr: 0.0010\n",
            "Epoch 42/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5784 - acc: 0.7927 - val_loss: 0.7442 - val_acc: 0.7413 - lr: 0.0010\n",
            "Epoch 43/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5725 - acc: 0.7885 - val_loss: 0.7168 - val_acc: 0.7401 - lr: 0.0010\n",
            "Epoch 44/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5688 - acc: 0.7909 - val_loss: 0.7238 - val_acc: 0.7407 - lr: 0.0010\n",
            "Epoch 45/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5705 - acc: 0.7897 - val_loss: 0.7152 - val_acc: 0.7436 - lr: 0.0010\n",
            "Epoch 46/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5620 - acc: 0.7840 - val_loss: 0.7393 - val_acc: 0.7348 - lr: 0.0010\n",
            "Epoch 47/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5567 - acc: 0.7949 - val_loss: 0.7212 - val_acc: 0.7459 - lr: 0.0010\n",
            "Epoch 48/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5613 - acc: 0.7933 - val_loss: 0.7225 - val_acc: 0.7413 - lr: 0.0010\n",
            "Epoch 49/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.5605 - acc: 0.7870 - val_loss: 0.7768 - val_acc: 0.7343 - lr: 0.0010\n",
            "Epoch 50/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5507 - acc: 0.8002 - val_loss: 0.7537 - val_acc: 0.7378 - lr: 0.0010\n",
            "Epoch 51/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5510 - acc: 0.7924 - val_loss: 0.7661 - val_acc: 0.7343 - lr: 0.0010\n",
            "Epoch 52/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5558 - acc: 0.7970 - val_loss: 0.7510 - val_acc: 0.7343 - lr: 0.0010\n",
            "Epoch 53/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5461 - acc: 0.7939 - val_loss: 0.7087 - val_acc: 0.7395 - lr: 0.0010\n",
            "Epoch 54/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5477 - acc: 0.7943 - val_loss: 0.7196 - val_acc: 0.7436 - lr: 0.0010\n",
            "Epoch 55/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5487 - acc: 0.7964 - val_loss: 0.7265 - val_acc: 0.7424 - lr: 0.0010\n",
            "Epoch 56/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5406 - acc: 0.7955 - val_loss: 0.6998 - val_acc: 0.7442 - lr: 0.0010\n",
            "Epoch 57/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5394 - acc: 0.7967 - val_loss: 0.7188 - val_acc: 0.7430 - lr: 0.0010\n",
            "Epoch 58/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5297 - acc: 0.8082 - val_loss: 0.7035 - val_acc: 0.7459 - lr: 0.0010\n",
            "Epoch 59/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5384 - acc: 0.8000 - val_loss: 0.7299 - val_acc: 0.7413 - lr: 0.0010\n",
            "Epoch 60/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5368 - acc: 0.7964 - val_loss: 0.7205 - val_acc: 0.7378 - lr: 0.0010\n",
            "Epoch 61/70\n",
            "26/26 [==============================] - 2s 92ms/step - loss: 0.5410 - acc: 0.8024 - val_loss: 0.7363 - val_acc: 0.7366 - lr: 1.0000e-05\n",
            "Epoch 62/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5256 - acc: 0.8006 - val_loss: 0.7311 - val_acc: 0.7465 - lr: 1.0000e-05\n",
            "Epoch 63/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5399 - acc: 0.7979 - val_loss: 0.7197 - val_acc: 0.7395 - lr: 1.0000e-05\n",
            "Epoch 64/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5356 - acc: 0.7979 - val_loss: 0.7394 - val_acc: 0.7389 - lr: 1.0000e-05\n",
            "Epoch 65/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5294 - acc: 0.8091 - val_loss: 0.7578 - val_acc: 0.7366 - lr: 1.0000e-05\n",
            "Epoch 66/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5264 - acc: 0.8012 - val_loss: 0.7211 - val_acc: 0.7383 - lr: 1.0000e-05\n",
            "Epoch 67/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5294 - acc: 0.8018 - val_loss: 0.7053 - val_acc: 0.7436 - lr: 1.0000e-05\n",
            "Epoch 68/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5269 - acc: 0.8021 - val_loss: 0.7909 - val_acc: 0.7319 - lr: 1.0000e-05\n",
            "Epoch 69/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5236 - acc: 0.8015 - val_loss: 0.7261 - val_acc: 0.7453 - lr: 1.0000e-05\n",
            "Epoch 70/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5350 - acc: 0.7997 - val_loss: 0.7378 - val_acc: 0.7448 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7035 - acc: 0.7400\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.8039 - acc: 0.7120\n",
            "epsilon: 0.003 and test evaluation : 0.8039376735687256, 0.7120419144630432\n",
            "SNR: 50.2353572845459\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.8753 - acc: 0.6859\n",
            "epsilon: 0.005 and test evaluation : 0.8753227591514587, 0.6858638525009155\n",
            "SNR: 45.79806327819824\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.0690 - acc: 0.6265\n",
            "epsilon: 0.01 and test evaluation : 1.068984866142273, 0.6265270709991455\n",
            "SNR: 39.777467250823975\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.5009 - acc: 0.4939\n",
            "epsilon: 0.02 and test evaluation : 1.5008822679519653, 0.49389180541038513\n",
            "SNR: 33.756866455078125\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/70\n",
            "26/26 [==============================] - 3s 114ms/step - loss: 1.4618 - acc: 0.3086 - val_loss: 1.4601 - val_acc: 0.2809 - lr: 0.1000\n",
            "Epoch 2/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.3885 - acc: 0.3585 - val_loss: 1.3488 - val_acc: 0.3770 - lr: 0.1000\n",
            "Epoch 3/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.3436 - acc: 0.3598 - val_loss: 1.3511 - val_acc: 0.3782 - lr: 0.1000\n",
            "Epoch 4/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.3274 - acc: 0.3694 - val_loss: 1.3463 - val_acc: 0.3712 - lr: 0.1000\n",
            "Epoch 5/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.3075 - acc: 0.3867 - val_loss: 1.4252 - val_acc: 0.3071 - lr: 0.1000\n",
            "Epoch 6/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.2943 - acc: 0.3997 - val_loss: 1.3003 - val_acc: 0.3788 - lr: 0.1000\n",
            "Epoch 7/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.2863 - acc: 0.3933 - val_loss: 1.2692 - val_acc: 0.3957 - lr: 0.1000\n",
            "Epoch 8/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2684 - acc: 0.4030 - val_loss: 1.2892 - val_acc: 0.3939 - lr: 0.1000\n",
            "Epoch 9/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2425 - acc: 0.4227 - val_loss: 1.2188 - val_acc: 0.4330 - lr: 0.1000\n",
            "Epoch 10/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2324 - acc: 0.4381 - val_loss: 1.3781 - val_acc: 0.3368 - lr: 0.1000\n",
            "Epoch 11/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2233 - acc: 0.4411 - val_loss: 1.4898 - val_acc: 0.4056 - lr: 0.1000\n",
            "Epoch 12/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2200 - acc: 0.4617 - val_loss: 1.1963 - val_acc: 0.4604 - lr: 0.1000\n",
            "Epoch 13/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1936 - acc: 0.4835 - val_loss: 1.1724 - val_acc: 0.4580 - lr: 0.1000\n",
            "Epoch 14/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1517 - acc: 0.5238 - val_loss: 1.2069 - val_acc: 0.4307 - lr: 0.1000\n",
            "Epoch 15/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.1002 - acc: 0.5483 - val_loss: 4.0493 - val_acc: 0.2220 - lr: 0.1000\n",
            "Epoch 16/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.0974 - acc: 0.5486 - val_loss: 1.7631 - val_acc: 0.3794 - lr: 0.1000\n",
            "Epoch 17/70\n",
            "26/26 [==============================] - 3s 99ms/step - loss: 1.0261 - acc: 0.5900 - val_loss: 1.0330 - val_acc: 0.5868 - lr: 0.1000\n",
            "Epoch 18/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.0251 - acc: 0.5927 - val_loss: 0.9688 - val_acc: 0.6171 - lr: 0.1000\n",
            "Epoch 19/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9490 - acc: 0.6257 - val_loss: 1.0773 - val_acc: 0.5973 - lr: 0.1000\n",
            "Epoch 20/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9076 - acc: 0.6526 - val_loss: 1.0688 - val_acc: 0.5571 - lr: 0.1000\n",
            "Epoch 21/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.9076 - acc: 0.6442 - val_loss: 0.9755 - val_acc: 0.6026 - lr: 0.1000\n",
            "Epoch 22/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8905 - acc: 0.6460 - val_loss: 0.8926 - val_acc: 0.6556 - lr: 0.1000\n",
            "Epoch 23/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.8529 - acc: 0.6759 - val_loss: 0.9255 - val_acc: 0.6311 - lr: 0.1000\n",
            "Epoch 24/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8507 - acc: 0.6641 - val_loss: 1.1197 - val_acc: 0.5629 - lr: 0.1000\n",
            "Epoch 25/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7930 - acc: 0.7029 - val_loss: 0.7826 - val_acc: 0.6888 - lr: 0.1000\n",
            "Epoch 26/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.8006 - acc: 0.6920 - val_loss: 0.7899 - val_acc: 0.6859 - lr: 0.1000\n",
            "Epoch 27/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7788 - acc: 0.7077 - val_loss: 0.9633 - val_acc: 0.6265 - lr: 0.1000\n",
            "Epoch 28/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7944 - acc: 0.6998 - val_loss: 0.9670 - val_acc: 0.5973 - lr: 0.1000\n",
            "Epoch 29/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.7732 - acc: 0.7002 - val_loss: 0.7333 - val_acc: 0.7209 - lr: 0.1000\n",
            "Epoch 30/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7454 - acc: 0.7147 - val_loss: 0.8078 - val_acc: 0.7162 - lr: 0.1000\n",
            "Epoch 31/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7529 - acc: 0.7165 - val_loss: 0.7492 - val_acc: 0.7284 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7096 - acc: 0.7319 - val_loss: 0.7066 - val_acc: 0.7383 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6817 - acc: 0.7440 - val_loss: 0.7111 - val_acc: 0.7389 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6761 - acc: 0.7486 - val_loss: 0.7005 - val_acc: 0.7401 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6532 - acc: 0.7564 - val_loss: 0.6831 - val_acc: 0.7506 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6493 - acc: 0.7477 - val_loss: 0.6741 - val_acc: 0.7529 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6393 - acc: 0.7622 - val_loss: 0.6782 - val_acc: 0.7529 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6283 - acc: 0.7604 - val_loss: 0.6792 - val_acc: 0.7541 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6305 - acc: 0.7670 - val_loss: 0.6762 - val_acc: 0.7523 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6193 - acc: 0.7631 - val_loss: 0.6762 - val_acc: 0.7512 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6126 - acc: 0.7749 - val_loss: 0.6693 - val_acc: 0.7587 - lr: 0.0010\n",
            "Epoch 42/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6131 - acc: 0.7661 - val_loss: 0.6600 - val_acc: 0.7593 - lr: 0.0010\n",
            "Epoch 43/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6031 - acc: 0.7782 - val_loss: 0.6583 - val_acc: 0.7547 - lr: 0.0010\n",
            "Epoch 44/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5967 - acc: 0.7788 - val_loss: 0.6520 - val_acc: 0.7564 - lr: 0.0010\n",
            "Epoch 45/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6030 - acc: 0.7722 - val_loss: 0.6483 - val_acc: 0.7576 - lr: 0.0010\n",
            "Epoch 46/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6078 - acc: 0.7746 - val_loss: 0.6491 - val_acc: 0.7640 - lr: 0.0010\n",
            "Epoch 47/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6011 - acc: 0.7755 - val_loss: 0.6705 - val_acc: 0.7622 - lr: 0.0010\n",
            "Epoch 48/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5921 - acc: 0.7837 - val_loss: 0.6513 - val_acc: 0.7593 - lr: 0.0010\n",
            "Epoch 49/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5929 - acc: 0.7794 - val_loss: 0.6494 - val_acc: 0.7611 - lr: 0.0010\n",
            "Epoch 50/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5823 - acc: 0.7785 - val_loss: 0.6612 - val_acc: 0.7570 - lr: 0.0010\n",
            "Epoch 51/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5782 - acc: 0.7809 - val_loss: 0.6453 - val_acc: 0.7640 - lr: 0.0010\n",
            "Epoch 52/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5718 - acc: 0.7912 - val_loss: 0.6483 - val_acc: 0.7640 - lr: 0.0010\n",
            "Epoch 53/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5816 - acc: 0.7870 - val_loss: 0.6406 - val_acc: 0.7640 - lr: 0.0010\n",
            "Epoch 54/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5788 - acc: 0.7879 - val_loss: 0.6431 - val_acc: 0.7593 - lr: 0.0010\n",
            "Epoch 55/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5664 - acc: 0.7882 - val_loss: 0.6468 - val_acc: 0.7576 - lr: 0.0010\n",
            "Epoch 56/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5770 - acc: 0.7837 - val_loss: 0.6458 - val_acc: 0.7640 - lr: 0.0010\n",
            "Epoch 57/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5603 - acc: 0.7927 - val_loss: 0.6439 - val_acc: 0.7652 - lr: 0.0010\n",
            "Epoch 58/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5732 - acc: 0.7873 - val_loss: 0.6549 - val_acc: 0.7622 - lr: 0.0010\n",
            "Epoch 59/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5722 - acc: 0.7873 - val_loss: 0.6470 - val_acc: 0.7611 - lr: 0.0010\n",
            "Epoch 60/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5561 - acc: 0.7970 - val_loss: 0.6388 - val_acc: 0.7710 - lr: 0.0010\n",
            "Epoch 61/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5669 - acc: 0.7970 - val_loss: 0.6525 - val_acc: 0.7599 - lr: 1.0000e-05\n",
            "Epoch 62/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5657 - acc: 0.7927 - val_loss: 0.6560 - val_acc: 0.7541 - lr: 1.0000e-05\n",
            "Epoch 63/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5710 - acc: 0.7834 - val_loss: 0.6442 - val_acc: 0.7652 - lr: 1.0000e-05\n",
            "Epoch 64/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5718 - acc: 0.7882 - val_loss: 0.6486 - val_acc: 0.7611 - lr: 1.0000e-05\n",
            "Epoch 65/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5525 - acc: 0.7988 - val_loss: 0.6577 - val_acc: 0.7599 - lr: 1.0000e-05\n",
            "Epoch 66/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.5650 - acc: 0.7909 - val_loss: 0.6462 - val_acc: 0.7622 - lr: 1.0000e-05\n",
            "Epoch 67/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5648 - acc: 0.7952 - val_loss: 0.6427 - val_acc: 0.7646 - lr: 1.0000e-05\n",
            "Epoch 68/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5565 - acc: 0.7918 - val_loss: 0.6448 - val_acc: 0.7640 - lr: 1.0000e-05\n",
            "Epoch 69/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5483 - acc: 0.8054 - val_loss: 0.6408 - val_acc: 0.7652 - lr: 1.0000e-05\n",
            "Epoch 70/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5507 - acc: 0.8018 - val_loss: 0.6411 - val_acc: 0.7681 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6617 - acc: 0.7609\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7771 - acc: 0.7016\n",
            "epsilon: 0.003 and test evaluation : 0.7771152853965759, 0.7015706896781921\n",
            "SNR: 50.2353572845459\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.8607 - acc: 0.6719\n",
            "epsilon: 0.005 and test evaluation : 0.8607445359230042, 0.6719022393226624\n",
            "SNR: 45.79806327819824\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.0887 - acc: 0.5846\n",
            "epsilon: 0.01 and test evaluation : 1.0887192487716675, 0.584642231464386\n",
            "SNR: 39.777467250823975\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.5841 - acc: 0.4398\n",
            "epsilon: 0.02 and test evaluation : 1.584057331085205, 0.4397905766963959\n",
            "SNR: 33.756866455078125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5KYPHDImp62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df[\"acc_clean_mean\"]= np.sum(result_df['acc_clean'])/3.0\n",
        "result_df[\"acc_0.003_mean\"]= np.sum(result_df['acc1'])/3.0\n",
        "result_df[\"acc_0.005_mean\"]= np.sum(result_df['acc2'])/3.0\n",
        "result_df[\"acc_0.02_mean\"]= np.sum(result_df['acc3'])/3.0\n",
        "result_df[\"acc_0.01_mean\"]= np.sum(result_df['acc4'])/3.0"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihcS6J2vzv6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "b3a36677-7271-43a4-ce84-e5ee86b89250"
      },
      "source": [
        "result_df.head(1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>loss4</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc_clean_mean</th>\n",
              "      <th>acc_0.003_mean</th>\n",
              "      <th>acc_0.005_mean</th>\n",
              "      <th>acc_0.02_mean</th>\n",
              "      <th>acc_0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.681034</td>\n",
              "      <td>0.753927</td>\n",
              "      <td>0.806312</td>\n",
              "      <td>0.708551</td>\n",
              "      <td>0.897867</td>\n",
              "      <td>0.682373</td>\n",
              "      <td>1.145841</td>\n",
              "      <td>0.595113</td>\n",
              "      <td>1.676069</td>\n",
              "      <td>0.458988</td>\n",
              "      <td>0.7516</td>\n",
              "      <td>0.707388</td>\n",
              "      <td>0.680047</td>\n",
              "      <td>0.602094</td>\n",
              "      <td>0.464223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  ...  acc_0.02_mean  acc_0.01_mean\n",
              "0    0.681034   0.753927  ...       0.602094       0.464223\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC_90XJcmu5l",
        "colab_type": "text"
      },
      "source": [
        "# **Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7m-n2RCmyse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Adversarial Training \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "class AdversarialTraining(object):\n",
        "    \"\"\"Adversarial Training  \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def train(self, pretrained_model, X_train, Y_train, X_test, y_test, epochs, BS, epsilon_list, sgd):\n",
        "        init = (32, 32,1)\n",
        "        res_df = pd.DataFrame(columns=['loss_clean','acc_clean',\n",
        "                                 'loss1', 'acc1','loss2', 'acc2','loss3',\n",
        "                                  'acc3','loss4', 'acc4'])\n",
        "\n",
        "        kfold = KFold(n_splits = 3, random_state = 42)\n",
        "        for j, (train, val) in enumerate(kfold.split(X_train)):\n",
        "          x_train, y_train = self.data_augmentation(X_train[train], Y_train[train], BS, pretrained_model, epsilon_list)\n",
        "          x_val, y_val = self.data_augmentation(X_train[val], Y_train[val], BS, pretrained_model, epsilon_list)\n",
        "          model = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "          model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "          hist = model.fit(generator.flow(x_train, y_train, batch_size=BS), steps_per_epoch=len(x_train) // BS, epochs=epochs,\n",
        "                          callbacks = [lr_scheduler],\n",
        "                          validation_data=(x_val, y_val),\n",
        "                          validation_steps=x_val.shape[0] // BS,)\n",
        "          loss, acc = model.evaluate(X_test, y_test)\n",
        "          loss1, acc1 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[0]),X_test, y_test, epsilon_list[0])\n",
        "          loss2, acc2 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[1]),X_test, y_test, epsilon_list[1])\n",
        "          loss3, acc3 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[2]),X_test, y_test, epsilon_list[2])\n",
        "          loss4, acc4 = print_test(model, get_adversarial_examples(pretrained_model, X_test, y_test, epsilon_list[3]),X_test, y_test, epsilon_list[3])\n",
        "          row = {'loss_clean':loss,'acc_clean':acc, 'loss1':loss1, 'acc1':acc1, 'loss2':loss2,\n",
        "                  'acc2':acc2, 'loss3':loss3, 'acc3':acc3, 'loss4':loss4, 'acc4':acc4}\n",
        "          res_df = res_df.append(row , ignore_index=True)\n",
        "          \n",
        "        return res_df\n",
        "    def mini_batch_train(self, model, X_train,y_train, x_val, y_val, BS, pretrained_model, epsilon):\n",
        "\n",
        "\n",
        "        hist = model.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=1,\n",
        "                   validation_data=(x_val, y_val),\n",
        "                   validation_steps=x_val.shape[0] // BS, shuffle = True)\n",
        "        \n",
        "        ### TODO ###\n",
        "        ## Save hist on file.###\n",
        "\n",
        "\n",
        "    def data_augmentation(self, X_train, Y_train, batch_size, pretrained_model, epsilon_list):\n",
        "      ### divide data 16,16,16,16 for 4 different epsilons and 64 is true image. ### \n",
        "        #start_index = self.data_iteration(X_train, batch_size)\n",
        "        first_half_end = int(len(X_train)/2)\n",
        "        second_half_end = int(len(X_train))\n",
        "        x_clean = X_train[0:first_half_end,:,:,:]\n",
        "        x_adv = self.get_adversarial(X_train[first_half_end:second_half_end,:,:,:], Y_train[first_half_end:second_half_end], epsilon_list)\n",
        "        x_mix = self.merge_data(x_clean, x_adv)\n",
        "        y_mix = Y_train[0:second_half_end]\n",
        "        ### TODO###\n",
        "        # Mixture data for 4 epsilon values\n",
        "\n",
        "        return x_mix, y_mix\n",
        "\n",
        "    def data_iteration(self, X_train, batch_size):\n",
        "        N = X_train.shape[0]\n",
        "        start = np.random.randint(0, N-batch_size)\n",
        "        return start\n",
        "\n",
        "    def merge_data(self, x_clean, x_adv):\n",
        "        x_mix = []\n",
        "        for i in range(len(x_clean)):\n",
        "          x_mix.append(x_clean[i])\n",
        "        for j in range(len(x_adv)):\n",
        "          x_mix.append(x_adv[j])\n",
        "        x_mix = np.array(x_mix)\n",
        "\n",
        "        return x_mix\n",
        "\n",
        "\n",
        "    def get_adversarial(self, X_true, y_true, epsilon_list):\n",
        "\n",
        "        return self.adversarial_example(X_true, y_true, epsilon_list)\n",
        "\n",
        "    def adversarial_example(self, X_true, Y_true, epsilon_list):\n",
        "        size = len(X_true)\n",
        "        X_adv = []\n",
        "        interval = int(size/4)\n",
        "        index_list = [0,interval, interval*2, interval*3, size]\n",
        "        index = 0\n",
        "        for epsilon in epsilon_list:\n",
        "          if index == 4:\n",
        "            break\n",
        "          x_true = X_true[index_list[index]:index_list[index+1],:,:,:]\n",
        "          y_true = Y_true[index_list[index]:index_list[index+1]]\n",
        "\n",
        "          index = index + 1\n",
        "\n",
        "          for i in range(len(x_true)):\n",
        "            random_index = i\n",
        "            original_image = x_true[random_index]\n",
        "            original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "            original_label = y_true[random_index]\n",
        "            original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "            adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "            X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "          \n",
        "        X_adv = np.array(X_adv)\n",
        "        return X_adv\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swjxYRDJm5Iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56d95163-b3ef-4cc4-8b0d-b4da4b588041"
      },
      "source": [
        "epsilon_list = [0.003,0.005,0.01,0.02]\n",
        "adversarial_training =  AdversarialTraining()\n",
        "sgd = SGD(lr=0.1, momentum=0.6)\n",
        "logits_model = tf.keras.Model(parseval_16_2.input, parseval_16_2.layers[-1].output)\n",
        "result_adv_df = adversarial_training.train(logits_model, X_train, Y_train, X_test, y_test, EPOCHS, BS, epsilon_list, sgd)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/70\n",
            "26/26 [==============================] - 3s 117ms/step - loss: 1.4617 - acc: 0.3287 - val_loss: 1.4115 - val_acc: 0.3593 - lr: 0.1000\n",
            "Epoch 2/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 1.3745 - acc: 0.3720 - val_loss: 1.3623 - val_acc: 0.3541 - lr: 0.1000\n",
            "Epoch 3/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 1.3411 - acc: 0.3771 - val_loss: 1.3179 - val_acc: 0.3762 - lr: 0.1000\n",
            "Epoch 4/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 1.3208 - acc: 0.3789 - val_loss: 1.3277 - val_acc: 0.3582 - lr: 0.1000\n",
            "Epoch 5/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.3137 - acc: 0.3804 - val_loss: 1.2639 - val_acc: 0.3809 - lr: 0.1000\n",
            "Epoch 6/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 1.2815 - acc: 0.4019 - val_loss: 1.2784 - val_acc: 0.4321 - lr: 0.1000\n",
            "Epoch 7/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.2861 - acc: 0.4071 - val_loss: 1.3123 - val_acc: 0.3914 - lr: 0.1000\n",
            "Epoch 8/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2632 - acc: 0.4234 - val_loss: 1.2546 - val_acc: 0.4409 - lr: 0.1000\n",
            "Epoch 9/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.2539 - acc: 0.4319 - val_loss: 1.2069 - val_acc: 0.4688 - lr: 0.1000\n",
            "Epoch 10/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.2308 - acc: 0.4570 - val_loss: 1.1742 - val_acc: 0.5195 - lr: 0.1000\n",
            "Epoch 11/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 1.1763 - acc: 0.5127 - val_loss: 1.1382 - val_acc: 0.5271 - lr: 0.1000\n",
            "Epoch 12/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 1.1592 - acc: 0.5176 - val_loss: 1.1464 - val_acc: 0.4980 - lr: 0.1000\n",
            "Epoch 13/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1105 - acc: 0.5393 - val_loss: 1.0369 - val_acc: 0.5696 - lr: 0.1000\n",
            "Epoch 14/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.0507 - acc: 0.5748 - val_loss: 1.0934 - val_acc: 0.5667 - lr: 0.1000\n",
            "Epoch 15/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.0417 - acc: 0.5763 - val_loss: 2.0562 - val_acc: 0.3809 - lr: 0.1000\n",
            "Epoch 16/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9961 - acc: 0.6017 - val_loss: 1.0851 - val_acc: 0.5579 - lr: 0.1000\n",
            "Epoch 17/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9822 - acc: 0.6156 - val_loss: 1.0419 - val_acc: 0.5562 - lr: 0.1000\n",
            "Epoch 18/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.9427 - acc: 0.6183 - val_loss: 1.0519 - val_acc: 0.5614 - lr: 0.1000\n",
            "Epoch 19/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.9115 - acc: 0.6438 - val_loss: 1.0973 - val_acc: 0.5667 - lr: 0.1000\n",
            "Epoch 20/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.9049 - acc: 0.6465 - val_loss: 0.8817 - val_acc: 0.6564 - lr: 0.1000\n",
            "Epoch 21/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.8816 - acc: 0.6501 - val_loss: 1.0009 - val_acc: 0.6197 - lr: 0.1000\n",
            "Epoch 22/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.8394 - acc: 0.6749 - val_loss: 0.9985 - val_acc: 0.6232 - lr: 0.1000\n",
            "Epoch 23/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.8430 - acc: 0.6728 - val_loss: 1.0405 - val_acc: 0.6377 - lr: 0.1000\n",
            "Epoch 24/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8021 - acc: 0.6964 - val_loss: 0.8545 - val_acc: 0.6872 - lr: 0.1000\n",
            "Epoch 25/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8062 - acc: 0.6825 - val_loss: 0.9997 - val_acc: 0.6040 - lr: 0.1000\n",
            "Epoch 26/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8055 - acc: 0.6804 - val_loss: 1.0859 - val_acc: 0.6214 - lr: 0.1000\n",
            "Epoch 27/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7903 - acc: 0.6961 - val_loss: 1.1600 - val_acc: 0.5527 - lr: 0.1000\n",
            "Epoch 28/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7915 - acc: 0.6931 - val_loss: 0.9098 - val_acc: 0.6634 - lr: 0.1000\n",
            "Epoch 29/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.7649 - acc: 0.7079 - val_loss: 1.1864 - val_acc: 0.5906 - lr: 0.1000\n",
            "Epoch 30/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.7643 - acc: 0.7064 - val_loss: 0.8231 - val_acc: 0.6843 - lr: 0.1000\n",
            "Epoch 31/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7350 - acc: 0.7246 - val_loss: 0.8226 - val_acc: 0.6872 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6947 - acc: 0.7424 - val_loss: 0.8418 - val_acc: 0.6942 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.6929 - acc: 0.7385 - val_loss: 0.8228 - val_acc: 0.6989 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6762 - acc: 0.7461 - val_loss: 0.8021 - val_acc: 0.6989 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.6673 - acc: 0.7530 - val_loss: 0.7857 - val_acc: 0.7047 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6492 - acc: 0.7567 - val_loss: 0.7899 - val_acc: 0.7036 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6507 - acc: 0.7599 - val_loss: 0.7806 - val_acc: 0.7076 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6547 - acc: 0.7624 - val_loss: 0.7985 - val_acc: 0.7030 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6459 - acc: 0.7582 - val_loss: 0.8139 - val_acc: 0.7070 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6307 - acc: 0.7712 - val_loss: 0.7804 - val_acc: 0.7100 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6388 - acc: 0.7715 - val_loss: 0.7745 - val_acc: 0.7094 - lr: 0.0010\n",
            "Epoch 42/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6273 - acc: 0.7663 - val_loss: 0.7628 - val_acc: 0.7129 - lr: 0.0010\n",
            "Epoch 43/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.6300 - acc: 0.7733 - val_loss: 0.8091 - val_acc: 0.7065 - lr: 0.0010\n",
            "Epoch 44/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6225 - acc: 0.7663 - val_loss: 0.8016 - val_acc: 0.7117 - lr: 0.0010\n",
            "Epoch 45/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6157 - acc: 0.7772 - val_loss: 0.7566 - val_acc: 0.7210 - lr: 0.0010\n",
            "Epoch 46/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.6204 - acc: 0.7745 - val_loss: 0.7856 - val_acc: 0.7100 - lr: 0.0010\n",
            "Epoch 47/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6188 - acc: 0.7691 - val_loss: 0.7428 - val_acc: 0.7187 - lr: 0.0010\n",
            "Epoch 48/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6056 - acc: 0.7797 - val_loss: 0.8028 - val_acc: 0.7094 - lr: 0.0010\n",
            "Epoch 49/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6148 - acc: 0.7766 - val_loss: 0.7675 - val_acc: 0.7135 - lr: 0.0010\n",
            "Epoch 50/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6188 - acc: 0.7745 - val_loss: 0.7707 - val_acc: 0.7187 - lr: 0.0010\n",
            "Epoch 51/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.5952 - acc: 0.7781 - val_loss: 0.7571 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 52/70\n",
            "26/26 [==============================] - 3s 99ms/step - loss: 0.6050 - acc: 0.7751 - val_loss: 0.7376 - val_acc: 0.7280 - lr: 0.0010\n",
            "Epoch 53/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5916 - acc: 0.7815 - val_loss: 0.7522 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 54/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5941 - acc: 0.7818 - val_loss: 0.7904 - val_acc: 0.7158 - lr: 0.0010\n",
            "Epoch 55/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5981 - acc: 0.7857 - val_loss: 0.7668 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 56/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5871 - acc: 0.7830 - val_loss: 0.7508 - val_acc: 0.7228 - lr: 0.0010\n",
            "Epoch 57/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5968 - acc: 0.7760 - val_loss: 0.7322 - val_acc: 0.7251 - lr: 0.0010\n",
            "Epoch 58/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5829 - acc: 0.7836 - val_loss: 0.7744 - val_acc: 0.7216 - lr: 0.0010\n",
            "Epoch 59/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5944 - acc: 0.7766 - val_loss: 0.7562 - val_acc: 0.7216 - lr: 0.0010\n",
            "Epoch 60/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5853 - acc: 0.7769 - val_loss: 0.7541 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 61/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5835 - acc: 0.7857 - val_loss: 0.7532 - val_acc: 0.7210 - lr: 1.0000e-05\n",
            "Epoch 62/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5856 - acc: 0.7858 - val_loss: 0.7515 - val_acc: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 63/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5885 - acc: 0.7875 - val_loss: 0.7603 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 64/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5812 - acc: 0.7806 - val_loss: 0.7637 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 65/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5877 - acc: 0.7751 - val_loss: 0.7506 - val_acc: 0.7193 - lr: 1.0000e-05\n",
            "Epoch 66/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5782 - acc: 0.7839 - val_loss: 0.7434 - val_acc: 0.7234 - lr: 1.0000e-05\n",
            "Epoch 67/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5840 - acc: 0.7833 - val_loss: 0.7557 - val_acc: 0.7286 - lr: 1.0000e-05\n",
            "Epoch 68/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5888 - acc: 0.7800 - val_loss: 0.7750 - val_acc: 0.7181 - lr: 1.0000e-05\n",
            "Epoch 69/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5831 - acc: 0.7915 - val_loss: 0.7363 - val_acc: 0.7245 - lr: 1.0000e-05\n",
            "Epoch 70/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5821 - acc: 0.7791 - val_loss: 0.7296 - val_acc: 0.7239 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6406 - acc: 0.7679\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6660 - acc: 0.7557\n",
            "epsilon: 0.003 and test evaluation : 0.6659995317459106, 0.7556719183921814\n",
            "SNR: 50.2353572845459\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6837 - acc: 0.7435\n",
            "epsilon: 0.005 and test evaluation : 0.6837051510810852, 0.7434554696083069\n",
            "SNR: 45.79806327819824\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7303 - acc: 0.7208\n",
            "epsilon: 0.01 and test evaluation : 0.7302854061126709, 0.7207679152488708\n",
            "SNR: 39.777467250823975\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.8337 - acc: 0.6736\n",
            "epsilon: 0.02 and test evaluation : 0.8336511850357056, 0.6736474633216858\n",
            "SNR: 33.756866455078125\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/70\n",
            "26/26 [==============================] - 3s 113ms/step - loss: 1.4623 - acc: 0.3144 - val_loss: 1.4196 - val_acc: 0.3526 - lr: 0.1000\n",
            "Epoch 2/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.3772 - acc: 0.3661 - val_loss: 1.4312 - val_acc: 0.3572 - lr: 0.1000\n",
            "Epoch 3/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.3335 - acc: 0.3661 - val_loss: 1.3286 - val_acc: 0.3677 - lr: 0.1000\n",
            "Epoch 4/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.3064 - acc: 0.3828 - val_loss: 1.5192 - val_acc: 0.3293 - lr: 0.1000\n",
            "Epoch 5/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.2893 - acc: 0.3964 - val_loss: 1.3654 - val_acc: 0.3287 - lr: 0.1000\n",
            "Epoch 6/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2728 - acc: 0.4042 - val_loss: 1.2858 - val_acc: 0.4324 - lr: 0.1000\n",
            "Epoch 7/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.2484 - acc: 0.4272 - val_loss: 1.2867 - val_acc: 0.4248 - lr: 0.1000\n",
            "Epoch 8/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2382 - acc: 0.4351 - val_loss: 1.3281 - val_acc: 0.3741 - lr: 0.1000\n",
            "Epoch 9/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 1.2260 - acc: 0.4684 - val_loss: 1.2271 - val_acc: 0.4604 - lr: 0.1000\n",
            "Epoch 10/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1759 - acc: 0.5023 - val_loss: 1.3948 - val_acc: 0.4295 - lr: 0.1000\n",
            "Epoch 11/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.1521 - acc: 0.5120 - val_loss: 1.1662 - val_acc: 0.5041 - lr: 0.1000\n",
            "Epoch 12/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1137 - acc: 0.5452 - val_loss: 1.1850 - val_acc: 0.5140 - lr: 0.1000\n",
            "Epoch 13/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.0990 - acc: 0.5540 - val_loss: 1.3434 - val_acc: 0.5192 - lr: 0.1000\n",
            "Epoch 14/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.0709 - acc: 0.5558 - val_loss: 1.1923 - val_acc: 0.5076 - lr: 0.1000\n",
            "Epoch 15/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.0525 - acc: 0.5710 - val_loss: 1.0960 - val_acc: 0.5478 - lr: 0.1000\n",
            "Epoch 16/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.0402 - acc: 0.5746 - val_loss: 1.0357 - val_acc: 0.5874 - lr: 0.1000\n",
            "Epoch 17/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.0058 - acc: 0.5943 - val_loss: 1.4834 - val_acc: 0.4965 - lr: 0.1000\n",
            "Epoch 18/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9992 - acc: 0.6030 - val_loss: 1.1244 - val_acc: 0.5431 - lr: 0.1000\n",
            "Epoch 19/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9737 - acc: 0.6076 - val_loss: 1.0379 - val_acc: 0.5810 - lr: 0.1000\n",
            "Epoch 20/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.9322 - acc: 0.6297 - val_loss: 1.5539 - val_acc: 0.4872 - lr: 0.1000\n",
            "Epoch 21/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.9182 - acc: 0.6324 - val_loss: 1.2011 - val_acc: 0.5769 - lr: 0.1000\n",
            "Epoch 22/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.8671 - acc: 0.6523 - val_loss: 1.0253 - val_acc: 0.6160 - lr: 0.1000\n",
            "Epoch 23/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8674 - acc: 0.6617 - val_loss: 0.9098 - val_acc: 0.6428 - lr: 0.1000\n",
            "Epoch 24/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8517 - acc: 0.6641 - val_loss: 0.8907 - val_acc: 0.6515 - lr: 0.1000\n",
            "Epoch 25/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8418 - acc: 0.6651 - val_loss: 1.1791 - val_acc: 0.5862 - lr: 0.1000\n",
            "Epoch 26/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8320 - acc: 0.6711 - val_loss: 1.0052 - val_acc: 0.6259 - lr: 0.1000\n",
            "Epoch 27/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8103 - acc: 0.6850 - val_loss: 0.9254 - val_acc: 0.6731 - lr: 0.1000\n",
            "Epoch 28/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7817 - acc: 0.6932 - val_loss: 0.8721 - val_acc: 0.6731 - lr: 0.1000\n",
            "Epoch 29/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.8020 - acc: 0.6893 - val_loss: 0.9080 - val_acc: 0.6719 - lr: 0.1000\n",
            "Epoch 30/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.7726 - acc: 0.7047 - val_loss: 0.8758 - val_acc: 0.6579 - lr: 0.1000\n",
            "Epoch 31/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7851 - acc: 0.6917 - val_loss: 0.9237 - val_acc: 0.6568 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7620 - acc: 0.7077 - val_loss: 0.8288 - val_acc: 0.6871 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7272 - acc: 0.7186 - val_loss: 0.8341 - val_acc: 0.6818 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7116 - acc: 0.7295 - val_loss: 0.7784 - val_acc: 0.7040 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7059 - acc: 0.7343 - val_loss: 0.7787 - val_acc: 0.7086 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6893 - acc: 0.7362 - val_loss: 0.8043 - val_acc: 0.6993 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6823 - acc: 0.7440 - val_loss: 0.8026 - val_acc: 0.7080 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6733 - acc: 0.7474 - val_loss: 0.8161 - val_acc: 0.6941 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.6628 - acc: 0.7510 - val_loss: 0.7548 - val_acc: 0.7232 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6644 - acc: 0.7546 - val_loss: 0.8316 - val_acc: 0.6894 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6589 - acc: 0.7501 - val_loss: 0.7750 - val_acc: 0.7115 - lr: 0.0010\n",
            "Epoch 42/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6619 - acc: 0.7537 - val_loss: 0.8027 - val_acc: 0.7115 - lr: 0.0010\n",
            "Epoch 43/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6458 - acc: 0.7576 - val_loss: 0.7800 - val_acc: 0.7115 - lr: 0.0010\n",
            "Epoch 44/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6504 - acc: 0.7567 - val_loss: 0.7778 - val_acc: 0.7179 - lr: 0.0010\n",
            "Epoch 45/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6497 - acc: 0.7513 - val_loss: 0.8042 - val_acc: 0.7069 - lr: 0.0010\n",
            "Epoch 46/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6473 - acc: 0.7564 - val_loss: 0.8132 - val_acc: 0.7022 - lr: 0.0010\n",
            "Epoch 47/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6353 - acc: 0.7622 - val_loss: 0.8134 - val_acc: 0.7092 - lr: 0.0010\n",
            "Epoch 48/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6424 - acc: 0.7598 - val_loss: 0.7958 - val_acc: 0.7127 - lr: 0.0010\n",
            "Epoch 49/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6371 - acc: 0.7637 - val_loss: 0.7977 - val_acc: 0.7133 - lr: 0.0010\n",
            "Epoch 50/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6383 - acc: 0.7560 - val_loss: 0.8088 - val_acc: 0.7115 - lr: 0.0010\n",
            "Epoch 51/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6207 - acc: 0.7755 - val_loss: 0.8100 - val_acc: 0.7051 - lr: 0.0010\n",
            "Epoch 52/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6278 - acc: 0.7643 - val_loss: 0.7873 - val_acc: 0.7156 - lr: 0.0010\n",
            "Epoch 53/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6276 - acc: 0.7607 - val_loss: 0.7803 - val_acc: 0.7127 - lr: 0.0010\n",
            "Epoch 54/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6286 - acc: 0.7661 - val_loss: 0.8079 - val_acc: 0.7127 - lr: 0.0010\n",
            "Epoch 55/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6223 - acc: 0.7664 - val_loss: 0.7758 - val_acc: 0.7174 - lr: 0.0010\n",
            "Epoch 56/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6160 - acc: 0.7649 - val_loss: 0.7889 - val_acc: 0.7133 - lr: 0.0010\n",
            "Epoch 57/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6221 - acc: 0.7658 - val_loss: 0.7826 - val_acc: 0.7214 - lr: 0.0010\n",
            "Epoch 58/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6167 - acc: 0.7634 - val_loss: 0.8328 - val_acc: 0.7045 - lr: 0.0010\n",
            "Epoch 59/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.6234 - acc: 0.7619 - val_loss: 0.7899 - val_acc: 0.7139 - lr: 0.0010\n",
            "Epoch 60/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6167 - acc: 0.7658 - val_loss: 0.7859 - val_acc: 0.7185 - lr: 0.0010\n",
            "Epoch 61/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6100 - acc: 0.7676 - val_loss: 0.7654 - val_acc: 0.7226 - lr: 1.0000e-05\n",
            "Epoch 62/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6152 - acc: 0.7679 - val_loss: 0.7811 - val_acc: 0.7226 - lr: 1.0000e-05\n",
            "Epoch 63/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6192 - acc: 0.7617 - val_loss: 0.7783 - val_acc: 0.7191 - lr: 1.0000e-05\n",
            "Epoch 64/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.6120 - acc: 0.7758 - val_loss: 0.7879 - val_acc: 0.7156 - lr: 1.0000e-05\n",
            "Epoch 65/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6069 - acc: 0.7728 - val_loss: 0.7819 - val_acc: 0.7179 - lr: 1.0000e-05\n",
            "Epoch 66/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6127 - acc: 0.7746 - val_loss: 0.7893 - val_acc: 0.7168 - lr: 1.0000e-05\n",
            "Epoch 67/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6216 - acc: 0.7658 - val_loss: 0.8310 - val_acc: 0.7051 - lr: 1.0000e-05\n",
            "Epoch 68/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6257 - acc: 0.7661 - val_loss: 0.8201 - val_acc: 0.7092 - lr: 1.0000e-05\n",
            "Epoch 69/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6165 - acc: 0.7644 - val_loss: 0.8114 - val_acc: 0.7075 - lr: 1.0000e-05\n",
            "Epoch 70/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5996 - acc: 0.7731 - val_loss: 0.7771 - val_acc: 0.7226 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7019 - acc: 0.7382\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7254 - acc: 0.7260\n",
            "epsilon: 0.003 and test evaluation : 0.7254215478897095, 0.7260034680366516\n",
            "SNR: 50.2353572845459\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7416 - acc: 0.7190\n",
            "epsilon: 0.005 and test evaluation : 0.7415654063224792, 0.7190226912498474\n",
            "SNR: 45.79806327819824\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7838 - acc: 0.7033\n",
            "epsilon: 0.01 and test evaluation : 0.7838426232337952, 0.7033158540725708\n",
            "SNR: 39.777467250823975\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8765 - acc: 0.6632\n",
            "epsilon: 0.02 and test evaluation : 0.8764724731445312, 0.6631762385368347\n",
            "SNR: 33.756866455078125\n",
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Epoch 1/70\n",
            "26/26 [==============================] - 3s 113ms/step - loss: 1.4662 - acc: 0.3147 - val_loss: 1.4668 - val_acc: 0.2809 - lr: 0.1000\n",
            "Epoch 2/70\n",
            "26/26 [==============================] - 3s 99ms/step - loss: 1.3849 - acc: 0.3567 - val_loss: 1.3640 - val_acc: 0.3584 - lr: 0.1000\n",
            "Epoch 3/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.3450 - acc: 0.3676 - val_loss: 1.3604 - val_acc: 0.3735 - lr: 0.1000\n",
            "Epoch 4/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.3201 - acc: 0.3812 - val_loss: 1.2991 - val_acc: 0.3875 - lr: 0.1000\n",
            "Epoch 5/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.3013 - acc: 0.3818 - val_loss: 1.2981 - val_acc: 0.3899 - lr: 0.1000\n",
            "Epoch 6/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 1.2915 - acc: 0.3976 - val_loss: 1.3493 - val_acc: 0.3601 - lr: 0.1000\n",
            "Epoch 7/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 1.2774 - acc: 0.4182 - val_loss: 1.5039 - val_acc: 0.3357 - lr: 0.1000\n",
            "Epoch 8/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2588 - acc: 0.4369 - val_loss: 1.2860 - val_acc: 0.3805 - lr: 0.1000\n",
            "Epoch 9/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.2246 - acc: 0.4617 - val_loss: 1.4600 - val_acc: 0.3549 - lr: 0.1000\n",
            "Epoch 10/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 1.1957 - acc: 0.4923 - val_loss: 1.1481 - val_acc: 0.5315 - lr: 0.1000\n",
            "Epoch 11/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.1670 - acc: 0.5174 - val_loss: 1.1283 - val_acc: 0.5385 - lr: 0.1000\n",
            "Epoch 12/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.1426 - acc: 0.5274 - val_loss: 1.5778 - val_acc: 0.3572 - lr: 0.1000\n",
            "Epoch 13/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 1.0774 - acc: 0.5604 - val_loss: 1.1783 - val_acc: 0.4953 - lr: 0.1000\n",
            "Epoch 14/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 1.1018 - acc: 0.5483 - val_loss: 1.1579 - val_acc: 0.5012 - lr: 0.1000\n",
            "Epoch 15/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 1.0264 - acc: 0.5882 - val_loss: 1.0648 - val_acc: 0.5775 - lr: 0.1000\n",
            "Epoch 16/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.9860 - acc: 0.6070 - val_loss: 0.9975 - val_acc: 0.6020 - lr: 0.1000\n",
            "Epoch 17/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9700 - acc: 0.6130 - val_loss: 0.9889 - val_acc: 0.5892 - lr: 0.1000\n",
            "Epoch 18/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.9420 - acc: 0.6281 - val_loss: 0.9736 - val_acc: 0.6393 - lr: 0.1000\n",
            "Epoch 19/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.9149 - acc: 0.6505 - val_loss: 1.0847 - val_acc: 0.5688 - lr: 0.1000\n",
            "Epoch 20/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8906 - acc: 0.6602 - val_loss: 1.3340 - val_acc: 0.5128 - lr: 0.1000\n",
            "Epoch 21/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8752 - acc: 0.6499 - val_loss: 0.9460 - val_acc: 0.6294 - lr: 0.1000\n",
            "Epoch 22/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8609 - acc: 0.6557 - val_loss: 0.8188 - val_acc: 0.6772 - lr: 0.1000\n",
            "Epoch 23/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.8322 - acc: 0.6778 - val_loss: 0.8388 - val_acc: 0.6760 - lr: 0.1000\n",
            "Epoch 24/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.8114 - acc: 0.6896 - val_loss: 0.8041 - val_acc: 0.6824 - lr: 0.1000\n",
            "Epoch 25/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.8166 - acc: 0.6890 - val_loss: 0.8989 - val_acc: 0.6853 - lr: 0.1000\n",
            "Epoch 26/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7880 - acc: 0.6908 - val_loss: 0.9783 - val_acc: 0.6235 - lr: 0.1000\n",
            "Epoch 27/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7793 - acc: 0.7056 - val_loss: 0.9431 - val_acc: 0.6241 - lr: 0.1000\n",
            "Epoch 28/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7805 - acc: 0.6947 - val_loss: 0.7654 - val_acc: 0.7040 - lr: 0.1000\n",
            "Epoch 29/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7500 - acc: 0.7148 - val_loss: 1.3219 - val_acc: 0.5612 - lr: 0.1000\n",
            "Epoch 30/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7552 - acc: 0.7098 - val_loss: 0.9786 - val_acc: 0.6043 - lr: 0.1000\n",
            "Epoch 31/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.8646 - acc: 0.6666 - val_loss: 0.8946 - val_acc: 0.6439 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.7652 - acc: 0.7065 - val_loss: 0.7829 - val_acc: 0.6906 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.7073 - acc: 0.7292 - val_loss: 0.7767 - val_acc: 0.6964 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.6821 - acc: 0.7440 - val_loss: 0.7570 - val_acc: 0.7110 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6556 - acc: 0.7486 - val_loss: 0.7347 - val_acc: 0.7214 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6474 - acc: 0.7477 - val_loss: 0.7351 - val_acc: 0.7104 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6475 - acc: 0.7552 - val_loss: 0.7219 - val_acc: 0.7261 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6375 - acc: 0.7667 - val_loss: 0.7237 - val_acc: 0.7284 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6362 - acc: 0.7623 - val_loss: 0.7182 - val_acc: 0.7273 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6248 - acc: 0.7628 - val_loss: 0.7144 - val_acc: 0.7284 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6249 - acc: 0.7649 - val_loss: 0.7043 - val_acc: 0.7343 - lr: 0.0010\n",
            "Epoch 42/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6154 - acc: 0.7664 - val_loss: 0.7043 - val_acc: 0.7383 - lr: 0.0010\n",
            "Epoch 43/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.6068 - acc: 0.7761 - val_loss: 0.6983 - val_acc: 0.7378 - lr: 0.0010\n",
            "Epoch 44/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6232 - acc: 0.7688 - val_loss: 0.7171 - val_acc: 0.7360 - lr: 0.0010\n",
            "Epoch 45/70\n",
            "26/26 [==============================] - 3s 96ms/step - loss: 0.6160 - acc: 0.7694 - val_loss: 0.7085 - val_acc: 0.7302 - lr: 0.0010\n",
            "Epoch 46/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6171 - acc: 0.7691 - val_loss: 0.7178 - val_acc: 0.7331 - lr: 0.0010\n",
            "Epoch 47/70\n",
            "26/26 [==============================] - 3s 98ms/step - loss: 0.6068 - acc: 0.7700 - val_loss: 0.7115 - val_acc: 0.7284 - lr: 0.0010\n",
            "Epoch 48/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.6012 - acc: 0.7725 - val_loss: 0.7154 - val_acc: 0.7214 - lr: 0.0010\n",
            "Epoch 49/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6031 - acc: 0.7770 - val_loss: 0.6925 - val_acc: 0.7395 - lr: 0.0010\n",
            "Epoch 50/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5900 - acc: 0.7812 - val_loss: 0.6967 - val_acc: 0.7372 - lr: 0.0010\n",
            "Epoch 51/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.6018 - acc: 0.7776 - val_loss: 0.6980 - val_acc: 0.7319 - lr: 0.0010\n",
            "Epoch 52/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5958 - acc: 0.7719 - val_loss: 0.6998 - val_acc: 0.7418 - lr: 0.0010\n",
            "Epoch 53/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5921 - acc: 0.7825 - val_loss: 0.7017 - val_acc: 0.7407 - lr: 0.0010\n",
            "Epoch 54/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5882 - acc: 0.7870 - val_loss: 0.6887 - val_acc: 0.7407 - lr: 0.0010\n",
            "Epoch 55/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5826 - acc: 0.7858 - val_loss: 0.7080 - val_acc: 0.7372 - lr: 0.0010\n",
            "Epoch 56/70\n",
            "26/26 [==============================] - 3s 97ms/step - loss: 0.5861 - acc: 0.7831 - val_loss: 0.6938 - val_acc: 0.7372 - lr: 0.0010\n",
            "Epoch 57/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5767 - acc: 0.7897 - val_loss: 0.6889 - val_acc: 0.7366 - lr: 0.0010\n",
            "Epoch 58/70\n",
            "26/26 [==============================] - 2s 96ms/step - loss: 0.5834 - acc: 0.7891 - val_loss: 0.7090 - val_acc: 0.7343 - lr: 0.0010\n",
            "Epoch 59/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5760 - acc: 0.7879 - val_loss: 0.7008 - val_acc: 0.7465 - lr: 0.0010\n",
            "Epoch 60/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5796 - acc: 0.7888 - val_loss: 0.6915 - val_acc: 0.7453 - lr: 0.0010\n",
            "Epoch 61/70\n",
            "26/26 [==============================] - 2s 93ms/step - loss: 0.5770 - acc: 0.7876 - val_loss: 0.7005 - val_acc: 0.7325 - lr: 1.0000e-05\n",
            "Epoch 62/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5741 - acc: 0.7891 - val_loss: 0.6923 - val_acc: 0.7331 - lr: 1.0000e-05\n",
            "Epoch 63/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5845 - acc: 0.7840 - val_loss: 0.7042 - val_acc: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 64/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5687 - acc: 0.7888 - val_loss: 0.6997 - val_acc: 0.7325 - lr: 1.0000e-05\n",
            "Epoch 65/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5711 - acc: 0.7876 - val_loss: 0.6919 - val_acc: 0.7453 - lr: 1.0000e-05\n",
            "Epoch 66/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5813 - acc: 0.7846 - val_loss: 0.6964 - val_acc: 0.7319 - lr: 1.0000e-05\n",
            "Epoch 67/70\n",
            "26/26 [==============================] - 3s 98ms/step - loss: 0.5722 - acc: 0.7861 - val_loss: 0.6958 - val_acc: 0.7360 - lr: 1.0000e-05\n",
            "Epoch 68/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5650 - acc: 0.7921 - val_loss: 0.7019 - val_acc: 0.7389 - lr: 1.0000e-05\n",
            "Epoch 69/70\n",
            "26/26 [==============================] - 2s 95ms/step - loss: 0.5721 - acc: 0.7852 - val_loss: 0.6951 - val_acc: 0.7354 - lr: 1.0000e-05\n",
            "Epoch 70/70\n",
            "26/26 [==============================] - 2s 94ms/step - loss: 0.5730 - acc: 0.7764 - val_loss: 0.6830 - val_acc: 0.7407 - lr: 1.0000e-05\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6461 - acc: 0.7749\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6673 - acc: 0.7679\n",
            "epsilon: 0.003 and test evaluation : 0.6672896146774292, 0.7678883075714111\n",
            "SNR: 50.2353572845459\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6820 - acc: 0.7661\n",
            "epsilon: 0.005 and test evaluation : 0.6819977760314941, 0.7661430835723877\n",
            "SNR: 45.79806327819824\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.7210 - acc: 0.7487\n",
            "epsilon: 0.01 and test evaluation : 0.7210329174995422, 0.7486910820007324\n",
            "SNR: 39.777467250823975\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8080 - acc: 0.7016\n",
            "epsilon: 0.02 and test evaluation : 0.807954728603363, 0.7015706896781921\n",
            "SNR: 33.756866455078125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjkUsNKHq_L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_adv_df[\"acc_clean_mean\"]= np.sum(result_adv_df['acc_clean'])/3.0\n",
        "result_adv_df[\"acc_0.003_mean\"]= np.sum(result_adv_df['acc1'])/3.0\n",
        "result_adv_df[\"acc_0.005_mean\"]= np.sum(result_adv_df['acc2'])/3.0\n",
        "result_adv_df[\"acc_0.02_mean\"]= np.sum(result_adv_df['acc3'])/3.0\n",
        "result_adv_df[\"acc_0.01_mean\"]= np.sum(result_adv_df['acc4'])/3.0"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iYansuX0T5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "1bec8997-3e1e-47b6-eba1-09d03610954b"
      },
      "source": [
        "result_adv_df.head(1)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_clean</th>\n",
              "      <th>acc_clean</th>\n",
              "      <th>loss1</th>\n",
              "      <th>acc1</th>\n",
              "      <th>loss2</th>\n",
              "      <th>acc2</th>\n",
              "      <th>loss3</th>\n",
              "      <th>acc3</th>\n",
              "      <th>loss4</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc_clean_mean</th>\n",
              "      <th>acc_0.003_mean</th>\n",
              "      <th>acc_0.005_mean</th>\n",
              "      <th>acc_0.02_mean</th>\n",
              "      <th>acc_0.01_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.640599</td>\n",
              "      <td>0.767888</td>\n",
              "      <td>0.666</td>\n",
              "      <td>0.755672</td>\n",
              "      <td>0.683705</td>\n",
              "      <td>0.743455</td>\n",
              "      <td>0.730285</td>\n",
              "      <td>0.720768</td>\n",
              "      <td>0.833651</td>\n",
              "      <td>0.673647</td>\n",
              "      <td>0.760326</td>\n",
              "      <td>0.749855</td>\n",
              "      <td>0.742874</td>\n",
              "      <td>0.724258</td>\n",
              "      <td>0.679465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_clean  acc_clean  loss1  ...  acc_0.005_mean  acc_0.02_mean  acc_0.01_mean\n",
              "0    0.640599   0.767888  0.666  ...        0.742874       0.724258       0.679465\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}