{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ParsevalNetwork.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_idgCcuZdv0S",
        "colab_type": "text"
      },
      "source": [
        "# **Parseval Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO1kBOuDd2_r",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXS1STy_O_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nX1rD7_O_t",
        "colab_type": "code",
        "outputId": "478be04e-6ea2-45d7-f076-750f4eecf30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(row['crop'])\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmyV1MMm_O_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_data_X, Y_data, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRS393n_O_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoh02WT5wiLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx0sJsJDwiJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCu-tWhd_O_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# creating initial dataframe\n",
        "\n",
        "y_train_df = pd.DataFrame(y_train, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_train_df['New'] = labelencoder.fit_transform(y_train_df['Label'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_test_df['New'] = labelencoder.fit_transform(y_test_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ5CHhcF_PAA",
        "colab_type": "code",
        "outputId": "f058c847-7e44-4cc6-c06b-e19a4cb9f639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import backend as K\n",
        "img_rows, img_cols = X_train[0].shape\n",
        "\n",
        "\n",
        "# transform data set\n",
        "if K.common.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTmOEDcMtSQp",
        "colab_type": "text"
      },
      "source": [
        "# Othogonal Constraint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S2jnj2otWlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.constraints import Constraint\n",
        "from tensorflow.python.ops import math_ops, array_ops\n",
        "\n",
        "class TightFrame(Constraint):\n",
        "\n",
        "\n",
        "    def __init__(self, scale, num_passes=1):\n",
        "        self.scale = scale\n",
        "\n",
        "        if num_passes < 1:\n",
        "            raise ValueError(\"Number of passes cannot be non-positive! (got {})\".format(num_passes))\n",
        "        self.num_passes = num_passes\n",
        "\n",
        "\n",
        "    def __call__(self, w):\n",
        "        transpose_channels = (len(w.shape) == 4)\n",
        "\n",
        "        # Move channels_num to the front in order to make the dimensions correct for matmul\n",
        "        if transpose_channels:\n",
        "            w_reordered = array_ops.reshape(w, (-1, w.shape[0]))\n",
        "\n",
        "        else:\n",
        "            w_reordered = w\n",
        "\n",
        "        last = w_reordered\n",
        "        for i in range(self.num_passes):\n",
        "            temp1 = math_ops.matmul(last, last, transpose_a=True)\n",
        "            temp2 = (1 + self.scale) * w_reordered - self.scale * math_ops.matmul(w_reordered, temp1)\n",
        "\n",
        "            last = temp2\n",
        "\n",
        "        # Move channels_num to the back again\n",
        "        if transpose_channels:\n",
        "            return array_ops.reshape(last, w.shape)\n",
        "        else:\n",
        "            return last\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'scale': self.scale, 'num_passes': self.num_passes}\n",
        "\n",
        "\n",
        "# Alias\n",
        "tight_frame = TightFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4VciYzctsSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3g_vzsy_ndF",
        "colab_type": "text"
      },
      "source": [
        "**Parseval Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN76FYUZ_3YA",
        "colab_type": "code",
        "outputId": "82113577-8022-465d-f744-a8094c99f07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      \n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='Orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_parseval_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, activation='softmax' )(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (68, 100,1)\n",
        "\n",
        "    parseval_16_2 = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxyMKoeaBqPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.callbacks as callbacks\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiFrat1Bv1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200\n",
        "BS = 128\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygMFWH8Bzfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUvPL0dB48O",
        "colab_type": "code",
        "outputId": "0f930ff5-5d1b-41fd-caaf-d2a8ec4acd98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "parseval_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrJ7xy1Q5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4EpGTMG9jeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 60:\n",
        "        return 0.1\n",
        "    elif epoch < 120:\n",
        "        return 0.02\n",
        "    elif epoch < 160:\n",
        "        return 0.004\n",
        "    else:\n",
        "        return 0.0008\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bu78FGi9jhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0CbPY_24ns",
        "colab_type": "code",
        "outputId": "42f5471c-d29d-4507-9654-f31d72b0ff65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "hist = parseval_16_2.fit(generator.flow(X_train, to_categorical(y_train_df['New']), batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   validation_data=(X_test, to_categorical(y_test_df['New'])), callbacks = [lr_scheduler],\n",
        "                   validation_steps=X_test.shape[0] // BS,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "29/29 [==============================] - 13s 439ms/step - loss: 1.3324 - acc: 0.3406 - val_loss: 1.5744 - val_acc: 0.2912 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 1.2603 - acc: 0.3970 - val_loss: 1.2040 - val_acc: 0.4415 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 1.2331 - acc: 0.4227 - val_loss: 1.2220 - val_acc: 0.4352 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 10s 355ms/step - loss: 1.2114 - acc: 0.4459 - val_loss: 1.1742 - val_acc: 0.4600 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 1.1638 - acc: 0.4696 - val_loss: 1.7581 - val_acc: 0.3695 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 1.1504 - acc: 0.4947 - val_loss: 1.0782 - val_acc: 0.5437 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 1.0985 - acc: 0.5285 - val_loss: 1.1574 - val_acc: 0.4918 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 1.0676 - acc: 0.5371 - val_loss: 1.0265 - val_acc: 0.5717 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 1.0436 - acc: 0.5544 - val_loss: 1.1409 - val_acc: 0.4897 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 1.0136 - acc: 0.5795 - val_loss: 1.0308 - val_acc: 0.5447 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.9769 - acc: 0.5843 - val_loss: 0.9470 - val_acc: 0.6056 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 0.9341 - acc: 0.6076 - val_loss: 1.0009 - val_acc: 0.5574 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.9369 - acc: 0.6175 - val_loss: 0.9009 - val_acc: 0.6379 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.9045 - acc: 0.6399 - val_loss: 0.8367 - val_acc: 0.6480 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.8637 - acc: 0.6518 - val_loss: 0.8757 - val_acc: 0.6273 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.8377 - acc: 0.6621 - val_loss: 0.8083 - val_acc: 0.6760 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.8214 - acc: 0.6696 - val_loss: 1.4399 - val_acc: 0.4801 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.8004 - acc: 0.6845 - val_loss: 0.7953 - val_acc: 0.6961 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.7752 - acc: 0.6988 - val_loss: 0.8840 - val_acc: 0.6294 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.7815 - acc: 0.6948 - val_loss: 0.7902 - val_acc: 0.6866 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.7895 - acc: 0.6977 - val_loss: 0.8434 - val_acc: 0.6707 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.7663 - acc: 0.6972 - val_loss: 0.7412 - val_acc: 0.7136 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.7017 - acc: 0.7296 - val_loss: 0.7872 - val_acc: 0.6988 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 0.7037 - acc: 0.7220 - val_loss: 0.7042 - val_acc: 0.7152 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.7082 - acc: 0.7347 - val_loss: 0.6959 - val_acc: 0.7258 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.6808 - acc: 0.7457 - val_loss: 0.6793 - val_acc: 0.7417 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.6657 - acc: 0.7452 - val_loss: 0.6992 - val_acc: 0.7136 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.6415 - acc: 0.7568 - val_loss: 0.8023 - val_acc: 0.6792 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.6297 - acc: 0.7584 - val_loss: 0.7826 - val_acc: 0.7009 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.6502 - acc: 0.7503 - val_loss: 0.7492 - val_acc: 0.7094 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.5960 - acc: 0.7660 - val_loss: 0.6594 - val_acc: 0.7422 - lr: 0.1000\n",
            "Epoch 32/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.6134 - acc: 0.7649 - val_loss: 0.6690 - val_acc: 0.7406 - lr: 0.1000\n",
            "Epoch 33/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.5965 - acc: 0.7709 - val_loss: 0.6690 - val_acc: 0.7538 - lr: 0.1000\n",
            "Epoch 34/200\n",
            "29/29 [==============================] - 10s 362ms/step - loss: 0.5701 - acc: 0.7884 - val_loss: 0.7940 - val_acc: 0.7268 - lr: 0.1000\n",
            "Epoch 35/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.5882 - acc: 0.7730 - val_loss: 0.6516 - val_acc: 0.7332 - lr: 0.1000\n",
            "Epoch 36/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.5933 - acc: 0.7746 - val_loss: 0.6882 - val_acc: 0.7385 - lr: 0.1000\n",
            "Epoch 37/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.5797 - acc: 0.7754 - val_loss: 0.6981 - val_acc: 0.7411 - lr: 0.1000\n",
            "Epoch 38/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.5661 - acc: 0.7825 - val_loss: 0.6763 - val_acc: 0.7316 - lr: 0.1000\n",
            "Epoch 39/200\n",
            "29/29 [==============================] - 10s 362ms/step - loss: 0.5831 - acc: 0.7792 - val_loss: 0.7123 - val_acc: 0.7210 - lr: 0.1000\n",
            "Epoch 40/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.5424 - acc: 0.7919 - val_loss: 0.6956 - val_acc: 0.7348 - lr: 0.1000\n",
            "Epoch 41/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.5560 - acc: 0.7887 - val_loss: 0.6454 - val_acc: 0.7687 - lr: 0.1000\n",
            "Epoch 42/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.5313 - acc: 0.7962 - val_loss: 0.6968 - val_acc: 0.7369 - lr: 0.1000\n",
            "Epoch 43/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.4892 - acc: 0.8148 - val_loss: 0.6926 - val_acc: 0.7480 - lr: 0.1000\n",
            "Epoch 44/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.4993 - acc: 0.8054 - val_loss: 0.6526 - val_acc: 0.7618 - lr: 0.1000\n",
            "Epoch 45/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.4859 - acc: 0.8178 - val_loss: 0.6126 - val_acc: 0.7798 - lr: 0.1000\n",
            "Epoch 46/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.4773 - acc: 0.8178 - val_loss: 0.8067 - val_acc: 0.7046 - lr: 0.1000\n",
            "Epoch 47/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.4998 - acc: 0.8062 - val_loss: 0.6228 - val_acc: 0.7655 - lr: 0.1000\n",
            "Epoch 48/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.4717 - acc: 0.8229 - val_loss: 0.7327 - val_acc: 0.7279 - lr: 0.1000\n",
            "Epoch 49/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.4249 - acc: 0.8421 - val_loss: 0.6234 - val_acc: 0.7597 - lr: 0.1000\n",
            "Epoch 50/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.5001 - acc: 0.8130 - val_loss: 0.7620 - val_acc: 0.7274 - lr: 0.1000\n",
            "Epoch 51/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.4782 - acc: 0.8232 - val_loss: 0.7771 - val_acc: 0.7051 - lr: 0.1000\n",
            "Epoch 52/200\n",
            "29/29 [==============================] - 10s 362ms/step - loss: 0.4516 - acc: 0.8354 - val_loss: 0.6143 - val_acc: 0.7782 - lr: 0.1000\n",
            "Epoch 53/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.4200 - acc: 0.8383 - val_loss: 0.6894 - val_acc: 0.7417 - lr: 0.1000\n",
            "Epoch 54/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.4587 - acc: 0.8259 - val_loss: 0.9533 - val_acc: 0.6728 - lr: 0.1000\n",
            "Epoch 55/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.4314 - acc: 0.8372 - val_loss: 0.6129 - val_acc: 0.7808 - lr: 0.1000\n",
            "Epoch 56/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.3880 - acc: 0.8513 - val_loss: 0.6628 - val_acc: 0.7644 - lr: 0.1000\n",
            "Epoch 57/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.4610 - acc: 0.8283 - val_loss: 0.6351 - val_acc: 0.7639 - lr: 0.1000\n",
            "Epoch 58/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.4330 - acc: 0.8356 - val_loss: 0.7078 - val_acc: 0.7639 - lr: 0.1000\n",
            "Epoch 59/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.4655 - acc: 0.8281 - val_loss: 0.6827 - val_acc: 0.7702 - lr: 0.1000\n",
            "Epoch 60/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.4642 - acc: 0.8246 - val_loss: 0.8682 - val_acc: 0.7221 - lr: 0.1000\n",
            "Epoch 61/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.4559 - acc: 0.8316 - val_loss: 0.6539 - val_acc: 0.7697 - lr: 0.0200\n",
            "Epoch 62/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.3197 - acc: 0.8883 - val_loss: 0.5819 - val_acc: 0.7978 - lr: 0.0200\n",
            "Epoch 63/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.2760 - acc: 0.9053 - val_loss: 0.5477 - val_acc: 0.8110 - lr: 0.0200\n",
            "Epoch 64/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.2553 - acc: 0.9074 - val_loss: 0.5678 - val_acc: 0.8068 - lr: 0.0200\n",
            "Epoch 65/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.2424 - acc: 0.9136 - val_loss: 0.5747 - val_acc: 0.8158 - lr: 0.0200\n",
            "Epoch 66/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.2305 - acc: 0.9209 - val_loss: 0.5867 - val_acc: 0.8036 - lr: 0.0200\n",
            "Epoch 67/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.2176 - acc: 0.9250 - val_loss: 0.5911 - val_acc: 0.8084 - lr: 0.0200\n",
            "Epoch 68/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.2047 - acc: 0.9325 - val_loss: 0.6209 - val_acc: 0.8036 - lr: 0.0200\n",
            "Epoch 69/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.2074 - acc: 0.9220 - val_loss: 0.6145 - val_acc: 0.7994 - lr: 0.0200\n",
            "Epoch 70/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1941 - acc: 0.9304 - val_loss: 0.6214 - val_acc: 0.8015 - lr: 0.0200\n",
            "Epoch 71/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1897 - acc: 0.9336 - val_loss: 0.6175 - val_acc: 0.8068 - lr: 0.0200\n",
            "Epoch 72/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.2047 - acc: 0.9244 - val_loss: 0.7129 - val_acc: 0.7856 - lr: 0.0200\n",
            "Epoch 73/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1943 - acc: 0.9309 - val_loss: 0.6648 - val_acc: 0.7920 - lr: 0.0200\n",
            "Epoch 74/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1941 - acc: 0.9336 - val_loss: 0.7339 - val_acc: 0.7808 - lr: 0.0200\n",
            "Epoch 75/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1830 - acc: 0.9341 - val_loss: 0.6603 - val_acc: 0.8068 - lr: 0.0200\n",
            "Epoch 76/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.1942 - acc: 0.9252 - val_loss: 0.6719 - val_acc: 0.7909 - lr: 0.0200\n",
            "Epoch 77/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.2034 - acc: 0.9317 - val_loss: 0.6814 - val_acc: 0.8025 - lr: 0.0200\n",
            "Epoch 78/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1822 - acc: 0.9339 - val_loss: 0.6996 - val_acc: 0.7920 - lr: 0.0200\n",
            "Epoch 79/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1798 - acc: 0.9350 - val_loss: 0.7089 - val_acc: 0.7925 - lr: 0.0200\n",
            "Epoch 80/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1886 - acc: 0.9341 - val_loss: 0.7503 - val_acc: 0.8010 - lr: 0.0200\n",
            "Epoch 81/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.2012 - acc: 0.9274 - val_loss: 0.6484 - val_acc: 0.7994 - lr: 0.0200\n",
            "Epoch 82/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.1943 - acc: 0.9350 - val_loss: 0.7239 - val_acc: 0.7967 - lr: 0.0200\n",
            "Epoch 83/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1869 - acc: 0.9336 - val_loss: 0.7276 - val_acc: 0.7803 - lr: 0.0200\n",
            "Epoch 84/200\n",
            "29/29 [==============================] - 10s 362ms/step - loss: 0.1679 - acc: 0.9404 - val_loss: 0.7879 - val_acc: 0.7803 - lr: 0.0200\n",
            "Epoch 85/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1825 - acc: 0.9328 - val_loss: 0.7009 - val_acc: 0.7845 - lr: 0.0200\n",
            "Epoch 86/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1609 - acc: 0.9449 - val_loss: 0.7435 - val_acc: 0.7920 - lr: 0.0200\n",
            "Epoch 87/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.1836 - acc: 0.9324 - val_loss: 0.7250 - val_acc: 0.7962 - lr: 0.0200\n",
            "Epoch 88/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1663 - acc: 0.9409 - val_loss: 0.7411 - val_acc: 0.7957 - lr: 0.0200\n",
            "Epoch 89/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.1742 - acc: 0.9387 - val_loss: 0.6640 - val_acc: 0.8020 - lr: 0.0200\n",
            "Epoch 90/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1802 - acc: 0.9341 - val_loss: 0.7030 - val_acc: 0.8089 - lr: 0.0200\n",
            "Epoch 91/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1725 - acc: 0.9344 - val_loss: 0.7201 - val_acc: 0.8015 - lr: 0.0200\n",
            "Epoch 92/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1780 - acc: 0.9379 - val_loss: 0.6941 - val_acc: 0.7951 - lr: 0.0200\n",
            "Epoch 93/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1661 - acc: 0.9355 - val_loss: 0.7333 - val_acc: 0.8062 - lr: 0.0200\n",
            "Epoch 94/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1912 - acc: 0.9306 - val_loss: 0.7276 - val_acc: 0.7967 - lr: 0.0200\n",
            "Epoch 95/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.2184 - acc: 0.9271 - val_loss: 0.6539 - val_acc: 0.8036 - lr: 0.0200\n",
            "Epoch 96/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1943 - acc: 0.9282 - val_loss: 0.7272 - val_acc: 0.7898 - lr: 0.0200\n",
            "Epoch 97/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1717 - acc: 0.9417 - val_loss: 0.7024 - val_acc: 0.8068 - lr: 0.0200\n",
            "Epoch 98/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1688 - acc: 0.9395 - val_loss: 0.7045 - val_acc: 0.8089 - lr: 0.0200\n",
            "Epoch 99/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.1883 - acc: 0.9312 - val_loss: 0.7551 - val_acc: 0.7898 - lr: 0.0200\n",
            "Epoch 100/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1606 - acc: 0.9417 - val_loss: 0.7568 - val_acc: 0.8020 - lr: 0.0200\n",
            "Epoch 101/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1608 - acc: 0.9409 - val_loss: 0.9273 - val_acc: 0.7750 - lr: 0.0200\n",
            "Epoch 102/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1608 - acc: 0.9420 - val_loss: 0.7822 - val_acc: 0.7962 - lr: 0.0200\n",
            "Epoch 103/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 0.1486 - acc: 0.9484 - val_loss: 0.7197 - val_acc: 0.8073 - lr: 0.0200\n",
            "Epoch 104/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1464 - acc: 0.9474 - val_loss: 0.6687 - val_acc: 0.8131 - lr: 0.0200\n",
            "Epoch 105/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1304 - acc: 0.9544 - val_loss: 0.7678 - val_acc: 0.7840 - lr: 0.0200\n",
            "Epoch 106/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1673 - acc: 0.9401 - val_loss: 0.7391 - val_acc: 0.8057 - lr: 0.0200\n",
            "Epoch 107/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1906 - acc: 0.9293 - val_loss: 0.7637 - val_acc: 0.7941 - lr: 0.0200\n",
            "Epoch 108/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1788 - acc: 0.9328 - val_loss: 0.7879 - val_acc: 0.7782 - lr: 0.0200\n",
            "Epoch 109/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1792 - acc: 0.9382 - val_loss: 0.7249 - val_acc: 0.8078 - lr: 0.0200\n",
            "Epoch 110/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1624 - acc: 0.9422 - val_loss: 0.6909 - val_acc: 0.8004 - lr: 0.0200\n",
            "Epoch 111/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1614 - acc: 0.9412 - val_loss: 0.8695 - val_acc: 0.7904 - lr: 0.0200\n",
            "Epoch 112/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1773 - acc: 0.9360 - val_loss: 0.6845 - val_acc: 0.7967 - lr: 0.0200\n",
            "Epoch 113/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1549 - acc: 0.9449 - val_loss: 0.7044 - val_acc: 0.8020 - lr: 0.0200\n",
            "Epoch 114/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.1532 - acc: 0.9422 - val_loss: 0.7008 - val_acc: 0.8068 - lr: 0.0200\n",
            "Epoch 115/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1650 - acc: 0.9390 - val_loss: 0.7839 - val_acc: 0.7803 - lr: 0.0200\n",
            "Epoch 116/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.1652 - acc: 0.9428 - val_loss: 0.8144 - val_acc: 0.7935 - lr: 0.0200\n",
            "Epoch 117/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1673 - acc: 0.9398 - val_loss: 0.7476 - val_acc: 0.8052 - lr: 0.0200\n",
            "Epoch 118/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1667 - acc: 0.9430 - val_loss: 0.8439 - val_acc: 0.7777 - lr: 0.0200\n",
            "Epoch 119/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1643 - acc: 0.9374 - val_loss: 0.7310 - val_acc: 0.8115 - lr: 0.0200\n",
            "Epoch 120/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.1535 - acc: 0.9463 - val_loss: 0.7630 - val_acc: 0.7951 - lr: 0.0200\n",
            "Epoch 121/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.1889 - acc: 0.9344 - val_loss: 0.7605 - val_acc: 0.7946 - lr: 0.0040\n",
            "Epoch 122/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0964 - acc: 0.9668 - val_loss: 0.6874 - val_acc: 0.8184 - lr: 0.0040\n",
            "Epoch 123/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0655 - acc: 0.9816 - val_loss: 0.6650 - val_acc: 0.8158 - lr: 0.0040\n",
            "Epoch 124/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0590 - acc: 0.9841 - val_loss: 0.6895 - val_acc: 0.8205 - lr: 0.0040\n",
            "Epoch 125/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0520 - acc: 0.9846 - val_loss: 0.6899 - val_acc: 0.8216 - lr: 0.0040\n",
            "Epoch 126/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0465 - acc: 0.9870 - val_loss: 0.6710 - val_acc: 0.8200 - lr: 0.0040\n",
            "Epoch 127/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0407 - acc: 0.9908 - val_loss: 0.7022 - val_acc: 0.8248 - lr: 0.0040\n",
            "Epoch 128/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0363 - acc: 0.9911 - val_loss: 0.6995 - val_acc: 0.8221 - lr: 0.0040\n",
            "Epoch 129/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0358 - acc: 0.9933 - val_loss: 0.8092 - val_acc: 0.8062 - lr: 0.0040\n",
            "Epoch 130/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0324 - acc: 0.9933 - val_loss: 0.7249 - val_acc: 0.8317 - lr: 0.0040\n",
            "Epoch 131/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0331 - acc: 0.9916 - val_loss: 0.7318 - val_acc: 0.8264 - lr: 0.0040\n",
            "Epoch 132/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0335 - acc: 0.9906 - val_loss: 0.7273 - val_acc: 0.8317 - lr: 0.0040\n",
            "Epoch 133/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 0.0349 - acc: 0.9908 - val_loss: 0.7494 - val_acc: 0.8322 - lr: 0.0040\n",
            "Epoch 134/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0275 - acc: 0.9938 - val_loss: 0.7651 - val_acc: 0.8242 - lr: 0.0040\n",
            "Epoch 135/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0287 - acc: 0.9933 - val_loss: 0.7321 - val_acc: 0.8274 - lr: 0.0040\n",
            "Epoch 136/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0294 - acc: 0.9930 - val_loss: 0.7766 - val_acc: 0.8232 - lr: 0.0040\n",
            "Epoch 137/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0292 - acc: 0.9903 - val_loss: 0.7437 - val_acc: 0.8253 - lr: 0.0040\n",
            "Epoch 138/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0291 - acc: 0.9938 - val_loss: 0.7355 - val_acc: 0.8264 - lr: 0.0040\n",
            "Epoch 139/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0305 - acc: 0.9919 - val_loss: 0.7950 - val_acc: 0.8184 - lr: 0.0040\n",
            "Epoch 140/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0234 - acc: 0.9951 - val_loss: 0.7897 - val_acc: 0.8211 - lr: 0.0040\n",
            "Epoch 141/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0258 - acc: 0.9941 - val_loss: 0.7639 - val_acc: 0.8237 - lr: 0.0040\n",
            "Epoch 142/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0228 - acc: 0.9954 - val_loss: 0.8271 - val_acc: 0.8205 - lr: 0.0040\n",
            "Epoch 143/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0255 - acc: 0.9935 - val_loss: 0.7748 - val_acc: 0.8237 - lr: 0.0040\n",
            "Epoch 144/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0265 - acc: 0.9924 - val_loss: 0.7941 - val_acc: 0.8190 - lr: 0.0040\n",
            "Epoch 145/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0238 - acc: 0.9960 - val_loss: 0.7763 - val_acc: 0.8221 - lr: 0.0040\n",
            "Epoch 146/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 0.0259 - acc: 0.9930 - val_loss: 0.8059 - val_acc: 0.8242 - lr: 0.0040\n",
            "Epoch 147/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0237 - acc: 0.9954 - val_loss: 0.8102 - val_acc: 0.8370 - lr: 0.0040\n",
            "Epoch 148/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0242 - acc: 0.9930 - val_loss: 0.7981 - val_acc: 0.8301 - lr: 0.0040\n",
            "Epoch 149/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0226 - acc: 0.9949 - val_loss: 0.7743 - val_acc: 0.8253 - lr: 0.0040\n",
            "Epoch 150/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0222 - acc: 0.9941 - val_loss: 0.8395 - val_acc: 0.8227 - lr: 0.0040\n",
            "Epoch 151/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0194 - acc: 0.9962 - val_loss: 0.8121 - val_acc: 0.8242 - lr: 0.0040\n",
            "Epoch 152/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 0.0208 - acc: 0.9957 - val_loss: 0.8114 - val_acc: 0.8227 - lr: 0.0040\n",
            "Epoch 153/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0213 - acc: 0.9949 - val_loss: 0.8516 - val_acc: 0.8227 - lr: 0.0040\n",
            "Epoch 154/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0197 - acc: 0.9954 - val_loss: 0.7740 - val_acc: 0.8242 - lr: 0.0040\n",
            "Epoch 155/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0201 - acc: 0.9946 - val_loss: 0.8355 - val_acc: 0.8295 - lr: 0.0040\n",
            "Epoch 156/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0199 - acc: 0.9954 - val_loss: 0.8400 - val_acc: 0.8168 - lr: 0.0040\n",
            "Epoch 157/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.8046 - val_acc: 0.8264 - lr: 0.0040\n",
            "Epoch 158/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0200 - acc: 0.9951 - val_loss: 0.7909 - val_acc: 0.8258 - lr: 0.0040\n",
            "Epoch 159/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0199 - acc: 0.9960 - val_loss: 0.8270 - val_acc: 0.8258 - lr: 0.0040\n",
            "Epoch 160/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0203 - acc: 0.9951 - val_loss: 0.8014 - val_acc: 0.8253 - lr: 0.0040\n",
            "Epoch 161/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0201 - acc: 0.9941 - val_loss: 0.7917 - val_acc: 0.8301 - lr: 8.0000e-04\n",
            "Epoch 162/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0194 - acc: 0.9954 - val_loss: 0.7968 - val_acc: 0.8258 - lr: 8.0000e-04\n",
            "Epoch 163/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0186 - acc: 0.9954 - val_loss: 0.7885 - val_acc: 0.8253 - lr: 8.0000e-04\n",
            "Epoch 164/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0132 - acc: 0.9973 - val_loss: 0.7790 - val_acc: 0.8269 - lr: 8.0000e-04\n",
            "Epoch 165/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0115 - acc: 0.9976 - val_loss: 0.7967 - val_acc: 0.8237 - lr: 8.0000e-04\n",
            "Epoch 166/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0131 - acc: 0.9976 - val_loss: 0.8024 - val_acc: 0.8290 - lr: 8.0000e-04\n",
            "Epoch 167/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.7742 - val_acc: 0.8327 - lr: 8.0000e-04\n",
            "Epoch 168/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0129 - acc: 0.9978 - val_loss: 0.8003 - val_acc: 0.8280 - lr: 8.0000e-04\n",
            "Epoch 169/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0129 - acc: 0.9976 - val_loss: 0.8031 - val_acc: 0.8322 - lr: 8.0000e-04\n",
            "Epoch 170/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0108 - acc: 0.9984 - val_loss: 0.7923 - val_acc: 0.8301 - lr: 8.0000e-04\n",
            "Epoch 171/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0105 - acc: 0.9992 - val_loss: 0.7841 - val_acc: 0.8322 - lr: 8.0000e-04\n",
            "Epoch 172/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0135 - acc: 0.9965 - val_loss: 0.8261 - val_acc: 0.8285 - lr: 8.0000e-04\n",
            "Epoch 173/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.7986 - val_acc: 0.8306 - lr: 8.0000e-04\n",
            "Epoch 174/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0096 - acc: 0.9989 - val_loss: 0.8016 - val_acc: 0.8311 - lr: 8.0000e-04\n",
            "Epoch 175/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0115 - acc: 0.9973 - val_loss: 0.8023 - val_acc: 0.8327 - lr: 8.0000e-04\n",
            "Epoch 176/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0099 - acc: 0.9992 - val_loss: 0.8020 - val_acc: 0.8332 - lr: 8.0000e-04\n",
            "Epoch 177/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0118 - acc: 0.9981 - val_loss: 0.8305 - val_acc: 0.8290 - lr: 8.0000e-04\n",
            "Epoch 178/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0117 - acc: 0.9984 - val_loss: 0.8221 - val_acc: 0.8301 - lr: 8.0000e-04\n",
            "Epoch 179/200\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 0.0085 - acc: 0.9995 - val_loss: 0.8094 - val_acc: 0.8306 - lr: 8.0000e-04\n",
            "Epoch 180/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0098 - acc: 0.9984 - val_loss: 0.8158 - val_acc: 0.8301 - lr: 8.0000e-04\n",
            "Epoch 181/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0092 - acc: 0.9987 - val_loss: 0.8286 - val_acc: 0.8242 - lr: 8.0000e-04\n",
            "Epoch 182/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0100 - acc: 0.9984 - val_loss: 0.8002 - val_acc: 0.8301 - lr: 8.0000e-04\n",
            "Epoch 183/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0098 - acc: 0.9984 - val_loss: 0.7900 - val_acc: 0.8338 - lr: 8.0000e-04\n",
            "Epoch 184/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0102 - acc: 0.9989 - val_loss: 0.8082 - val_acc: 0.8327 - lr: 8.0000e-04\n",
            "Epoch 185/200\n",
            "29/29 [==============================] - 10s 361ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.8075 - val_acc: 0.8285 - lr: 8.0000e-04\n",
            "Epoch 186/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0096 - acc: 0.9989 - val_loss: 0.7993 - val_acc: 0.8274 - lr: 8.0000e-04\n",
            "Epoch 187/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0087 - acc: 0.9987 - val_loss: 0.8020 - val_acc: 0.8317 - lr: 8.0000e-04\n",
            "Epoch 188/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0095 - acc: 0.9987 - val_loss: 0.8023 - val_acc: 0.8322 - lr: 8.0000e-04\n",
            "Epoch 189/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0097 - acc: 0.9981 - val_loss: 0.8288 - val_acc: 0.8290 - lr: 8.0000e-04\n",
            "Epoch 190/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0086 - acc: 0.9992 - val_loss: 0.8070 - val_acc: 0.8317 - lr: 8.0000e-04\n",
            "Epoch 191/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0102 - acc: 0.9976 - val_loss: 0.8206 - val_acc: 0.8322 - lr: 8.0000e-04\n",
            "Epoch 192/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.8279 - val_acc: 0.8290 - lr: 8.0000e-04\n",
            "Epoch 193/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0080 - acc: 0.9984 - val_loss: 0.8125 - val_acc: 0.8317 - lr: 8.0000e-04\n",
            "Epoch 194/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0102 - acc: 0.9987 - val_loss: 0.8327 - val_acc: 0.8295 - lr: 8.0000e-04\n",
            "Epoch 195/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0117 - acc: 0.9987 - val_loss: 0.8229 - val_acc: 0.8295 - lr: 8.0000e-04\n",
            "Epoch 196/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0086 - acc: 0.9989 - val_loss: 0.8146 - val_acc: 0.8317 - lr: 8.0000e-04\n",
            "Epoch 197/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0087 - acc: 0.9992 - val_loss: 0.8411 - val_acc: 0.8264 - lr: 8.0000e-04\n",
            "Epoch 198/200\n",
            "29/29 [==============================] - 10s 359ms/step - loss: 0.0077 - acc: 0.9992 - val_loss: 0.8319 - val_acc: 0.8269 - lr: 8.0000e-04\n",
            "Epoch 199/200\n",
            "29/29 [==============================] - 10s 360ms/step - loss: 0.0071 - acc: 0.9997 - val_loss: 0.8260 - val_acc: 0.8280 - lr: 8.0000e-04\n",
            "Epoch 200/200\n",
            "29/29 [==============================] - 10s 358ms/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.8171 - val_acc: 0.8317 - lr: 8.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-QerZ4RN91R",
        "colab_type": "code",
        "outputId": "8260a6e9-736d-46cd-bad2-3d53e4872f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc55b5cd518>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeg6MBf-GSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_err = [1.0-x for x in hist.history['val_acc']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgiKT6i5GiJ9",
        "colab_type": "code",
        "outputId": "090feebf-b0e1-4a8a-cf74-45d50afc802b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "pyplot.plot(test_err, label='test')\n",
        "pyplot.savefig(\"deneme_err.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IJ9Z-dQKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "parseval_16_2.save(\"parseval_tensor_lst.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqddlwbmEV9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = parseval_16_2.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ysop6NFDbs",
        "colab_type": "code",
        "outputId": "0343737d-7d1d-468d-8531-fe503a38d5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "parseval_16_2.evaluate(X_test,to_categorical(y_test_df['New']),batch_size=128,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 - 1s - loss: 0.8171 - acc: 0.8317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.817147433757782, 0.8316569328308105]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THYCAlBW15Kg",
        "colab_type": "code",
        "outputId": "c947688e-b185-4a4f-f4a4-d0c4f889e127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 35kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 52.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 56.3MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-nh_dsdoh/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-nh_dsdoh/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 31.1MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.4)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=708b7304ac7a6e28e4ef9ea44126f4a715f8f96b8ee650c8814df301078e521a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jif2zqq_/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-23-67a2c783edbc>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNev4Y9U2sFQ",
        "colab_type": "code",
        "outputId": "c87f32ea-ddb6-4e79-e7e5-4f90c61f1501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(wrn_28_10.input,wrn_28_10.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4733b5d5dfed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#The attack requires the model to ouput the logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogits_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrn_28_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrn_28_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'wrn_28_10' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtKEw7Uq3Dj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_index = 5\n",
        "\n",
        "original_image = X_test[random_index]\n",
        "original_image = tf.convert_to_tensor(original_image.reshape((1,68,100))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdxYTfSn3R4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSa4WKy33U3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_28_10(original_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jrP3jw83fwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_cat = to_categorical(y_test_df['New'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VoJsNJX4HiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_label = y_test_cat[random_index]\n",
        "original_label "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70kNexu3l-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon = 0.33\n",
        "\n",
        "\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "adv_example_untargeted_label_pred = wrn_28_10.predict(adv_example_untargeted_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-LglBmM4gNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adv_example_untargeted_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d6rZhTp4i2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(adv_example_untargeted_label_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKCXvIXY66lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image = tf.reshape(adv_example_untargeted_label, (68,100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0jgK_uG7cwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70uI8BLT7r5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "X = np.random.random((100, 100)) # sample 2D array\n",
        "plt.imshow(original_image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SumJnhN98Y0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_cat[random_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woaZe08I8kM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test[random_index]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}